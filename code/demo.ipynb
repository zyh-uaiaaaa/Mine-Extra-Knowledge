{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a0d4837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:0.9270. \n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "from backbones import get_model\n",
    "from expression import *\n",
    "from expression.datasets import RAFDBDataset\n",
    "from utils.utils_config import get_config\n",
    "from expression.models import SwinTransFER\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "\n",
    "total_predicts = []\n",
    "total_logits = []\n",
    "swin = get_model('swin_t')\n",
    "net = SwinTransFER(swin=swin, swin_num_features=768, num_classes=7, cam=True)\n",
    "\n",
    "dict_checkpoint = torch.load('results/checkpoint_step_59999_gpu_0.pt')\n",
    "net.load_state_dict(dict_checkpoint[\"state_dict_model\"])\n",
    "\n",
    "\n",
    "dataset_val = RAFDBDataset(choose=\"test\",\n",
    "                           data_path=\"dataset/RAF\",\n",
    "                         label_path=\"dataset/list_patition_label.txt\",\n",
    "                         img_size=112)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_val, batch_size=128,\n",
    "                shuffle=False, num_workers=2, pin_memory=True, drop_last=False)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    net.cuda()\n",
    "    net.eval()\n",
    "    \n",
    "    bingo_cnt = 0\n",
    "    sample_cnt = 0\n",
    "    for idx, (images, target, _) in enumerate(test_loader):\n",
    "        img = images.cuda(non_blocking=True)\n",
    "        target = target.cuda(non_blocking=True)\n",
    "\n",
    "        outputs, _ = net(img)\n",
    "\n",
    "        _, predicts = torch.max(outputs, 1)\n",
    "        total_predicts.append(predicts.cpu().numpy())\n",
    "        total_logits.append(outputs.cpu().numpy())\n",
    "        \n",
    "        correct_num = torch.eq(predicts, target)\n",
    "        bingo_cnt += correct_num.sum().cpu()\n",
    "        sample_cnt += outputs.size(0)\n",
    "        \n",
    "    acc = bingo_cnt.float() / float(sample_cnt)\n",
    "    acc = np.around(acc.numpy(), 4)\n",
    "    print(\"Validation accuracy:%.4f. \" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e25ec72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9270516717325228\n",
      "0.7432432432432432\n",
      "0.85625\n",
      "0.9687763713080169\n",
      "0.899581589958159\n",
      "0.8641975308641975\n",
      "0.925\n",
      "0.883442915300877 mean\n"
     ]
    }
   ],
   "source": [
    "new_total_predicts = np.concatenate(total_predicts)\n",
    "total_labels = test_loader.dataset.labels\n",
    "\n",
    "mean_acc = 0\n",
    "for j in range(7):\n",
    "    class_num = j\n",
    "    class_idx = []\n",
    "    for i in range(len(total_labels)):\n",
    "        if total_labels[i] == class_num:\n",
    "            class_idx.append(i)\n",
    "    tempt = (new_total_predicts[np.array(class_idx)]==total_labels[np.array(class_idx)]).sum()/len(class_idx)\n",
    "    mean_acc += tempt\n",
    "    print(tempt)\n",
    "print(mean_acc/7, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01484cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
