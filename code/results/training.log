Training: 2023-08-17 21:02:38,665-rank_id: 0
Training: 2023-08-17 21:02:52,721-: network                  swin_t
Training: 2023-08-17 21:02:52,721-: resume                   False
Training: 2023-08-17 21:02:52,721-: resume_step              0
Training: 2023-08-17 21:02:52,721-: init                     True
Training: 2023-08-17 21:02:52,721-: init_model               ./
Training: 2023-08-17 21:02:52,721-: save_all_states          True
Training: 2023-08-17 21:02:52,721-: output                   ./results
Training: 2023-08-17 21:02:52,721-: img_size                 112
Training: 2023-08-17 21:02:52,722-: embedding_size           512
Training: 2023-08-17 21:02:52,722-: fp16                     True
Training: 2023-08-17 21:02:52,722-: optimizer                adamw
Training: 2023-08-17 21:02:52,722-: lr                       3.125e-05
Training: 2023-08-17 21:02:52,722-: weight_decay             0.05
Training: 2023-08-17 21:02:52,722-: lr_name                  cosine
Training: 2023-08-17 21:02:52,722-: warmup_lr                3.125e-08
Training: 2023-08-17 21:02:52,722-: min_lr                   3.125e-07
Training: 2023-08-17 21:02:52,722-: decay_epoch              10
Training: 2023-08-17 21:02:52,722-: decay_rate               0.1
Training: 2023-08-17 21:02:52,722-: verbose                  1000
Training: 2023-08-17 21:02:52,722-: save_verbose             6000
Training: 2023-08-17 21:02:52,722-: frequent                 10
Training: 2023-08-17 21:02:52,722-: dali                     False
Training: 2023-08-17 21:02:52,722-: seed                     2048
Training: 2023-08-17 21:02:52,722-: num_workers              0
Training: 2023-08-17 21:02:52,722-: warmup_step              2000
Training: 2023-08-17 21:02:52,722-: total_step               60000
Training: 2023-08-17 21:02:52,722-: expression_train_dataset RAF-DB
Training: 2023-08-17 21:02:52,722-: expression_val_dataset   RAF-DB
Training: 2023-08-17 21:02:52,722-: RAF_data                 dataset/RAF
Training: 2023-08-17 21:02:52,722-: RAF_label                dataset/list_patition_label.txt
Training: 2023-08-17 21:02:52,722-: standard_train_sample_num1000000
Training: 2023-08-17 21:02:52,722-: INTERPOLATION            bicubic
Training: 2023-08-17 21:02:52,722-: RAF_NUM_CLASSES          7
Training: 2023-08-17 21:02:52,722-: RAF_LABEL_SMOOTHING      0.1
Training: 2023-08-17 21:02:52,722-: AUG_COLOR_JITTER         0.4
Training: 2023-08-17 21:02:52,722-: AUG_AUTO_AUGMENT         rand-m9-mstd0.5-inc1
Training: 2023-08-17 21:02:52,723-: AUG_REPROB               0.25
Training: 2023-08-17 21:02:52,723-: AUG_REMODE               pixel
Training: 2023-08-17 21:02:52,723-: AUG_RECOUNT              1
Training: 2023-08-17 21:02:52,723-: AUG_MIXUP                0.0
Training: 2023-08-17 21:02:52,723-: AUG_CUTMIX               0.0
Training: 2023-08-17 21:02:52,723-: AUG_CUTMIX_MINMAX        None
Training: 2023-08-17 21:02:52,723-: AUG_MIXUP_PROB           1.0
Training: 2023-08-17 21:02:52,723-: AUG_MIXUP_SWITCH_PROB    0.5
Training: 2023-08-17 21:02:52,723-: AUG_MIXUP_MODE           batch
Training: 2023-08-17 21:02:52,723-: AUG_SCALE_SET            True
Training: 2023-08-17 21:02:52,723-: AUG_SCALE_SCALE          [1.0, 1.0]
Training: 2023-08-17 21:02:52,723-: AUG_SCALE_RATIO          [1.0, 1.0]
Training: 2023-08-17 21:02:52,723-: batch_size               32
Training: 2023-08-17 21:02:52,723-: train_num_workers        2
Training: 2023-08-17 21:02:52,723-: train_pin_memory         True
Training: 2023-08-17 21:02:52,723-: val_batch_size           64
Training: 2023-08-17 21:02:52,723-: val_num_workers          0
Training: 2023-08-17 21:02:52,723-: val_pin_memory           True
Training: 2023-08-17 21:02:52,723-: total_batch_size         32
Training: 2023-08-17 21:02:52,723-: epoch_step               31250
Training: 2023-08-17 21:02:52,723-: num_epoch                2
Training: 2023-08-17 21:02:59,143-Speed 144.59 samples/sec   Loss 2.1932   LearningRate 0.000000   Epoch: 0   Global Step: 20   Fp16 Grad Scale: 65536   Required: 5 hours
Training: 2023-08-17 21:03:01,368-Speed 143.88 samples/sec   Loss 2.1810   LearningRate 0.000000   Epoch: 0   Global Step: 30   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:03:03,587-Speed 144.18 samples/sec   Loss 2.1624   LearningRate 0.000001   Epoch: 0   Global Step: 40   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:03:05,811-Speed 143.98 samples/sec   Loss 2.1518   LearningRate 0.000001   Epoch: 0   Global Step: 50   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:03:08,030-Speed 144.24 samples/sec   Loss 2.1853   LearningRate 0.000001   Epoch: 0   Global Step: 60   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:03:10,261-Speed 143.45 samples/sec   Loss 2.1369   LearningRate 0.000001   Epoch: 0   Global Step: 70   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:03:12,513-Speed 142.18 samples/sec   Loss 2.0950   LearningRate 0.000001   Epoch: 0   Global Step: 80   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:03:14,753-Speed 142.90 samples/sec   Loss 2.1303   LearningRate 0.000001   Epoch: 0   Global Step: 90   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:03:16,963-Speed 144.81 samples/sec   Loss 2.0898   LearningRate 0.000002   Epoch: 0   Global Step: 100   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:03:19,191-Speed 143.72 samples/sec   Loss 2.0825   LearningRate 0.000002   Epoch: 0   Global Step: 110   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:03:21,441-Speed 142.23 samples/sec   Loss 2.0820   LearningRate 0.000002   Epoch: 0   Global Step: 120   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:03:23,682-Speed 142.81 samples/sec   Loss 2.0606   LearningRate 0.000002   Epoch: 0   Global Step: 130   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:03:25,946-Speed 141.41 samples/sec   Loss 2.0551   LearningRate 0.000002   Epoch: 0   Global Step: 140   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:03:28,211-Speed 141.32 samples/sec   Loss 2.0566   LearningRate 0.000002   Epoch: 0   Global Step: 150   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:03:30,454-Speed 142.67 samples/sec   Loss 2.0369   LearningRate 0.000003   Epoch: 0   Global Step: 160   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:03:32,705-Speed 142.22 samples/sec   Loss 2.0076   LearningRate 0.000003   Epoch: 0   Global Step: 170   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:03:34,955-Speed 142.28 samples/sec   Loss 2.0038   LearningRate 0.000003   Epoch: 0   Global Step: 180   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:03:37,203-Speed 142.38 samples/sec   Loss 1.9850   LearningRate 0.000003   Epoch: 0   Global Step: 190   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:03:39,447-Speed 142.64 samples/sec   Loss 1.9584   LearningRate 0.000003   Epoch: 0   Global Step: 200   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:03:41,714-Speed 141.19 samples/sec   Loss 1.9704   LearningRate 0.000003   Epoch: 0   Global Step: 210   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:03:43,961-Speed 142.45 samples/sec   Loss 1.9316   LearningRate 0.000003   Epoch: 0   Global Step: 220   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:03:46,221-Speed 141.64 samples/sec   Loss 1.9382   LearningRate 0.000004   Epoch: 0   Global Step: 230   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:03:48,460-Speed 142.97 samples/sec   Loss 1.9329   LearningRate 0.000004   Epoch: 0   Global Step: 240   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:03:50,696-Speed 143.19 samples/sec   Loss 1.9011   LearningRate 0.000004   Epoch: 0   Global Step: 250   Fp16 Grad Scale: 131072   Required: 4 hours
Training: 2023-08-17 21:03:52,920-Speed 143.92 samples/sec   Loss 1.9094   LearningRate 0.000004   Epoch: 0   Global Step: 260   Fp16 Grad Scale: 131072   Required: 4 hours
Training: 2023-08-17 21:03:55,169-Speed 142.31 samples/sec   Loss 1.9105   LearningRate 0.000004   Epoch: 0   Global Step: 270   Fp16 Grad Scale: 131072   Required: 4 hours
Training: 2023-08-17 21:03:57,426-Speed 141.79 samples/sec   Loss 1.9017   LearningRate 0.000004   Epoch: 0   Global Step: 280   Fp16 Grad Scale: 131072   Required: 4 hours
Training: 2023-08-17 21:03:59,693-Speed 141.22 samples/sec   Loss 1.8785   LearningRate 0.000005   Epoch: 0   Global Step: 290   Fp16 Grad Scale: 131072   Required: 4 hours
Training: 2023-08-17 21:04:01,950-Speed 141.82 samples/sec   Loss 1.8901   LearningRate 0.000005   Epoch: 0   Global Step: 300   Fp16 Grad Scale: 131072   Required: 4 hours
Training: 2023-08-17 21:04:04,209-Speed 141.69 samples/sec   Loss 1.8761   LearningRate 0.000005   Epoch: 0   Global Step: 310   Fp16 Grad Scale: 131072   Required: 4 hours
Training: 2023-08-17 21:04:06,468-Speed 141.71 samples/sec   Loss 1.8862   LearningRate 0.000005   Epoch: 0   Global Step: 320   Fp16 Grad Scale: 131072   Required: 4 hours
Training: 2023-08-17 21:04:08,750-Speed 140.29 samples/sec   Loss 1.8647   LearningRate 0.000005   Epoch: 0   Global Step: 330   Fp16 Grad Scale: 131072   Required: 4 hours
Training: 2023-08-17 21:04:11,034-Speed 140.12 samples/sec   Loss 1.8503   LearningRate 0.000005   Epoch: 0   Global Step: 340   Fp16 Grad Scale: 131072   Required: 4 hours
Training: 2023-08-17 21:04:13,306-Speed 140.89 samples/sec   Loss 1.8198   LearningRate 0.000005   Epoch: 0   Global Step: 350   Fp16 Grad Scale: 262144   Required: 4 hours
Training: 2023-08-17 21:04:15,561-Speed 141.96 samples/sec   Loss 1.8373   LearningRate 0.000006   Epoch: 0   Global Step: 360   Fp16 Grad Scale: 262144   Required: 4 hours
Training: 2023-08-17 21:04:17,833-Speed 140.89 samples/sec   Loss 1.8749   LearningRate 0.000006   Epoch: 0   Global Step: 370   Fp16 Grad Scale: 262144   Required: 4 hours
Training: 2023-08-17 21:04:20,103-Speed 141.00 samples/sec   Loss 1.8414   LearningRate 0.000006   Epoch: 0   Global Step: 380   Fp16 Grad Scale: 262144   Required: 4 hours
Training: 2023-08-17 21:04:22,377-Speed 140.75 samples/sec   Loss 1.8183   LearningRate 0.000006   Epoch: 0   Global Step: 390   Fp16 Grad Scale: 262144   Required: 4 hours
Training: 2023-08-17 21:04:24,633-Speed 141.87 samples/sec   Loss 1.8440   LearningRate 0.000006   Epoch: 0   Global Step: 400   Fp16 Grad Scale: 131072   Required: 4 hours
Training: 2023-08-17 21:04:26,892-Speed 141.73 samples/sec   Loss 1.7855   LearningRate 0.000006   Epoch: 0   Global Step: 410   Fp16 Grad Scale: 131072   Required: 4 hours
Training: 2023-08-17 21:04:29,161-Speed 141.08 samples/sec   Loss 1.7834   LearningRate 0.000007   Epoch: 0   Global Step: 420   Fp16 Grad Scale: 131072   Required: 4 hours
Training: 2023-08-17 21:04:31,426-Speed 141.31 samples/sec   Loss 1.7983   LearningRate 0.000007   Epoch: 0   Global Step: 430   Fp16 Grad Scale: 131072   Required: 4 hours
Training: 2023-08-17 21:04:33,691-Speed 141.27 samples/sec   Loss 1.8035   LearningRate 0.000007   Epoch: 0   Global Step: 440   Fp16 Grad Scale: 131072   Required: 4 hours
Training: 2023-08-17 21:04:35,965-Speed 140.78 samples/sec   Loss 1.7817   LearningRate 0.000007   Epoch: 0   Global Step: 450   Fp16 Grad Scale: 131072   Required: 4 hours
Training: 2023-08-17 21:04:38,245-Speed 140.41 samples/sec   Loss 1.7867   LearningRate 0.000007   Epoch: 0   Global Step: 460   Fp16 Grad Scale: 131072   Required: 4 hours
Training: 2023-08-17 21:04:40,513-Speed 141.12 samples/sec   Loss 1.7892   LearningRate 0.000007   Epoch: 0   Global Step: 470   Fp16 Grad Scale: 131072   Required: 4 hours
Training: 2023-08-17 21:04:42,778-Speed 141.31 samples/sec   Loss 1.7372   LearningRate 0.000008   Epoch: 0   Global Step: 480   Fp16 Grad Scale: 131072   Required: 4 hours
Training: 2023-08-17 21:04:45,028-Speed 142.26 samples/sec   Loss 1.7239   LearningRate 0.000008   Epoch: 0   Global Step: 490   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:04:47,284-Speed 141.88 samples/sec   Loss 1.7400   LearningRate 0.000008   Epoch: 0   Global Step: 500   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:04:49,569-Speed 140.11 samples/sec   Loss 1.7457   LearningRate 0.000008   Epoch: 0   Global Step: 510   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:04:51,842-Speed 140.84 samples/sec   Loss 1.7636   LearningRate 0.000008   Epoch: 0   Global Step: 520   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:04:54,130-Speed 139.89 samples/sec   Loss 1.6504   LearningRate 0.000008   Epoch: 0   Global Step: 530   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:04:56,401-Speed 140.97 samples/sec   Loss 1.6992   LearningRate 0.000008   Epoch: 0   Global Step: 540   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:04:58,673-Speed 140.83 samples/sec   Loss 1.7174   LearningRate 0.000009   Epoch: 0   Global Step: 550   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:05:00,957-Speed 140.14 samples/sec   Loss 1.6756   LearningRate 0.000009   Epoch: 0   Global Step: 560   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:05:03,223-Speed 141.26 samples/sec   Loss 1.7100   LearningRate 0.000009   Epoch: 0   Global Step: 570   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:05:05,489-Speed 141.29 samples/sec   Loss 1.6708   LearningRate 0.000009   Epoch: 0   Global Step: 580   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:05:07,745-Speed 141.84 samples/sec   Loss 1.7051   LearningRate 0.000009   Epoch: 0   Global Step: 590   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:05:10,012-Speed 141.23 samples/sec   Loss 1.6737   LearningRate 0.000009   Epoch: 0   Global Step: 600   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:05:12,266-Speed 142.00 samples/sec   Loss 1.6578   LearningRate 0.000010   Epoch: 0   Global Step: 610   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:05:14,513-Speed 142.46 samples/sec   Loss 1.6594   LearningRate 0.000010   Epoch: 0   Global Step: 620   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:05:16,780-Speed 141.17 samples/sec   Loss 1.6319   LearningRate 0.000010   Epoch: 0   Global Step: 630   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:05:19,040-Speed 141.64 samples/sec   Loss 1.6594   LearningRate 0.000010   Epoch: 0   Global Step: 640   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:05:21,316-Speed 140.59 samples/sec   Loss 1.6323   LearningRate 0.000010   Epoch: 0   Global Step: 650   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:05:23,578-Speed 141.58 samples/sec   Loss 1.6181   LearningRate 0.000010   Epoch: 0   Global Step: 660   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:05:25,850-Speed 140.84 samples/sec   Loss 1.6411   LearningRate 0.000010   Epoch: 0   Global Step: 670   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:05:28,126-Speed 140.65 samples/sec   Loss 1.6000   LearningRate 0.000011   Epoch: 0   Global Step: 680   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:05:30,413-Speed 139.94 samples/sec   Loss 1.6088   LearningRate 0.000011   Epoch: 0   Global Step: 690   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:05:32,720-Speed 138.74 samples/sec   Loss 1.5887   LearningRate 0.000011   Epoch: 0   Global Step: 700   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:05:35,017-Speed 139.38 samples/sec   Loss 1.5823   LearningRate 0.000011   Epoch: 0   Global Step: 710   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:05:37,309-Speed 139.62 samples/sec   Loss 1.6069   LearningRate 0.000011   Epoch: 0   Global Step: 720   Fp16 Grad Scale: 131072   Required: 4 hours
Training: 2023-08-17 21:05:39,587-Speed 140.51 samples/sec   Loss 1.6188   LearningRate 0.000011   Epoch: 0   Global Step: 730   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:05:41,869-Speed 140.26 samples/sec   Loss 1.5849   LearningRate 0.000012   Epoch: 0   Global Step: 740   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:05:44,168-Speed 139.26 samples/sec   Loss 1.5972   LearningRate 0.000012   Epoch: 0   Global Step: 750   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:05:46,435-Speed 141.15 samples/sec   Loss 1.6007   LearningRate 0.000012   Epoch: 0   Global Step: 760   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:05:48,701-Speed 141.25 samples/sec   Loss 1.5546   LearningRate 0.000012   Epoch: 0   Global Step: 770   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:05:50,970-Speed 141.12 samples/sec   Loss 1.5690   LearningRate 0.000012   Epoch: 0   Global Step: 780   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:05:53,229-Speed 141.67 samples/sec   Loss 1.5236   LearningRate 0.000012   Epoch: 0   Global Step: 790   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:05:55,499-Speed 140.98 samples/sec   Loss 1.5589   LearningRate 0.000013   Epoch: 0   Global Step: 800   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:05:57,755-Speed 141.93 samples/sec   Loss 1.5340   LearningRate 0.000013   Epoch: 0   Global Step: 810   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:06:00,025-Speed 141.01 samples/sec   Loss 1.5562   LearningRate 0.000013   Epoch: 0   Global Step: 820   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:06:02,287-Speed 141.48 samples/sec   Loss 1.5730   LearningRate 0.000013   Epoch: 0   Global Step: 830   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:06:04,548-Speed 141.55 samples/sec   Loss 1.5860   LearningRate 0.000013   Epoch: 0   Global Step: 840   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:06:06,819-Speed 140.98 samples/sec   Loss 1.5279   LearningRate 0.000013   Epoch: 0   Global Step: 850   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:06:09,084-Speed 141.26 samples/sec   Loss 1.5429   LearningRate 0.000013   Epoch: 0   Global Step: 860   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:06:11,364-Speed 140.40 samples/sec   Loss 1.5158   LearningRate 0.000014   Epoch: 0   Global Step: 870   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:06:13,641-Speed 140.62 samples/sec   Loss 1.5556   LearningRate 0.000014   Epoch: 0   Global Step: 880   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:06:15,913-Speed 140.89 samples/sec   Loss 1.5507   LearningRate 0.000014   Epoch: 0   Global Step: 890   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:06:18,171-Speed 141.75 samples/sec   Loss 1.5355   LearningRate 0.000014   Epoch: 0   Global Step: 900   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:06:20,448-Speed 140.52 samples/sec   Loss 1.4903   LearningRate 0.000014   Epoch: 0   Global Step: 910   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:06:22,726-Speed 140.52 samples/sec   Loss 1.5596   LearningRate 0.000014   Epoch: 0   Global Step: 920   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:06:25,007-Speed 140.35 samples/sec   Loss 1.5186   LearningRate 0.000015   Epoch: 0   Global Step: 930   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:06:27,272-Speed 141.28 samples/sec   Loss 1.4999   LearningRate 0.000015   Epoch: 0   Global Step: 940   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:06:29,536-Speed 141.41 samples/sec   Loss 1.5263   LearningRate 0.000015   Epoch: 0   Global Step: 950   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:06:31,805-Speed 141.08 samples/sec   Loss 1.5303   LearningRate 0.000015   Epoch: 0   Global Step: 960   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:06:34,071-Speed 141.22 samples/sec   Loss 1.4969   LearningRate 0.000015   Epoch: 0   Global Step: 970   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:06:36,332-Speed 141.61 samples/sec   Loss 1.4949   LearningRate 0.000015   Epoch: 0   Global Step: 980   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:06:38,579-Speed 142.44 samples/sec   Loss 1.4579   LearningRate 0.000015   Epoch: 0   Global Step: 990   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:06:40,620-Val on RAF/AffectNet:
Training: 2023-08-17 21:06:40,894-Test: [0/48]	Time 0.273 (0.273)	Loss 0.7824 (0.7824)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-17 21:06:42,006-Test: [10/48]	Time 0.110 (0.126)	Loss 0.7814 (0.7710)	Acc@1 82.812 (82.812)	Acc@5 100.000 (99.148)	Mem 5268MB
Training: 2023-08-17 21:06:43,105-Test: [20/48]	Time 0.109 (0.118)	Loss 0.6356 (0.7846)	Acc@1 90.625 (81.622)	Acc@5 100.000 (99.033)	Mem 5268MB
Training: 2023-08-17 21:06:44,198-Test: [30/48]	Time 0.106 (0.115)	Loss 0.8867 (0.7920)	Acc@1 75.000 (81.099)	Acc@5 96.875 (98.841)	Mem 5268MB
Training: 2023-08-17 21:06:45,259-Test: [40/48]	Time 0.106 (0.113)	Loss 0.7112 (0.7903)	Acc@1 85.938 (81.288)	Acc@5 100.000 (98.895)	Mem 5268MB
Training: 2023-08-17 21:06:46,020-[999]Expression Loss: 0.79207
Training: 2023-08-17 21:06:46,021-[999]Expression Acc@1: 81.35593
Training: 2023-08-17 21:06:46,021-[999]Expression Acc@1-Highest: 81.35593
Training: 2023-08-17 21:06:46,021-[999]Expression Acc@5: 98.98957
Training: 2023-08-17 21:06:46,021-[999]Expression Acc@5-Highest: 98.98957
Training: 2023-08-17 21:06:46,021-[999]10 Times Expression Acc@1: 81.35593
Training: 2023-08-17 21:06:46,021-[999]10 Times Expression Acc@1-Highest: 81.35593
Training: 2023-08-17 21:06:46,249-Speed 41.72 samples/sec   Loss 1.5070   LearningRate 0.000016   Epoch: 0   Global Step: 1000   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:06:48,527-Speed 140.48 samples/sec   Loss 1.4938   LearningRate 0.000016   Epoch: 0   Global Step: 1010   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:06:50,789-Speed 141.52 samples/sec   Loss 1.4810   LearningRate 0.000016   Epoch: 0   Global Step: 1020   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:06:53,054-Speed 141.31 samples/sec   Loss 1.5206   LearningRate 0.000016   Epoch: 0   Global Step: 1030   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:06:55,334-Speed 140.41 samples/sec   Loss 1.5315   LearningRate 0.000016   Epoch: 0   Global Step: 1040   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:06:57,624-Speed 139.77 samples/sec   Loss 1.5006   LearningRate 0.000016   Epoch: 0   Global Step: 1050   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:06:59,914-Speed 139.79 samples/sec   Loss 1.5315   LearningRate 0.000017   Epoch: 0   Global Step: 1060   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:07:02,209-Speed 139.47 samples/sec   Loss 1.4799   LearningRate 0.000017   Epoch: 0   Global Step: 1070   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:07:04,516-Speed 138.69 samples/sec   Loss 1.5070   LearningRate 0.000017   Epoch: 0   Global Step: 1080   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:07:06,830-Speed 138.39 samples/sec   Loss 1.5001   LearningRate 0.000017   Epoch: 0   Global Step: 1090   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:07:09,106-Speed 140.59 samples/sec   Loss 1.5396   LearningRate 0.000017   Epoch: 0   Global Step: 1100   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:07:11,395-Speed 139.86 samples/sec   Loss 1.5041   LearningRate 0.000017   Epoch: 0   Global Step: 1110   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:07:13,673-Speed 140.52 samples/sec   Loss 1.4855   LearningRate 0.000018   Epoch: 0   Global Step: 1120   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:07:15,962-Speed 139.83 samples/sec   Loss 1.4704   LearningRate 0.000018   Epoch: 0   Global Step: 1130   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:07:18,244-Speed 140.28 samples/sec   Loss 1.5261   LearningRate 0.000018   Epoch: 0   Global Step: 1140   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:07:20,529-Speed 140.07 samples/sec   Loss 1.4847   LearningRate 0.000018   Epoch: 0   Global Step: 1150   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:07:22,804-Speed 140.74 samples/sec   Loss 1.5227   LearningRate 0.000018   Epoch: 0   Global Step: 1160   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:07:25,078-Speed 140.72 samples/sec   Loss 1.5298   LearningRate 0.000018   Epoch: 0   Global Step: 1170   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:07:27,364-Speed 140.02 samples/sec   Loss 1.4748   LearningRate 0.000018   Epoch: 0   Global Step: 1180   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:07:29,657-Speed 139.61 samples/sec   Loss 1.4414   LearningRate 0.000019   Epoch: 0   Global Step: 1190   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:07:31,957-Speed 139.21 samples/sec   Loss 1.4767   LearningRate 0.000019   Epoch: 0   Global Step: 1200   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:07:34,238-Speed 140.27 samples/sec   Loss 1.4988   LearningRate 0.000019   Epoch: 0   Global Step: 1210   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:07:36,537-Speed 139.28 samples/sec   Loss 1.4430   LearningRate 0.000019   Epoch: 0   Global Step: 1220   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:07:38,829-Speed 139.65 samples/sec   Loss 1.4689   LearningRate 0.000019   Epoch: 0   Global Step: 1230   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:07:41,122-Speed 139.59 samples/sec   Loss 1.4301   LearningRate 0.000019   Epoch: 0   Global Step: 1240   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:07:43,405-Speed 140.19 samples/sec   Loss 1.4891   LearningRate 0.000020   Epoch: 0   Global Step: 1250   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:07:45,692-Speed 139.96 samples/sec   Loss 1.4699   LearningRate 0.000020   Epoch: 0   Global Step: 1260   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:07:47,988-Speed 139.42 samples/sec   Loss 1.5094   LearningRate 0.000020   Epoch: 0   Global Step: 1270   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:07:50,275-Speed 139.99 samples/sec   Loss 1.4854   LearningRate 0.000020   Epoch: 0   Global Step: 1280   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:07:52,570-Speed 139.48 samples/sec   Loss 1.4737   LearningRate 0.000020   Epoch: 0   Global Step: 1290   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:07:54,858-Speed 139.89 samples/sec   Loss 1.4461   LearningRate 0.000020   Epoch: 0   Global Step: 1300   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:07:57,157-Speed 139.23 samples/sec   Loss 1.4612   LearningRate 0.000020   Epoch: 0   Global Step: 1310   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:07:59,454-Speed 139.39 samples/sec   Loss 1.4264   LearningRate 0.000021   Epoch: 0   Global Step: 1320   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:08:01,756-Speed 139.04 samples/sec   Loss 1.4161   LearningRate 0.000021   Epoch: 0   Global Step: 1330   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:08:04,065-Speed 138.60 samples/sec   Loss 1.4342   LearningRate 0.000021   Epoch: 0   Global Step: 1340   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:08:06,362-Speed 139.36 samples/sec   Loss 1.4435   LearningRate 0.000021   Epoch: 0   Global Step: 1350   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:08:08,659-Speed 139.36 samples/sec   Loss 1.4627   LearningRate 0.000021   Epoch: 0   Global Step: 1360   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:08:10,960-Speed 139.10 samples/sec   Loss 1.4560   LearningRate 0.000021   Epoch: 0   Global Step: 1370   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:08:13,254-Speed 139.53 samples/sec   Loss 1.4692   LearningRate 0.000022   Epoch: 0   Global Step: 1380   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:08:15,534-Speed 140.44 samples/sec   Loss 1.5174   LearningRate 0.000022   Epoch: 0   Global Step: 1390   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:08:17,835-Speed 139.11 samples/sec   Loss 1.4786   LearningRate 0.000022   Epoch: 0   Global Step: 1400   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:08:20,125-Speed 139.78 samples/sec   Loss 1.4675   LearningRate 0.000022   Epoch: 0   Global Step: 1410   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:08:22,426-Speed 139.08 samples/sec   Loss 1.4665   LearningRate 0.000022   Epoch: 0   Global Step: 1420   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:08:24,717-Speed 139.70 samples/sec   Loss 1.4536   LearningRate 0.000022   Epoch: 0   Global Step: 1430   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:08:27,009-Speed 139.70 samples/sec   Loss 1.4351   LearningRate 0.000023   Epoch: 0   Global Step: 1440   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:08:29,307-Speed 139.29 samples/sec   Loss 1.4410   LearningRate 0.000023   Epoch: 0   Global Step: 1450   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:08:31,609-Speed 139.02 samples/sec   Loss 1.4302   LearningRate 0.000023   Epoch: 0   Global Step: 1460   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:08:33,893-Speed 140.19 samples/sec   Loss 1.4169   LearningRate 0.000023   Epoch: 0   Global Step: 1470   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:08:36,193-Speed 139.13 samples/sec   Loss 1.4231   LearningRate 0.000023   Epoch: 0   Global Step: 1480   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:08:38,485-Speed 139.65 samples/sec   Loss 1.4554   LearningRate 0.000023   Epoch: 0   Global Step: 1490   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:08:40,771-Speed 140.05 samples/sec   Loss 1.4458   LearningRate 0.000023   Epoch: 0   Global Step: 1500   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:08:43,065-Speed 139.53 samples/sec   Loss 1.3934   LearningRate 0.000024   Epoch: 0   Global Step: 1510   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:08:45,357-Speed 139.64 samples/sec   Loss 1.4102   LearningRate 0.000024   Epoch: 0   Global Step: 1520   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:08:47,642-Speed 140.08 samples/sec   Loss 1.4580   LearningRate 0.000024   Epoch: 0   Global Step: 1530   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:08:49,927-Speed 140.11 samples/sec   Loss 1.4465   LearningRate 0.000024   Epoch: 0   Global Step: 1540   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:08:52,216-Speed 139.78 samples/sec   Loss 1.4462   LearningRate 0.000024   Epoch: 0   Global Step: 1550   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:08:54,504-Speed 139.95 samples/sec   Loss 1.4181   LearningRate 0.000024   Epoch: 0   Global Step: 1560   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:08:56,792-Speed 139.88 samples/sec   Loss 1.4533   LearningRate 0.000025   Epoch: 0   Global Step: 1570   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:08:59,089-Speed 139.34 samples/sec   Loss 1.4763   LearningRate 0.000025   Epoch: 0   Global Step: 1580   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:09:01,380-Speed 139.74 samples/sec   Loss 1.4385   LearningRate 0.000025   Epoch: 0   Global Step: 1590   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:09:03,671-Speed 139.73 samples/sec   Loss 1.4228   LearningRate 0.000025   Epoch: 0   Global Step: 1600   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:09:05,962-Speed 139.71 samples/sec   Loss 1.4226   LearningRate 0.000025   Epoch: 0   Global Step: 1610   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:09:08,262-Speed 139.19 samples/sec   Loss 1.4545   LearningRate 0.000025   Epoch: 0   Global Step: 1620   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:09:10,554-Speed 139.65 samples/sec   Loss 1.4519   LearningRate 0.000025   Epoch: 0   Global Step: 1630   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:09:12,836-Speed 140.27 samples/sec   Loss 1.4581   LearningRate 0.000026   Epoch: 0   Global Step: 1640   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:09:15,112-Speed 140.64 samples/sec   Loss 1.4003   LearningRate 0.000026   Epoch: 0   Global Step: 1650   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:09:17,401-Speed 139.82 samples/sec   Loss 1.4686   LearningRate 0.000026   Epoch: 0   Global Step: 1660   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:09:19,704-Speed 138.96 samples/sec   Loss 1.4136   LearningRate 0.000026   Epoch: 0   Global Step: 1670   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:09:21,985-Speed 140.34 samples/sec   Loss 1.4024   LearningRate 0.000026   Epoch: 0   Global Step: 1680   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:09:24,279-Speed 139.51 samples/sec   Loss 1.4464   LearningRate 0.000026   Epoch: 0   Global Step: 1690   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:09:26,567-Speed 139.93 samples/sec   Loss 1.3895   LearningRate 0.000027   Epoch: 0   Global Step: 1700   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:09:28,868-Speed 139.08 samples/sec   Loss 1.4138   LearningRate 0.000027   Epoch: 0   Global Step: 1710   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:09:31,168-Speed 139.19 samples/sec   Loss 1.4203   LearningRate 0.000027   Epoch: 0   Global Step: 1720   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:09:33,464-Speed 139.41 samples/sec   Loss 1.3871   LearningRate 0.000027   Epoch: 0   Global Step: 1730   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:09:35,755-Speed 139.69 samples/sec   Loss 1.3735   LearningRate 0.000027   Epoch: 0   Global Step: 1740   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:09:38,057-Speed 139.03 samples/sec   Loss 1.3901   LearningRate 0.000027   Epoch: 0   Global Step: 1750   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:09:40,345-Speed 139.89 samples/sec   Loss 1.4053   LearningRate 0.000028   Epoch: 0   Global Step: 1760   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:09:42,637-Speed 139.68 samples/sec   Loss 1.4189   LearningRate 0.000028   Epoch: 0   Global Step: 1770   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:09:44,945-Speed 138.69 samples/sec   Loss 1.3926   LearningRate 0.000028   Epoch: 0   Global Step: 1780   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:09:47,244-Speed 139.21 samples/sec   Loss 1.4074   LearningRate 0.000028   Epoch: 0   Global Step: 1790   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:09:49,549-Speed 138.90 samples/sec   Loss 1.3977   LearningRate 0.000028   Epoch: 0   Global Step: 1800   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:09:51,842-Speed 139.58 samples/sec   Loss 1.4451   LearningRate 0.000028   Epoch: 0   Global Step: 1810   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:09:54,130-Speed 139.91 samples/sec   Loss 1.4471   LearningRate 0.000028   Epoch: 0   Global Step: 1820   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:09:56,421-Speed 139.70 samples/sec   Loss 1.4015   LearningRate 0.000029   Epoch: 0   Global Step: 1830   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:09:58,708-Speed 139.96 samples/sec   Loss 1.3963   LearningRate 0.000029   Epoch: 0   Global Step: 1840   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:10:00,976-Speed 141.09 samples/sec   Loss 1.3723   LearningRate 0.000029   Epoch: 0   Global Step: 1850   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:10:03,246-Speed 141.04 samples/sec   Loss 1.3857   LearningRate 0.000029   Epoch: 0   Global Step: 1860   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:10:05,528-Speed 140.25 samples/sec   Loss 1.4210   LearningRate 0.000029   Epoch: 0   Global Step: 1870   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:10:07,811-Speed 140.21 samples/sec   Loss 1.3935   LearningRate 0.000029   Epoch: 0   Global Step: 1880   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:10:10,110-Speed 139.23 samples/sec   Loss 1.3783   LearningRate 0.000030   Epoch: 0   Global Step: 1890   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:10:12,440-Speed 137.37 samples/sec   Loss 1.3960   LearningRate 0.000030   Epoch: 0   Global Step: 1900   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:10:14,749-Speed 138.63 samples/sec   Loss 1.3881   LearningRate 0.000030   Epoch: 0   Global Step: 1910   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:10:17,071-Speed 137.84 samples/sec   Loss 1.4060   LearningRate 0.000030   Epoch: 0   Global Step: 1920   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:10:19,393-Speed 137.84 samples/sec   Loss 1.4018   LearningRate 0.000030   Epoch: 0   Global Step: 1930   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:10:21,739-Speed 136.45 samples/sec   Loss 1.4322   LearningRate 0.000030   Epoch: 0   Global Step: 1940   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:10:24,065-Speed 137.60 samples/sec   Loss 1.4125   LearningRate 0.000030   Epoch: 0   Global Step: 1950   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:10:26,393-Speed 137.52 samples/sec   Loss 1.4043   LearningRate 0.000031   Epoch: 0   Global Step: 1960   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:10:28,724-Speed 137.32 samples/sec   Loss 1.4170   LearningRate 0.000031   Epoch: 0   Global Step: 1970   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:10:31,031-Speed 138.74 samples/sec   Loss 1.3848   LearningRate 0.000031   Epoch: 0   Global Step: 1980   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:10:33,349-Speed 138.08 samples/sec   Loss 1.3948   LearningRate 0.000031   Epoch: 0   Global Step: 1990   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:10:35,401-Val on RAF/AffectNet:
Training: 2023-08-17 21:10:35,508-Test: [0/48]	Time 0.107 (0.107)	Loss 0.6862 (0.6862)	Acc@1 84.375 (84.375)	Acc@5 98.438 (98.438)	Mem 5268MB
Training: 2023-08-17 21:10:36,535-Test: [10/48]	Time 0.104 (0.103)	Loss 0.6733 (0.7078)	Acc@1 87.500 (83.949)	Acc@5 100.000 (99.006)	Mem 5268MB
Training: 2023-08-17 21:10:37,569-Test: [20/48]	Time 0.105 (0.103)	Loss 0.5790 (0.7130)	Acc@1 93.750 (84.301)	Acc@5 100.000 (99.107)	Mem 5268MB
Training: 2023-08-17 21:10:38,613-Test: [30/48]	Time 0.105 (0.104)	Loss 0.7428 (0.7138)	Acc@1 84.375 (83.972)	Acc@5 95.312 (98.992)	Mem 5268MB
Training: 2023-08-17 21:10:39,669-Test: [40/48]	Time 0.108 (0.104)	Loss 0.6764 (0.7159)	Acc@1 81.250 (83.765)	Acc@5 100.000 (98.895)	Mem 5268MB
Training: 2023-08-17 21:10:40,421-[1999]Expression Loss: 0.71084
Training: 2023-08-17 21:10:40,421-[1999]Expression Acc@1: 83.96349
Training: 2023-08-17 21:10:40,421-[1999]Expression Acc@1-Highest: 83.96349
Training: 2023-08-17 21:10:40,421-[1999]Expression Acc@5: 98.82660
Training: 2023-08-17 21:10:40,421-[1999]Expression Acc@5-Highest: 98.98957
Training: 2023-08-17 21:10:40,422-[1999]10 Times Expression Acc@1: 82.65971
Training: 2023-08-17 21:10:40,422-[1999]10 Times Expression Acc@1-Highest: 82.65971
Training: 2023-08-17 21:10:40,656-Speed 43.80 samples/sec   Loss 1.3697   LearningRate 0.000031   Epoch: 0   Global Step: 2000   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:10:42,957-Speed 139.13 samples/sec   Loss 1.4071   LearningRate 0.000031   Epoch: 0   Global Step: 2010   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:10:45,251-Speed 139.50 samples/sec   Loss 1.3889   LearningRate 0.000031   Epoch: 0   Global Step: 2020   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:10:47,558-Speed 138.80 samples/sec   Loss 1.4191   LearningRate 0.000031   Epoch: 0   Global Step: 2030   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:10:49,856-Speed 139.27 samples/sec   Loss 1.3320   LearningRate 0.000031   Epoch: 0   Global Step: 2040   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:10:52,146-Speed 139.80 samples/sec   Loss 1.3728   LearningRate 0.000031   Epoch: 0   Global Step: 2050   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:10:54,428-Speed 140.24 samples/sec   Loss 1.4458   LearningRate 0.000031   Epoch: 0   Global Step: 2060   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:10:56,727-Speed 139.24 samples/sec   Loss 1.3880   LearningRate 0.000031   Epoch: 0   Global Step: 2070   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:10:59,019-Speed 139.65 samples/sec   Loss 1.4292   LearningRate 0.000031   Epoch: 0   Global Step: 2080   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:11:01,304-Speed 140.07 samples/sec   Loss 1.3956   LearningRate 0.000031   Epoch: 0   Global Step: 2090   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:11:03,606-Speed 139.05 samples/sec   Loss 1.4270   LearningRate 0.000031   Epoch: 0   Global Step: 2100   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:11:05,904-Speed 139.29 samples/sec   Loss 1.4455   LearningRate 0.000031   Epoch: 0   Global Step: 2110   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:11:08,205-Speed 139.14 samples/sec   Loss 1.4104   LearningRate 0.000031   Epoch: 0   Global Step: 2120   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:11:10,513-Speed 138.69 samples/sec   Loss 1.4179   LearningRate 0.000031   Epoch: 0   Global Step: 2130   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:11:12,830-Speed 138.12 samples/sec   Loss 1.4654   LearningRate 0.000031   Epoch: 0   Global Step: 2140   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:11:15,142-Speed 138.46 samples/sec   Loss 1.4302   LearningRate 0.000031   Epoch: 0   Global Step: 2150   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:11:17,461-Speed 138.02 samples/sec   Loss 1.3932   LearningRate 0.000031   Epoch: 0   Global Step: 2160   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:11:19,766-Speed 138.87 samples/sec   Loss 1.4087   LearningRate 0.000031   Epoch: 0   Global Step: 2170   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:11:22,052-Speed 140.06 samples/sec   Loss 1.4003   LearningRate 0.000031   Epoch: 0   Global Step: 2180   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:11:24,370-Speed 138.07 samples/sec   Loss 1.3925   LearningRate 0.000031   Epoch: 0   Global Step: 2190   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:11:26,673-Speed 138.97 samples/sec   Loss 1.4049   LearningRate 0.000031   Epoch: 0   Global Step: 2200   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:11:28,965-Speed 139.69 samples/sec   Loss 1.3737   LearningRate 0.000031   Epoch: 0   Global Step: 2210   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:11:31,260-Speed 139.43 samples/sec   Loss 1.3378   LearningRate 0.000031   Epoch: 0   Global Step: 2220   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:11:33,566-Speed 138.83 samples/sec   Loss 1.3819   LearningRate 0.000031   Epoch: 0   Global Step: 2230   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:11:35,869-Speed 138.97 samples/sec   Loss 1.3932   LearningRate 0.000031   Epoch: 0   Global Step: 2240   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:11:38,171-Speed 139.10 samples/sec   Loss 1.3829   LearningRate 0.000031   Epoch: 0   Global Step: 2250   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:11:40,469-Speed 139.28 samples/sec   Loss 1.3844   LearningRate 0.000031   Epoch: 0   Global Step: 2260   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:11:42,756-Speed 139.91 samples/sec   Loss 1.3911   LearningRate 0.000031   Epoch: 0   Global Step: 2270   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:11:45,060-Speed 138.92 samples/sec   Loss 1.3791   LearningRate 0.000031   Epoch: 0   Global Step: 2280   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:11:47,347-Speed 140.03 samples/sec   Loss 1.4107   LearningRate 0.000031   Epoch: 0   Global Step: 2290   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:11:49,651-Speed 138.90 samples/sec   Loss 1.3497   LearningRate 0.000031   Epoch: 0   Global Step: 2300   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:11:51,962-Speed 138.50 samples/sec   Loss 1.3932   LearningRate 0.000031   Epoch: 0   Global Step: 2310   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:11:54,249-Speed 140.00 samples/sec   Loss 1.3849   LearningRate 0.000031   Epoch: 0   Global Step: 2320   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:11:56,540-Speed 139.66 samples/sec   Loss 1.3816   LearningRate 0.000031   Epoch: 0   Global Step: 2330   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:11:58,840-Speed 139.22 samples/sec   Loss 1.4256   LearningRate 0.000031   Epoch: 0   Global Step: 2340   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:12:01,139-Speed 139.24 samples/sec   Loss 1.3969   LearningRate 0.000031   Epoch: 0   Global Step: 2350   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:12:03,424-Speed 140.07 samples/sec   Loss 1.4160   LearningRate 0.000031   Epoch: 0   Global Step: 2360   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:12:05,715-Speed 139.72 samples/sec   Loss 1.3695   LearningRate 0.000031   Epoch: 0   Global Step: 2370   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:12:08,005-Speed 139.77 samples/sec   Loss 1.3872   LearningRate 0.000031   Epoch: 0   Global Step: 2380   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:12:10,295-Speed 139.79 samples/sec   Loss 1.4083   LearningRate 0.000031   Epoch: 0   Global Step: 2390   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:12:12,596-Speed 139.11 samples/sec   Loss 1.3963   LearningRate 0.000031   Epoch: 0   Global Step: 2400   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:12:14,892-Speed 139.41 samples/sec   Loss 1.3942   LearningRate 0.000031   Epoch: 0   Global Step: 2410   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:12:17,169-Speed 140.58 samples/sec   Loss 1.3718   LearningRate 0.000031   Epoch: 0   Global Step: 2420   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:12:19,461-Speed 139.66 samples/sec   Loss 1.4235   LearningRate 0.000031   Epoch: 0   Global Step: 2430   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:12:21,760-Speed 139.18 samples/sec   Loss 1.3687   LearningRate 0.000031   Epoch: 0   Global Step: 2440   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:12:24,060-Speed 139.19 samples/sec   Loss 1.3832   LearningRate 0.000031   Epoch: 0   Global Step: 2450   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:12:26,339-Speed 140.42 samples/sec   Loss 1.3484   LearningRate 0.000031   Epoch: 0   Global Step: 2460   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:12:28,638-Speed 139.29 samples/sec   Loss 1.3710   LearningRate 0.000031   Epoch: 0   Global Step: 2470   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:12:30,923-Speed 140.08 samples/sec   Loss 1.4065   LearningRate 0.000031   Epoch: 0   Global Step: 2480   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:12:33,209-Speed 140.03 samples/sec   Loss 1.3502   LearningRate 0.000031   Epoch: 0   Global Step: 2490   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:12:35,504-Speed 139.47 samples/sec   Loss 1.3369   LearningRate 0.000031   Epoch: 0   Global Step: 2500   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:12:37,801-Speed 139.32 samples/sec   Loss 1.3137   LearningRate 0.000031   Epoch: 0   Global Step: 2510   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:12:40,079-Speed 140.52 samples/sec   Loss 1.3670   LearningRate 0.000031   Epoch: 0   Global Step: 2520   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:12:42,357-Speed 140.52 samples/sec   Loss 1.3661   LearningRate 0.000031   Epoch: 0   Global Step: 2530   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:12:44,651-Speed 139.57 samples/sec   Loss 1.4206   LearningRate 0.000031   Epoch: 0   Global Step: 2540   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:12:46,952-Speed 139.07 samples/sec   Loss 1.3810   LearningRate 0.000031   Epoch: 0   Global Step: 2550   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:12:49,248-Speed 139.43 samples/sec   Loss 1.3608   LearningRate 0.000031   Epoch: 0   Global Step: 2560   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:12:51,531-Speed 140.19 samples/sec   Loss 1.3719   LearningRate 0.000031   Epoch: 0   Global Step: 2570   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:12:53,823-Speed 139.70 samples/sec   Loss 1.3513   LearningRate 0.000031   Epoch: 0   Global Step: 2580   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:12:56,113-Speed 139.79 samples/sec   Loss 1.3584   LearningRate 0.000031   Epoch: 0   Global Step: 2590   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:12:58,414-Speed 139.11 samples/sec   Loss 1.4072   LearningRate 0.000031   Epoch: 0   Global Step: 2600   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:13:00,699-Speed 140.08 samples/sec   Loss 1.4049   LearningRate 0.000031   Epoch: 0   Global Step: 2610   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:13:02,970-Speed 140.89 samples/sec   Loss 1.3849   LearningRate 0.000031   Epoch: 0   Global Step: 2620   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:13:05,249-Speed 140.49 samples/sec   Loss 1.3479   LearningRate 0.000031   Epoch: 0   Global Step: 2630   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:13:07,530-Speed 140.36 samples/sec   Loss 1.4053   LearningRate 0.000031   Epoch: 0   Global Step: 2640   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:13:09,817-Speed 139.93 samples/sec   Loss 1.3565   LearningRate 0.000031   Epoch: 0   Global Step: 2650   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:13:12,084-Speed 141.23 samples/sec   Loss 1.3876   LearningRate 0.000031   Epoch: 0   Global Step: 2660   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:13:14,344-Speed 141.61 samples/sec   Loss 1.3693   LearningRate 0.000031   Epoch: 0   Global Step: 2670   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:13:16,618-Speed 140.78 samples/sec   Loss 1.3712   LearningRate 0.000031   Epoch: 0   Global Step: 2680   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:13:18,871-Speed 142.06 samples/sec   Loss 1.4385   LearningRate 0.000031   Epoch: 0   Global Step: 2690   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:13:21,134-Speed 141.46 samples/sec   Loss 1.3267   LearningRate 0.000031   Epoch: 0   Global Step: 2700   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:13:23,389-Speed 141.94 samples/sec   Loss 1.3961   LearningRate 0.000031   Epoch: 0   Global Step: 2710   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:13:25,650-Speed 141.58 samples/sec   Loss 1.3581   LearningRate 0.000031   Epoch: 0   Global Step: 2720   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:13:27,905-Speed 141.92 samples/sec   Loss 1.3487   LearningRate 0.000031   Epoch: 0   Global Step: 2730   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:13:30,161-Speed 141.87 samples/sec   Loss 1.3665   LearningRate 0.000031   Epoch: 0   Global Step: 2740   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:13:32,415-Speed 142.03 samples/sec   Loss 1.3635   LearningRate 0.000031   Epoch: 0   Global Step: 2750   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:13:34,669-Speed 142.05 samples/sec   Loss 1.3522   LearningRate 0.000031   Epoch: 0   Global Step: 2760   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:13:36,913-Speed 142.62 samples/sec   Loss 1.3674   LearningRate 0.000031   Epoch: 0   Global Step: 2770   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:13:39,159-Speed 142.47 samples/sec   Loss 1.3722   LearningRate 0.000031   Epoch: 0   Global Step: 2780   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:13:41,421-Speed 141.58 samples/sec   Loss 1.3234   LearningRate 0.000031   Epoch: 0   Global Step: 2790   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:13:43,675-Speed 142.00 samples/sec   Loss 1.3686   LearningRate 0.000031   Epoch: 0   Global Step: 2800   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:13:45,925-Speed 142.22 samples/sec   Loss 1.3825   LearningRate 0.000031   Epoch: 0   Global Step: 2810   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:13:48,181-Speed 141.91 samples/sec   Loss 1.3342   LearningRate 0.000031   Epoch: 0   Global Step: 2820   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:13:50,444-Speed 141.46 samples/sec   Loss 1.3906   LearningRate 0.000031   Epoch: 0   Global Step: 2830   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:13:52,708-Speed 141.38 samples/sec   Loss 1.3701   LearningRate 0.000031   Epoch: 0   Global Step: 2840   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:13:54,986-Speed 140.47 samples/sec   Loss 1.3672   LearningRate 0.000031   Epoch: 0   Global Step: 2850   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:13:57,262-Speed 140.68 samples/sec   Loss 1.3456   LearningRate 0.000031   Epoch: 0   Global Step: 2860   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:13:59,544-Speed 140.27 samples/sec   Loss 1.3278   LearningRate 0.000031   Epoch: 0   Global Step: 2870   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:14:01,818-Speed 140.74 samples/sec   Loss 1.3508   LearningRate 0.000031   Epoch: 0   Global Step: 2880   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:14:04,100-Speed 140.25 samples/sec   Loss 1.3486   LearningRate 0.000031   Epoch: 0   Global Step: 2890   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:14:06,391-Speed 139.73 samples/sec   Loss 1.3582   LearningRate 0.000031   Epoch: 0   Global Step: 2900   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:14:08,677-Speed 140.02 samples/sec   Loss 1.3290   LearningRate 0.000031   Epoch: 0   Global Step: 2910   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:14:10,971-Speed 139.56 samples/sec   Loss 1.3580   LearningRate 0.000031   Epoch: 0   Global Step: 2920   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:14:13,250-Speed 140.43 samples/sec   Loss 1.3443   LearningRate 0.000031   Epoch: 0   Global Step: 2930   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:14:15,519-Speed 141.12 samples/sec   Loss 1.3611   LearningRate 0.000031   Epoch: 0   Global Step: 2940   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:14:17,781-Speed 141.44 samples/sec   Loss 1.3591   LearningRate 0.000031   Epoch: 0   Global Step: 2950   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:14:20,051-Speed 141.02 samples/sec   Loss 1.3415   LearningRate 0.000031   Epoch: 0   Global Step: 2960   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:14:22,326-Speed 140.70 samples/sec   Loss 1.3889   LearningRate 0.000031   Epoch: 0   Global Step: 2970   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:14:24,614-Speed 139.94 samples/sec   Loss 1.3457   LearningRate 0.000031   Epoch: 0   Global Step: 2980   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:14:26,910-Speed 139.42 samples/sec   Loss 1.3343   LearningRate 0.000031   Epoch: 0   Global Step: 2990   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:14:28,965-Val on RAF/AffectNet:
Training: 2023-08-17 21:14:29,077-Test: [0/48]	Time 0.111 (0.111)	Loss 0.6590 (0.6590)	Acc@1 85.938 (85.938)	Acc@5 98.438 (98.438)	Mem 5268MB
Training: 2023-08-17 21:14:30,149-Test: [10/48]	Time 0.115 (0.108)	Loss 0.4473 (0.5881)	Acc@1 96.875 (90.767)	Acc@5 100.000 (99.148)	Mem 5268MB
Training: 2023-08-17 21:14:31,207-Test: [20/48]	Time 0.104 (0.107)	Loss 0.5616 (0.6038)	Acc@1 90.625 (89.807)	Acc@5 98.438 (99.033)	Mem 5268MB
Training: 2023-08-17 21:14:32,274-Test: [30/48]	Time 0.111 (0.107)	Loss 0.5292 (0.6103)	Acc@1 92.188 (89.163)	Acc@5 100.000 (99.042)	Mem 5268MB
Training: 2023-08-17 21:14:33,348-Test: [40/48]	Time 0.107 (0.107)	Loss 0.7304 (0.6085)	Acc@1 79.688 (88.986)	Acc@5 100.000 (99.238)	Mem 5268MB
Training: 2023-08-17 21:14:34,090-[2999]Expression Loss: 0.61554
Training: 2023-08-17 21:14:34,090-[2999]Expression Acc@1: 88.49413
Training: 2023-08-17 21:14:34,090-[2999]Expression Acc@1-Highest: 88.49413
Training: 2023-08-17 21:14:34,090-[2999]Expression Acc@5: 99.25033
Training: 2023-08-17 21:14:34,090-[2999]Expression Acc@5-Highest: 99.25033
Training: 2023-08-17 21:14:34,090-[2999]10 Times Expression Acc@1: 84.60452
Training: 2023-08-17 21:14:34,090-[2999]10 Times Expression Acc@1-Highest: 84.60452
Training: 2023-08-17 21:14:34,320-Speed 43.19 samples/sec   Loss 1.3263   LearningRate 0.000031   Epoch: 0   Global Step: 3000   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:14:36,596-Speed 140.64 samples/sec   Loss 1.3873   LearningRate 0.000031   Epoch: 0   Global Step: 3010   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:14:38,882-Speed 140.04 samples/sec   Loss 1.3533   LearningRate 0.000031   Epoch: 0   Global Step: 3020   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:14:41,154-Speed 140.85 samples/sec   Loss 1.3413   LearningRate 0.000031   Epoch: 0   Global Step: 3030   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:14:43,420-Speed 141.29 samples/sec   Loss 1.3653   LearningRate 0.000031   Epoch: 0   Global Step: 3040   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:14:45,707-Speed 139.98 samples/sec   Loss 1.3482   LearningRate 0.000031   Epoch: 0   Global Step: 3050   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:14:47,986-Speed 140.39 samples/sec   Loss 1.3489   LearningRate 0.000031   Epoch: 0   Global Step: 3060   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:14:50,270-Speed 140.18 samples/sec   Loss 1.3268   LearningRate 0.000031   Epoch: 0   Global Step: 3070   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:14:52,551-Speed 140.36 samples/sec   Loss 1.3311   LearningRate 0.000031   Epoch: 0   Global Step: 3080   Fp16 Grad Scale: 131072   Required: 4 hours
Training: 2023-08-17 21:14:54,827-Speed 140.60 samples/sec   Loss 1.3139   LearningRate 0.000031   Epoch: 0   Global Step: 3090   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:14:57,112-Speed 140.07 samples/sec   Loss 1.3248   LearningRate 0.000031   Epoch: 0   Global Step: 3100   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:14:59,405-Speed 139.57 samples/sec   Loss 1.3357   LearningRate 0.000031   Epoch: 0   Global Step: 3110   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:15:01,698-Speed 139.63 samples/sec   Loss 1.3752   LearningRate 0.000031   Epoch: 0   Global Step: 3120   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:15:03,986-Speed 139.90 samples/sec   Loss 1.3633   LearningRate 0.000031   Epoch: 0   Global Step: 3130   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:15:06,282-Speed 139.45 samples/sec   Loss 1.3624   LearningRate 0.000031   Epoch: 0   Global Step: 3140   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:15:08,567-Speed 140.07 samples/sec   Loss 1.3387   LearningRate 0.000031   Epoch: 0   Global Step: 3150   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:15:10,844-Speed 140.56 samples/sec   Loss 1.3150   LearningRate 0.000031   Epoch: 0   Global Step: 3160   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:15:13,120-Speed 140.61 samples/sec   Loss 1.3687   LearningRate 0.000031   Epoch: 0   Global Step: 3170   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:15:15,417-Speed 139.36 samples/sec   Loss 1.3707   LearningRate 0.000031   Epoch: 0   Global Step: 3180   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:15:17,722-Speed 138.88 samples/sec   Loss 1.3426   LearningRate 0.000031   Epoch: 0   Global Step: 3190   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:15:20,009-Speed 139.97 samples/sec   Loss 1.3516   LearningRate 0.000031   Epoch: 0   Global Step: 3200   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:15:22,292-Speed 140.23 samples/sec   Loss 1.3288   LearningRate 0.000031   Epoch: 0   Global Step: 3210   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:15:24,583-Speed 139.68 samples/sec   Loss 1.3818   LearningRate 0.000031   Epoch: 0   Global Step: 3220   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:15:26,885-Speed 139.08 samples/sec   Loss 1.3286   LearningRate 0.000031   Epoch: 0   Global Step: 3230   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:15:29,178-Speed 139.54 samples/sec   Loss 1.3323   LearningRate 0.000031   Epoch: 0   Global Step: 3240   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:15:31,469-Speed 139.75 samples/sec   Loss 1.3274   LearningRate 0.000031   Epoch: 0   Global Step: 3250   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:15:33,758-Speed 139.84 samples/sec   Loss 1.3624   LearningRate 0.000031   Epoch: 0   Global Step: 3260   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:15:36,021-Speed 141.41 samples/sec   Loss 1.3705   LearningRate 0.000031   Epoch: 0   Global Step: 3270   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:15:38,306-Speed 140.10 samples/sec   Loss 1.3123   LearningRate 0.000031   Epoch: 0   Global Step: 3280   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:15:40,579-Speed 140.81 samples/sec   Loss 1.3786   LearningRate 0.000031   Epoch: 0   Global Step: 3290   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:15:42,868-Speed 139.88 samples/sec   Loss 1.3568   LearningRate 0.000031   Epoch: 0   Global Step: 3300   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:15:45,129-Speed 141.53 samples/sec   Loss 1.3241   LearningRate 0.000031   Epoch: 0   Global Step: 3310   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:15:47,408-Speed 140.46 samples/sec   Loss 1.3400   LearningRate 0.000031   Epoch: 0   Global Step: 3320   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:15:49,683-Speed 140.70 samples/sec   Loss 1.3594   LearningRate 0.000031   Epoch: 0   Global Step: 3330   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:15:51,969-Speed 140.06 samples/sec   Loss 1.3495   LearningRate 0.000031   Epoch: 0   Global Step: 3340   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:15:54,241-Speed 140.86 samples/sec   Loss 1.3605   LearningRate 0.000031   Epoch: 0   Global Step: 3350   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:15:56,513-Speed 140.89 samples/sec   Loss 1.3675   LearningRate 0.000031   Epoch: 0   Global Step: 3360   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:15:58,789-Speed 140.67 samples/sec   Loss 1.3000   LearningRate 0.000031   Epoch: 0   Global Step: 3370   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:16:01,057-Speed 141.10 samples/sec   Loss 1.3302   LearningRate 0.000031   Epoch: 0   Global Step: 3380   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:16:03,344-Speed 140.00 samples/sec   Loss 1.3288   LearningRate 0.000031   Epoch: 0   Global Step: 3390   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:16:05,618-Speed 140.75 samples/sec   Loss 1.3493   LearningRate 0.000031   Epoch: 0   Global Step: 3400   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:16:07,907-Speed 139.83 samples/sec   Loss 1.3216   LearningRate 0.000031   Epoch: 0   Global Step: 3410   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:16:10,184-Speed 140.60 samples/sec   Loss 1.3428   LearningRate 0.000031   Epoch: 0   Global Step: 3420   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:16:12,478-Speed 139.53 samples/sec   Loss 1.2920   LearningRate 0.000031   Epoch: 0   Global Step: 3430   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:16:14,762-Speed 140.15 samples/sec   Loss 1.3277   LearningRate 0.000031   Epoch: 0   Global Step: 3440   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:16:17,037-Speed 140.70 samples/sec   Loss 1.3427   LearningRate 0.000031   Epoch: 0   Global Step: 3450   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:16:19,322-Speed 140.09 samples/sec   Loss 1.3502   LearningRate 0.000031   Epoch: 0   Global Step: 3460   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:16:21,614-Speed 139.60 samples/sec   Loss 1.3407   LearningRate 0.000031   Epoch: 0   Global Step: 3470   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:16:23,902-Speed 139.90 samples/sec   Loss 1.3248   LearningRate 0.000031   Epoch: 0   Global Step: 3480   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:16:26,199-Speed 139.36 samples/sec   Loss 1.3409   LearningRate 0.000031   Epoch: 0   Global Step: 3490   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:16:28,506-Speed 138.78 samples/sec   Loss 1.3631   LearningRate 0.000031   Epoch: 0   Global Step: 3500   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:16:30,807-Speed 139.09 samples/sec   Loss 1.2981   LearningRate 0.000031   Epoch: 0   Global Step: 3510   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:16:33,101-Speed 139.51 samples/sec   Loss 1.2982   LearningRate 0.000031   Epoch: 0   Global Step: 3520   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:16:35,400-Speed 139.24 samples/sec   Loss 1.3623   LearningRate 0.000031   Epoch: 0   Global Step: 3530   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:16:37,704-Speed 138.91 samples/sec   Loss 1.3416   LearningRate 0.000031   Epoch: 0   Global Step: 3540   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:16:40,026-Speed 137.86 samples/sec   Loss 1.3440   LearningRate 0.000031   Epoch: 0   Global Step: 3550   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:16:42,303-Speed 140.62 samples/sec   Loss 1.3105   LearningRate 0.000031   Epoch: 0   Global Step: 3560   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:16:44,622-Speed 138.00 samples/sec   Loss 1.3275   LearningRate 0.000031   Epoch: 0   Global Step: 3570   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:16:46,922-Speed 139.16 samples/sec   Loss 1.2990   LearningRate 0.000031   Epoch: 0   Global Step: 3580   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:16:49,236-Speed 138.32 samples/sec   Loss 1.2897   LearningRate 0.000031   Epoch: 0   Global Step: 3590   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:16:51,517-Speed 140.32 samples/sec   Loss 1.3531   LearningRate 0.000031   Epoch: 0   Global Step: 3600   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:16:53,806-Speed 139.85 samples/sec   Loss 1.3324   LearningRate 0.000031   Epoch: 0   Global Step: 3610   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:16:56,092-Speed 140.01 samples/sec   Loss 1.3012   LearningRate 0.000031   Epoch: 0   Global Step: 3620   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:16:58,373-Speed 140.38 samples/sec   Loss 1.3207   LearningRate 0.000031   Epoch: 0   Global Step: 3630   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:17:00,663-Speed 139.76 samples/sec   Loss 1.3221   LearningRate 0.000031   Epoch: 0   Global Step: 3640   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:17:02,957-Speed 139.50 samples/sec   Loss 1.3658   LearningRate 0.000031   Epoch: 0   Global Step: 3650   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:17:05,251-Speed 139.58 samples/sec   Loss 1.3344   LearningRate 0.000031   Epoch: 0   Global Step: 3660   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:17:07,547-Speed 139.41 samples/sec   Loss 1.3486   LearningRate 0.000031   Epoch: 0   Global Step: 3670   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:17:09,829-Speed 140.27 samples/sec   Loss 1.3368   LearningRate 0.000031   Epoch: 0   Global Step: 3680   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:17:12,123-Speed 139.51 samples/sec   Loss 1.3838   LearningRate 0.000031   Epoch: 0   Global Step: 3690   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:17:14,409-Speed 140.06 samples/sec   Loss 1.3196   LearningRate 0.000031   Epoch: 0   Global Step: 3700   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:17:16,688-Speed 140.44 samples/sec   Loss 1.3600   LearningRate 0.000031   Epoch: 0   Global Step: 3710   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:17:18,978-Speed 139.76 samples/sec   Loss 1.3364   LearningRate 0.000031   Epoch: 0   Global Step: 3720   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:17:21,253-Speed 140.67 samples/sec   Loss 1.4035   LearningRate 0.000031   Epoch: 0   Global Step: 3730   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:17:23,535-Speed 140.29 samples/sec   Loss 1.3270   LearningRate 0.000031   Epoch: 0   Global Step: 3740   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:17:25,832-Speed 139.36 samples/sec   Loss 1.3112   LearningRate 0.000031   Epoch: 0   Global Step: 3750   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:17:28,125-Speed 139.61 samples/sec   Loss 1.2981   LearningRate 0.000031   Epoch: 0   Global Step: 3760   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:17:30,409-Speed 140.12 samples/sec   Loss 1.3781   LearningRate 0.000031   Epoch: 0   Global Step: 3770   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:17:32,698-Speed 139.82 samples/sec   Loss 1.3269   LearningRate 0.000031   Epoch: 0   Global Step: 3780   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:17:34,995-Speed 139.39 samples/sec   Loss 1.3506   LearningRate 0.000031   Epoch: 0   Global Step: 3790   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:17:37,296-Speed 139.12 samples/sec   Loss 1.3524   LearningRate 0.000031   Epoch: 0   Global Step: 3800   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:17:39,567-Speed 140.96 samples/sec   Loss 1.3424   LearningRate 0.000031   Epoch: 0   Global Step: 3810   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:17:41,872-Speed 138.87 samples/sec   Loss 1.3251   LearningRate 0.000031   Epoch: 0   Global Step: 3820   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:17:44,183-Speed 138.47 samples/sec   Loss 1.3231   LearningRate 0.000031   Epoch: 0   Global Step: 3830   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:17:46,479-Speed 139.41 samples/sec   Loss 1.3063   LearningRate 0.000031   Epoch: 0   Global Step: 3840   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:17:48,776-Speed 139.38 samples/sec   Loss 1.2993   LearningRate 0.000031   Epoch: 0   Global Step: 3850   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:17:51,068-Speed 139.65 samples/sec   Loss 1.3256   LearningRate 0.000031   Epoch: 0   Global Step: 3860   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:17:53,356-Speed 139.85 samples/sec   Loss 1.3325   LearningRate 0.000031   Epoch: 0   Global Step: 3870   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:17:55,649-Speed 139.64 samples/sec   Loss 1.3191   LearningRate 0.000031   Epoch: 0   Global Step: 3880   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:17:57,947-Speed 139.24 samples/sec   Loss 1.3200   LearningRate 0.000031   Epoch: 0   Global Step: 3890   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:18:00,236-Speed 139.86 samples/sec   Loss 1.3144   LearningRate 0.000031   Epoch: 0   Global Step: 3900   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:18:02,540-Speed 138.93 samples/sec   Loss 1.3246   LearningRate 0.000031   Epoch: 0   Global Step: 3910   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:18:04,839-Speed 139.21 samples/sec   Loss 1.3008   LearningRate 0.000031   Epoch: 0   Global Step: 3920   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:18:07,106-Speed 141.23 samples/sec   Loss 1.3346   LearningRate 0.000031   Epoch: 0   Global Step: 3930   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:18:09,390-Speed 140.17 samples/sec   Loss 1.3295   LearningRate 0.000031   Epoch: 0   Global Step: 3940   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:18:11,683-Speed 139.53 samples/sec   Loss 1.3467   LearningRate 0.000031   Epoch: 0   Global Step: 3950   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:18:13,961-Speed 140.57 samples/sec   Loss 1.3223   LearningRate 0.000031   Epoch: 0   Global Step: 3960   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:18:16,250-Speed 139.82 samples/sec   Loss 1.2907   LearningRate 0.000031   Epoch: 0   Global Step: 3970   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:18:18,539-Speed 139.83 samples/sec   Loss 1.3427   LearningRate 0.000031   Epoch: 0   Global Step: 3980   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:18:20,843-Speed 138.96 samples/sec   Loss 1.3268   LearningRate 0.000031   Epoch: 0   Global Step: 3990   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:18:22,912-Val on RAF/AffectNet:
Training: 2023-08-17 21:18:23,022-Test: [0/48]	Time 0.110 (0.110)	Loss 0.6401 (0.6401)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-17 21:18:24,094-Test: [10/48]	Time 0.107 (0.107)	Loss 0.6463 (0.6343)	Acc@1 87.500 (90.625)	Acc@5 98.438 (99.148)	Mem 5268MB
Training: 2023-08-17 21:18:25,159-Test: [20/48]	Time 0.105 (0.107)	Loss 0.6919 (0.6378)	Acc@1 84.375 (90.327)	Acc@5 100.000 (99.405)	Mem 5268MB
Training: 2023-08-17 21:18:26,250-Test: [30/48]	Time 0.111 (0.108)	Loss 0.7689 (0.6464)	Acc@1 82.812 (89.919)	Acc@5 96.875 (99.294)	Mem 5268MB
Training: 2023-08-17 21:18:27,321-Test: [40/48]	Time 0.105 (0.108)	Loss 0.5911 (0.6576)	Acc@1 95.312 (89.329)	Acc@5 100.000 (99.238)	Mem 5268MB
Training: 2023-08-17 21:18:28,069-[3999]Expression Loss: 0.65637
Training: 2023-08-17 21:18:28,069-[3999]Expression Acc@1: 89.40678
Training: 2023-08-17 21:18:28,069-[3999]Expression Acc@1-Highest: 89.40678
Training: 2023-08-17 21:18:28,069-[3999]Expression Acc@5: 99.21773
Training: 2023-08-17 21:18:28,069-[3999]Expression Acc@5-Highest: 99.25033
Training: 2023-08-17 21:18:28,069-[3999]10 Times Expression Acc@1: 85.80508
Training: 2023-08-17 21:18:28,069-[3999]10 Times Expression Acc@1-Highest: 85.80508
Training: 2023-08-17 21:18:28,298-Speed 42.92 samples/sec   Loss 1.3281   LearningRate 0.000031   Epoch: 0   Global Step: 4000   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:18:30,570-Speed 140.88 samples/sec   Loss 1.3560   LearningRate 0.000031   Epoch: 0   Global Step: 4010   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:18:32,845-Speed 140.72 samples/sec   Loss 1.3301   LearningRate 0.000031   Epoch: 0   Global Step: 4020   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:18:35,105-Speed 141.66 samples/sec   Loss 1.3469   LearningRate 0.000031   Epoch: 0   Global Step: 4030   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:18:37,358-Speed 142.04 samples/sec   Loss 1.2856   LearningRate 0.000031   Epoch: 0   Global Step: 4040   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:18:39,629-Speed 140.96 samples/sec   Loss 1.3082   LearningRate 0.000031   Epoch: 0   Global Step: 4050   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:18:41,904-Speed 140.65 samples/sec   Loss 1.3317   LearningRate 0.000031   Epoch: 0   Global Step: 4060   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:18:44,171-Speed 141.24 samples/sec   Loss 1.2979   LearningRate 0.000031   Epoch: 0   Global Step: 4070   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:18:46,449-Speed 140.52 samples/sec   Loss 1.2979   LearningRate 0.000031   Epoch: 0   Global Step: 4080   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:18:48,709-Speed 141.59 samples/sec   Loss 1.2904   LearningRate 0.000031   Epoch: 0   Global Step: 4090   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:18:50,996-Speed 139.95 samples/sec   Loss 1.2921   LearningRate 0.000031   Epoch: 0   Global Step: 4100   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:18:53,297-Speed 139.14 samples/sec   Loss 1.3361   LearningRate 0.000031   Epoch: 0   Global Step: 4110   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:18:55,586-Speed 139.86 samples/sec   Loss 1.3006   LearningRate 0.000031   Epoch: 0   Global Step: 4120   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:18:57,880-Speed 139.51 samples/sec   Loss 1.3311   LearningRate 0.000031   Epoch: 0   Global Step: 4130   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:19:00,159-Speed 140.47 samples/sec   Loss 1.3243   LearningRate 0.000031   Epoch: 0   Global Step: 4140   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:19:02,446-Speed 139.95 samples/sec   Loss 1.2793   LearningRate 0.000031   Epoch: 0   Global Step: 4150   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:19:04,723-Speed 140.50 samples/sec   Loss 1.3222   LearningRate 0.000031   Epoch: 0   Global Step: 4160   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:19:07,012-Speed 139.88 samples/sec   Loss 1.3049   LearningRate 0.000031   Epoch: 0   Global Step: 4170   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:19:09,291-Speed 140.43 samples/sec   Loss 1.3521   LearningRate 0.000031   Epoch: 0   Global Step: 4180   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:19:11,547-Speed 141.92 samples/sec   Loss 1.3473   LearningRate 0.000031   Epoch: 0   Global Step: 4190   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:19:13,824-Speed 140.53 samples/sec   Loss 1.3113   LearningRate 0.000031   Epoch: 0   Global Step: 4200   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:19:16,111-Speed 139.98 samples/sec   Loss 1.3359   LearningRate 0.000031   Epoch: 0   Global Step: 4210   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:19:18,396-Speed 140.06 samples/sec   Loss 1.3193   LearningRate 0.000031   Epoch: 0   Global Step: 4220   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:19:20,687-Speed 139.74 samples/sec   Loss 1.3402   LearningRate 0.000031   Epoch: 0   Global Step: 4230   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:19:22,978-Speed 139.68 samples/sec   Loss 1.3312   LearningRate 0.000031   Epoch: 0   Global Step: 4240   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:19:25,271-Speed 139.60 samples/sec   Loss 1.2904   LearningRate 0.000031   Epoch: 0   Global Step: 4250   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:19:27,549-Speed 140.49 samples/sec   Loss 1.3139   LearningRate 0.000031   Epoch: 0   Global Step: 4260   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:19:29,830-Speed 140.35 samples/sec   Loss 1.3401   LearningRate 0.000031   Epoch: 0   Global Step: 4270   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:19:32,119-Speed 139.79 samples/sec   Loss 1.3054   LearningRate 0.000031   Epoch: 0   Global Step: 4280   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:19:34,407-Speed 139.96 samples/sec   Loss 1.3195   LearningRate 0.000031   Epoch: 0   Global Step: 4290   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:19:36,679-Speed 140.86 samples/sec   Loss 1.3247   LearningRate 0.000031   Epoch: 0   Global Step: 4300   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:19:38,964-Speed 140.07 samples/sec   Loss 1.2899   LearningRate 0.000031   Epoch: 0   Global Step: 4310   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:19:41,249-Speed 140.09 samples/sec   Loss 1.2861   LearningRate 0.000031   Epoch: 0   Global Step: 4320   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:19:43,539-Speed 139.75 samples/sec   Loss 1.3052   LearningRate 0.000031   Epoch: 0   Global Step: 4330   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:19:45,825-Speed 140.04 samples/sec   Loss 1.3418   LearningRate 0.000031   Epoch: 0   Global Step: 4340   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:19:48,113-Speed 139.86 samples/sec   Loss 1.3105   LearningRate 0.000031   Epoch: 0   Global Step: 4350   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:19:50,379-Speed 141.26 samples/sec   Loss 1.3033   LearningRate 0.000031   Epoch: 0   Global Step: 4360   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:19:52,664-Speed 140.06 samples/sec   Loss 1.3103   LearningRate 0.000031   Epoch: 0   Global Step: 4370   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:19:54,946-Speed 140.26 samples/sec   Loss 1.3414   LearningRate 0.000031   Epoch: 0   Global Step: 4380   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:19:57,236-Speed 139.80 samples/sec   Loss 1.3142   LearningRate 0.000031   Epoch: 0   Global Step: 4390   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:19:59,540-Speed 138.91 samples/sec   Loss 1.3052   LearningRate 0.000031   Epoch: 0   Global Step: 4400   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:20:01,838-Speed 139.31 samples/sec   Loss 1.3132   LearningRate 0.000031   Epoch: 0   Global Step: 4410   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:20:04,142-Speed 138.92 samples/sec   Loss 1.2924   LearningRate 0.000031   Epoch: 0   Global Step: 4420   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:20:06,419-Speed 140.55 samples/sec   Loss 1.3098   LearningRate 0.000031   Epoch: 0   Global Step: 4430   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:20:08,721-Speed 139.07 samples/sec   Loss 1.2985   LearningRate 0.000031   Epoch: 0   Global Step: 4440   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:20:10,997-Speed 140.63 samples/sec   Loss 1.3176   LearningRate 0.000031   Epoch: 0   Global Step: 4450   Fp16 Grad Scale: 16384   Required: 4 hours
Training: 2023-08-17 21:20:13,296-Speed 139.22 samples/sec   Loss 1.3029   LearningRate 0.000031   Epoch: 0   Global Step: 4460   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:20:15,571-Speed 140.71 samples/sec   Loss 1.3096   LearningRate 0.000031   Epoch: 0   Global Step: 4470   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:20:17,845-Speed 140.73 samples/sec   Loss 1.3116   LearningRate 0.000031   Epoch: 0   Global Step: 4480   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:20:20,105-Speed 141.64 samples/sec   Loss 1.3311   LearningRate 0.000031   Epoch: 0   Global Step: 4490   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:20:22,370-Speed 141.33 samples/sec   Loss 1.3036   LearningRate 0.000031   Epoch: 0   Global Step: 4500   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:20:24,644-Speed 140.76 samples/sec   Loss 1.2782   LearningRate 0.000031   Epoch: 0   Global Step: 4510   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:20:26,915-Speed 140.90 samples/sec   Loss 1.2730   LearningRate 0.000031   Epoch: 0   Global Step: 4520   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:20:29,187-Speed 140.92 samples/sec   Loss 1.2921   LearningRate 0.000031   Epoch: 0   Global Step: 4530   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:20:31,466-Speed 140.44 samples/sec   Loss 1.3351   LearningRate 0.000031   Epoch: 0   Global Step: 4540   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:20:33,726-Speed 141.63 samples/sec   Loss 1.3329   LearningRate 0.000031   Epoch: 0   Global Step: 4550   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:20:36,000-Speed 140.75 samples/sec   Loss 1.3407   LearningRate 0.000031   Epoch: 0   Global Step: 4560   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:20:38,269-Speed 141.05 samples/sec   Loss 1.3116   LearningRate 0.000031   Epoch: 0   Global Step: 4570   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:20:40,537-Speed 141.13 samples/sec   Loss 1.2797   LearningRate 0.000031   Epoch: 0   Global Step: 4580   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:20:42,825-Speed 139.90 samples/sec   Loss 1.2904   LearningRate 0.000031   Epoch: 0   Global Step: 4590   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:20:45,118-Speed 139.62 samples/sec   Loss 1.3158   LearningRate 0.000031   Epoch: 0   Global Step: 4600   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:20:47,431-Speed 138.39 samples/sec   Loss 1.3038   LearningRate 0.000031   Epoch: 0   Global Step: 4610   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:20:49,723-Speed 139.61 samples/sec   Loss 1.3347   LearningRate 0.000031   Epoch: 0   Global Step: 4620   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:20:52,012-Speed 139.84 samples/sec   Loss 1.3117   LearningRate 0.000031   Epoch: 0   Global Step: 4630   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:20:54,300-Speed 139.91 samples/sec   Loss 1.3131   LearningRate 0.000031   Epoch: 0   Global Step: 4640   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:20:56,595-Speed 139.48 samples/sec   Loss 1.2971   LearningRate 0.000031   Epoch: 0   Global Step: 4650   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:20:58,891-Speed 139.40 samples/sec   Loss 1.3427   LearningRate 0.000031   Epoch: 0   Global Step: 4660   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:21:01,179-Speed 139.95 samples/sec   Loss 1.3180   LearningRate 0.000031   Epoch: 0   Global Step: 4670   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:21:03,471-Speed 139.61 samples/sec   Loss 1.3284   LearningRate 0.000031   Epoch: 0   Global Step: 4680   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:21:05,770-Speed 139.25 samples/sec   Loss 1.3597   LearningRate 0.000031   Epoch: 0   Global Step: 4690   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:21:08,056-Speed 140.01 samples/sec   Loss 1.2661   LearningRate 0.000031   Epoch: 0   Global Step: 4700   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:21:10,350-Speed 139.53 samples/sec   Loss 1.3321   LearningRate 0.000031   Epoch: 0   Global Step: 4710   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:21:12,666-Speed 138.25 samples/sec   Loss 1.2964   LearningRate 0.000031   Epoch: 0   Global Step: 4720   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:21:14,968-Speed 139.05 samples/sec   Loss 1.2996   LearningRate 0.000031   Epoch: 0   Global Step: 4730   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:21:17,283-Speed 138.25 samples/sec   Loss 1.3454   LearningRate 0.000031   Epoch: 0   Global Step: 4740   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:21:19,570-Speed 139.96 samples/sec   Loss 1.2744   LearningRate 0.000031   Epoch: 0   Global Step: 4750   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:21:21,866-Speed 139.42 samples/sec   Loss 1.2918   LearningRate 0.000031   Epoch: 0   Global Step: 4760   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:21:24,171-Speed 138.88 samples/sec   Loss 1.3210   LearningRate 0.000031   Epoch: 0   Global Step: 4770   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:21:26,474-Speed 138.96 samples/sec   Loss 1.2916   LearningRate 0.000031   Epoch: 0   Global Step: 4780   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:21:28,777-Speed 139.02 samples/sec   Loss 1.2845   LearningRate 0.000031   Epoch: 0   Global Step: 4790   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:21:31,078-Speed 139.11 samples/sec   Loss 1.2765   LearningRate 0.000031   Epoch: 0   Global Step: 4800   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:21:33,363-Speed 140.04 samples/sec   Loss 1.3179   LearningRate 0.000031   Epoch: 0   Global Step: 4810   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:21:35,660-Speed 139.36 samples/sec   Loss 1.3077   LearningRate 0.000031   Epoch: 0   Global Step: 4820   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:21:37,972-Speed 138.46 samples/sec   Loss 1.3096   LearningRate 0.000031   Epoch: 0   Global Step: 4830   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:21:40,245-Speed 140.85 samples/sec   Loss 1.2949   LearningRate 0.000031   Epoch: 0   Global Step: 4840   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:21:42,536-Speed 139.72 samples/sec   Loss 1.3106   LearningRate 0.000031   Epoch: 0   Global Step: 4850   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:21:44,828-Speed 139.59 samples/sec   Loss 1.2599   LearningRate 0.000031   Epoch: 0   Global Step: 4860   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:21:47,100-Speed 140.93 samples/sec   Loss 1.3184   LearningRate 0.000031   Epoch: 0   Global Step: 4870   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:21:49,394-Speed 139.50 samples/sec   Loss 1.2932   LearningRate 0.000031   Epoch: 0   Global Step: 4880   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:21:51,680-Speed 140.06 samples/sec   Loss 1.3102   LearningRate 0.000031   Epoch: 0   Global Step: 4890   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:21:53,978-Speed 139.26 samples/sec   Loss 1.2974   LearningRate 0.000031   Epoch: 0   Global Step: 4900   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:21:56,270-Speed 139.70 samples/sec   Loss 1.2522   LearningRate 0.000031   Epoch: 0   Global Step: 4910   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:21:58,565-Speed 139.48 samples/sec   Loss 1.2621   LearningRate 0.000031   Epoch: 0   Global Step: 4920   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:22:00,856-Speed 139.71 samples/sec   Loss 1.2969   LearningRate 0.000031   Epoch: 0   Global Step: 4930   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:22:03,139-Speed 140.21 samples/sec   Loss 1.2896   LearningRate 0.000031   Epoch: 0   Global Step: 4940   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:22:05,429-Speed 139.73 samples/sec   Loss 1.2751   LearningRate 0.000031   Epoch: 0   Global Step: 4950   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:22:07,714-Speed 140.12 samples/sec   Loss 1.3304   LearningRate 0.000031   Epoch: 0   Global Step: 4960   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:22:09,985-Speed 140.95 samples/sec   Loss 1.3227   LearningRate 0.000031   Epoch: 0   Global Step: 4970   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:22:12,253-Speed 141.14 samples/sec   Loss 1.3068   LearningRate 0.000031   Epoch: 0   Global Step: 4980   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:22:14,534-Speed 140.30 samples/sec   Loss 1.3120   LearningRate 0.000031   Epoch: 0   Global Step: 4990   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:22:16,579-Val on RAF/AffectNet:
Training: 2023-08-17 21:22:16,685-Test: [0/48]	Time 0.106 (0.106)	Loss 0.6516 (0.6516)	Acc@1 89.062 (89.062)	Acc@5 98.438 (98.438)	Mem 5268MB
Training: 2023-08-17 21:22:17,733-Test: [10/48]	Time 0.106 (0.105)	Loss 0.5896 (0.5961)	Acc@1 85.938 (89.915)	Acc@5 100.000 (99.148)	Mem 5268MB
Training: 2023-08-17 21:22:18,791-Test: [20/48]	Time 0.105 (0.105)	Loss 0.5661 (0.5918)	Acc@1 92.188 (90.402)	Acc@5 100.000 (98.884)	Mem 5268MB
Training: 2023-08-17 21:22:19,854-Test: [30/48]	Time 0.111 (0.106)	Loss 0.5133 (0.5816)	Acc@1 96.875 (91.079)	Acc@5 100.000 (99.093)	Mem 5268MB
Training: 2023-08-17 21:22:20,912-Test: [40/48]	Time 0.105 (0.106)	Loss 0.5334 (0.5848)	Acc@1 92.188 (90.930)	Acc@5 100.000 (99.162)	Mem 5268MB
Training: 2023-08-17 21:22:21,647-[4999]Expression Loss: 0.59099
Training: 2023-08-17 21:22:21,647-[4999]Expression Acc@1: 90.64537
Training: 2023-08-17 21:22:21,647-[4999]Expression Acc@1-Highest: 90.64537
Training: 2023-08-17 21:22:21,647-[4999]Expression Acc@5: 99.18514
Training: 2023-08-17 21:22:21,647-[4999]Expression Acc@5-Highest: 99.25033
Training: 2023-08-17 21:22:21,647-[4999]10 Times Expression Acc@1: 86.77314
Training: 2023-08-17 21:22:21,647-[4999]10 Times Expression Acc@1-Highest: 86.77314
Training: 2023-08-17 21:22:21,882-Speed 43.55 samples/sec   Loss 1.2918   LearningRate 0.000031   Epoch: 0   Global Step: 5000   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:22:24,152-Speed 141.03 samples/sec   Loss 1.2789   LearningRate 0.000031   Epoch: 0   Global Step: 5010   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:22:26,430-Speed 140.50 samples/sec   Loss 1.3154   LearningRate 0.000031   Epoch: 0   Global Step: 5020   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:22:28,718-Speed 139.88 samples/sec   Loss 1.3180   LearningRate 0.000031   Epoch: 0   Global Step: 5030   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:22:30,990-Speed 140.94 samples/sec   Loss 1.3317   LearningRate 0.000031   Epoch: 0   Global Step: 5040   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:22:33,264-Speed 140.74 samples/sec   Loss 1.3029   LearningRate 0.000031   Epoch: 0   Global Step: 5050   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:22:35,530-Speed 141.21 samples/sec   Loss 1.3192   LearningRate 0.000031   Epoch: 0   Global Step: 5060   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:22:37,817-Speed 139.98 samples/sec   Loss 1.3029   LearningRate 0.000031   Epoch: 0   Global Step: 5070   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:22:40,108-Speed 139.76 samples/sec   Loss 1.3279   LearningRate 0.000031   Epoch: 0   Global Step: 5080   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:22:42,384-Speed 140.63 samples/sec   Loss 1.3432   LearningRate 0.000031   Epoch: 0   Global Step: 5090   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:22:44,657-Speed 140.79 samples/sec   Loss 1.2804   LearningRate 0.000031   Epoch: 0   Global Step: 5100   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:22:46,938-Speed 140.33 samples/sec   Loss 1.2925   LearningRate 0.000031   Epoch: 0   Global Step: 5110   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:22:49,234-Speed 139.43 samples/sec   Loss 1.3153   LearningRate 0.000031   Epoch: 0   Global Step: 5120   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:22:51,521-Speed 139.96 samples/sec   Loss 1.3062   LearningRate 0.000031   Epoch: 0   Global Step: 5130   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:22:53,796-Speed 140.73 samples/sec   Loss 1.2694   LearningRate 0.000031   Epoch: 0   Global Step: 5140   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:22:56,078-Speed 140.23 samples/sec   Loss 1.3208   LearningRate 0.000031   Epoch: 0   Global Step: 5150   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:22:58,352-Speed 140.78 samples/sec   Loss 1.3200   LearningRate 0.000031   Epoch: 0   Global Step: 5160   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:23:00,623-Speed 140.92 samples/sec   Loss 1.2948   LearningRate 0.000031   Epoch: 0   Global Step: 5170   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:23:02,896-Speed 140.86 samples/sec   Loss 1.3121   LearningRate 0.000031   Epoch: 0   Global Step: 5180   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:23:05,169-Speed 140.82 samples/sec   Loss 1.3179   LearningRate 0.000031   Epoch: 0   Global Step: 5190   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:23:07,451-Speed 140.24 samples/sec   Loss 1.2937   LearningRate 0.000031   Epoch: 0   Global Step: 5200   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:23:09,722-Speed 140.99 samples/sec   Loss 1.3226   LearningRate 0.000031   Epoch: 0   Global Step: 5210   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:23:12,006-Speed 140.15 samples/sec   Loss 1.2962   LearningRate 0.000031   Epoch: 0   Global Step: 5220   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:23:14,273-Speed 141.17 samples/sec   Loss 1.3089   LearningRate 0.000031   Epoch: 0   Global Step: 5230   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:23:16,550-Speed 140.56 samples/sec   Loss 1.3030   LearningRate 0.000031   Epoch: 0   Global Step: 5240   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:23:18,816-Speed 141.28 samples/sec   Loss 1.3079   LearningRate 0.000031   Epoch: 0   Global Step: 5250   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:23:21,091-Speed 140.72 samples/sec   Loss 1.2473   LearningRate 0.000031   Epoch: 0   Global Step: 5260   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:23:23,376-Speed 140.07 samples/sec   Loss 1.2859   LearningRate 0.000031   Epoch: 0   Global Step: 5270   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:23:25,641-Speed 141.29 samples/sec   Loss 1.2669   LearningRate 0.000031   Epoch: 0   Global Step: 5280   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:23:27,911-Speed 141.03 samples/sec   Loss 1.2826   LearningRate 0.000031   Epoch: 0   Global Step: 5290   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:23:30,193-Speed 140.29 samples/sec   Loss 1.3088   LearningRate 0.000031   Epoch: 0   Global Step: 5300   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:23:32,474-Speed 140.31 samples/sec   Loss 1.3222   LearningRate 0.000031   Epoch: 0   Global Step: 5310   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:23:34,756-Speed 140.25 samples/sec   Loss 1.2403   LearningRate 0.000031   Epoch: 0   Global Step: 5320   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:23:37,033-Speed 140.60 samples/sec   Loss 1.2671   LearningRate 0.000031   Epoch: 0   Global Step: 5330   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:23:39,312-Speed 140.41 samples/sec   Loss 1.3095   LearningRate 0.000031   Epoch: 0   Global Step: 5340   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:23:41,592-Speed 140.41 samples/sec   Loss 1.3009   LearningRate 0.000031   Epoch: 0   Global Step: 5350   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:23:43,878-Speed 140.04 samples/sec   Loss 1.2954   LearningRate 0.000031   Epoch: 0   Global Step: 5360   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:23:46,157-Speed 140.45 samples/sec   Loss 1.2596   LearningRate 0.000031   Epoch: 0   Global Step: 5370   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:23:48,434-Speed 140.53 samples/sec   Loss 1.2924   LearningRate 0.000031   Epoch: 0   Global Step: 5380   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:23:50,700-Speed 141.30 samples/sec   Loss 1.2796   LearningRate 0.000031   Epoch: 0   Global Step: 5390   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:23:53,002-Speed 139.04 samples/sec   Loss 1.2959   LearningRate 0.000031   Epoch: 0   Global Step: 5400   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:23:55,285-Speed 140.24 samples/sec   Loss 1.2809   LearningRate 0.000031   Epoch: 0   Global Step: 5410   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:23:57,565-Speed 140.39 samples/sec   Loss 1.2687   LearningRate 0.000031   Epoch: 0   Global Step: 5420   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:23:59,836-Speed 140.93 samples/sec   Loss 1.2842   LearningRate 0.000031   Epoch: 0   Global Step: 5430   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:24:02,139-Speed 138.96 samples/sec   Loss 1.2671   LearningRate 0.000031   Epoch: 0   Global Step: 5440   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:24:04,451-Speed 138.47 samples/sec   Loss 1.3016   LearningRate 0.000031   Epoch: 0   Global Step: 5450   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:24:06,748-Speed 139.38 samples/sec   Loss 1.2825   LearningRate 0.000031   Epoch: 0   Global Step: 5460   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:24:09,024-Speed 140.62 samples/sec   Loss 1.3454   LearningRate 0.000031   Epoch: 0   Global Step: 5470   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:24:11,301-Speed 140.55 samples/sec   Loss 1.2812   LearningRate 0.000031   Epoch: 0   Global Step: 5480   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:24:13,596-Speed 139.49 samples/sec   Loss 1.2811   LearningRate 0.000031   Epoch: 0   Global Step: 5490   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:24:15,892-Speed 139.44 samples/sec   Loss 1.3157   LearningRate 0.000031   Epoch: 0   Global Step: 5500   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:24:18,148-Speed 141.89 samples/sec   Loss 1.3023   LearningRate 0.000031   Epoch: 0   Global Step: 5510   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:24:20,441-Speed 139.54 samples/sec   Loss 1.2835   LearningRate 0.000031   Epoch: 0   Global Step: 5520   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:24:22,734-Speed 139.63 samples/sec   Loss 1.3161   LearningRate 0.000031   Epoch: 0   Global Step: 5530   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:24:25,011-Speed 140.58 samples/sec   Loss 1.3248   LearningRate 0.000031   Epoch: 0   Global Step: 5540   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:24:27,289-Speed 140.48 samples/sec   Loss 1.2714   LearningRate 0.000031   Epoch: 0   Global Step: 5550   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:24:29,562-Speed 140.86 samples/sec   Loss 1.2415   LearningRate 0.000031   Epoch: 0   Global Step: 5560   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:24:31,841-Speed 140.47 samples/sec   Loss 1.2889   LearningRate 0.000031   Epoch: 0   Global Step: 5570   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:24:34,125-Speed 140.08 samples/sec   Loss 1.2722   LearningRate 0.000031   Epoch: 0   Global Step: 5580   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:24:36,403-Speed 140.58 samples/sec   Loss 1.2709   LearningRate 0.000031   Epoch: 0   Global Step: 5590   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:24:38,681-Speed 140.47 samples/sec   Loss 1.2861   LearningRate 0.000031   Epoch: 0   Global Step: 5600   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:24:40,960-Speed 140.50 samples/sec   Loss 1.3523   LearningRate 0.000031   Epoch: 0   Global Step: 5610   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:24:43,235-Speed 140.68 samples/sec   Loss 1.2832   LearningRate 0.000031   Epoch: 0   Global Step: 5620   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:24:45,496-Speed 141.57 samples/sec   Loss 1.2972   LearningRate 0.000031   Epoch: 0   Global Step: 5630   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:24:47,768-Speed 140.87 samples/sec   Loss 1.3027   LearningRate 0.000031   Epoch: 0   Global Step: 5640   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:24:50,035-Speed 141.21 samples/sec   Loss 1.2681   LearningRate 0.000031   Epoch: 0   Global Step: 5650   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:24:52,319-Speed 140.14 samples/sec   Loss 1.3070   LearningRate 0.000031   Epoch: 0   Global Step: 5660   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:24:54,586-Speed 141.17 samples/sec   Loss 1.2963   LearningRate 0.000031   Epoch: 0   Global Step: 5670   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:24:56,881-Speed 139.53 samples/sec   Loss 1.2721   LearningRate 0.000031   Epoch: 0   Global Step: 5680   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:24:59,171-Speed 139.73 samples/sec   Loss 1.2706   LearningRate 0.000031   Epoch: 0   Global Step: 5690   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:25:01,451-Speed 140.41 samples/sec   Loss 1.2693   LearningRate 0.000031   Epoch: 0   Global Step: 5700   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:25:03,754-Speed 138.98 samples/sec   Loss 1.2823   LearningRate 0.000031   Epoch: 0   Global Step: 5710   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:25:06,040-Speed 140.04 samples/sec   Loss 1.2973   LearningRate 0.000031   Epoch: 0   Global Step: 5720   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:25:08,310-Speed 140.97 samples/sec   Loss 1.2944   LearningRate 0.000031   Epoch: 0   Global Step: 5730   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:25:10,592-Speed 140.29 samples/sec   Loss 1.2639   LearningRate 0.000031   Epoch: 0   Global Step: 5740   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:25:12,880-Speed 139.90 samples/sec   Loss 1.2915   LearningRate 0.000031   Epoch: 0   Global Step: 5750   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:25:15,156-Speed 140.61 samples/sec   Loss 1.3074   LearningRate 0.000031   Epoch: 0   Global Step: 5760   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:25:17,435-Speed 140.45 samples/sec   Loss 1.2970   LearningRate 0.000031   Epoch: 0   Global Step: 5770   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:25:19,715-Speed 140.44 samples/sec   Loss 1.3282   LearningRate 0.000031   Epoch: 0   Global Step: 5780   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:25:21,995-Speed 140.37 samples/sec   Loss 1.2999   LearningRate 0.000031   Epoch: 0   Global Step: 5790   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:25:24,277-Speed 140.28 samples/sec   Loss 1.2879   LearningRate 0.000031   Epoch: 0   Global Step: 5800   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:25:26,553-Speed 140.63 samples/sec   Loss 1.2556   LearningRate 0.000031   Epoch: 0   Global Step: 5810   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:25:28,826-Speed 140.82 samples/sec   Loss 1.2438   LearningRate 0.000031   Epoch: 0   Global Step: 5820   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:25:31,079-Speed 142.07 samples/sec   Loss 1.3062   LearningRate 0.000031   Epoch: 0   Global Step: 5830   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:25:33,353-Speed 140.76 samples/sec   Loss 1.3122   LearningRate 0.000031   Epoch: 0   Global Step: 5840   Fp16 Grad Scale: 65536   Required: 4 hours
Training: 2023-08-17 21:25:35,610-Speed 141.77 samples/sec   Loss 1.3376   LearningRate 0.000031   Epoch: 0   Global Step: 5850   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:25:37,885-Speed 140.69 samples/sec   Loss 1.2698   LearningRate 0.000031   Epoch: 0   Global Step: 5860   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:25:40,157-Speed 140.89 samples/sec   Loss 1.2960   LearningRate 0.000031   Epoch: 0   Global Step: 5870   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:25:42,423-Speed 141.26 samples/sec   Loss 1.2916   LearningRate 0.000031   Epoch: 0   Global Step: 5880   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:25:44,690-Speed 141.20 samples/sec   Loss 1.2567   LearningRate 0.000031   Epoch: 0   Global Step: 5890   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:25:46,948-Speed 141.76 samples/sec   Loss 1.2713   LearningRate 0.000031   Epoch: 0   Global Step: 5900   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:25:49,218-Speed 140.98 samples/sec   Loss 1.2599   LearningRate 0.000031   Epoch: 0   Global Step: 5910   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:25:51,483-Speed 141.33 samples/sec   Loss 1.2947   LearningRate 0.000031   Epoch: 0   Global Step: 5920   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:25:53,748-Speed 141.30 samples/sec   Loss 1.2913   LearningRate 0.000031   Epoch: 0   Global Step: 5930   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:25:56,039-Speed 139.74 samples/sec   Loss 1.2979   LearningRate 0.000031   Epoch: 0   Global Step: 5940   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:25:58,306-Speed 141.14 samples/sec   Loss 1.2829   LearningRate 0.000031   Epoch: 0   Global Step: 5950   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:26:00,568-Speed 141.52 samples/sec   Loss 1.2859   LearningRate 0.000031   Epoch: 0   Global Step: 5960   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:26:02,821-Speed 142.11 samples/sec   Loss 1.2553   LearningRate 0.000031   Epoch: 0   Global Step: 5970   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:26:05,080-Speed 141.68 samples/sec   Loss 1.3034   LearningRate 0.000030   Epoch: 0   Global Step: 5980   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:26:07,343-Speed 141.46 samples/sec   Loss 1.2983   LearningRate 0.000030   Epoch: 0   Global Step: 5990   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:26:09,371-Val on RAF/AffectNet:
Training: 2023-08-17 21:26:09,482-Test: [0/48]	Time 0.111 (0.111)	Loss 0.5611 (0.5611)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)	Mem 5268MB
Training: 2023-08-17 21:26:10,551-Test: [10/48]	Time 0.107 (0.107)	Loss 0.4667 (0.5388)	Acc@1 95.312 (92.188)	Acc@5 100.000 (99.432)	Mem 5268MB
Training: 2023-08-17 21:26:11,600-Test: [20/48]	Time 0.104 (0.106)	Loss 0.4372 (0.5632)	Acc@1 98.438 (91.071)	Acc@5 100.000 (99.330)	Mem 5268MB
Training: 2023-08-17 21:26:12,645-Test: [30/48]	Time 0.105 (0.106)	Loss 0.7382 (0.5713)	Acc@1 85.938 (90.625)	Acc@5 96.875 (99.244)	Mem 5268MB
Training: 2023-08-17 21:26:13,692-Test: [40/48]	Time 0.107 (0.105)	Loss 0.6557 (0.5671)	Acc@1 85.938 (90.816)	Acc@5 96.875 (99.276)	Mem 5268MB
Training: 2023-08-17 21:26:14,422-[5999]Expression Loss: 0.56704
Training: 2023-08-17 21:26:14,422-[5999]Expression Acc@1: 90.84094
Training: 2023-08-17 21:26:14,422-[5999]Expression Acc@1-Highest: 90.84094
Training: 2023-08-17 21:26:14,422-[5999]Expression Acc@5: 99.28292
Training: 2023-08-17 21:26:14,422-[5999]Expression Acc@5-Highest: 99.28292
Training: 2023-08-17 21:26:14,422-[5999]10 Times Expression Acc@1: 87.45111
Training: 2023-08-17 21:26:14,422-[5999]10 Times Expression Acc@1-Highest: 87.45111
Training: 2023-08-17 21:26:15,011-Speed 41.73 samples/sec   Loss 1.3043   LearningRate 0.000030   Epoch: 0   Global Step: 6000   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:26:17,282-Speed 140.92 samples/sec   Loss 1.2678   LearningRate 0.000030   Epoch: 0   Global Step: 6010   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:26:19,548-Speed 141.31 samples/sec   Loss 1.2448   LearningRate 0.000030   Epoch: 0   Global Step: 6020   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:26:21,809-Speed 141.54 samples/sec   Loss 1.2997   LearningRate 0.000030   Epoch: 0   Global Step: 6030   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:26:24,082-Speed 140.82 samples/sec   Loss 1.2822   LearningRate 0.000030   Epoch: 0   Global Step: 6040   Fp16 Grad Scale: 32768   Required: 4 hours
Training: 2023-08-17 21:26:26,379-Speed 139.37 samples/sec   Loss 1.2872   LearningRate 0.000030   Epoch: 0   Global Step: 6050   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:26:28,668-Speed 139.85 samples/sec   Loss 1.3052   LearningRate 0.000030   Epoch: 0   Global Step: 6060   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:26:30,942-Speed 140.73 samples/sec   Loss 1.2751   LearningRate 0.000030   Epoch: 0   Global Step: 6070   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:26:33,218-Speed 140.65 samples/sec   Loss 1.2765   LearningRate 0.000030   Epoch: 0   Global Step: 6080   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:26:35,505-Speed 139.96 samples/sec   Loss 1.2958   LearningRate 0.000030   Epoch: 0   Global Step: 6090   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:26:37,788-Speed 140.24 samples/sec   Loss 1.2808   LearningRate 0.000030   Epoch: 0   Global Step: 6100   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:26:40,063-Speed 140.68 samples/sec   Loss 1.3121   LearningRate 0.000030   Epoch: 0   Global Step: 6110   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:26:42,327-Speed 141.36 samples/sec   Loss 1.3194   LearningRate 0.000030   Epoch: 0   Global Step: 6120   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:26:44,600-Speed 140.82 samples/sec   Loss 1.3124   LearningRate 0.000030   Epoch: 0   Global Step: 6130   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:26:46,890-Speed 139.75 samples/sec   Loss 1.2878   LearningRate 0.000030   Epoch: 0   Global Step: 6140   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:26:49,175-Speed 140.11 samples/sec   Loss 1.3385   LearningRate 0.000030   Epoch: 0   Global Step: 6150   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:26:51,486-Speed 138.55 samples/sec   Loss 1.3153   LearningRate 0.000030   Epoch: 0   Global Step: 6160   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:26:53,767-Speed 140.31 samples/sec   Loss 1.2637   LearningRate 0.000030   Epoch: 0   Global Step: 6170   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:26:56,054-Speed 139.95 samples/sec   Loss 1.2827   LearningRate 0.000030   Epoch: 0   Global Step: 6180   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:26:58,331-Speed 140.61 samples/sec   Loss 1.2734   LearningRate 0.000030   Epoch: 0   Global Step: 6190   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:27:00,627-Speed 139.37 samples/sec   Loss 1.3181   LearningRate 0.000030   Epoch: 0   Global Step: 6200   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:27:02,915-Speed 139.95 samples/sec   Loss 1.2826   LearningRate 0.000030   Epoch: 0   Global Step: 6210   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:27:05,189-Speed 140.72 samples/sec   Loss 1.2983   LearningRate 0.000030   Epoch: 0   Global Step: 6220   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:27:07,478-Speed 139.84 samples/sec   Loss 1.2659   LearningRate 0.000030   Epoch: 0   Global Step: 6230   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:27:09,748-Speed 141.01 samples/sec   Loss 1.2560   LearningRate 0.000030   Epoch: 0   Global Step: 6240   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:27:12,024-Speed 140.69 samples/sec   Loss 1.2782   LearningRate 0.000030   Epoch: 0   Global Step: 6250   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:27:14,325-Speed 139.11 samples/sec   Loss 1.2814   LearningRate 0.000030   Epoch: 0   Global Step: 6260   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:27:16,606-Speed 140.30 samples/sec   Loss 1.2596   LearningRate 0.000030   Epoch: 0   Global Step: 6270   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:27:18,880-Speed 140.78 samples/sec   Loss 1.2591   LearningRate 0.000030   Epoch: 0   Global Step: 6280   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:27:21,170-Speed 139.75 samples/sec   Loss 1.2413   LearningRate 0.000030   Epoch: 0   Global Step: 6290   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:27:23,448-Speed 140.50 samples/sec   Loss 1.2654   LearningRate 0.000030   Epoch: 0   Global Step: 6300   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:27:25,739-Speed 139.71 samples/sec   Loss 1.2668   LearningRate 0.000030   Epoch: 0   Global Step: 6310   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:27:28,034-Speed 139.49 samples/sec   Loss 1.2786   LearningRate 0.000030   Epoch: 0   Global Step: 6320   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:27:30,320-Speed 140.04 samples/sec   Loss 1.2694   LearningRate 0.000030   Epoch: 0   Global Step: 6330   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:27:32,611-Speed 139.70 samples/sec   Loss 1.2373   LearningRate 0.000030   Epoch: 0   Global Step: 6340   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:27:34,899-Speed 139.91 samples/sec   Loss 1.2757   LearningRate 0.000030   Epoch: 0   Global Step: 6350   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:27:37,175-Speed 140.67 samples/sec   Loss 1.2675   LearningRate 0.000030   Epoch: 0   Global Step: 6360   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:27:39,464-Speed 139.78 samples/sec   Loss 1.2895   LearningRate 0.000030   Epoch: 0   Global Step: 6370   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:27:41,790-Speed 137.61 samples/sec   Loss 1.2647   LearningRate 0.000030   Epoch: 0   Global Step: 6380   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:27:44,119-Speed 137.49 samples/sec   Loss 1.3084   LearningRate 0.000030   Epoch: 0   Global Step: 6390   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:27:46,378-Speed 141.64 samples/sec   Loss 1.2529   LearningRate 0.000030   Epoch: 0   Global Step: 6400   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:27:48,640-Speed 141.56 samples/sec   Loss 1.2692   LearningRate 0.000030   Epoch: 0   Global Step: 6410   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:27:50,901-Speed 141.56 samples/sec   Loss 1.3060   LearningRate 0.000030   Epoch: 0   Global Step: 6420   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:27:53,165-Speed 141.39 samples/sec   Loss 1.3177   LearningRate 0.000030   Epoch: 0   Global Step: 6430   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:27:55,423-Speed 141.76 samples/sec   Loss 1.2908   LearningRate 0.000030   Epoch: 0   Global Step: 6440   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:27:57,702-Speed 140.45 samples/sec   Loss 1.2762   LearningRate 0.000030   Epoch: 0   Global Step: 6450   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:27:59,975-Speed 140.83 samples/sec   Loss 1.3005   LearningRate 0.000030   Epoch: 0   Global Step: 6460   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:28:02,252-Speed 140.57 samples/sec   Loss 1.2899   LearningRate 0.000030   Epoch: 0   Global Step: 6470   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:28:04,534-Speed 140.27 samples/sec   Loss 1.3272   LearningRate 0.000030   Epoch: 0   Global Step: 6480   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:28:06,818-Speed 140.15 samples/sec   Loss 1.2865   LearningRate 0.000030   Epoch: 0   Global Step: 6490   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:28:09,089-Speed 140.96 samples/sec   Loss 1.3030   LearningRate 0.000030   Epoch: 0   Global Step: 6500   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:28:11,363-Speed 140.74 samples/sec   Loss 1.2572   LearningRate 0.000030   Epoch: 0   Global Step: 6510   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:28:13,634-Speed 140.92 samples/sec   Loss 1.2895   LearningRate 0.000030   Epoch: 0   Global Step: 6520   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:28:15,908-Speed 140.80 samples/sec   Loss 1.2658   LearningRate 0.000030   Epoch: 0   Global Step: 6530   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:28:18,200-Speed 139.66 samples/sec   Loss 1.2909   LearningRate 0.000030   Epoch: 0   Global Step: 6540   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:28:20,485-Speed 140.08 samples/sec   Loss 1.2579   LearningRate 0.000030   Epoch: 0   Global Step: 6550   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:28:22,772-Speed 139.95 samples/sec   Loss 1.2529   LearningRate 0.000030   Epoch: 0   Global Step: 6560   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:28:25,062-Speed 139.77 samples/sec   Loss 1.2563   LearningRate 0.000030   Epoch: 0   Global Step: 6570   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:28:27,356-Speed 139.53 samples/sec   Loss 1.2494   LearningRate 0.000030   Epoch: 0   Global Step: 6580   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:28:29,617-Speed 141.61 samples/sec   Loss 1.2810   LearningRate 0.000030   Epoch: 0   Global Step: 6590   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:28:31,881-Speed 141.36 samples/sec   Loss 1.2682   LearningRate 0.000030   Epoch: 0   Global Step: 6600   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:28:34,156-Speed 140.70 samples/sec   Loss 1.2363   LearningRate 0.000030   Epoch: 0   Global Step: 6610   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:28:36,435-Speed 140.46 samples/sec   Loss 1.2719   LearningRate 0.000030   Epoch: 0   Global Step: 6620   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:28:38,728-Speed 139.56 samples/sec   Loss 1.2820   LearningRate 0.000030   Epoch: 0   Global Step: 6630   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:28:41,022-Speed 139.52 samples/sec   Loss 1.3121   LearningRate 0.000030   Epoch: 0   Global Step: 6640   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:28:43,313-Speed 139.76 samples/sec   Loss 1.2808   LearningRate 0.000030   Epoch: 0   Global Step: 6650   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:28:45,606-Speed 139.55 samples/sec   Loss 1.2688   LearningRate 0.000030   Epoch: 0   Global Step: 6660   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:28:47,915-Speed 138.66 samples/sec   Loss 1.3141   LearningRate 0.000030   Epoch: 0   Global Step: 6670   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:28:50,210-Speed 139.44 samples/sec   Loss 1.2713   LearningRate 0.000030   Epoch: 0   Global Step: 6680   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:28:52,513-Speed 139.02 samples/sec   Loss 1.2464   LearningRate 0.000030   Epoch: 0   Global Step: 6690   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:28:54,818-Speed 138.84 samples/sec   Loss 1.2798   LearningRate 0.000030   Epoch: 0   Global Step: 6700   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:28:57,107-Speed 139.81 samples/sec   Loss 1.2880   LearningRate 0.000030   Epoch: 0   Global Step: 6710   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:28:59,400-Speed 139.62 samples/sec   Loss 1.2929   LearningRate 0.000030   Epoch: 0   Global Step: 6720   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:29:01,691-Speed 139.70 samples/sec   Loss 1.2664   LearningRate 0.000030   Epoch: 0   Global Step: 6730   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:29:03,995-Speed 138.97 samples/sec   Loss 1.2501   LearningRate 0.000030   Epoch: 0   Global Step: 6740   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:29:06,272-Speed 140.55 samples/sec   Loss 1.3076   LearningRate 0.000030   Epoch: 0   Global Step: 6750   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:29:08,570-Speed 139.28 samples/sec   Loss 1.2512   LearningRate 0.000030   Epoch: 0   Global Step: 6760   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:29:10,873-Speed 139.00 samples/sec   Loss 1.2886   LearningRate 0.000030   Epoch: 0   Global Step: 6770   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:29:13,159-Speed 139.98 samples/sec   Loss 1.2533   LearningRate 0.000030   Epoch: 0   Global Step: 6780   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:29:15,457-Speed 139.33 samples/sec   Loss 1.2714   LearningRate 0.000030   Epoch: 0   Global Step: 6790   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:29:17,743-Speed 139.99 samples/sec   Loss 1.2580   LearningRate 0.000030   Epoch: 0   Global Step: 6800   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:29:20,032-Speed 139.82 samples/sec   Loss 1.2599   LearningRate 0.000030   Epoch: 0   Global Step: 6810   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:29:22,315-Speed 140.21 samples/sec   Loss 1.2743   LearningRate 0.000030   Epoch: 0   Global Step: 6820   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:29:24,595-Speed 140.41 samples/sec   Loss 1.2576   LearningRate 0.000030   Epoch: 0   Global Step: 6830   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:29:26,885-Speed 139.79 samples/sec   Loss 1.2810   LearningRate 0.000030   Epoch: 0   Global Step: 6840   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:29:29,151-Speed 141.23 samples/sec   Loss 1.2538   LearningRate 0.000030   Epoch: 0   Global Step: 6850   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:29:31,420-Speed 141.06 samples/sec   Loss 1.2902   LearningRate 0.000030   Epoch: 0   Global Step: 6860   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:29:33,693-Speed 140.80 samples/sec   Loss 1.2913   LearningRate 0.000030   Epoch: 0   Global Step: 6870   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:29:35,980-Speed 139.99 samples/sec   Loss 1.2734   LearningRate 0.000030   Epoch: 0   Global Step: 6880   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:29:38,264-Speed 140.12 samples/sec   Loss 1.2914   LearningRate 0.000030   Epoch: 0   Global Step: 6890   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:29:40,541-Speed 140.54 samples/sec   Loss 1.2414   LearningRate 0.000030   Epoch: 0   Global Step: 6900   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:29:42,821-Speed 140.40 samples/sec   Loss 1.2913   LearningRate 0.000030   Epoch: 0   Global Step: 6910   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:29:45,114-Speed 139.62 samples/sec   Loss 1.2871   LearningRate 0.000030   Epoch: 0   Global Step: 6920   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:29:47,409-Speed 139.44 samples/sec   Loss 1.2630   LearningRate 0.000030   Epoch: 0   Global Step: 6930   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:29:49,693-Speed 140.14 samples/sec   Loss 1.2928   LearningRate 0.000030   Epoch: 0   Global Step: 6940   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:29:51,980-Speed 139.97 samples/sec   Loss 1.2453   LearningRate 0.000030   Epoch: 0   Global Step: 6950   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:29:54,263-Speed 140.20 samples/sec   Loss 1.2706   LearningRate 0.000030   Epoch: 0   Global Step: 6960   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:29:56,550-Speed 139.95 samples/sec   Loss 1.2819   LearningRate 0.000030   Epoch: 0   Global Step: 6970   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:29:58,850-Speed 139.18 samples/sec   Loss 1.2826   LearningRate 0.000030   Epoch: 0   Global Step: 6980   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:30:01,126-Speed 140.64 samples/sec   Loss 1.2533   LearningRate 0.000030   Epoch: 0   Global Step: 6990   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:30:03,177-Val on RAF/AffectNet:
Training: 2023-08-17 21:30:03,288-Test: [0/48]	Time 0.110 (0.110)	Loss 0.6730 (0.6730)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)	Mem 5268MB
Training: 2023-08-17 21:30:04,382-Test: [10/48]	Time 0.108 (0.109)	Loss 0.6669 (0.6023)	Acc@1 87.500 (91.051)	Acc@5 100.000 (99.432)	Mem 5268MB
Training: 2023-08-17 21:30:05,463-Test: [20/48]	Time 0.108 (0.109)	Loss 0.6548 (0.6216)	Acc@1 89.062 (89.881)	Acc@5 98.438 (99.182)	Mem 5268MB
Training: 2023-08-17 21:30:06,533-Test: [30/48]	Time 0.107 (0.108)	Loss 0.5700 (0.6149)	Acc@1 93.750 (90.373)	Acc@5 98.438 (99.244)	Mem 5268MB
Training: 2023-08-17 21:30:07,592-Test: [40/48]	Time 0.107 (0.108)	Loss 0.5499 (0.6217)	Acc@1 95.312 (90.396)	Acc@5 100.000 (99.276)	Mem 5268MB
Training: 2023-08-17 21:30:08,324-[6999]Expression Loss: 0.62174
Training: 2023-08-17 21:30:08,325-[6999]Expression Acc@1: 90.41721
Training: 2023-08-17 21:30:08,325-[6999]Expression Acc@1-Highest: 90.84094
Training: 2023-08-17 21:30:08,325-[6999]Expression Acc@5: 99.25033
Training: 2023-08-17 21:30:08,325-[6999]Expression Acc@5-Highest: 99.28292
Training: 2023-08-17 21:30:08,325-[6999]10 Times Expression Acc@1: 87.87484
Training: 2023-08-17 21:30:08,325-[6999]10 Times Expression Acc@1-Highest: 87.87484
Training: 2023-08-17 21:30:08,558-Speed 43.06 samples/sec   Loss 1.3101   LearningRate 0.000030   Epoch: 0   Global Step: 7000   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:30:10,873-Speed 138.27 samples/sec   Loss 1.2658   LearningRate 0.000030   Epoch: 0   Global Step: 7010   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:30:13,193-Speed 137.96 samples/sec   Loss 1.2973   LearningRate 0.000030   Epoch: 0   Global Step: 7020   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:30:15,510-Speed 138.14 samples/sec   Loss 1.2884   LearningRate 0.000030   Epoch: 0   Global Step: 7030   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:30:17,825-Speed 138.24 samples/sec   Loss 1.2730   LearningRate 0.000030   Epoch: 0   Global Step: 7040   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:30:20,145-Speed 138.00 samples/sec   Loss 1.2440   LearningRate 0.000030   Epoch: 0   Global Step: 7050   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:30:22,457-Speed 138.47 samples/sec   Loss 1.2867   LearningRate 0.000030   Epoch: 0   Global Step: 7060   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:30:24,758-Speed 139.10 samples/sec   Loss 1.2416   LearningRate 0.000030   Epoch: 0   Global Step: 7070   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:30:27,062-Speed 138.94 samples/sec   Loss 1.2816   LearningRate 0.000030   Epoch: 0   Global Step: 7080   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:30:29,361-Speed 139.24 samples/sec   Loss 1.2797   LearningRate 0.000030   Epoch: 0   Global Step: 7090   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:30:31,642-Speed 140.33 samples/sec   Loss 1.2380   LearningRate 0.000030   Epoch: 0   Global Step: 7100   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:30:33,938-Speed 139.36 samples/sec   Loss 1.2762   LearningRate 0.000030   Epoch: 0   Global Step: 7110   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:30:36,224-Speed 140.07 samples/sec   Loss 1.2750   LearningRate 0.000030   Epoch: 0   Global Step: 7120   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:30:38,512-Speed 139.91 samples/sec   Loss 1.2776   LearningRate 0.000030   Epoch: 0   Global Step: 7130   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:30:40,808-Speed 139.40 samples/sec   Loss 1.2814   LearningRate 0.000030   Epoch: 0   Global Step: 7140   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:30:43,091-Speed 140.23 samples/sec   Loss 1.2550   LearningRate 0.000030   Epoch: 0   Global Step: 7150   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:30:45,390-Speed 139.21 samples/sec   Loss 1.2468   LearningRate 0.000030   Epoch: 0   Global Step: 7160   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:30:47,663-Speed 140.81 samples/sec   Loss 1.2402   LearningRate 0.000030   Epoch: 0   Global Step: 7170   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:30:49,927-Speed 141.38 samples/sec   Loss 1.2868   LearningRate 0.000030   Epoch: 0   Global Step: 7180   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:30:52,203-Speed 140.67 samples/sec   Loss 1.3101   LearningRate 0.000030   Epoch: 0   Global Step: 7190   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:30:54,480-Speed 140.57 samples/sec   Loss 1.2894   LearningRate 0.000030   Epoch: 0   Global Step: 7200   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:30:56,771-Speed 139.68 samples/sec   Loss 1.2539   LearningRate 0.000030   Epoch: 0   Global Step: 7210   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:30:59,053-Speed 140.27 samples/sec   Loss 1.2827   LearningRate 0.000030   Epoch: 0   Global Step: 7220   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:31:01,321-Speed 141.14 samples/sec   Loss 1.2529   LearningRate 0.000030   Epoch: 0   Global Step: 7230   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:31:03,630-Speed 138.64 samples/sec   Loss 1.2676   LearningRate 0.000030   Epoch: 0   Global Step: 7240   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:31:05,930-Speed 139.18 samples/sec   Loss 1.2432   LearningRate 0.000030   Epoch: 0   Global Step: 7250   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:31:08,227-Speed 139.37 samples/sec   Loss 1.2460   LearningRate 0.000030   Epoch: 0   Global Step: 7260   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:31:10,495-Speed 141.13 samples/sec   Loss 1.2660   LearningRate 0.000030   Epoch: 0   Global Step: 7270   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:31:12,771-Speed 140.58 samples/sec   Loss 1.2803   LearningRate 0.000030   Epoch: 0   Global Step: 7280   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:31:15,031-Speed 141.68 samples/sec   Loss 1.2647   LearningRate 0.000030   Epoch: 0   Global Step: 7290   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:31:17,309-Speed 140.47 samples/sec   Loss 1.2815   LearningRate 0.000030   Epoch: 0   Global Step: 7300   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:31:19,588-Speed 140.48 samples/sec   Loss 1.2644   LearningRate 0.000030   Epoch: 0   Global Step: 7310   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:31:21,878-Speed 139.77 samples/sec   Loss 1.2648   LearningRate 0.000030   Epoch: 0   Global Step: 7320   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:31:24,159-Speed 140.34 samples/sec   Loss 1.2466   LearningRate 0.000030   Epoch: 0   Global Step: 7330   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:31:26,452-Speed 139.59 samples/sec   Loss 1.2717   LearningRate 0.000030   Epoch: 0   Global Step: 7340   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:31:28,743-Speed 139.70 samples/sec   Loss 1.3004   LearningRate 0.000030   Epoch: 0   Global Step: 7350   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:31:31,027-Speed 140.18 samples/sec   Loss 1.2607   LearningRate 0.000030   Epoch: 0   Global Step: 7360   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:31:33,315-Speed 139.89 samples/sec   Loss 1.2770   LearningRate 0.000030   Epoch: 0   Global Step: 7370   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:31:35,598-Speed 140.20 samples/sec   Loss 1.2619   LearningRate 0.000030   Epoch: 0   Global Step: 7380   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:31:37,892-Speed 139.51 samples/sec   Loss 1.2699   LearningRate 0.000030   Epoch: 0   Global Step: 7390   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:31:40,178-Speed 140.03 samples/sec   Loss 1.2880   LearningRate 0.000030   Epoch: 0   Global Step: 7400   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:31:42,445-Speed 141.18 samples/sec   Loss 1.2502   LearningRate 0.000030   Epoch: 0   Global Step: 7410   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:31:44,738-Speed 139.59 samples/sec   Loss 1.2288   LearningRate 0.000030   Epoch: 0   Global Step: 7420   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:31:47,030-Speed 139.67 samples/sec   Loss 1.2471   LearningRate 0.000030   Epoch: 0   Global Step: 7430   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:31:49,304-Speed 140.78 samples/sec   Loss 1.3255   LearningRate 0.000030   Epoch: 0   Global Step: 7440   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:31:51,573-Speed 141.05 samples/sec   Loss 1.2714   LearningRate 0.000030   Epoch: 0   Global Step: 7450   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:31:53,860-Speed 139.98 samples/sec   Loss 1.2907   LearningRate 0.000030   Epoch: 0   Global Step: 7460   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:31:56,156-Speed 139.39 samples/sec   Loss 1.2568   LearningRate 0.000030   Epoch: 0   Global Step: 7470   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:31:58,464-Speed 138.66 samples/sec   Loss 1.2747   LearningRate 0.000030   Epoch: 0   Global Step: 7480   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:32:00,755-Speed 139.77 samples/sec   Loss 1.2349   LearningRate 0.000030   Epoch: 0   Global Step: 7490   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:32:03,062-Speed 138.73 samples/sec   Loss 1.2734   LearningRate 0.000030   Epoch: 0   Global Step: 7500   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:32:05,357-Speed 139.45 samples/sec   Loss 1.2715   LearningRate 0.000030   Epoch: 0   Global Step: 7510   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:32:07,664-Speed 138.75 samples/sec   Loss 1.2973   LearningRate 0.000030   Epoch: 0   Global Step: 7520   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:32:09,962-Speed 139.32 samples/sec   Loss 1.2876   LearningRate 0.000030   Epoch: 0   Global Step: 7530   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:32:12,241-Speed 140.49 samples/sec   Loss 1.2471   LearningRate 0.000030   Epoch: 0   Global Step: 7540   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:32:14,535-Speed 139.48 samples/sec   Loss 1.2826   LearningRate 0.000030   Epoch: 0   Global Step: 7550   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:32:16,827-Speed 139.69 samples/sec   Loss 1.2354   LearningRate 0.000030   Epoch: 0   Global Step: 7560   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:32:19,126-Speed 139.23 samples/sec   Loss 1.2750   LearningRate 0.000030   Epoch: 0   Global Step: 7570   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:32:21,436-Speed 138.58 samples/sec   Loss 1.2221   LearningRate 0.000030   Epoch: 0   Global Step: 7580   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:32:23,728-Speed 139.64 samples/sec   Loss 1.2734   LearningRate 0.000030   Epoch: 0   Global Step: 7590   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:32:26,012-Speed 140.17 samples/sec   Loss 1.2486   LearningRate 0.000030   Epoch: 0   Global Step: 7600   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:32:28,307-Speed 139.45 samples/sec   Loss 1.2679   LearningRate 0.000030   Epoch: 0   Global Step: 7610   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:32:30,592-Speed 140.06 samples/sec   Loss 1.2750   LearningRate 0.000030   Epoch: 0   Global Step: 7620   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:32:32,886-Speed 139.54 samples/sec   Loss 1.2732   LearningRate 0.000030   Epoch: 0   Global Step: 7630   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:32:35,187-Speed 139.11 samples/sec   Loss 1.2516   LearningRate 0.000030   Epoch: 0   Global Step: 7640   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:32:37,487-Speed 139.18 samples/sec   Loss 1.2496   LearningRate 0.000030   Epoch: 0   Global Step: 7650   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:32:39,804-Speed 138.16 samples/sec   Loss 1.3045   LearningRate 0.000030   Epoch: 0   Global Step: 7660   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:32:42,093-Speed 139.82 samples/sec   Loss 1.2629   LearningRate 0.000030   Epoch: 0   Global Step: 7670   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:32:44,388-Speed 139.46 samples/sec   Loss 1.2580   LearningRate 0.000030   Epoch: 0   Global Step: 7680   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:32:46,666-Speed 140.54 samples/sec   Loss 1.2875   LearningRate 0.000030   Epoch: 0   Global Step: 7690   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:32:48,958-Speed 139.66 samples/sec   Loss 1.2732   LearningRate 0.000030   Epoch: 0   Global Step: 7700   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:32:51,259-Speed 139.14 samples/sec   Loss 1.2167   LearningRate 0.000030   Epoch: 0   Global Step: 7710   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:32:53,531-Speed 140.86 samples/sec   Loss 1.2627   LearningRate 0.000030   Epoch: 0   Global Step: 7720   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:32:55,847-Speed 138.18 samples/sec   Loss 1.2369   LearningRate 0.000030   Epoch: 0   Global Step: 7730   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:32:58,113-Speed 141.28 samples/sec   Loss 1.2882   LearningRate 0.000030   Epoch: 0   Global Step: 7740   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:33:00,408-Speed 139.47 samples/sec   Loss 1.3066   LearningRate 0.000030   Epoch: 0   Global Step: 7750   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:33:02,728-Speed 137.97 samples/sec   Loss 1.2623   LearningRate 0.000030   Epoch: 0   Global Step: 7760   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:33:05,041-Speed 138.42 samples/sec   Loss 1.2420   LearningRate 0.000030   Epoch: 0   Global Step: 7770   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:33:07,364-Speed 137.77 samples/sec   Loss 1.2237   LearningRate 0.000030   Epoch: 0   Global Step: 7780   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:33:09,672-Speed 138.66 samples/sec   Loss 1.2298   LearningRate 0.000030   Epoch: 0   Global Step: 7790   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:33:11,965-Speed 139.62 samples/sec   Loss 1.2917   LearningRate 0.000030   Epoch: 0   Global Step: 7800   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:33:14,246-Speed 140.33 samples/sec   Loss 1.2597   LearningRate 0.000030   Epoch: 0   Global Step: 7810   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:33:16,540-Speed 139.52 samples/sec   Loss 1.2771   LearningRate 0.000030   Epoch: 0   Global Step: 7820   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:33:18,822-Speed 140.30 samples/sec   Loss 1.2836   LearningRate 0.000030   Epoch: 0   Global Step: 7830   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:33:21,105-Speed 140.20 samples/sec   Loss 1.2277   LearningRate 0.000030   Epoch: 0   Global Step: 7840   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:33:23,403-Speed 139.30 samples/sec   Loss 1.2470   LearningRate 0.000030   Epoch: 0   Global Step: 7850   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:33:25,690-Speed 139.93 samples/sec   Loss 1.2552   LearningRate 0.000030   Epoch: 0   Global Step: 7860   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:33:27,985-Speed 139.47 samples/sec   Loss 1.2522   LearningRate 0.000030   Epoch: 0   Global Step: 7870   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:33:30,280-Speed 139.51 samples/sec   Loss 1.2639   LearningRate 0.000030   Epoch: 0   Global Step: 7880   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:33:32,559-Speed 140.44 samples/sec   Loss 1.2675   LearningRate 0.000030   Epoch: 0   Global Step: 7890   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:33:34,848-Speed 139.83 samples/sec   Loss 1.2554   LearningRate 0.000030   Epoch: 0   Global Step: 7900   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:33:37,138-Speed 139.81 samples/sec   Loss 1.2841   LearningRate 0.000030   Epoch: 0   Global Step: 7910   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:33:39,415-Speed 140.58 samples/sec   Loss 1.2700   LearningRate 0.000030   Epoch: 0   Global Step: 7920   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:33:41,704-Speed 139.81 samples/sec   Loss 1.2450   LearningRate 0.000030   Epoch: 0   Global Step: 7930   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:33:43,998-Speed 139.51 samples/sec   Loss 1.2736   LearningRate 0.000030   Epoch: 0   Global Step: 7940   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:33:46,285-Speed 140.02 samples/sec   Loss 1.2479   LearningRate 0.000030   Epoch: 0   Global Step: 7950   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:33:48,560-Speed 140.64 samples/sec   Loss 1.3025   LearningRate 0.000030   Epoch: 0   Global Step: 7960   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:33:50,847-Speed 140.00 samples/sec   Loss 1.2797   LearningRate 0.000030   Epoch: 0   Global Step: 7970   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:33:53,136-Speed 139.81 samples/sec   Loss 1.2656   LearningRate 0.000030   Epoch: 0   Global Step: 7980   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:33:55,421-Speed 140.11 samples/sec   Loss 1.2951   LearningRate 0.000030   Epoch: 0   Global Step: 7990   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:33:57,499-Val on RAF/AffectNet:
Training: 2023-08-17 21:33:57,616-Test: [0/48]	Time 0.116 (0.116)	Loss 0.5059 (0.5059)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-17 21:33:58,666-Test: [10/48]	Time 0.102 (0.106)	Loss 0.4641 (0.5425)	Acc@1 93.750 (92.898)	Acc@5 100.000 (99.574)	Mem 5268MB
Training: 2023-08-17 21:33:59,694-Test: [20/48]	Time 0.102 (0.104)	Loss 0.5669 (0.5589)	Acc@1 93.750 (92.634)	Acc@5 100.000 (99.405)	Mem 5268MB
Training: 2023-08-17 21:34:00,741-Test: [30/48]	Time 0.105 (0.105)	Loss 0.6297 (0.5763)	Acc@1 90.625 (91.885)	Acc@5 96.875 (99.194)	Mem 5268MB
Training: 2023-08-17 21:34:01,777-Test: [40/48]	Time 0.105 (0.104)	Loss 0.5038 (0.5700)	Acc@1 96.875 (92.035)	Acc@5 100.000 (99.238)	Mem 5268MB
Training: 2023-08-17 21:34:02,499-[7999]Expression Loss: 0.57489
Training: 2023-08-17 21:34:02,499-[7999]Expression Acc@1: 91.65580
Training: 2023-08-17 21:34:02,500-[7999]Expression Acc@1-Highest: 91.65580
Training: 2023-08-17 21:34:02,500-[7999]Expression Acc@5: 99.25033
Training: 2023-08-17 21:34:02,500-[7999]Expression Acc@5-Highest: 99.28292
Training: 2023-08-17 21:34:02,500-[7999]10 Times Expression Acc@1: 88.34746
Training: 2023-08-17 21:34:02,500-[7999]10 Times Expression Acc@1-Highest: 88.34746
Training: 2023-08-17 21:34:02,729-Speed 43.79 samples/sec   Loss 1.2539   LearningRate 0.000030   Epoch: 0   Global Step: 8000   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:34:05,026-Speed 139.38 samples/sec   Loss 1.2731   LearningRate 0.000030   Epoch: 0   Global Step: 8010   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:34:07,304-Speed 140.49 samples/sec   Loss 1.2510   LearningRate 0.000030   Epoch: 0   Global Step: 8020   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:34:09,583-Speed 140.48 samples/sec   Loss 1.2505   LearningRate 0.000030   Epoch: 0   Global Step: 8030   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:34:11,855-Speed 140.86 samples/sec   Loss 1.2548   LearningRate 0.000030   Epoch: 0   Global Step: 8040   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:34:14,139-Speed 140.12 samples/sec   Loss 1.2623   LearningRate 0.000030   Epoch: 0   Global Step: 8050   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:34:16,419-Speed 140.40 samples/sec   Loss 1.2728   LearningRate 0.000030   Epoch: 0   Global Step: 8060   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:34:18,704-Speed 140.13 samples/sec   Loss 1.2527   LearningRate 0.000030   Epoch: 0   Global Step: 8070   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:34:20,997-Speed 139.60 samples/sec   Loss 1.2843   LearningRate 0.000030   Epoch: 0   Global Step: 8080   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:34:23,270-Speed 140.77 samples/sec   Loss 1.2412   LearningRate 0.000030   Epoch: 0   Global Step: 8090   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:34:25,547-Speed 140.57 samples/sec   Loss 1.2830   LearningRate 0.000030   Epoch: 0   Global Step: 8100   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:34:27,840-Speed 139.63 samples/sec   Loss 1.2848   LearningRate 0.000030   Epoch: 0   Global Step: 8110   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:34:30,113-Speed 140.80 samples/sec   Loss 1.3030   LearningRate 0.000030   Epoch: 0   Global Step: 8120   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:34:32,404-Speed 139.71 samples/sec   Loss 1.2682   LearningRate 0.000030   Epoch: 0   Global Step: 8130   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:34:34,707-Speed 139.02 samples/sec   Loss 1.2812   LearningRate 0.000030   Epoch: 0   Global Step: 8140   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:34:36,999-Speed 139.68 samples/sec   Loss 1.2417   LearningRate 0.000030   Epoch: 0   Global Step: 8150   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:34:39,280-Speed 140.27 samples/sec   Loss 1.2945   LearningRate 0.000030   Epoch: 0   Global Step: 8160   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 21:34:41,568-Speed 139.91 samples/sec   Loss 1.2746   LearningRate 0.000030   Epoch: 0   Global Step: 8170   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 21:34:43,853-Speed 140.13 samples/sec   Loss 1.2702   LearningRate 0.000030   Epoch: 0   Global Step: 8180   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 21:34:46,136-Speed 140.19 samples/sec   Loss 1.3198   LearningRate 0.000030   Epoch: 0   Global Step: 8190   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 21:34:48,427-Speed 139.68 samples/sec   Loss 1.2805   LearningRate 0.000030   Epoch: 0   Global Step: 8200   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 21:34:50,731-Speed 138.94 samples/sec   Loss 1.2566   LearningRate 0.000030   Epoch: 0   Global Step: 8210   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 21:34:53,020-Speed 139.85 samples/sec   Loss 1.2683   LearningRate 0.000030   Epoch: 0   Global Step: 8220   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 21:34:55,319-Speed 139.23 samples/sec   Loss 1.2714   LearningRate 0.000030   Epoch: 0   Global Step: 8230   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 21:34:57,615-Speed 139.40 samples/sec   Loss 1.2854   LearningRate 0.000030   Epoch: 0   Global Step: 8240   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 21:34:59,902-Speed 139.93 samples/sec   Loss 1.2695   LearningRate 0.000030   Epoch: 0   Global Step: 8250   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 21:35:02,200-Speed 139.30 samples/sec   Loss 1.2647   LearningRate 0.000030   Epoch: 0   Global Step: 8260   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:35:04,514-Speed 138.34 samples/sec   Loss 1.2220   LearningRate 0.000030   Epoch: 0   Global Step: 8270   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:35:06,836-Speed 137.87 samples/sec   Loss 1.2815   LearningRate 0.000030   Epoch: 0   Global Step: 8280   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:35:09,114-Speed 140.52 samples/sec   Loss 1.2738   LearningRate 0.000030   Epoch: 0   Global Step: 8290   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:35:11,395-Speed 140.28 samples/sec   Loss 1.2927   LearningRate 0.000030   Epoch: 0   Global Step: 8300   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:35:13,688-Speed 139.63 samples/sec   Loss 1.2633   LearningRate 0.000030   Epoch: 0   Global Step: 8310   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:35:15,982-Speed 139.50 samples/sec   Loss 1.2697   LearningRate 0.000030   Epoch: 0   Global Step: 8320   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:35:18,276-Speed 139.57 samples/sec   Loss 1.2705   LearningRate 0.000030   Epoch: 0   Global Step: 8330   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:35:20,581-Speed 138.84 samples/sec   Loss 1.2767   LearningRate 0.000030   Epoch: 0   Global Step: 8340   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:35:22,893-Speed 138.45 samples/sec   Loss 1.2448   LearningRate 0.000030   Epoch: 0   Global Step: 8350   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:35:25,188-Speed 139.50 samples/sec   Loss 1.2595   LearningRate 0.000030   Epoch: 0   Global Step: 8360   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:35:27,493-Speed 138.84 samples/sec   Loss 1.2826   LearningRate 0.000030   Epoch: 0   Global Step: 8370   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:35:29,783-Speed 139.80 samples/sec   Loss 1.2745   LearningRate 0.000030   Epoch: 0   Global Step: 8380   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:35:32,085-Speed 139.05 samples/sec   Loss 1.3050   LearningRate 0.000030   Epoch: 0   Global Step: 8390   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:35:34,380-Speed 139.47 samples/sec   Loss 1.2898   LearningRate 0.000030   Epoch: 0   Global Step: 8400   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:35:36,668-Speed 139.90 samples/sec   Loss 1.2626   LearningRate 0.000030   Epoch: 0   Global Step: 8410   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:35:38,953-Speed 140.08 samples/sec   Loss 1.2676   LearningRate 0.000030   Epoch: 0   Global Step: 8420   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:35:41,244-Speed 139.70 samples/sec   Loss 1.2510   LearningRate 0.000030   Epoch: 0   Global Step: 8430   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:35:43,551-Speed 138.75 samples/sec   Loss 1.2499   LearningRate 0.000030   Epoch: 0   Global Step: 8440   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:35:45,841-Speed 139.80 samples/sec   Loss 1.2531   LearningRate 0.000030   Epoch: 0   Global Step: 8450   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:35:48,137-Speed 139.34 samples/sec   Loss 1.2326   LearningRate 0.000030   Epoch: 0   Global Step: 8460   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:35:50,427-Speed 139.80 samples/sec   Loss 1.2506   LearningRate 0.000030   Epoch: 0   Global Step: 8470   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:35:52,711-Speed 140.16 samples/sec   Loss 1.2538   LearningRate 0.000030   Epoch: 0   Global Step: 8480   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:35:55,003-Speed 139.65 samples/sec   Loss 1.2468   LearningRate 0.000030   Epoch: 0   Global Step: 8490   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:35:57,285-Speed 140.31 samples/sec   Loss 1.2273   LearningRate 0.000030   Epoch: 0   Global Step: 8500   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:35:59,574-Speed 139.80 samples/sec   Loss 1.2435   LearningRate 0.000030   Epoch: 0   Global Step: 8510   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:36:01,865-Speed 139.75 samples/sec   Loss 1.2607   LearningRate 0.000030   Epoch: 0   Global Step: 8520   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:36:04,160-Speed 139.46 samples/sec   Loss 1.2777   LearningRate 0.000030   Epoch: 0   Global Step: 8530   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:36:06,442-Speed 140.22 samples/sec   Loss 1.3036   LearningRate 0.000030   Epoch: 0   Global Step: 8540   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:36:08,720-Speed 140.56 samples/sec   Loss 1.2760   LearningRate 0.000030   Epoch: 0   Global Step: 8550   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:36:11,003-Speed 140.24 samples/sec   Loss 1.2423   LearningRate 0.000030   Epoch: 0   Global Step: 8560   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:36:13,304-Speed 139.07 samples/sec   Loss 1.2606   LearningRate 0.000030   Epoch: 0   Global Step: 8570   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:36:15,609-Speed 138.88 samples/sec   Loss 1.2658   LearningRate 0.000030   Epoch: 0   Global Step: 8580   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:36:17,934-Speed 137.64 samples/sec   Loss 1.2860   LearningRate 0.000030   Epoch: 0   Global Step: 8590   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:36:20,245-Speed 138.54 samples/sec   Loss 1.2675   LearningRate 0.000030   Epoch: 0   Global Step: 8600   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:36:22,550-Speed 138.88 samples/sec   Loss 1.2477   LearningRate 0.000030   Epoch: 0   Global Step: 8610   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:36:24,838-Speed 139.84 samples/sec   Loss 1.2613   LearningRate 0.000030   Epoch: 0   Global Step: 8620   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:36:27,136-Speed 139.33 samples/sec   Loss 1.2584   LearningRate 0.000030   Epoch: 0   Global Step: 8630   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:36:29,414-Speed 140.50 samples/sec   Loss 1.2513   LearningRate 0.000030   Epoch: 0   Global Step: 8640   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:36:31,685-Speed 140.95 samples/sec   Loss 1.2710   LearningRate 0.000030   Epoch: 0   Global Step: 8650   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:36:33,947-Speed 141.50 samples/sec   Loss 1.2473   LearningRate 0.000030   Epoch: 0   Global Step: 8660   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:36:36,206-Speed 141.69 samples/sec   Loss 1.2500   LearningRate 0.000030   Epoch: 0   Global Step: 8670   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:36:38,467-Speed 141.58 samples/sec   Loss 1.2777   LearningRate 0.000030   Epoch: 0   Global Step: 8680   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:36:40,729-Speed 141.50 samples/sec   Loss 1.2589   LearningRate 0.000030   Epoch: 0   Global Step: 8690   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:36:42,994-Speed 141.32 samples/sec   Loss 1.2798   LearningRate 0.000030   Epoch: 0   Global Step: 8700   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:36:45,236-Speed 142.82 samples/sec   Loss 1.2262   LearningRate 0.000030   Epoch: 0   Global Step: 8710   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:36:47,501-Speed 141.29 samples/sec   Loss 1.2749   LearningRate 0.000030   Epoch: 0   Global Step: 8720   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:36:49,760-Speed 141.71 samples/sec   Loss 1.2447   LearningRate 0.000030   Epoch: 0   Global Step: 8730   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:36:52,028-Speed 141.12 samples/sec   Loss 1.2740   LearningRate 0.000030   Epoch: 0   Global Step: 8740   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:36:54,288-Speed 141.64 samples/sec   Loss 1.2233   LearningRate 0.000030   Epoch: 0   Global Step: 8750   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:36:56,552-Speed 141.35 samples/sec   Loss 1.2451   LearningRate 0.000030   Epoch: 0   Global Step: 8760   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:36:58,815-Speed 141.48 samples/sec   Loss 1.2362   LearningRate 0.000030   Epoch: 0   Global Step: 8770   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:37:01,081-Speed 141.25 samples/sec   Loss 1.2460   LearningRate 0.000030   Epoch: 0   Global Step: 8780   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:37:03,338-Speed 141.81 samples/sec   Loss 1.2417   LearningRate 0.000030   Epoch: 0   Global Step: 8790   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:37:05,604-Speed 141.24 samples/sec   Loss 1.2564   LearningRate 0.000030   Epoch: 0   Global Step: 8800   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:37:07,868-Speed 141.39 samples/sec   Loss 1.2988   LearningRate 0.000030   Epoch: 0   Global Step: 8810   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:37:10,134-Speed 141.30 samples/sec   Loss 1.2619   LearningRate 0.000030   Epoch: 0   Global Step: 8820   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:37:12,391-Speed 141.80 samples/sec   Loss 1.2741   LearningRate 0.000030   Epoch: 0   Global Step: 8830   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:37:14,659-Speed 141.10 samples/sec   Loss 1.2651   LearningRate 0.000030   Epoch: 0   Global Step: 8840   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:37:16,921-Speed 141.57 samples/sec   Loss 1.2890   LearningRate 0.000030   Epoch: 0   Global Step: 8850   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:37:19,170-Speed 142.31 samples/sec   Loss 1.2586   LearningRate 0.000030   Epoch: 0   Global Step: 8860   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:37:21,437-Speed 141.17 samples/sec   Loss 1.2288   LearningRate 0.000030   Epoch: 0   Global Step: 8870   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:37:23,701-Speed 141.41 samples/sec   Loss 1.2236   LearningRate 0.000030   Epoch: 0   Global Step: 8880   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:37:25,965-Speed 141.40 samples/sec   Loss 1.2682   LearningRate 0.000030   Epoch: 0   Global Step: 8890   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:37:28,223-Speed 141.75 samples/sec   Loss 1.2553   LearningRate 0.000030   Epoch: 0   Global Step: 8900   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:37:30,509-Speed 140.04 samples/sec   Loss 1.2264   LearningRate 0.000030   Epoch: 0   Global Step: 8910   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:37:32,812-Speed 138.95 samples/sec   Loss 1.2601   LearningRate 0.000030   Epoch: 0   Global Step: 8920   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:37:35,088-Speed 140.67 samples/sec   Loss 1.2510   LearningRate 0.000030   Epoch: 0   Global Step: 8930   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:37:37,375-Speed 139.91 samples/sec   Loss 1.2871   LearningRate 0.000030   Epoch: 0   Global Step: 8940   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:37:39,652-Speed 140.57 samples/sec   Loss 1.2546   LearningRate 0.000030   Epoch: 0   Global Step: 8950   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:37:41,951-Speed 139.25 samples/sec   Loss 1.2232   LearningRate 0.000030   Epoch: 0   Global Step: 8960   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:37:44,235-Speed 140.17 samples/sec   Loss 1.2563   LearningRate 0.000030   Epoch: 0   Global Step: 8970   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:37:46,517-Speed 140.25 samples/sec   Loss 1.2354   LearningRate 0.000030   Epoch: 0   Global Step: 8980   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:37:48,798-Speed 140.36 samples/sec   Loss 1.2491   LearningRate 0.000030   Epoch: 0   Global Step: 8990   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:37:50,860-Val on RAF/AffectNet:
Training: 2023-08-17 21:37:50,969-Test: [0/48]	Time 0.109 (0.109)	Loss 0.5280 (0.5280)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-17 21:37:52,015-Test: [10/48]	Time 0.107 (0.105)	Loss 0.6228 (0.5945)	Acc@1 89.062 (90.483)	Acc@5 98.438 (99.290)	Mem 5268MB
Training: 2023-08-17 21:37:53,059-Test: [20/48]	Time 0.103 (0.105)	Loss 0.5980 (0.6001)	Acc@1 90.625 (90.253)	Acc@5 100.000 (99.182)	Mem 5268MB
Training: 2023-08-17 21:37:54,116-Test: [30/48]	Time 0.105 (0.105)	Loss 0.5290 (0.5959)	Acc@1 93.750 (90.625)	Acc@5 100.000 (99.194)	Mem 5268MB
Training: 2023-08-17 21:37:55,164-Test: [40/48]	Time 0.105 (0.105)	Loss 0.4347 (0.6000)	Acc@1 96.875 (90.549)	Acc@5 100.000 (99.123)	Mem 5268MB
Training: 2023-08-17 21:37:55,890-[8999]Expression Loss: 0.60826
Training: 2023-08-17 21:37:55,891-[8999]Expression Acc@1: 90.25424
Training: 2023-08-17 21:37:55,891-[8999]Expression Acc@1-Highest: 91.65580
Training: 2023-08-17 21:37:55,891-[8999]Expression Acc@5: 99.05476
Training: 2023-08-17 21:37:55,891-[8999]Expression Acc@5-Highest: 99.28292
Training: 2023-08-17 21:37:55,891-[8999]10 Times Expression Acc@1: 88.55932
Training: 2023-08-17 21:37:55,891-[8999]10 Times Expression Acc@1-Highest: 88.55932
Training: 2023-08-17 21:37:56,119-Speed 43.71 samples/sec   Loss 1.3104   LearningRate 0.000030   Epoch: 0   Global Step: 9000   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:37:58,387-Speed 141.12 samples/sec   Loss 1.2416   LearningRate 0.000030   Epoch: 0   Global Step: 9010   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:38:00,647-Speed 141.66 samples/sec   Loss 1.2345   LearningRate 0.000030   Epoch: 0   Global Step: 9020   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:38:02,932-Speed 140.06 samples/sec   Loss 1.2638   LearningRate 0.000030   Epoch: 0   Global Step: 9030   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:38:05,203-Speed 140.95 samples/sec   Loss 1.2671   LearningRate 0.000030   Epoch: 0   Global Step: 9040   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:38:07,481-Speed 140.53 samples/sec   Loss 1.2538   LearningRate 0.000030   Epoch: 0   Global Step: 9050   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:38:09,758-Speed 140.59 samples/sec   Loss 1.2876   LearningRate 0.000030   Epoch: 0   Global Step: 9060   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:38:12,036-Speed 140.48 samples/sec   Loss 1.2831   LearningRate 0.000030   Epoch: 0   Global Step: 9070   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:38:14,303-Speed 141.19 samples/sec   Loss 1.2724   LearningRate 0.000030   Epoch: 0   Global Step: 9080   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:38:16,561-Speed 141.80 samples/sec   Loss 1.2538   LearningRate 0.000030   Epoch: 0   Global Step: 9090   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:38:18,840-Speed 140.43 samples/sec   Loss 1.2436   LearningRate 0.000030   Epoch: 0   Global Step: 9100   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:38:21,111-Speed 140.96 samples/sec   Loss 1.2311   LearningRate 0.000030   Epoch: 0   Global Step: 9110   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:38:23,386-Speed 140.67 samples/sec   Loss 1.3223   LearningRate 0.000030   Epoch: 0   Global Step: 9120   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:38:25,662-Speed 140.65 samples/sec   Loss 1.2888   LearningRate 0.000030   Epoch: 0   Global Step: 9130   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:38:27,947-Speed 140.14 samples/sec   Loss 1.2513   LearningRate 0.000030   Epoch: 0   Global Step: 9140   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:38:30,250-Speed 138.93 samples/sec   Loss 1.2499   LearningRate 0.000030   Epoch: 0   Global Step: 9150   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:38:32,542-Speed 139.70 samples/sec   Loss 1.2594   LearningRate 0.000030   Epoch: 0   Global Step: 9160   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:38:34,820-Speed 140.51 samples/sec   Loss 1.2451   LearningRate 0.000030   Epoch: 0   Global Step: 9170   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:38:37,098-Speed 140.47 samples/sec   Loss 1.2472   LearningRate 0.000029   Epoch: 0   Global Step: 9180   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:38:39,399-Speed 139.10 samples/sec   Loss 1.2629   LearningRate 0.000029   Epoch: 0   Global Step: 9190   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:38:41,672-Speed 140.85 samples/sec   Loss 1.2733   LearningRate 0.000029   Epoch: 0   Global Step: 9200   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:38:43,962-Speed 139.79 samples/sec   Loss 1.2663   LearningRate 0.000029   Epoch: 0   Global Step: 9210   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:38:46,259-Speed 139.33 samples/sec   Loss 1.2330   LearningRate 0.000029   Epoch: 0   Global Step: 9220   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:38:48,557-Speed 139.29 samples/sec   Loss 1.2492   LearningRate 0.000029   Epoch: 0   Global Step: 9230   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:38:50,844-Speed 139.94 samples/sec   Loss 1.2349   LearningRate 0.000029   Epoch: 0   Global Step: 9240   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:38:53,135-Speed 139.70 samples/sec   Loss 1.2689   LearningRate 0.000029   Epoch: 0   Global Step: 9250   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:38:55,422-Speed 139.98 samples/sec   Loss 1.2265   LearningRate 0.000029   Epoch: 0   Global Step: 9260   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:38:57,706-Speed 140.15 samples/sec   Loss 1.2854   LearningRate 0.000029   Epoch: 0   Global Step: 9270   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:38:59,982-Speed 140.62 samples/sec   Loss 1.2663   LearningRate 0.000029   Epoch: 0   Global Step: 9280   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:39:02,262-Speed 140.38 samples/sec   Loss 1.2935   LearningRate 0.000029   Epoch: 0   Global Step: 9290   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:39:04,543-Speed 140.35 samples/sec   Loss 1.2653   LearningRate 0.000029   Epoch: 0   Global Step: 9300   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:39:06,816-Speed 140.80 samples/sec   Loss 1.2541   LearningRate 0.000029   Epoch: 0   Global Step: 9310   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:39:09,088-Speed 140.89 samples/sec   Loss 1.2687   LearningRate 0.000029   Epoch: 0   Global Step: 9320   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:39:11,375-Speed 139.96 samples/sec   Loss 1.2433   LearningRate 0.000029   Epoch: 0   Global Step: 9330   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:39:13,665-Speed 139.75 samples/sec   Loss 1.2468   LearningRate 0.000029   Epoch: 0   Global Step: 9340   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:39:15,944-Speed 140.42 samples/sec   Loss 1.2388   LearningRate 0.000029   Epoch: 0   Global Step: 9350   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:39:18,218-Speed 140.76 samples/sec   Loss 1.2229   LearningRate 0.000029   Epoch: 0   Global Step: 9360   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:39:20,502-Speed 140.17 samples/sec   Loss 1.2505   LearningRate 0.000029   Epoch: 0   Global Step: 9370   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:39:22,776-Speed 140.78 samples/sec   Loss 1.2740   LearningRate 0.000029   Epoch: 0   Global Step: 9380   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:39:25,046-Speed 140.96 samples/sec   Loss 1.2667   LearningRate 0.000029   Epoch: 0   Global Step: 9390   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:39:27,323-Speed 140.63 samples/sec   Loss 1.2103   LearningRate 0.000029   Epoch: 0   Global Step: 9400   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:39:29,600-Speed 140.54 samples/sec   Loss 1.2480   LearningRate 0.000029   Epoch: 0   Global Step: 9410   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:39:31,864-Speed 141.39 samples/sec   Loss 1.2688   LearningRate 0.000029   Epoch: 0   Global Step: 9420   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:39:34,176-Speed 138.44 samples/sec   Loss 1.2582   LearningRate 0.000029   Epoch: 0   Global Step: 9430   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:39:36,452-Speed 140.61 samples/sec   Loss 1.2696   LearningRate 0.000029   Epoch: 0   Global Step: 9440   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:39:38,731-Speed 140.50 samples/sec   Loss 1.2550   LearningRate 0.000029   Epoch: 0   Global Step: 9450   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:39:41,011-Speed 140.39 samples/sec   Loss 1.2393   LearningRate 0.000029   Epoch: 0   Global Step: 9460   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:39:43,290-Speed 140.45 samples/sec   Loss 1.2245   LearningRate 0.000029   Epoch: 0   Global Step: 9470   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:39:45,578-Speed 139.86 samples/sec   Loss 1.2304   LearningRate 0.000029   Epoch: 0   Global Step: 9480   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:39:47,861-Speed 140.22 samples/sec   Loss 1.2640   LearningRate 0.000029   Epoch: 0   Global Step: 9490   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:39:50,141-Speed 140.40 samples/sec   Loss 1.2410   LearningRate 0.000029   Epoch: 0   Global Step: 9500   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:39:52,418-Speed 140.54 samples/sec   Loss 1.2482   LearningRate 0.000029   Epoch: 0   Global Step: 9510   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:39:54,712-Speed 139.52 samples/sec   Loss 1.2671   LearningRate 0.000029   Epoch: 0   Global Step: 9520   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:39:57,034-Speed 137.87 samples/sec   Loss 1.2209   LearningRate 0.000029   Epoch: 0   Global Step: 9530   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:39:59,341-Speed 138.73 samples/sec   Loss 1.2419   LearningRate 0.000029   Epoch: 0   Global Step: 9540   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:40:01,666-Speed 137.67 samples/sec   Loss 1.2505   LearningRate 0.000029   Epoch: 0   Global Step: 9550   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:40:03,963-Speed 139.34 samples/sec   Loss 1.2567   LearningRate 0.000029   Epoch: 0   Global Step: 9560   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:40:06,283-Speed 138.03 samples/sec   Loss 1.2296   LearningRate 0.000029   Epoch: 0   Global Step: 9570   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:40:08,602-Speed 137.99 samples/sec   Loss 1.2722   LearningRate 0.000029   Epoch: 0   Global Step: 9580   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:40:10,910-Speed 138.67 samples/sec   Loss 1.2826   LearningRate 0.000029   Epoch: 0   Global Step: 9590   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:40:13,224-Speed 138.36 samples/sec   Loss 1.2228   LearningRate 0.000029   Epoch: 0   Global Step: 9600   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:40:15,544-Speed 137.97 samples/sec   Loss 1.2666   LearningRate 0.000029   Epoch: 0   Global Step: 9610   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:40:17,865-Speed 137.90 samples/sec   Loss 1.2397   LearningRate 0.000029   Epoch: 0   Global Step: 9620   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:40:20,177-Speed 138.48 samples/sec   Loss 1.2620   LearningRate 0.000029   Epoch: 0   Global Step: 9630   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:40:22,483-Speed 138.78 samples/sec   Loss 1.2679   LearningRate 0.000029   Epoch: 0   Global Step: 9640   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:40:24,806-Speed 137.77 samples/sec   Loss 1.2639   LearningRate 0.000029   Epoch: 0   Global Step: 9650   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:40:27,113-Speed 138.73 samples/sec   Loss 1.2542   LearningRate 0.000029   Epoch: 0   Global Step: 9660   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:40:29,421-Speed 138.74 samples/sec   Loss 1.2395   LearningRate 0.000029   Epoch: 0   Global Step: 9670   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:40:31,733-Speed 138.41 samples/sec   Loss 1.2376   LearningRate 0.000029   Epoch: 0   Global Step: 9680   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:40:34,041-Speed 138.69 samples/sec   Loss 1.2872   LearningRate 0.000029   Epoch: 0   Global Step: 9690   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:40:36,349-Speed 138.73 samples/sec   Loss 1.2614   LearningRate 0.000029   Epoch: 0   Global Step: 9700   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:40:38,653-Speed 138.93 samples/sec   Loss 1.2418   LearningRate 0.000029   Epoch: 0   Global Step: 9710   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:40:40,947-Speed 139.52 samples/sec   Loss 1.2410   LearningRate 0.000029   Epoch: 0   Global Step: 9720   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:40:43,241-Speed 139.54 samples/sec   Loss 1.2748   LearningRate 0.000029   Epoch: 0   Global Step: 9730   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:40:45,526-Speed 140.05 samples/sec   Loss 1.2276   LearningRate 0.000029   Epoch: 0   Global Step: 9740   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:40:47,833-Speed 138.74 samples/sec   Loss 1.2563   LearningRate 0.000029   Epoch: 0   Global Step: 9750   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:40:50,136-Speed 138.99 samples/sec   Loss 1.2423   LearningRate 0.000029   Epoch: 0   Global Step: 9760   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:40:52,452-Speed 138.21 samples/sec   Loss 1.2555   LearningRate 0.000029   Epoch: 0   Global Step: 9770   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:40:54,732-Speed 140.39 samples/sec   Loss 1.2393   LearningRate 0.000029   Epoch: 0   Global Step: 9780   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:40:57,034-Speed 139.09 samples/sec   Loss 1.2905   LearningRate 0.000029   Epoch: 0   Global Step: 9790   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:40:59,329-Speed 139.42 samples/sec   Loss 1.2576   LearningRate 0.000029   Epoch: 0   Global Step: 9800   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:41:01,631-Speed 139.06 samples/sec   Loss 1.2305   LearningRate 0.000029   Epoch: 0   Global Step: 9810   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:41:03,954-Speed 137.83 samples/sec   Loss 1.2140   LearningRate 0.000029   Epoch: 0   Global Step: 9820   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:41:06,268-Speed 138.28 samples/sec   Loss 1.2443   LearningRate 0.000029   Epoch: 0   Global Step: 9830   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:41:08,588-Speed 138.01 samples/sec   Loss 1.2588   LearningRate 0.000029   Epoch: 0   Global Step: 9840   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:41:10,877-Speed 139.79 samples/sec   Loss 1.2545   LearningRate 0.000029   Epoch: 0   Global Step: 9850   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:41:13,178-Speed 139.15 samples/sec   Loss 1.2467   LearningRate 0.000029   Epoch: 0   Global Step: 9860   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:41:15,482-Speed 138.92 samples/sec   Loss 1.2399   LearningRate 0.000029   Epoch: 0   Global Step: 9870   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:41:17,767-Speed 140.05 samples/sec   Loss 1.2601   LearningRate 0.000029   Epoch: 0   Global Step: 9880   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:41:20,070-Speed 138.98 samples/sec   Loss 1.2666   LearningRate 0.000029   Epoch: 0   Global Step: 9890   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:41:22,376-Speed 138.80 samples/sec   Loss 1.2441   LearningRate 0.000029   Epoch: 0   Global Step: 9900   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:41:24,679-Speed 139.02 samples/sec   Loss 1.2596   LearningRate 0.000029   Epoch: 0   Global Step: 9910   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:41:26,979-Speed 139.13 samples/sec   Loss 1.2585   LearningRate 0.000029   Epoch: 0   Global Step: 9920   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:41:29,278-Speed 139.27 samples/sec   Loss 1.2166   LearningRate 0.000029   Epoch: 0   Global Step: 9930   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:41:31,575-Speed 139.35 samples/sec   Loss 1.2375   LearningRate 0.000029   Epoch: 0   Global Step: 9940   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:41:33,852-Speed 140.60 samples/sec   Loss 1.2441   LearningRate 0.000029   Epoch: 0   Global Step: 9950   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:41:36,120-Speed 141.09 samples/sec   Loss 1.2772   LearningRate 0.000029   Epoch: 0   Global Step: 9960   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:41:38,408-Speed 139.89 samples/sec   Loss 1.2295   LearningRate 0.000029   Epoch: 0   Global Step: 9970   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:41:40,701-Speed 139.64 samples/sec   Loss 1.2523   LearningRate 0.000029   Epoch: 0   Global Step: 9980   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:41:42,961-Speed 141.63 samples/sec   Loss 1.2418   LearningRate 0.000029   Epoch: 0   Global Step: 9990   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:41:45,032-Val on RAF/AffectNet:
Training: 2023-08-17 21:41:45,143-Test: [0/48]	Time 0.110 (0.110)	Loss 0.5107 (0.5107)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-17 21:41:46,199-Test: [10/48]	Time 0.104 (0.106)	Loss 0.6017 (0.5515)	Acc@1 92.188 (91.335)	Acc@5 98.438 (99.432)	Mem 5268MB
Training: 2023-08-17 21:41:47,253-Test: [20/48]	Time 0.105 (0.106)	Loss 0.5121 (0.5592)	Acc@1 92.188 (90.997)	Acc@5 100.000 (99.033)	Mem 5268MB
Training: 2023-08-17 21:41:48,327-Test: [30/48]	Time 0.107 (0.106)	Loss 0.4600 (0.5611)	Acc@1 93.750 (90.978)	Acc@5 100.000 (98.992)	Mem 5268MB
Training: 2023-08-17 21:41:49,414-Test: [40/48]	Time 0.113 (0.107)	Loss 0.7034 (0.5568)	Acc@1 82.812 (90.968)	Acc@5 95.312 (99.085)	Mem 5268MB
Training: 2023-08-17 21:41:50,170-[9999]Expression Loss: 0.56148
Training: 2023-08-17 21:41:50,170-[9999]Expression Acc@1: 90.80834
Training: 2023-08-17 21:41:50,170-[9999]Expression Acc@1-Highest: 91.65580
Training: 2023-08-17 21:41:50,170-[9999]Expression Acc@5: 99.08735
Training: 2023-08-17 21:41:50,170-[9999]Expression Acc@5-Highest: 99.28292
Training: 2023-08-17 21:41:50,170-[9999]10 Times Expression Acc@1: 88.78422
Training: 2023-08-17 21:41:50,170-[9999]10 Times Expression Acc@1-Highest: 88.78422
Training: 2023-08-17 21:41:50,400-Speed 43.02 samples/sec   Loss 1.2377   LearningRate 0.000029   Epoch: 0   Global Step: 10000   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:41:52,664-Speed 141.36 samples/sec   Loss 1.2573   LearningRate 0.000029   Epoch: 0   Global Step: 10010   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:41:54,936-Speed 140.85 samples/sec   Loss 1.2750   LearningRate 0.000029   Epoch: 0   Global Step: 10020   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:41:57,219-Speed 140.22 samples/sec   Loss 1.2221   LearningRate 0.000029   Epoch: 0   Global Step: 10030   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:41:59,497-Speed 140.50 samples/sec   Loss 1.2669   LearningRate 0.000029   Epoch: 0   Global Step: 10040   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:42:01,796-Speed 139.24 samples/sec   Loss 1.2376   LearningRate 0.000029   Epoch: 0   Global Step: 10050   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:42:04,079-Speed 140.22 samples/sec   Loss 1.2049   LearningRate 0.000029   Epoch: 0   Global Step: 10060   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:42:06,375-Speed 139.42 samples/sec   Loss 1.2524   LearningRate 0.000029   Epoch: 0   Global Step: 10070   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:42:08,667-Speed 139.65 samples/sec   Loss 1.2486   LearningRate 0.000029   Epoch: 0   Global Step: 10080   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:42:10,965-Speed 139.28 samples/sec   Loss 1.2343   LearningRate 0.000029   Epoch: 0   Global Step: 10090   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:42:13,268-Speed 138.96 samples/sec   Loss 1.2555   LearningRate 0.000029   Epoch: 0   Global Step: 10100   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:42:15,578-Speed 138.60 samples/sec   Loss 1.2310   LearningRate 0.000029   Epoch: 0   Global Step: 10110   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:42:17,882-Speed 138.91 samples/sec   Loss 1.2292   LearningRate 0.000029   Epoch: 0   Global Step: 10120   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:42:20,191-Speed 138.62 samples/sec   Loss 1.2750   LearningRate 0.000029   Epoch: 0   Global Step: 10130   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:42:22,477-Speed 140.04 samples/sec   Loss 1.2404   LearningRate 0.000029   Epoch: 0   Global Step: 10140   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:42:24,772-Speed 139.44 samples/sec   Loss 1.2598   LearningRate 0.000029   Epoch: 0   Global Step: 10150   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:42:27,054-Speed 140.27 samples/sec   Loss 1.2447   LearningRate 0.000029   Epoch: 0   Global Step: 10160   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:42:29,346-Speed 139.70 samples/sec   Loss 1.2352   LearningRate 0.000029   Epoch: 0   Global Step: 10170   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:42:31,657-Speed 138.46 samples/sec   Loss 1.2582   LearningRate 0.000029   Epoch: 0   Global Step: 10180   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:42:33,965-Speed 138.69 samples/sec   Loss 1.2409   LearningRate 0.000029   Epoch: 0   Global Step: 10190   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:42:36,242-Speed 140.56 samples/sec   Loss 1.2643   LearningRate 0.000029   Epoch: 0   Global Step: 10200   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:42:38,522-Speed 140.40 samples/sec   Loss 1.2280   LearningRate 0.000029   Epoch: 0   Global Step: 10210   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:42:40,803-Speed 140.37 samples/sec   Loss 1.2483   LearningRate 0.000029   Epoch: 0   Global Step: 10220   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:42:43,090-Speed 139.93 samples/sec   Loss 1.2510   LearningRate 0.000029   Epoch: 0   Global Step: 10230   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:42:45,384-Speed 139.57 samples/sec   Loss 1.2207   LearningRate 0.000029   Epoch: 0   Global Step: 10240   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:42:47,654-Speed 140.97 samples/sec   Loss 1.2676   LearningRate 0.000029   Epoch: 0   Global Step: 10250   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:42:49,951-Speed 139.36 samples/sec   Loss 1.1956   LearningRate 0.000029   Epoch: 0   Global Step: 10260   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:42:52,240-Speed 139.83 samples/sec   Loss 1.2369   LearningRate 0.000029   Epoch: 0   Global Step: 10270   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:42:54,528-Speed 139.93 samples/sec   Loss 1.2465   LearningRate 0.000029   Epoch: 0   Global Step: 10280   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:42:56,819-Speed 139.70 samples/sec   Loss 1.2521   LearningRate 0.000029   Epoch: 0   Global Step: 10290   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:42:59,116-Speed 139.36 samples/sec   Loss 1.2161   LearningRate 0.000029   Epoch: 0   Global Step: 10300   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:43:01,405-Speed 139.84 samples/sec   Loss 1.2029   LearningRate 0.000029   Epoch: 0   Global Step: 10310   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:43:03,694-Speed 139.83 samples/sec   Loss 1.2723   LearningRate 0.000029   Epoch: 0   Global Step: 10320   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:43:05,983-Speed 139.84 samples/sec   Loss 1.2449   LearningRate 0.000029   Epoch: 0   Global Step: 10330   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:43:08,266-Speed 140.19 samples/sec   Loss 1.2188   LearningRate 0.000029   Epoch: 0   Global Step: 10340   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:43:10,553-Speed 139.96 samples/sec   Loss 1.2753   LearningRate 0.000029   Epoch: 0   Global Step: 10350   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:43:12,826-Speed 140.87 samples/sec   Loss 1.2499   LearningRate 0.000029   Epoch: 0   Global Step: 10360   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:43:15,112-Speed 139.98 samples/sec   Loss 1.2584   LearningRate 0.000029   Epoch: 0   Global Step: 10370   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:43:17,400-Speed 139.89 samples/sec   Loss 1.2337   LearningRate 0.000029   Epoch: 0   Global Step: 10380   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:43:19,709-Speed 138.64 samples/sec   Loss 1.3005   LearningRate 0.000029   Epoch: 0   Global Step: 10390   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:43:21,992-Speed 140.22 samples/sec   Loss 1.2391   LearningRate 0.000029   Epoch: 0   Global Step: 10400   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:43:24,299-Speed 138.71 samples/sec   Loss 1.2449   LearningRate 0.000029   Epoch: 0   Global Step: 10410   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:43:26,602-Speed 139.01 samples/sec   Loss 1.2523   LearningRate 0.000029   Epoch: 0   Global Step: 10420   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:43:28,908-Speed 138.79 samples/sec   Loss 1.2661   LearningRate 0.000029   Epoch: 0   Global Step: 10430   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:43:31,199-Speed 139.74 samples/sec   Loss 1.2513   LearningRate 0.000029   Epoch: 0   Global Step: 10440   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:43:33,493-Speed 139.53 samples/sec   Loss 1.2405   LearningRate 0.000029   Epoch: 0   Global Step: 10450   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:43:35,798-Speed 138.88 samples/sec   Loss 1.2661   LearningRate 0.000029   Epoch: 0   Global Step: 10460   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:43:38,110-Speed 138.41 samples/sec   Loss 1.2180   LearningRate 0.000029   Epoch: 0   Global Step: 10470   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:43:40,423-Speed 138.39 samples/sec   Loss 1.2191   LearningRate 0.000029   Epoch: 0   Global Step: 10480   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:43:42,719-Speed 139.40 samples/sec   Loss 1.2469   LearningRate 0.000029   Epoch: 0   Global Step: 10490   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:43:45,017-Speed 139.34 samples/sec   Loss 1.2322   LearningRate 0.000029   Epoch: 0   Global Step: 10500   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:43:47,309-Speed 139.65 samples/sec   Loss 1.2773   LearningRate 0.000029   Epoch: 0   Global Step: 10510   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:43:49,606-Speed 139.36 samples/sec   Loss 1.2817   LearningRate 0.000029   Epoch: 0   Global Step: 10520   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:43:51,901-Speed 139.44 samples/sec   Loss 1.2546   LearningRate 0.000029   Epoch: 0   Global Step: 10530   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:43:54,208-Speed 138.77 samples/sec   Loss 1.2175   LearningRate 0.000029   Epoch: 0   Global Step: 10540   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:43:56,497-Speed 139.85 samples/sec   Loss 1.2371   LearningRate 0.000029   Epoch: 0   Global Step: 10550   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:43:58,755-Speed 141.72 samples/sec   Loss 1.2690   LearningRate 0.000029   Epoch: 0   Global Step: 10560   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:44:01,030-Speed 140.68 samples/sec   Loss 1.2262   LearningRate 0.000029   Epoch: 0   Global Step: 10570   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:44:03,307-Speed 140.56 samples/sec   Loss 1.2211   LearningRate 0.000029   Epoch: 0   Global Step: 10580   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:44:05,588-Speed 140.38 samples/sec   Loss 1.2559   LearningRate 0.000029   Epoch: 0   Global Step: 10590   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:44:07,892-Speed 138.89 samples/sec   Loss 1.2474   LearningRate 0.000029   Epoch: 0   Global Step: 10600   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:44:10,169-Speed 140.59 samples/sec   Loss 1.2195   LearningRate 0.000029   Epoch: 0   Global Step: 10610   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:44:12,436-Speed 141.19 samples/sec   Loss 1.2026   LearningRate 0.000029   Epoch: 0   Global Step: 10620   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:44:14,725-Speed 139.84 samples/sec   Loss 1.2483   LearningRate 0.000029   Epoch: 0   Global Step: 10630   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:44:17,018-Speed 139.57 samples/sec   Loss 1.2707   LearningRate 0.000029   Epoch: 0   Global Step: 10640   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:44:19,301-Speed 140.18 samples/sec   Loss 1.2428   LearningRate 0.000029   Epoch: 0   Global Step: 10650   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:44:21,573-Speed 140.92 samples/sec   Loss 1.2350   LearningRate 0.000029   Epoch: 0   Global Step: 10660   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:44:23,863-Speed 139.74 samples/sec   Loss 1.2362   LearningRate 0.000029   Epoch: 0   Global Step: 10670   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:44:26,143-Speed 140.42 samples/sec   Loss 1.2671   LearningRate 0.000029   Epoch: 0   Global Step: 10680   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:44:28,427-Speed 140.14 samples/sec   Loss 1.2244   LearningRate 0.000029   Epoch: 0   Global Step: 10690   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:44:30,705-Speed 140.53 samples/sec   Loss 1.2414   LearningRate 0.000029   Epoch: 0   Global Step: 10700   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:44:32,994-Speed 139.79 samples/sec   Loss 1.2194   LearningRate 0.000029   Epoch: 0   Global Step: 10710   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:44:35,283-Speed 139.88 samples/sec   Loss 1.2421   LearningRate 0.000029   Epoch: 0   Global Step: 10720   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:44:37,552-Speed 141.06 samples/sec   Loss 1.2145   LearningRate 0.000029   Epoch: 0   Global Step: 10730   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:44:39,834-Speed 140.25 samples/sec   Loss 1.2372   LearningRate 0.000029   Epoch: 0   Global Step: 10740   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:44:42,105-Speed 140.97 samples/sec   Loss 1.2399   LearningRate 0.000029   Epoch: 0   Global Step: 10750   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:44:44,396-Speed 139.71 samples/sec   Loss 1.2648   LearningRate 0.000029   Epoch: 0   Global Step: 10760   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:44:46,696-Speed 139.11 samples/sec   Loss 1.2405   LearningRate 0.000029   Epoch: 0   Global Step: 10770   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:44:48,964-Speed 141.14 samples/sec   Loss 1.2307   LearningRate 0.000029   Epoch: 0   Global Step: 10780   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:44:51,243-Speed 140.49 samples/sec   Loss 1.1991   LearningRate 0.000029   Epoch: 0   Global Step: 10790   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:44:53,513-Speed 141.02 samples/sec   Loss 1.2124   LearningRate 0.000029   Epoch: 0   Global Step: 10800   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:44:55,808-Speed 139.45 samples/sec   Loss 1.2712   LearningRate 0.000029   Epoch: 0   Global Step: 10810   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:44:58,081-Speed 140.82 samples/sec   Loss 1.2644   LearningRate 0.000029   Epoch: 0   Global Step: 10820   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:45:00,360-Speed 140.44 samples/sec   Loss 1.2440   LearningRate 0.000029   Epoch: 0   Global Step: 10830   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:45:02,646-Speed 139.99 samples/sec   Loss 1.2542   LearningRate 0.000029   Epoch: 0   Global Step: 10840   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:45:04,928-Speed 140.27 samples/sec   Loss 1.2084   LearningRate 0.000029   Epoch: 0   Global Step: 10850   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:45:07,213-Speed 140.10 samples/sec   Loss 1.2402   LearningRate 0.000029   Epoch: 0   Global Step: 10860   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:45:09,508-Speed 139.48 samples/sec   Loss 1.2034   LearningRate 0.000029   Epoch: 0   Global Step: 10870   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:45:11,775-Speed 141.20 samples/sec   Loss 1.2351   LearningRate 0.000029   Epoch: 0   Global Step: 10880   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:45:14,065-Speed 139.78 samples/sec   Loss 1.2422   LearningRate 0.000029   Epoch: 0   Global Step: 10890   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:45:16,364-Speed 139.18 samples/sec   Loss 1.1990   LearningRate 0.000029   Epoch: 0   Global Step: 10900   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:45:18,660-Speed 139.43 samples/sec   Loss 1.2536   LearningRate 0.000029   Epoch: 0   Global Step: 10910   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:45:20,957-Speed 139.34 samples/sec   Loss 1.2193   LearningRate 0.000029   Epoch: 0   Global Step: 10920   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:45:23,247-Speed 139.81 samples/sec   Loss 1.2327   LearningRate 0.000029   Epoch: 0   Global Step: 10930   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:45:25,541-Speed 139.50 samples/sec   Loss 1.2540   LearningRate 0.000029   Epoch: 0   Global Step: 10940   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:45:27,833-Speed 139.69 samples/sec   Loss 1.1919   LearningRate 0.000029   Epoch: 0   Global Step: 10950   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:45:30,121-Speed 139.90 samples/sec   Loss 1.2275   LearningRate 0.000029   Epoch: 0   Global Step: 10960   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:45:32,417-Speed 139.40 samples/sec   Loss 1.2386   LearningRate 0.000029   Epoch: 0   Global Step: 10970   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:45:34,685-Speed 141.15 samples/sec   Loss 1.2242   LearningRate 0.000029   Epoch: 0   Global Step: 10980   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:45:36,984-Speed 139.24 samples/sec   Loss 1.1760   LearningRate 0.000029   Epoch: 0   Global Step: 10990   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:45:39,050-Val on RAF/AffectNet:
Training: 2023-08-17 21:45:39,166-Test: [0/48]	Time 0.116 (0.116)	Loss 0.6402 (0.6402)	Acc@1 89.062 (89.062)	Acc@5 95.312 (95.312)	Mem 5268MB
Training: 2023-08-17 21:45:40,275-Test: [10/48]	Time 0.112 (0.111)	Loss 0.6622 (0.6089)	Acc@1 85.938 (88.920)	Acc@5 98.438 (99.006)	Mem 5268MB
Training: 2023-08-17 21:45:41,346-Test: [20/48]	Time 0.108 (0.109)	Loss 0.5432 (0.5839)	Acc@1 90.625 (89.509)	Acc@5 100.000 (99.256)	Mem 5268MB
Training: 2023-08-17 21:45:42,464-Test: [30/48]	Time 0.113 (0.110)	Loss 0.5553 (0.5817)	Acc@1 92.188 (90.020)	Acc@5 100.000 (99.294)	Mem 5268MB
Training: 2023-08-17 21:45:43,562-Test: [40/48]	Time 0.109 (0.110)	Loss 0.5878 (0.5674)	Acc@1 90.625 (90.930)	Acc@5 100.000 (99.352)	Mem 5268MB
Training: 2023-08-17 21:45:44,305-[10999]Expression Loss: 0.56134
Training: 2023-08-17 21:45:44,305-[10999]Expression Acc@1: 91.23207
Training: 2023-08-17 21:45:44,305-[10999]Expression Acc@1-Highest: 91.65580
Training: 2023-08-17 21:45:44,305-[10999]Expression Acc@5: 99.44589
Training: 2023-08-17 21:45:44,306-[10999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 21:45:44,306-[10999]10 Times Expression Acc@1: 89.77184
Training: 2023-08-17 21:45:44,306-[10999]10 Times Expression Acc@1-Highest: 89.77184
Training: 2023-08-17 21:45:44,535-Speed 42.38 samples/sec   Loss 1.2171   LearningRate 0.000029   Epoch: 0   Global Step: 11000   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:45:46,815-Speed 140.35 samples/sec   Loss 1.2392   LearningRate 0.000029   Epoch: 0   Global Step: 11010   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:45:49,092-Speed 140.59 samples/sec   Loss 1.2418   LearningRate 0.000029   Epoch: 0   Global Step: 11020   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:45:51,365-Speed 140.85 samples/sec   Loss 1.2299   LearningRate 0.000029   Epoch: 0   Global Step: 11030   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:45:53,644-Speed 140.40 samples/sec   Loss 1.2296   LearningRate 0.000029   Epoch: 0   Global Step: 11040   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:45:55,931-Speed 139.98 samples/sec   Loss 1.2467   LearningRate 0.000029   Epoch: 0   Global Step: 11050   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:45:58,220-Speed 139.85 samples/sec   Loss 1.2099   LearningRate 0.000029   Epoch: 0   Global Step: 11060   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:46:00,500-Speed 140.40 samples/sec   Loss 1.2556   LearningRate 0.000029   Epoch: 0   Global Step: 11070   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:46:02,799-Speed 139.22 samples/sec   Loss 1.2183   LearningRate 0.000029   Epoch: 0   Global Step: 11080   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:46:05,091-Speed 139.71 samples/sec   Loss 1.2583   LearningRate 0.000029   Epoch: 0   Global Step: 11090   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:46:07,394-Speed 138.97 samples/sec   Loss 1.2559   LearningRate 0.000029   Epoch: 0   Global Step: 11100   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:46:09,695-Speed 139.12 samples/sec   Loss 1.2410   LearningRate 0.000029   Epoch: 0   Global Step: 11110   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:46:11,998-Speed 138.99 samples/sec   Loss 1.2802   LearningRate 0.000029   Epoch: 0   Global Step: 11120   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:46:14,301-Speed 138.97 samples/sec   Loss 1.2514   LearningRate 0.000029   Epoch: 0   Global Step: 11130   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:46:16,583-Speed 140.28 samples/sec   Loss 1.2385   LearningRate 0.000029   Epoch: 0   Global Step: 11140   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:46:18,876-Speed 139.54 samples/sec   Loss 1.2324   LearningRate 0.000029   Epoch: 0   Global Step: 11150   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:46:21,178-Speed 139.12 samples/sec   Loss 1.2232   LearningRate 0.000029   Epoch: 0   Global Step: 11160   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:46:23,479-Speed 139.07 samples/sec   Loss 1.2269   LearningRate 0.000029   Epoch: 0   Global Step: 11170   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:46:25,759-Speed 140.41 samples/sec   Loss 1.2549   LearningRate 0.000029   Epoch: 0   Global Step: 11180   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:46:28,054-Speed 139.45 samples/sec   Loss 1.2399   LearningRate 0.000029   Epoch: 0   Global Step: 11190   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:46:30,344-Speed 139.79 samples/sec   Loss 1.2535   LearningRate 0.000029   Epoch: 0   Global Step: 11200   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:46:32,652-Speed 138.67 samples/sec   Loss 1.2186   LearningRate 0.000029   Epoch: 0   Global Step: 11210   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:46:34,950-Speed 139.28 samples/sec   Loss 1.2240   LearningRate 0.000029   Epoch: 0   Global Step: 11220   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:46:37,234-Speed 140.15 samples/sec   Loss 1.2319   LearningRate 0.000029   Epoch: 0   Global Step: 11230   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:46:39,512-Speed 140.51 samples/sec   Loss 1.2677   LearningRate 0.000029   Epoch: 0   Global Step: 11240   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:46:41,802-Speed 139.80 samples/sec   Loss 1.2483   LearningRate 0.000029   Epoch: 0   Global Step: 11250   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:46:44,081-Speed 140.42 samples/sec   Loss 1.2378   LearningRate 0.000029   Epoch: 0   Global Step: 11260   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:46:46,353-Speed 140.92 samples/sec   Loss 1.2173   LearningRate 0.000029   Epoch: 0   Global Step: 11270   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:46:48,645-Speed 139.64 samples/sec   Loss 1.2102   LearningRate 0.000029   Epoch: 0   Global Step: 11280   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:46:50,938-Speed 139.62 samples/sec   Loss 1.2766   LearningRate 0.000029   Epoch: 0   Global Step: 11290   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:46:53,227-Speed 139.79 samples/sec   Loss 1.2209   LearningRate 0.000029   Epoch: 0   Global Step: 11300   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:46:55,539-Speed 138.46 samples/sec   Loss 1.2177   LearningRate 0.000029   Epoch: 0   Global Step: 11310   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:46:57,863-Speed 137.72 samples/sec   Loss 1.2070   LearningRate 0.000029   Epoch: 0   Global Step: 11320   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:47:00,163-Speed 139.22 samples/sec   Loss 1.2748   LearningRate 0.000029   Epoch: 0   Global Step: 11330   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:47:02,482-Speed 138.03 samples/sec   Loss 1.2561   LearningRate 0.000029   Epoch: 0   Global Step: 11340   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:47:04,791-Speed 138.62 samples/sec   Loss 1.2385   LearningRate 0.000029   Epoch: 0   Global Step: 11350   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:47:07,110-Speed 138.03 samples/sec   Loss 1.2656   LearningRate 0.000029   Epoch: 0   Global Step: 11360   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:47:09,425-Speed 138.24 samples/sec   Loss 1.2278   LearningRate 0.000029   Epoch: 0   Global Step: 11370   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:47:11,739-Speed 138.37 samples/sec   Loss 1.2437   LearningRate 0.000029   Epoch: 0   Global Step: 11380   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:47:14,063-Speed 137.70 samples/sec   Loss 1.2401   LearningRate 0.000029   Epoch: 0   Global Step: 11390   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:47:16,384-Speed 137.90 samples/sec   Loss 1.2143   LearningRate 0.000029   Epoch: 0   Global Step: 11400   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:47:18,675-Speed 139.71 samples/sec   Loss 1.2597   LearningRate 0.000029   Epoch: 0   Global Step: 11410   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:47:20,993-Speed 138.13 samples/sec   Loss 1.2477   LearningRate 0.000029   Epoch: 0   Global Step: 11420   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:47:23,269-Speed 140.61 samples/sec   Loss 1.2447   LearningRate 0.000029   Epoch: 0   Global Step: 11430   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:47:25,586-Speed 138.17 samples/sec   Loss 1.2395   LearningRate 0.000029   Epoch: 0   Global Step: 11440   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:47:27,880-Speed 139.47 samples/sec   Loss 1.2452   LearningRate 0.000029   Epoch: 0   Global Step: 11450   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:47:30,197-Speed 138.16 samples/sec   Loss 1.2777   LearningRate 0.000029   Epoch: 0   Global Step: 11460   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:47:32,508-Speed 138.53 samples/sec   Loss 1.2557   LearningRate 0.000029   Epoch: 0   Global Step: 11470   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:47:34,832-Speed 137.72 samples/sec   Loss 1.2332   LearningRate 0.000029   Epoch: 0   Global Step: 11480   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:47:37,145-Speed 138.42 samples/sec   Loss 1.2459   LearningRate 0.000029   Epoch: 0   Global Step: 11490   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:47:39,444-Speed 139.24 samples/sec   Loss 1.2630   LearningRate 0.000029   Epoch: 0   Global Step: 11500   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:47:41,737-Speed 139.56 samples/sec   Loss 1.2389   LearningRate 0.000029   Epoch: 0   Global Step: 11510   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:47:44,037-Speed 139.18 samples/sec   Loss 1.2634   LearningRate 0.000029   Epoch: 0   Global Step: 11520   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:47:46,340-Speed 139.01 samples/sec   Loss 1.2358   LearningRate 0.000029   Epoch: 0   Global Step: 11530   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:47:48,641-Speed 139.09 samples/sec   Loss 1.2515   LearningRate 0.000029   Epoch: 0   Global Step: 11540   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:47:50,893-Speed 142.10 samples/sec   Loss 1.2344   LearningRate 0.000029   Epoch: 0   Global Step: 11550   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:47:53,181-Speed 139.90 samples/sec   Loss 1.2431   LearningRate 0.000029   Epoch: 0   Global Step: 11560   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:47:55,467-Speed 140.03 samples/sec   Loss 1.2318   LearningRate 0.000028   Epoch: 0   Global Step: 11570   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:47:57,751-Speed 140.20 samples/sec   Loss 1.2206   LearningRate 0.000028   Epoch: 0   Global Step: 11580   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:48:00,026-Speed 140.70 samples/sec   Loss 1.2097   LearningRate 0.000028   Epoch: 0   Global Step: 11590   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:48:02,302-Speed 140.62 samples/sec   Loss 1.2008   LearningRate 0.000028   Epoch: 0   Global Step: 11600   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:48:04,603-Speed 139.11 samples/sec   Loss 1.2115   LearningRate 0.000028   Epoch: 0   Global Step: 11610   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:48:06,891-Speed 139.89 samples/sec   Loss 1.2229   LearningRate 0.000028   Epoch: 0   Global Step: 11620   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:48:09,180-Speed 139.83 samples/sec   Loss 1.2573   LearningRate 0.000028   Epoch: 0   Global Step: 11630   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:48:11,475-Speed 139.50 samples/sec   Loss 1.2492   LearningRate 0.000028   Epoch: 0   Global Step: 11640   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:48:13,760-Speed 140.08 samples/sec   Loss 1.2182   LearningRate 0.000028   Epoch: 0   Global Step: 11650   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:48:16,040-Speed 140.37 samples/sec   Loss 1.2289   LearningRate 0.000028   Epoch: 0   Global Step: 11660   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:48:18,329-Speed 139.84 samples/sec   Loss 1.2352   LearningRate 0.000028   Epoch: 0   Global Step: 11670   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:48:20,621-Speed 139.68 samples/sec   Loss 1.2429   LearningRate 0.000028   Epoch: 0   Global Step: 11680   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:48:22,916-Speed 139.48 samples/sec   Loss 1.1965   LearningRate 0.000028   Epoch: 0   Global Step: 11690   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:48:25,212-Speed 139.42 samples/sec   Loss 1.2255   LearningRate 0.000028   Epoch: 0   Global Step: 11700   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:48:27,498-Speed 139.98 samples/sec   Loss 1.2271   LearningRate 0.000028   Epoch: 0   Global Step: 11710   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:48:29,784-Speed 140.04 samples/sec   Loss 1.2378   LearningRate 0.000028   Epoch: 0   Global Step: 11720   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:48:32,083-Speed 139.32 samples/sec   Loss 1.2273   LearningRate 0.000028   Epoch: 0   Global Step: 11730   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:48:34,365-Speed 140.26 samples/sec   Loss 1.2734   LearningRate 0.000028   Epoch: 0   Global Step: 11740   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:48:36,656-Speed 139.70 samples/sec   Loss 1.1921   LearningRate 0.000028   Epoch: 0   Global Step: 11750   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:48:38,938-Speed 140.25 samples/sec   Loss 1.2274   LearningRate 0.000028   Epoch: 0   Global Step: 11760   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:48:41,220-Speed 140.31 samples/sec   Loss 1.2315   LearningRate 0.000028   Epoch: 0   Global Step: 11770   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:48:43,503-Speed 140.18 samples/sec   Loss 1.2152   LearningRate 0.000028   Epoch: 0   Global Step: 11780   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:48:45,780-Speed 140.61 samples/sec   Loss 1.2056   LearningRate 0.000028   Epoch: 0   Global Step: 11790   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:48:48,071-Speed 139.69 samples/sec   Loss 1.2467   LearningRate 0.000028   Epoch: 0   Global Step: 11800   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:48:50,360-Speed 139.83 samples/sec   Loss 1.2630   LearningRate 0.000028   Epoch: 0   Global Step: 11810   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:48:52,639-Speed 140.47 samples/sec   Loss 1.2409   LearningRate 0.000028   Epoch: 0   Global Step: 11820   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:48:54,923-Speed 140.15 samples/sec   Loss 1.2544   LearningRate 0.000028   Epoch: 0   Global Step: 11830   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:48:57,207-Speed 140.14 samples/sec   Loss 1.2248   LearningRate 0.000028   Epoch: 0   Global Step: 11840   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:48:59,499-Speed 139.67 samples/sec   Loss 1.2293   LearningRate 0.000028   Epoch: 0   Global Step: 11850   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:49:01,773-Speed 140.72 samples/sec   Loss 1.2362   LearningRate 0.000028   Epoch: 0   Global Step: 11860   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:49:04,071-Speed 139.35 samples/sec   Loss 1.2344   LearningRate 0.000028   Epoch: 0   Global Step: 11870   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:49:06,371-Speed 139.12 samples/sec   Loss 1.2084   LearningRate 0.000028   Epoch: 0   Global Step: 11880   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:49:08,652-Speed 140.39 samples/sec   Loss 1.2284   LearningRate 0.000028   Epoch: 0   Global Step: 11890   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:49:10,952-Speed 139.13 samples/sec   Loss 1.2228   LearningRate 0.000028   Epoch: 0   Global Step: 11900   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:49:13,241-Speed 139.85 samples/sec   Loss 1.2044   LearningRate 0.000028   Epoch: 0   Global Step: 11910   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:49:15,537-Speed 139.40 samples/sec   Loss 1.2058   LearningRate 0.000028   Epoch: 0   Global Step: 11920   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:49:17,829-Speed 139.65 samples/sec   Loss 1.2522   LearningRate 0.000028   Epoch: 0   Global Step: 11930   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:49:20,111-Speed 140.29 samples/sec   Loss 1.2772   LearningRate 0.000028   Epoch: 0   Global Step: 11940   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:49:22,406-Speed 139.50 samples/sec   Loss 1.2209   LearningRate 0.000028   Epoch: 0   Global Step: 11950   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:49:24,689-Speed 140.18 samples/sec   Loss 1.2203   LearningRate 0.000028   Epoch: 0   Global Step: 11960   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:49:26,974-Speed 140.07 samples/sec   Loss 1.2179   LearningRate 0.000028   Epoch: 0   Global Step: 11970   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:49:29,253-Speed 140.44 samples/sec   Loss 1.2081   LearningRate 0.000028   Epoch: 0   Global Step: 11980   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:49:31,527-Speed 140.82 samples/sec   Loss 1.2063   LearningRate 0.000028   Epoch: 0   Global Step: 11990   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:49:33,576-Val on RAF/AffectNet:
Training: 2023-08-17 21:49:33,684-Test: [0/48]	Time 0.107 (0.107)	Loss 0.6801 (0.6801)	Acc@1 84.375 (84.375)	Acc@5 98.438 (98.438)	Mem 5268MB
Training: 2023-08-17 21:49:34,725-Test: [10/48]	Time 0.103 (0.104)	Loss 0.5904 (0.5845)	Acc@1 85.938 (90.483)	Acc@5 100.000 (98.864)	Mem 5268MB
Training: 2023-08-17 21:49:35,759-Test: [20/48]	Time 0.102 (0.104)	Loss 0.5634 (0.5743)	Acc@1 90.625 (91.443)	Acc@5 100.000 (99.107)	Mem 5268MB
Training: 2023-08-17 21:49:36,805-Test: [30/48]	Time 0.102 (0.104)	Loss 0.7394 (0.5709)	Acc@1 84.375 (91.482)	Acc@5 98.438 (99.143)	Mem 5268MB
Training: 2023-08-17 21:49:37,841-Test: [40/48]	Time 0.102 (0.104)	Loss 0.4391 (0.5656)	Acc@1 96.875 (91.616)	Acc@5 100.000 (99.238)	Mem 5268MB
Training: 2023-08-17 21:49:38,562-[11999]Expression Loss: 0.56731
Training: 2023-08-17 21:49:38,562-[11999]Expression Acc@1: 91.52542
Training: 2023-08-17 21:49:38,563-[11999]Expression Acc@1-Highest: 91.65580
Training: 2023-08-17 21:49:38,563-[11999]Expression Acc@5: 99.21773
Training: 2023-08-17 21:49:38,563-[11999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 21:49:38,563-[11999]10 Times Expression Acc@1: 90.52803
Training: 2023-08-17 21:49:38,563-[11999]10 Times Expression Acc@1-Highest: 90.52803
Training: 2023-08-17 21:49:39,152-Speed 41.97 samples/sec   Loss 1.2220   LearningRate 0.000028   Epoch: 0   Global Step: 12000   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:49:41,432-Speed 140.41 samples/sec   Loss 1.2387   LearningRate 0.000028   Epoch: 0   Global Step: 12010   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:49:43,692-Speed 141.63 samples/sec   Loss 1.2235   LearningRate 0.000028   Epoch: 0   Global Step: 12020   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:49:45,969-Speed 140.58 samples/sec   Loss 1.2151   LearningRate 0.000028   Epoch: 0   Global Step: 12030   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:49:48,253-Speed 140.10 samples/sec   Loss 1.2522   LearningRate 0.000028   Epoch: 0   Global Step: 12040   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:49:50,533-Speed 140.45 samples/sec   Loss 1.2453   LearningRate 0.000028   Epoch: 0   Global Step: 12050   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:49:52,810-Speed 140.55 samples/sec   Loss 1.2063   LearningRate 0.000028   Epoch: 0   Global Step: 12060   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:49:55,093-Speed 140.18 samples/sec   Loss 1.2136   LearningRate 0.000028   Epoch: 0   Global Step: 12070   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:49:57,374-Speed 140.37 samples/sec   Loss 1.2602   LearningRate 0.000028   Epoch: 0   Global Step: 12080   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:49:59,668-Speed 139.52 samples/sec   Loss 1.2403   LearningRate 0.000028   Epoch: 0   Global Step: 12090   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:50:01,972-Speed 138.94 samples/sec   Loss 1.2254   LearningRate 0.000028   Epoch: 0   Global Step: 12100   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:50:04,283-Speed 138.51 samples/sec   Loss 1.2177   LearningRate 0.000028   Epoch: 0   Global Step: 12110   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:50:06,582-Speed 139.21 samples/sec   Loss 1.2405   LearningRate 0.000028   Epoch: 0   Global Step: 12120   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:50:08,888-Speed 138.81 samples/sec   Loss 1.2682   LearningRate 0.000028   Epoch: 0   Global Step: 12130   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:50:11,204-Speed 138.18 samples/sec   Loss 1.2622   LearningRate 0.000028   Epoch: 0   Global Step: 12140   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:50:13,525-Speed 137.93 samples/sec   Loss 1.2357   LearningRate 0.000028   Epoch: 0   Global Step: 12150   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:50:15,836-Speed 138.52 samples/sec   Loss 1.2388   LearningRate 0.000028   Epoch: 0   Global Step: 12160   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:50:18,158-Speed 137.86 samples/sec   Loss 1.2376   LearningRate 0.000028   Epoch: 0   Global Step: 12170   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:50:20,482-Speed 137.73 samples/sec   Loss 1.2233   LearningRate 0.000028   Epoch: 0   Global Step: 12180   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:50:22,797-Speed 138.30 samples/sec   Loss 1.2460   LearningRate 0.000028   Epoch: 0   Global Step: 12190   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:50:25,106-Speed 138.62 samples/sec   Loss 1.2272   LearningRate 0.000028   Epoch: 0   Global Step: 12200   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:50:27,424-Speed 138.10 samples/sec   Loss 1.2075   LearningRate 0.000028   Epoch: 0   Global Step: 12210   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:50:29,739-Speed 138.24 samples/sec   Loss 1.2109   LearningRate 0.000028   Epoch: 0   Global Step: 12220   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:50:32,054-Speed 138.26 samples/sec   Loss 1.2794   LearningRate 0.000028   Epoch: 0   Global Step: 12230   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:50:34,345-Speed 139.69 samples/sec   Loss 1.2483   LearningRate 0.000028   Epoch: 0   Global Step: 12240   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:50:36,667-Speed 137.88 samples/sec   Loss 1.2169   LearningRate 0.000028   Epoch: 0   Global Step: 12250   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:50:38,956-Speed 139.88 samples/sec   Loss 1.2413   LearningRate 0.000028   Epoch: 0   Global Step: 12260   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:50:41,261-Speed 138.81 samples/sec   Loss 1.2178   LearningRate 0.000028   Epoch: 0   Global Step: 12270   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:50:43,582-Speed 137.95 samples/sec   Loss 1.2215   LearningRate 0.000028   Epoch: 0   Global Step: 12280   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:50:45,898-Speed 138.18 samples/sec   Loss 1.2130   LearningRate 0.000028   Epoch: 0   Global Step: 12290   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:50:48,212-Speed 138.34 samples/sec   Loss 1.2376   LearningRate 0.000028   Epoch: 0   Global Step: 12300   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:50:50,538-Speed 137.58 samples/sec   Loss 1.2326   LearningRate 0.000028   Epoch: 0   Global Step: 12310   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:50:52,821-Speed 140.24 samples/sec   Loss 1.2431   LearningRate 0.000028   Epoch: 0   Global Step: 12320   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:50:55,098-Speed 140.56 samples/sec   Loss 1.2595   LearningRate 0.000028   Epoch: 0   Global Step: 12330   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:50:57,389-Speed 139.73 samples/sec   Loss 1.2288   LearningRate 0.000028   Epoch: 0   Global Step: 12340   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:50:59,654-Speed 141.32 samples/sec   Loss 1.2295   LearningRate 0.000028   Epoch: 0   Global Step: 12350   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:51:01,945-Speed 139.74 samples/sec   Loss 1.2143   LearningRate 0.000028   Epoch: 0   Global Step: 12360   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:51:04,230-Speed 140.08 samples/sec   Loss 1.2339   LearningRate 0.000028   Epoch: 0   Global Step: 12370   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:51:06,513-Speed 140.17 samples/sec   Loss 1.1901   LearningRate 0.000028   Epoch: 0   Global Step: 12380   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:51:08,798-Speed 140.09 samples/sec   Loss 1.2077   LearningRate 0.000028   Epoch: 0   Global Step: 12390   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:51:11,071-Speed 140.88 samples/sec   Loss 1.2291   LearningRate 0.000028   Epoch: 0   Global Step: 12400   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:51:13,336-Speed 141.31 samples/sec   Loss 1.1974   LearningRate 0.000028   Epoch: 0   Global Step: 12410   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:51:15,612-Speed 140.64 samples/sec   Loss 1.2423   LearningRate 0.000028   Epoch: 0   Global Step: 12420   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:51:17,895-Speed 140.18 samples/sec   Loss 1.2073   LearningRate 0.000028   Epoch: 0   Global Step: 12430   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:51:20,187-Speed 139.62 samples/sec   Loss 1.2488   LearningRate 0.000028   Epoch: 0   Global Step: 12440   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:51:22,455-Speed 141.16 samples/sec   Loss 1.2188   LearningRate 0.000028   Epoch: 0   Global Step: 12450   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:51:24,749-Speed 139.56 samples/sec   Loss 1.2577   LearningRate 0.000028   Epoch: 0   Global Step: 12460   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:51:27,030-Speed 140.34 samples/sec   Loss 1.2396   LearningRate 0.000028   Epoch: 0   Global Step: 12470   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:51:29,288-Speed 141.78 samples/sec   Loss 1.2586   LearningRate 0.000028   Epoch: 0   Global Step: 12480   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:51:31,545-Speed 141.80 samples/sec   Loss 1.2268   LearningRate 0.000028   Epoch: 0   Global Step: 12490   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:51:33,817-Speed 140.91 samples/sec   Loss 1.2518   LearningRate 0.000028   Epoch: 0   Global Step: 12500   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:51:36,105-Speed 139.84 samples/sec   Loss 1.2228   LearningRate 0.000028   Epoch: 0   Global Step: 12510   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:51:38,377-Speed 140.90 samples/sec   Loss 1.2116   LearningRate 0.000028   Epoch: 0   Global Step: 12520   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:51:40,640-Speed 141.42 samples/sec   Loss 1.2591   LearningRate 0.000028   Epoch: 0   Global Step: 12530   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:51:42,911-Speed 140.98 samples/sec   Loss 1.2453   LearningRate 0.000028   Epoch: 0   Global Step: 12540   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:51:45,190-Speed 140.48 samples/sec   Loss 1.2248   LearningRate 0.000028   Epoch: 0   Global Step: 12550   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:51:47,469-Speed 140.45 samples/sec   Loss 1.2391   LearningRate 0.000028   Epoch: 0   Global Step: 12560   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:51:49,740-Speed 140.91 samples/sec   Loss 1.2295   LearningRate 0.000028   Epoch: 0   Global Step: 12570   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:51:52,009-Speed 141.09 samples/sec   Loss 1.2094   LearningRate 0.000028   Epoch: 0   Global Step: 12580   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:51:54,303-Speed 139.55 samples/sec   Loss 1.2197   LearningRate 0.000028   Epoch: 0   Global Step: 12590   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:51:56,578-Speed 140.71 samples/sec   Loss 1.1940   LearningRate 0.000028   Epoch: 0   Global Step: 12600   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:51:58,871-Speed 139.59 samples/sec   Loss 1.2234   LearningRate 0.000028   Epoch: 0   Global Step: 12610   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:52:01,147-Speed 140.63 samples/sec   Loss 1.2336   LearningRate 0.000028   Epoch: 0   Global Step: 12620   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:52:03,441-Speed 139.54 samples/sec   Loss 1.2015   LearningRate 0.000028   Epoch: 0   Global Step: 12630   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:52:05,763-Speed 137.88 samples/sec   Loss 1.2236   LearningRate 0.000028   Epoch: 0   Global Step: 12640   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:52:08,081-Speed 138.10 samples/sec   Loss 1.2088   LearningRate 0.000028   Epoch: 0   Global Step: 12650   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:52:10,372-Speed 139.69 samples/sec   Loss 1.2409   LearningRate 0.000028   Epoch: 0   Global Step: 12660   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:52:12,660-Speed 139.91 samples/sec   Loss 1.2171   LearningRate 0.000028   Epoch: 0   Global Step: 12670   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:52:14,974-Speed 138.31 samples/sec   Loss 1.2581   LearningRate 0.000028   Epoch: 0   Global Step: 12680   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:52:17,281-Speed 138.73 samples/sec   Loss 1.2461   LearningRate 0.000028   Epoch: 0   Global Step: 12690   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:52:19,598-Speed 138.18 samples/sec   Loss 1.2271   LearningRate 0.000028   Epoch: 0   Global Step: 12700   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:52:21,928-Speed 137.40 samples/sec   Loss 1.2166   LearningRate 0.000028   Epoch: 0   Global Step: 12710   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:52:24,257-Speed 137.43 samples/sec   Loss 1.2242   LearningRate 0.000028   Epoch: 0   Global Step: 12720   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:52:26,586-Speed 137.43 samples/sec   Loss 1.2562   LearningRate 0.000028   Epoch: 0   Global Step: 12730   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:52:28,910-Speed 137.73 samples/sec   Loss 1.2286   LearningRate 0.000028   Epoch: 0   Global Step: 12740   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:52:31,229-Speed 138.06 samples/sec   Loss 1.2131   LearningRate 0.000028   Epoch: 0   Global Step: 12750   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:52:33,550-Speed 137.88 samples/sec   Loss 1.2394   LearningRate 0.000028   Epoch: 0   Global Step: 12760   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:52:35,870-Speed 137.97 samples/sec   Loss 1.2201   LearningRate 0.000028   Epoch: 0   Global Step: 12770   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:52:38,189-Speed 138.04 samples/sec   Loss 1.2203   LearningRate 0.000028   Epoch: 0   Global Step: 12780   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:52:40,513-Speed 137.75 samples/sec   Loss 1.2235   LearningRate 0.000028   Epoch: 0   Global Step: 12790   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:52:42,834-Speed 137.87 samples/sec   Loss 1.2525   LearningRate 0.000028   Epoch: 0   Global Step: 12800   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:52:45,152-Speed 138.12 samples/sec   Loss 1.2407   LearningRate 0.000028   Epoch: 0   Global Step: 12810   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:52:47,466-Speed 138.33 samples/sec   Loss 1.2213   LearningRate 0.000028   Epoch: 0   Global Step: 12820   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:52:49,758-Speed 139.64 samples/sec   Loss 1.2124   LearningRate 0.000028   Epoch: 0   Global Step: 12830   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:52:52,053-Speed 139.48 samples/sec   Loss 1.2368   LearningRate 0.000028   Epoch: 0   Global Step: 12840   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:52:54,361-Speed 138.69 samples/sec   Loss 1.2682   LearningRate 0.000028   Epoch: 0   Global Step: 12850   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:52:56,669-Speed 138.68 samples/sec   Loss 1.2107   LearningRate 0.000028   Epoch: 0   Global Step: 12860   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:52:58,981-Speed 138.46 samples/sec   Loss 1.2276   LearningRate 0.000028   Epoch: 0   Global Step: 12870   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:53:01,282-Speed 139.10 samples/sec   Loss 1.2240   LearningRate 0.000028   Epoch: 0   Global Step: 12880   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:53:03,577-Speed 139.50 samples/sec   Loss 1.2310   LearningRate 0.000028   Epoch: 0   Global Step: 12890   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:53:05,895-Speed 138.08 samples/sec   Loss 1.2247   LearningRate 0.000028   Epoch: 0   Global Step: 12900   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:53:08,172-Speed 140.55 samples/sec   Loss 1.2484   LearningRate 0.000028   Epoch: 0   Global Step: 12910   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:53:10,459-Speed 139.98 samples/sec   Loss 1.2178   LearningRate 0.000028   Epoch: 0   Global Step: 12920   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:53:12,761-Speed 139.06 samples/sec   Loss 1.2313   LearningRate 0.000028   Epoch: 0   Global Step: 12930   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:53:15,068-Speed 138.77 samples/sec   Loss 1.2193   LearningRate 0.000028   Epoch: 0   Global Step: 12940   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:53:17,364-Speed 139.36 samples/sec   Loss 1.1995   LearningRate 0.000028   Epoch: 0   Global Step: 12950   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:53:19,659-Speed 139.53 samples/sec   Loss 1.2377   LearningRate 0.000028   Epoch: 0   Global Step: 12960   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:53:21,954-Speed 139.46 samples/sec   Loss 1.2111   LearningRate 0.000028   Epoch: 0   Global Step: 12970   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:53:24,259-Speed 138.87 samples/sec   Loss 1.2839   LearningRate 0.000028   Epoch: 0   Global Step: 12980   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:53:26,553-Speed 139.56 samples/sec   Loss 1.2347   LearningRate 0.000028   Epoch: 0   Global Step: 12990   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:53:28,609-Val on RAF/AffectNet:
Training: 2023-08-17 21:53:28,721-Test: [0/48]	Time 0.112 (0.112)	Loss 0.5238 (0.5238)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-17 21:53:29,761-Test: [10/48]	Time 0.104 (0.105)	Loss 0.5271 (0.5379)	Acc@1 95.312 (93.608)	Acc@5 100.000 (99.574)	Mem 5268MB
Training: 2023-08-17 21:53:30,807-Test: [20/48]	Time 0.102 (0.105)	Loss 0.6340 (0.5563)	Acc@1 90.625 (92.560)	Acc@5 96.875 (99.405)	Mem 5268MB
Training: 2023-08-17 21:53:31,858-Test: [30/48]	Time 0.108 (0.105)	Loss 0.5025 (0.5571)	Acc@1 93.750 (92.440)	Acc@5 100.000 (99.446)	Mem 5268MB
Training: 2023-08-17 21:53:32,907-Test: [40/48]	Time 0.105 (0.105)	Loss 0.5292 (0.5591)	Acc@1 92.188 (92.073)	Acc@5 100.000 (99.352)	Mem 5268MB
Training: 2023-08-17 21:53:33,657-[12999]Expression Loss: 0.56145
Training: 2023-08-17 21:53:33,658-[12999]Expression Acc@1: 91.94915
Training: 2023-08-17 21:53:33,658-[12999]Expression Acc@1-Highest: 91.94915
Training: 2023-08-17 21:53:33,658-[12999]Expression Acc@5: 99.25033
Training: 2023-08-17 21:53:33,658-[12999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 21:53:33,658-[12999]10 Times Expression Acc@1: 90.87353
Training: 2023-08-17 21:53:33,658-[12999]10 Times Expression Acc@1-Highest: 90.87353
Training: 2023-08-17 21:53:33,888-Speed 43.63 samples/sec   Loss 1.2373   LearningRate 0.000028   Epoch: 0   Global Step: 13000   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:53:36,183-Speed 139.47 samples/sec   Loss 1.2454   LearningRate 0.000028   Epoch: 0   Global Step: 13010   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:53:38,478-Speed 139.49 samples/sec   Loss 1.2021   LearningRate 0.000028   Epoch: 0   Global Step: 13020   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:53:40,754-Speed 140.60 samples/sec   Loss 1.2810   LearningRate 0.000028   Epoch: 0   Global Step: 13030   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:53:43,029-Speed 140.74 samples/sec   Loss 1.2147   LearningRate 0.000028   Epoch: 0   Global Step: 13040   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:53:45,286-Speed 141.78 samples/sec   Loss 1.2130   LearningRate 0.000028   Epoch: 0   Global Step: 13050   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:53:47,538-Speed 142.13 samples/sec   Loss 1.2168   LearningRate 0.000028   Epoch: 0   Global Step: 13060   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:53:49,800-Speed 141.53 samples/sec   Loss 1.2421   LearningRate 0.000028   Epoch: 0   Global Step: 13070   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:53:52,077-Speed 140.59 samples/sec   Loss 1.2225   LearningRate 0.000028   Epoch: 0   Global Step: 13080   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:53:54,329-Speed 142.12 samples/sec   Loss 1.2301   LearningRate 0.000028   Epoch: 0   Global Step: 13090   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:53:56,590-Speed 141.55 samples/sec   Loss 1.2403   LearningRate 0.000028   Epoch: 0   Global Step: 13100   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:53:58,879-Speed 139.84 samples/sec   Loss 1.2119   LearningRate 0.000028   Epoch: 0   Global Step: 13110   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:54:01,167-Speed 139.93 samples/sec   Loss 1.2488   LearningRate 0.000028   Epoch: 0   Global Step: 13120   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:54:03,449-Speed 140.26 samples/sec   Loss 1.2279   LearningRate 0.000028   Epoch: 0   Global Step: 13130   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:54:05,746-Speed 139.34 samples/sec   Loss 1.1810   LearningRate 0.000028   Epoch: 0   Global Step: 13140   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:54:08,037-Speed 139.70 samples/sec   Loss 1.2122   LearningRate 0.000028   Epoch: 0   Global Step: 13150   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:54:10,320-Speed 140.18 samples/sec   Loss 1.2835   LearningRate 0.000028   Epoch: 0   Global Step: 13160   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:54:12,602-Speed 140.25 samples/sec   Loss 1.2235   LearningRate 0.000028   Epoch: 0   Global Step: 13170   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:54:14,905-Speed 139.02 samples/sec   Loss 1.2507   LearningRate 0.000028   Epoch: 0   Global Step: 13180   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:54:17,199-Speed 139.50 samples/sec   Loss 1.2326   LearningRate 0.000028   Epoch: 0   Global Step: 13190   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:54:19,485-Speed 140.04 samples/sec   Loss 1.2526   LearningRate 0.000028   Epoch: 0   Global Step: 13200   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:54:21,779-Speed 139.55 samples/sec   Loss 1.2706   LearningRate 0.000028   Epoch: 0   Global Step: 13210   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:54:24,064-Speed 140.09 samples/sec   Loss 1.2259   LearningRate 0.000028   Epoch: 0   Global Step: 13220   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:54:26,359-Speed 139.48 samples/sec   Loss 1.2246   LearningRate 0.000028   Epoch: 0   Global Step: 13230   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:54:28,630-Speed 140.90 samples/sec   Loss 1.2250   LearningRate 0.000028   Epoch: 0   Global Step: 13240   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:54:30,904-Speed 140.75 samples/sec   Loss 1.2383   LearningRate 0.000028   Epoch: 0   Global Step: 13250   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:54:33,187-Speed 140.25 samples/sec   Loss 1.2469   LearningRate 0.000028   Epoch: 0   Global Step: 13260   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:54:35,479-Speed 139.64 samples/sec   Loss 1.2437   LearningRate 0.000028   Epoch: 0   Global Step: 13270   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:54:37,789-Speed 138.57 samples/sec   Loss 1.2488   LearningRate 0.000028   Epoch: 0   Global Step: 13280   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:54:40,086-Speed 139.31 samples/sec   Loss 1.2060   LearningRate 0.000028   Epoch: 0   Global Step: 13290   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:54:42,380-Speed 139.56 samples/sec   Loss 1.2127   LearningRate 0.000028   Epoch: 0   Global Step: 13300   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:54:44,667-Speed 139.94 samples/sec   Loss 1.2243   LearningRate 0.000028   Epoch: 0   Global Step: 13310   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:54:46,961-Speed 139.54 samples/sec   Loss 1.2144   LearningRate 0.000028   Epoch: 0   Global Step: 13320   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:54:49,244-Speed 140.22 samples/sec   Loss 1.2296   LearningRate 0.000028   Epoch: 0   Global Step: 13330   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:54:51,539-Speed 139.47 samples/sec   Loss 1.2463   LearningRate 0.000028   Epoch: 0   Global Step: 13340   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:54:53,825-Speed 139.98 samples/sec   Loss 1.2302   LearningRate 0.000028   Epoch: 0   Global Step: 13350   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:54:56,115-Speed 139.79 samples/sec   Loss 1.2169   LearningRate 0.000028   Epoch: 0   Global Step: 13360   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:54:58,395-Speed 140.37 samples/sec   Loss 1.2328   LearningRate 0.000028   Epoch: 0   Global Step: 13370   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:55:00,692-Speed 139.35 samples/sec   Loss 1.2113   LearningRate 0.000028   Epoch: 0   Global Step: 13380   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:55:02,984-Speed 139.69 samples/sec   Loss 1.2205   LearningRate 0.000028   Epoch: 0   Global Step: 13390   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:55:05,293-Speed 138.57 samples/sec   Loss 1.2497   LearningRate 0.000028   Epoch: 0   Global Step: 13400   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:55:07,596-Speed 139.01 samples/sec   Loss 1.2245   LearningRate 0.000028   Epoch: 0   Global Step: 13410   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:55:09,885-Speed 139.84 samples/sec   Loss 1.2130   LearningRate 0.000028   Epoch: 0   Global Step: 13420   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:55:12,167-Speed 140.29 samples/sec   Loss 1.2192   LearningRate 0.000028   Epoch: 0   Global Step: 13430   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:55:14,448-Speed 140.29 samples/sec   Loss 1.2422   LearningRate 0.000028   Epoch: 0   Global Step: 13440   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:55:16,741-Speed 139.59 samples/sec   Loss 1.2163   LearningRate 0.000028   Epoch: 0   Global Step: 13450   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:55:19,033-Speed 139.69 samples/sec   Loss 1.2466   LearningRate 0.000028   Epoch: 0   Global Step: 13460   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:55:21,344-Speed 138.48 samples/sec   Loss 1.2216   LearningRate 0.000028   Epoch: 0   Global Step: 13470   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:55:23,644-Speed 139.16 samples/sec   Loss 1.2284   LearningRate 0.000028   Epoch: 0   Global Step: 13480   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:55:25,948-Speed 138.91 samples/sec   Loss 1.2142   LearningRate 0.000028   Epoch: 0   Global Step: 13490   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:55:28,250-Speed 139.04 samples/sec   Loss 1.2289   LearningRate 0.000028   Epoch: 0   Global Step: 13500   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:55:30,546-Speed 139.43 samples/sec   Loss 1.2220   LearningRate 0.000028   Epoch: 0   Global Step: 13510   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:55:32,840-Speed 139.55 samples/sec   Loss 1.2433   LearningRate 0.000028   Epoch: 0   Global Step: 13520   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:55:35,116-Speed 140.60 samples/sec   Loss 1.2055   LearningRate 0.000028   Epoch: 0   Global Step: 13530   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:55:37,408-Speed 139.68 samples/sec   Loss 1.2143   LearningRate 0.000028   Epoch: 0   Global Step: 13540   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:55:39,698-Speed 139.74 samples/sec   Loss 1.2154   LearningRate 0.000028   Epoch: 0   Global Step: 13550   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:55:41,949-Speed 142.20 samples/sec   Loss 1.2656   LearningRate 0.000028   Epoch: 0   Global Step: 13560   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:55:44,217-Speed 141.12 samples/sec   Loss 1.2537   LearningRate 0.000028   Epoch: 0   Global Step: 13570   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:55:46,485-Speed 141.16 samples/sec   Loss 1.2351   LearningRate 0.000028   Epoch: 0   Global Step: 13580   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:55:48,757-Speed 140.88 samples/sec   Loss 1.2187   LearningRate 0.000027   Epoch: 0   Global Step: 13590   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:55:51,020-Speed 141.46 samples/sec   Loss 1.2412   LearningRate 0.000027   Epoch: 0   Global Step: 13600   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:55:53,285-Speed 141.28 samples/sec   Loss 1.2178   LearningRate 0.000027   Epoch: 0   Global Step: 13610   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:55:55,555-Speed 141.03 samples/sec   Loss 1.1937   LearningRate 0.000027   Epoch: 0   Global Step: 13620   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:55:57,833-Speed 140.51 samples/sec   Loss 1.2025   LearningRate 0.000027   Epoch: 0   Global Step: 13630   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:56:00,117-Speed 140.16 samples/sec   Loss 1.2031   LearningRate 0.000027   Epoch: 0   Global Step: 13640   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:56:02,387-Speed 140.98 samples/sec   Loss 1.2311   LearningRate 0.000027   Epoch: 0   Global Step: 13650   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:56:04,641-Speed 142.03 samples/sec   Loss 1.2306   LearningRate 0.000027   Epoch: 0   Global Step: 13660   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:56:06,881-Speed 142.91 samples/sec   Loss 1.2300   LearningRate 0.000027   Epoch: 0   Global Step: 13670   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:56:09,143-Speed 141.51 samples/sec   Loss 1.2208   LearningRate 0.000027   Epoch: 0   Global Step: 13680   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:56:11,409-Speed 141.20 samples/sec   Loss 1.2560   LearningRate 0.000027   Epoch: 0   Global Step: 13690   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:56:13,661-Speed 142.14 samples/sec   Loss 1.2196   LearningRate 0.000027   Epoch: 0   Global Step: 13700   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:56:15,925-Speed 141.39 samples/sec   Loss 1.2184   LearningRate 0.000027   Epoch: 0   Global Step: 13710   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:56:18,186-Speed 141.60 samples/sec   Loss 1.2718   LearningRate 0.000027   Epoch: 0   Global Step: 13720   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:56:20,439-Speed 142.08 samples/sec   Loss 1.2457   LearningRate 0.000027   Epoch: 0   Global Step: 13730   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:56:22,704-Speed 141.27 samples/sec   Loss 1.2578   LearningRate 0.000027   Epoch: 0   Global Step: 13740   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:56:24,956-Speed 142.17 samples/sec   Loss 1.2086   LearningRate 0.000027   Epoch: 0   Global Step: 13750   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:56:27,213-Speed 141.83 samples/sec   Loss 1.2328   LearningRate 0.000027   Epoch: 0   Global Step: 13760   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:56:29,468-Speed 141.94 samples/sec   Loss 1.2171   LearningRate 0.000027   Epoch: 0   Global Step: 13770   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:56:31,727-Speed 141.67 samples/sec   Loss 1.2277   LearningRate 0.000027   Epoch: 0   Global Step: 13780   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:56:33,986-Speed 141.70 samples/sec   Loss 1.1970   LearningRate 0.000027   Epoch: 0   Global Step: 13790   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:56:36,246-Speed 141.63 samples/sec   Loss 1.1894   LearningRate 0.000027   Epoch: 0   Global Step: 13800   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:56:38,507-Speed 141.57 samples/sec   Loss 1.2112   LearningRate 0.000027   Epoch: 0   Global Step: 13810   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:56:40,749-Speed 142.74 samples/sec   Loss 1.2519   LearningRate 0.000027   Epoch: 0   Global Step: 13820   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:56:43,012-Speed 141.43 samples/sec   Loss 1.2468   LearningRate 0.000027   Epoch: 0   Global Step: 13830   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:56:45,273-Speed 141.57 samples/sec   Loss 1.2253   LearningRate 0.000027   Epoch: 0   Global Step: 13840   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:56:47,549-Speed 140.64 samples/sec   Loss 1.2369   LearningRate 0.000027   Epoch: 0   Global Step: 13850   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:56:49,810-Speed 141.58 samples/sec   Loss 1.2524   LearningRate 0.000027   Epoch: 0   Global Step: 13860   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:56:52,108-Speed 139.27 samples/sec   Loss 1.1971   LearningRate 0.000027   Epoch: 0   Global Step: 13870   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:56:54,408-Speed 139.18 samples/sec   Loss 1.2535   LearningRate 0.000027   Epoch: 0   Global Step: 13880   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:56:56,695-Speed 139.99 samples/sec   Loss 1.2148   LearningRate 0.000027   Epoch: 0   Global Step: 13890   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:56:58,984-Speed 139.78 samples/sec   Loss 1.2404   LearningRate 0.000027   Epoch: 0   Global Step: 13900   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:57:01,273-Speed 139.87 samples/sec   Loss 1.2312   LearningRate 0.000027   Epoch: 0   Global Step: 13910   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:57:03,553-Speed 140.36 samples/sec   Loss 1.2543   LearningRate 0.000027   Epoch: 0   Global Step: 13920   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:57:05,844-Speed 139.71 samples/sec   Loss 1.2460   LearningRate 0.000027   Epoch: 0   Global Step: 13930   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:57:08,137-Speed 139.62 samples/sec   Loss 1.2122   LearningRate 0.000027   Epoch: 0   Global Step: 13940   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:57:10,430-Speed 139.56 samples/sec   Loss 1.2199   LearningRate 0.000027   Epoch: 0   Global Step: 13950   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:57:12,725-Speed 139.48 samples/sec   Loss 1.2324   LearningRate 0.000027   Epoch: 0   Global Step: 13960   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:57:15,010-Speed 140.07 samples/sec   Loss 1.2192   LearningRate 0.000027   Epoch: 0   Global Step: 13970   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:57:17,287-Speed 140.58 samples/sec   Loss 1.2442   LearningRate 0.000027   Epoch: 0   Global Step: 13980   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:57:19,568-Speed 140.33 samples/sec   Loss 1.1874   LearningRate 0.000027   Epoch: 0   Global Step: 13990   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:57:21,634-Val on RAF/AffectNet:
Training: 2023-08-17 21:57:21,749-Test: [0/48]	Time 0.114 (0.114)	Loss 0.5626 (0.5626)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-17 21:57:22,826-Test: [10/48]	Time 0.104 (0.108)	Loss 0.5498 (0.5792)	Acc@1 89.062 (90.909)	Acc@5 100.000 (99.290)	Mem 5268MB
Training: 2023-08-17 21:57:23,895-Test: [20/48]	Time 0.105 (0.108)	Loss 0.6347 (0.5913)	Acc@1 87.500 (90.253)	Acc@5 98.438 (98.810)	Mem 5268MB
Training: 2023-08-17 21:57:24,982-Test: [30/48]	Time 0.107 (0.108)	Loss 0.7498 (0.5944)	Acc@1 84.375 (90.474)	Acc@5 98.438 (98.790)	Mem 5268MB
Training: 2023-08-17 21:57:26,065-Test: [40/48]	Time 0.109 (0.108)	Loss 0.5738 (0.5818)	Acc@1 90.625 (91.044)	Acc@5 96.875 (99.009)	Mem 5268MB
Training: 2023-08-17 21:57:26,812-[13999]Expression Loss: 0.57458
Training: 2023-08-17 21:57:26,812-[13999]Expression Acc@1: 91.29726
Training: 2023-08-17 21:57:26,813-[13999]Expression Acc@1-Highest: 91.94915
Training: 2023-08-17 21:57:26,813-[13999]Expression Acc@5: 99.02216
Training: 2023-08-17 21:57:26,813-[13999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 21:57:26,813-[13999]10 Times Expression Acc@1: 91.06258
Training: 2023-08-17 21:57:26,813-[13999]10 Times Expression Acc@1-Highest: 91.06258
Training: 2023-08-17 21:57:27,041-Speed 42.82 samples/sec   Loss 1.2307   LearningRate 0.000027   Epoch: 0   Global Step: 14000   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:57:29,314-Speed 140.86 samples/sec   Loss 1.2064   LearningRate 0.000027   Epoch: 0   Global Step: 14010   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:57:31,594-Speed 140.34 samples/sec   Loss 1.2056   LearningRate 0.000027   Epoch: 0   Global Step: 14020   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:57:33,871-Speed 140.59 samples/sec   Loss 1.2254   LearningRate 0.000027   Epoch: 0   Global Step: 14030   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:57:36,153-Speed 140.25 samples/sec   Loss 1.2750   LearningRate 0.000027   Epoch: 0   Global Step: 14040   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:57:38,426-Speed 140.81 samples/sec   Loss 1.2266   LearningRate 0.000027   Epoch: 0   Global Step: 14050   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:57:40,712-Speed 140.01 samples/sec   Loss 1.2104   LearningRate 0.000027   Epoch: 0   Global Step: 14060   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:57:43,021-Speed 138.68 samples/sec   Loss 1.1846   LearningRate 0.000027   Epoch: 0   Global Step: 14070   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:57:45,336-Speed 138.26 samples/sec   Loss 1.2001   LearningRate 0.000027   Epoch: 0   Global Step: 14080   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:57:47,633-Speed 139.33 samples/sec   Loss 1.2663   LearningRate 0.000027   Epoch: 0   Global Step: 14090   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:57:49,901-Speed 141.11 samples/sec   Loss 1.2128   LearningRate 0.000027   Epoch: 0   Global Step: 14100   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:57:52,191-Speed 139.79 samples/sec   Loss 1.1902   LearningRate 0.000027   Epoch: 0   Global Step: 14110   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:57:54,455-Speed 141.37 samples/sec   Loss 1.1868   LearningRate 0.000027   Epoch: 0   Global Step: 14120   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:57:56,729-Speed 140.83 samples/sec   Loss 1.2007   LearningRate 0.000027   Epoch: 0   Global Step: 14130   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:57:59,004-Speed 140.70 samples/sec   Loss 1.2473   LearningRate 0.000027   Epoch: 0   Global Step: 14140   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:58:01,290-Speed 140.02 samples/sec   Loss 1.2232   LearningRate 0.000027   Epoch: 0   Global Step: 14150   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:58:03,566-Speed 140.62 samples/sec   Loss 1.2213   LearningRate 0.000027   Epoch: 0   Global Step: 14160   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:58:05,834-Speed 141.10 samples/sec   Loss 1.2149   LearningRate 0.000027   Epoch: 0   Global Step: 14170   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:58:08,146-Speed 138.50 samples/sec   Loss 1.1972   LearningRate 0.000027   Epoch: 0   Global Step: 14180   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:58:10,438-Speed 139.61 samples/sec   Loss 1.2103   LearningRate 0.000027   Epoch: 0   Global Step: 14190   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:58:12,770-Speed 137.27 samples/sec   Loss 1.1935   LearningRate 0.000027   Epoch: 0   Global Step: 14200   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:58:15,094-Speed 137.71 samples/sec   Loss 1.1868   LearningRate 0.000027   Epoch: 0   Global Step: 14210   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:58:17,398-Speed 138.94 samples/sec   Loss 1.2464   LearningRate 0.000027   Epoch: 0   Global Step: 14220   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:58:19,713-Speed 138.28 samples/sec   Loss 1.1979   LearningRate 0.000027   Epoch: 0   Global Step: 14230   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:58:22,040-Speed 137.54 samples/sec   Loss 1.2396   LearningRate 0.000027   Epoch: 0   Global Step: 14240   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:58:24,358-Speed 138.10 samples/sec   Loss 1.2014   LearningRate 0.000027   Epoch: 0   Global Step: 14250   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:58:26,683-Speed 137.68 samples/sec   Loss 1.2181   LearningRate 0.000027   Epoch: 0   Global Step: 14260   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:58:28,999-Speed 138.21 samples/sec   Loss 1.2406   LearningRate 0.000027   Epoch: 0   Global Step: 14270   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:58:31,327-Speed 137.48 samples/sec   Loss 1.2382   LearningRate 0.000027   Epoch: 0   Global Step: 14280   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:58:33,646-Speed 138.00 samples/sec   Loss 1.2538   LearningRate 0.000027   Epoch: 0   Global Step: 14290   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:58:35,963-Speed 138.19 samples/sec   Loss 1.2210   LearningRate 0.000027   Epoch: 0   Global Step: 14300   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:58:38,274-Speed 138.48 samples/sec   Loss 1.2304   LearningRate 0.000027   Epoch: 0   Global Step: 14310   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:58:40,571-Speed 139.38 samples/sec   Loss 1.2236   LearningRate 0.000027   Epoch: 0   Global Step: 14320   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:58:42,883-Speed 138.41 samples/sec   Loss 1.2254   LearningRate 0.000027   Epoch: 0   Global Step: 14330   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:58:45,210-Speed 137.54 samples/sec   Loss 1.2196   LearningRate 0.000027   Epoch: 0   Global Step: 14340   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:58:47,525-Speed 138.28 samples/sec   Loss 1.1802   LearningRate 0.000027   Epoch: 0   Global Step: 14350   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:58:49,847-Speed 137.86 samples/sec   Loss 1.2417   LearningRate 0.000027   Epoch: 0   Global Step: 14360   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:58:52,164-Speed 138.18 samples/sec   Loss 1.2213   LearningRate 0.000027   Epoch: 0   Global Step: 14370   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:58:54,489-Speed 137.63 samples/sec   Loss 1.2251   LearningRate 0.000027   Epoch: 0   Global Step: 14380   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:58:56,809-Speed 137.99 samples/sec   Loss 1.2216   LearningRate 0.000027   Epoch: 0   Global Step: 14390   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:58:59,126-Speed 138.15 samples/sec   Loss 1.2093   LearningRate 0.000027   Epoch: 0   Global Step: 14400   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:59:01,439-Speed 138.38 samples/sec   Loss 1.2432   LearningRate 0.000027   Epoch: 0   Global Step: 14410   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:59:03,761-Speed 137.87 samples/sec   Loss 1.2486   LearningRate 0.000027   Epoch: 0   Global Step: 14420   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 21:59:06,072-Speed 138.47 samples/sec   Loss 1.2749   LearningRate 0.000027   Epoch: 0   Global Step: 14430   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:59:08,386-Speed 138.36 samples/sec   Loss 1.1994   LearningRate 0.000027   Epoch: 0   Global Step: 14440   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:59:10,718-Speed 137.23 samples/sec   Loss 1.2249   LearningRate 0.000027   Epoch: 0   Global Step: 14450   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:59:13,039-Speed 137.90 samples/sec   Loss 1.2263   LearningRate 0.000027   Epoch: 0   Global Step: 14460   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:59:15,341-Speed 139.05 samples/sec   Loss 1.2409   LearningRate 0.000027   Epoch: 0   Global Step: 14470   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:59:17,672-Speed 137.32 samples/sec   Loss 1.1967   LearningRate 0.000027   Epoch: 0   Global Step: 14480   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:59:19,992-Speed 137.96 samples/sec   Loss 1.1829   LearningRate 0.000027   Epoch: 0   Global Step: 14490   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:59:22,301-Speed 138.61 samples/sec   Loss 1.1885   LearningRate 0.000027   Epoch: 0   Global Step: 14500   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:59:24,604-Speed 139.00 samples/sec   Loss 1.2300   LearningRate 0.000027   Epoch: 0   Global Step: 14510   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:59:26,917-Speed 138.42 samples/sec   Loss 1.2070   LearningRate 0.000027   Epoch: 0   Global Step: 14520   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:59:29,202-Speed 140.06 samples/sec   Loss 1.2001   LearningRate 0.000027   Epoch: 0   Global Step: 14530   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:59:31,482-Speed 140.37 samples/sec   Loss 1.1889   LearningRate 0.000027   Epoch: 0   Global Step: 14540   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:59:33,768-Speed 140.04 samples/sec   Loss 1.2315   LearningRate 0.000027   Epoch: 0   Global Step: 14550   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:59:36,046-Speed 140.52 samples/sec   Loss 1.2138   LearningRate 0.000027   Epoch: 0   Global Step: 14560   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 21:59:38,321-Speed 140.68 samples/sec   Loss 1.2330   LearningRate 0.000027   Epoch: 0   Global Step: 14570   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:59:40,591-Speed 140.99 samples/sec   Loss 1.2462   LearningRate 0.000027   Epoch: 0   Global Step: 14580   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:59:42,877-Speed 140.03 samples/sec   Loss 1.2031   LearningRate 0.000027   Epoch: 0   Global Step: 14590   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:59:45,168-Speed 139.74 samples/sec   Loss 1.2382   LearningRate 0.000027   Epoch: 0   Global Step: 14600   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:59:47,442-Speed 140.78 samples/sec   Loss 1.2111   LearningRate 0.000027   Epoch: 0   Global Step: 14610   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:59:49,718-Speed 140.61 samples/sec   Loss 1.2166   LearningRate 0.000027   Epoch: 0   Global Step: 14620   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:59:51,999-Speed 140.31 samples/sec   Loss 1.2331   LearningRate 0.000027   Epoch: 0   Global Step: 14630   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:59:54,270-Speed 140.95 samples/sec   Loss 1.2161   LearningRate 0.000027   Epoch: 0   Global Step: 14640   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:59:56,559-Speed 139.82 samples/sec   Loss 1.1765   LearningRate 0.000027   Epoch: 0   Global Step: 14650   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 21:59:58,831-Speed 140.88 samples/sec   Loss 1.2144   LearningRate 0.000027   Epoch: 0   Global Step: 14660   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:00:01,099-Speed 141.18 samples/sec   Loss 1.2163   LearningRate 0.000027   Epoch: 0   Global Step: 14670   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:00:03,375-Speed 140.62 samples/sec   Loss 1.1776   LearningRate 0.000027   Epoch: 0   Global Step: 14680   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:00:05,624-Speed 142.31 samples/sec   Loss 1.2099   LearningRate 0.000027   Epoch: 0   Global Step: 14690   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:00:07,899-Speed 140.69 samples/sec   Loss 1.2423   LearningRate 0.000027   Epoch: 0   Global Step: 14700   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:00:10,161-Speed 141.52 samples/sec   Loss 1.2019   LearningRate 0.000027   Epoch: 0   Global Step: 14710   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:00:12,443-Speed 140.24 samples/sec   Loss 1.2057   LearningRate 0.000027   Epoch: 0   Global Step: 14720   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:00:14,726-Speed 140.25 samples/sec   Loss 1.2404   LearningRate 0.000027   Epoch: 0   Global Step: 14730   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:00:16,998-Speed 140.90 samples/sec   Loss 1.2094   LearningRate 0.000027   Epoch: 0   Global Step: 14740   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:00:19,283-Speed 140.06 samples/sec   Loss 1.2062   LearningRate 0.000027   Epoch: 0   Global Step: 14750   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:00:21,538-Speed 141.97 samples/sec   Loss 1.2014   LearningRate 0.000027   Epoch: 0   Global Step: 14760   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:00:23,806-Speed 141.07 samples/sec   Loss 1.2188   LearningRate 0.000027   Epoch: 0   Global Step: 14770   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:00:26,098-Speed 139.68 samples/sec   Loss 1.2228   LearningRate 0.000027   Epoch: 0   Global Step: 14780   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:00:28,361-Speed 141.45 samples/sec   Loss 1.2021   LearningRate 0.000027   Epoch: 0   Global Step: 14790   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:00:30,633-Speed 140.91 samples/sec   Loss 1.2461   LearningRate 0.000027   Epoch: 0   Global Step: 14800   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:00:32,918-Speed 140.03 samples/sec   Loss 1.2128   LearningRate 0.000027   Epoch: 0   Global Step: 14810   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:00:35,191-Speed 140.82 samples/sec   Loss 1.2091   LearningRate 0.000027   Epoch: 0   Global Step: 14820   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:00:37,457-Speed 141.30 samples/sec   Loss 1.2132   LearningRate 0.000027   Epoch: 0   Global Step: 14830   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:00:39,721-Speed 141.36 samples/sec   Loss 1.2441   LearningRate 0.000027   Epoch: 0   Global Step: 14840   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:00:42,002-Speed 140.33 samples/sec   Loss 1.2043   LearningRate 0.000027   Epoch: 0   Global Step: 14850   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:00:44,270-Speed 141.11 samples/sec   Loss 1.2296   LearningRate 0.000027   Epoch: 0   Global Step: 14860   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:00:46,540-Speed 141.03 samples/sec   Loss 1.2302   LearningRate 0.000027   Epoch: 0   Global Step: 14870   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:00:48,801-Speed 141.51 samples/sec   Loss 1.2300   LearningRate 0.000027   Epoch: 0   Global Step: 14880   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:00:51,069-Speed 141.17 samples/sec   Loss 1.2008   LearningRate 0.000027   Epoch: 0   Global Step: 14890   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:00:53,333-Speed 141.35 samples/sec   Loss 1.2610   LearningRate 0.000027   Epoch: 0   Global Step: 14900   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:00:55,636-Speed 139.04 samples/sec   Loss 1.2030   LearningRate 0.000027   Epoch: 0   Global Step: 14910   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:00:57,943-Speed 138.73 samples/sec   Loss 1.2431   LearningRate 0.000027   Epoch: 0   Global Step: 14920   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:01:00,236-Speed 139.58 samples/sec   Loss 1.2227   LearningRate 0.000027   Epoch: 0   Global Step: 14930   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:01:02,528-Speed 139.65 samples/sec   Loss 1.2418   LearningRate 0.000027   Epoch: 0   Global Step: 14940   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:01:04,826-Speed 139.32 samples/sec   Loss 1.2133   LearningRate 0.000027   Epoch: 0   Global Step: 14950   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:01:07,131-Speed 138.88 samples/sec   Loss 1.2303   LearningRate 0.000027   Epoch: 0   Global Step: 14960   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:01:09,433-Speed 139.02 samples/sec   Loss 1.2022   LearningRate 0.000027   Epoch: 0   Global Step: 14970   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:01:11,743-Speed 138.57 samples/sec   Loss 1.2151   LearningRate 0.000027   Epoch: 0   Global Step: 14980   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:01:14,061-Speed 138.07 samples/sec   Loss 1.1983   LearningRate 0.000027   Epoch: 0   Global Step: 14990   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:01:16,140-Val on RAF/AffectNet:
Training: 2023-08-17 22:01:16,247-Test: [0/48]	Time 0.107 (0.107)	Loss 0.5339 (0.5339)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-17 22:01:17,310-Test: [10/48]	Time 0.107 (0.106)	Loss 0.5374 (0.5406)	Acc@1 90.625 (92.472)	Acc@5 100.000 (99.574)	Mem 5268MB
Training: 2023-08-17 22:01:18,385-Test: [20/48]	Time 0.108 (0.107)	Loss 0.6452 (0.5670)	Acc@1 89.062 (91.890)	Acc@5 100.000 (99.182)	Mem 5268MB
Training: 2023-08-17 22:01:19,451-Test: [30/48]	Time 0.108 (0.107)	Loss 0.4662 (0.5565)	Acc@1 93.750 (92.188)	Acc@5 100.000 (99.143)	Mem 5268MB
Training: 2023-08-17 22:01:20,512-Test: [40/48]	Time 0.105 (0.107)	Loss 0.5683 (0.5510)	Acc@1 90.625 (92.226)	Acc@5 98.438 (99.238)	Mem 5268MB
Training: 2023-08-17 22:01:21,250-[14999]Expression Loss: 0.55491
Training: 2023-08-17 22:01:21,250-[14999]Expression Acc@1: 91.94915
Training: 2023-08-17 22:01:21,250-[14999]Expression Acc@1-Highest: 91.94915
Training: 2023-08-17 22:01:21,250-[14999]Expression Acc@5: 99.25033
Training: 2023-08-17 22:01:21,250-[14999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 22:01:21,250-[14999]10 Times Expression Acc@1: 91.19296
Training: 2023-08-17 22:01:21,250-[14999]10 Times Expression Acc@1-Highest: 91.19296
Training: 2023-08-17 22:01:21,482-Speed 43.13 samples/sec   Loss 1.2131   LearningRate 0.000027   Epoch: 0   Global Step: 15000   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:01:23,767-Speed 140.03 samples/sec   Loss 1.2104   LearningRate 0.000027   Epoch: 0   Global Step: 15010   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:01:26,035-Speed 141.17 samples/sec   Loss 1.2336   LearningRate 0.000027   Epoch: 0   Global Step: 15020   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:01:28,315-Speed 140.39 samples/sec   Loss 1.2180   LearningRate 0.000027   Epoch: 0   Global Step: 15030   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:01:30,604-Speed 139.83 samples/sec   Loss 1.1860   LearningRate 0.000027   Epoch: 0   Global Step: 15040   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:01:32,899-Speed 139.49 samples/sec   Loss 1.1812   LearningRate 0.000027   Epoch: 0   Global Step: 15050   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:01:35,190-Speed 139.68 samples/sec   Loss 1.2253   LearningRate 0.000027   Epoch: 0   Global Step: 15060   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:01:37,482-Speed 139.71 samples/sec   Loss 1.2269   LearningRate 0.000027   Epoch: 0   Global Step: 15070   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:01:39,766-Speed 140.12 samples/sec   Loss 1.2396   LearningRate 0.000027   Epoch: 0   Global Step: 15080   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:01:42,048-Speed 140.25 samples/sec   Loss 1.2332   LearningRate 0.000027   Epoch: 0   Global Step: 15090   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:01:44,339-Speed 139.75 samples/sec   Loss 1.2537   LearningRate 0.000027   Epoch: 0   Global Step: 15100   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:01:46,638-Speed 139.20 samples/sec   Loss 1.2254   LearningRate 0.000027   Epoch: 0   Global Step: 15110   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:01:48,924-Speed 140.02 samples/sec   Loss 1.2268   LearningRate 0.000027   Epoch: 0   Global Step: 15120   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:01:51,208-Speed 140.15 samples/sec   Loss 1.1929   LearningRate 0.000027   Epoch: 0   Global Step: 15130   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:01:53,501-Speed 139.60 samples/sec   Loss 1.2271   LearningRate 0.000027   Epoch: 0   Global Step: 15140   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:01:55,793-Speed 139.65 samples/sec   Loss 1.2299   LearningRate 0.000027   Epoch: 0   Global Step: 15150   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:01:58,091-Speed 139.32 samples/sec   Loss 1.1936   LearningRate 0.000027   Epoch: 0   Global Step: 15160   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:02:00,384-Speed 139.58 samples/sec   Loss 1.2164   LearningRate 0.000027   Epoch: 0   Global Step: 15170   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:02:02,693-Speed 138.64 samples/sec   Loss 1.2012   LearningRate 0.000027   Epoch: 0   Global Step: 15180   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:02:04,984-Speed 139.71 samples/sec   Loss 1.1992   LearningRate 0.000027   Epoch: 0   Global Step: 15190   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:02:07,279-Speed 139.46 samples/sec   Loss 1.2018   LearningRate 0.000027   Epoch: 0   Global Step: 15200   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:02:09,574-Speed 139.48 samples/sec   Loss 1.1919   LearningRate 0.000027   Epoch: 0   Global Step: 15210   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:02:11,867-Speed 139.61 samples/sec   Loss 1.2124   LearningRate 0.000027   Epoch: 0   Global Step: 15220   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:02:14,165-Speed 139.26 samples/sec   Loss 1.2550   LearningRate 0.000027   Epoch: 0   Global Step: 15230   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:02:16,457-Speed 139.67 samples/sec   Loss 1.2455   LearningRate 0.000027   Epoch: 0   Global Step: 15240   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:02:18,739-Speed 140.29 samples/sec   Loss 1.2135   LearningRate 0.000027   Epoch: 0   Global Step: 15250   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:02:21,024-Speed 140.08 samples/sec   Loss 1.2276   LearningRate 0.000027   Epoch: 0   Global Step: 15260   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:02:23,314-Speed 139.73 samples/sec   Loss 1.1935   LearningRate 0.000027   Epoch: 0   Global Step: 15270   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:02:25,613-Speed 139.26 samples/sec   Loss 1.1739   LearningRate 0.000027   Epoch: 0   Global Step: 15280   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:02:27,909-Speed 139.42 samples/sec   Loss 1.2164   LearningRate 0.000027   Epoch: 0   Global Step: 15290   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:02:30,204-Speed 139.47 samples/sec   Loss 1.2098   LearningRate 0.000027   Epoch: 0   Global Step: 15300   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:02:32,501-Speed 139.32 samples/sec   Loss 1.2105   LearningRate 0.000027   Epoch: 0   Global Step: 15310   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:02:34,794-Speed 139.64 samples/sec   Loss 1.2497   LearningRate 0.000027   Epoch: 0   Global Step: 15320   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:02:37,099-Speed 138.82 samples/sec   Loss 1.2194   LearningRate 0.000027   Epoch: 0   Global Step: 15330   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:02:39,401-Speed 139.06 samples/sec   Loss 1.2389   LearningRate 0.000027   Epoch: 0   Global Step: 15340   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:02:41,709-Speed 138.70 samples/sec   Loss 1.2003   LearningRate 0.000027   Epoch: 0   Global Step: 15350   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:02:43,997-Speed 139.92 samples/sec   Loss 1.1981   LearningRate 0.000027   Epoch: 0   Global Step: 15360   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:02:46,279-Speed 140.25 samples/sec   Loss 1.2377   LearningRate 0.000027   Epoch: 0   Global Step: 15370   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:02:48,580-Speed 139.09 samples/sec   Loss 1.2384   LearningRate 0.000026   Epoch: 0   Global Step: 15380   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:02:50,906-Speed 137.66 samples/sec   Loss 1.2241   LearningRate 0.000026   Epoch: 0   Global Step: 15390   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:02:53,229-Speed 137.77 samples/sec   Loss 1.1854   LearningRate 0.000026   Epoch: 0   Global Step: 15400   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:02:55,546-Speed 138.17 samples/sec   Loss 1.2268   LearningRate 0.000026   Epoch: 0   Global Step: 15410   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:02:57,870-Speed 137.72 samples/sec   Loss 1.2371   LearningRate 0.000026   Epoch: 0   Global Step: 15420   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:03:00,189-Speed 138.00 samples/sec   Loss 1.2063   LearningRate 0.000026   Epoch: 0   Global Step: 15430   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:03:02,523-Speed 137.19 samples/sec   Loss 1.2082   LearningRate 0.000026   Epoch: 0   Global Step: 15440   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:03:04,831-Speed 138.69 samples/sec   Loss 1.1919   LearningRate 0.000026   Epoch: 0   Global Step: 15450   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:03:07,153-Speed 137.86 samples/sec   Loss 1.2106   LearningRate 0.000026   Epoch: 0   Global Step: 15460   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:03:09,472-Speed 138.02 samples/sec   Loss 1.2121   LearningRate 0.000026   Epoch: 0   Global Step: 15470   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:03:11,792-Speed 137.95 samples/sec   Loss 1.2273   LearningRate 0.000026   Epoch: 0   Global Step: 15480   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:03:14,109-Speed 138.17 samples/sec   Loss 1.1840   LearningRate 0.000026   Epoch: 0   Global Step: 15490   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:03:16,433-Speed 137.74 samples/sec   Loss 1.2040   LearningRate 0.000026   Epoch: 0   Global Step: 15500   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:03:18,754-Speed 137.88 samples/sec   Loss 1.2312   LearningRate 0.000026   Epoch: 0   Global Step: 15510   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:03:21,071-Speed 138.18 samples/sec   Loss 1.2195   LearningRate 0.000026   Epoch: 0   Global Step: 15520   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:03:23,389-Speed 138.05 samples/sec   Loss 1.2237   LearningRate 0.000026   Epoch: 0   Global Step: 15530   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:03:25,718-Speed 137.47 samples/sec   Loss 1.2214   LearningRate 0.000026   Epoch: 0   Global Step: 15540   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:03:28,036-Speed 138.05 samples/sec   Loss 1.2311   LearningRate 0.000026   Epoch: 0   Global Step: 15550   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:03:30,353-Speed 138.17 samples/sec   Loss 1.2007   LearningRate 0.000026   Epoch: 0   Global Step: 15560   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:03:32,666-Speed 138.40 samples/sec   Loss 1.2244   LearningRate 0.000026   Epoch: 0   Global Step: 15570   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:03:34,978-Speed 138.47 samples/sec   Loss 1.2071   LearningRate 0.000026   Epoch: 0   Global Step: 15580   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:03:37,310-Speed 137.25 samples/sec   Loss 1.2254   LearningRate 0.000026   Epoch: 0   Global Step: 15590   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:03:39,629-Speed 138.03 samples/sec   Loss 1.2279   LearningRate 0.000026   Epoch: 0   Global Step: 15600   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:03:41,953-Speed 137.68 samples/sec   Loss 1.2181   LearningRate 0.000026   Epoch: 0   Global Step: 15610   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:03:44,281-Speed 137.51 samples/sec   Loss 1.2208   LearningRate 0.000026   Epoch: 0   Global Step: 15620   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:03:46,594-Speed 138.43 samples/sec   Loss 1.1767   LearningRate 0.000026   Epoch: 0   Global Step: 15630   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:03:48,917-Speed 137.79 samples/sec   Loss 1.2223   LearningRate 0.000026   Epoch: 0   Global Step: 15640   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:03:51,225-Speed 138.68 samples/sec   Loss 1.2303   LearningRate 0.000026   Epoch: 0   Global Step: 15650   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:03:53,541-Speed 138.19 samples/sec   Loss 1.2386   LearningRate 0.000026   Epoch: 0   Global Step: 15660   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:03:55,862-Speed 137.95 samples/sec   Loss 1.2181   LearningRate 0.000026   Epoch: 0   Global Step: 15670   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:03:58,193-Speed 137.29 samples/sec   Loss 1.2277   LearningRate 0.000026   Epoch: 0   Global Step: 15680   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:04:00,503-Speed 138.54 samples/sec   Loss 1.1980   LearningRate 0.000026   Epoch: 0   Global Step: 15690   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:04:02,801-Speed 139.30 samples/sec   Loss 1.2275   LearningRate 0.000026   Epoch: 0   Global Step: 15700   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:04:05,092-Speed 139.72 samples/sec   Loss 1.2023   LearningRate 0.000026   Epoch: 0   Global Step: 15710   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:04:07,390-Speed 139.30 samples/sec   Loss 1.1992   LearningRate 0.000026   Epoch: 0   Global Step: 15720   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:04:09,681-Speed 139.76 samples/sec   Loss 1.2116   LearningRate 0.000026   Epoch: 0   Global Step: 15730   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:04:11,971-Speed 139.75 samples/sec   Loss 1.1763   LearningRate 0.000026   Epoch: 0   Global Step: 15740   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:04:14,273-Speed 139.04 samples/sec   Loss 1.1942   LearningRate 0.000026   Epoch: 0   Global Step: 15750   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:04:16,577-Speed 138.95 samples/sec   Loss 1.1903   LearningRate 0.000026   Epoch: 0   Global Step: 15760   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:04:18,874-Speed 139.36 samples/sec   Loss 1.2264   LearningRate 0.000026   Epoch: 0   Global Step: 15770   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:04:21,158-Speed 140.14 samples/sec   Loss 1.2062   LearningRate 0.000026   Epoch: 0   Global Step: 15780   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:04:23,465-Speed 138.74 samples/sec   Loss 1.2459   LearningRate 0.000026   Epoch: 0   Global Step: 15790   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:04:25,760-Speed 139.48 samples/sec   Loss 1.2362   LearningRate 0.000026   Epoch: 0   Global Step: 15800   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:04:28,072-Speed 138.45 samples/sec   Loss 1.1927   LearningRate 0.000026   Epoch: 0   Global Step: 15810   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:04:30,375-Speed 138.98 samples/sec   Loss 1.2269   LearningRate 0.000026   Epoch: 0   Global Step: 15820   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:04:32,666-Speed 139.72 samples/sec   Loss 1.1791   LearningRate 0.000026   Epoch: 0   Global Step: 15830   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:04:34,965-Speed 139.23 samples/sec   Loss 1.1978   LearningRate 0.000026   Epoch: 0   Global Step: 15840   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:04:37,268-Speed 138.98 samples/sec   Loss 1.2167   LearningRate 0.000026   Epoch: 0   Global Step: 15850   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:04:39,566-Speed 139.29 samples/sec   Loss 1.1799   LearningRate 0.000026   Epoch: 0   Global Step: 15860   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:04:41,877-Speed 138.51 samples/sec   Loss 1.2288   LearningRate 0.000026   Epoch: 0   Global Step: 15870   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:04:44,179-Speed 139.06 samples/sec   Loss 1.1965   LearningRate 0.000026   Epoch: 0   Global Step: 15880   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:04:46,479-Speed 139.15 samples/sec   Loss 1.2186   LearningRate 0.000026   Epoch: 0   Global Step: 15890   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:04:48,784-Speed 138.89 samples/sec   Loss 1.2074   LearningRate 0.000026   Epoch: 0   Global Step: 15900   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:04:51,069-Speed 140.12 samples/sec   Loss 1.2104   LearningRate 0.000026   Epoch: 0   Global Step: 15910   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:04:53,366-Speed 139.29 samples/sec   Loss 1.2152   LearningRate 0.000026   Epoch: 0   Global Step: 15920   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:04:55,660-Speed 139.55 samples/sec   Loss 1.2199   LearningRate 0.000026   Epoch: 0   Global Step: 15930   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:04:57,955-Speed 139.48 samples/sec   Loss 1.2548   LearningRate 0.000026   Epoch: 0   Global Step: 15940   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:05:00,248-Speed 139.62 samples/sec   Loss 1.2528   LearningRate 0.000026   Epoch: 0   Global Step: 15950   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:05:02,540-Speed 139.68 samples/sec   Loss 1.2213   LearningRate 0.000026   Epoch: 0   Global Step: 15960   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:05:04,834-Speed 139.49 samples/sec   Loss 1.2112   LearningRate 0.000026   Epoch: 0   Global Step: 15970   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:05:07,136-Speed 139.07 samples/sec   Loss 1.2367   LearningRate 0.000026   Epoch: 0   Global Step: 15980   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:05:09,410-Speed 140.76 samples/sec   Loss 1.2253   LearningRate 0.000026   Epoch: 0   Global Step: 15990   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:05:11,467-Val on RAF/AffectNet:
Training: 2023-08-17 22:05:11,576-Test: [0/48]	Time 0.108 (0.108)	Loss 0.4934 (0.4934)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-17 22:05:12,626-Test: [10/48]	Time 0.107 (0.105)	Loss 0.6023 (0.5432)	Acc@1 89.062 (91.761)	Acc@5 100.000 (99.148)	Mem 5268MB
Training: 2023-08-17 22:05:13,680-Test: [20/48]	Time 0.108 (0.105)	Loss 0.5691 (0.5282)	Acc@1 90.625 (92.857)	Acc@5 100.000 (99.182)	Mem 5268MB
Training: 2023-08-17 22:05:14,744-Test: [30/48]	Time 0.108 (0.106)	Loss 0.5749 (0.5316)	Acc@1 92.188 (92.591)	Acc@5 96.875 (99.093)	Mem 5268MB
Training: 2023-08-17 22:05:15,797-Test: [40/48]	Time 0.109 (0.106)	Loss 0.6001 (0.5339)	Acc@1 89.062 (92.454)	Acc@5 98.438 (99.047)	Mem 5268MB
Training: 2023-08-17 22:05:16,532-[15999]Expression Loss: 0.53515
Training: 2023-08-17 22:05:16,533-[15999]Expression Acc@1: 92.24250
Training: 2023-08-17 22:05:16,533-[15999]Expression Acc@1-Highest: 92.24250
Training: 2023-08-17 22:05:16,533-[15999]Expression Acc@5: 99.15254
Training: 2023-08-17 22:05:16,533-[15999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 22:05:16,533-[15999]10 Times Expression Acc@1: 91.33312
Training: 2023-08-17 22:05:16,533-[15999]10 Times Expression Acc@1-Highest: 91.33312
Training: 2023-08-17 22:05:16,767-Speed 43.50 samples/sec   Loss 1.2286   LearningRate 0.000026   Epoch: 0   Global Step: 16000   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:05:19,060-Speed 139.57 samples/sec   Loss 1.2146   LearningRate 0.000026   Epoch: 0   Global Step: 16010   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:05:21,356-Speed 139.41 samples/sec   Loss 1.1927   LearningRate 0.000026   Epoch: 0   Global Step: 16020   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:05:23,645-Speed 139.84 samples/sec   Loss 1.2279   LearningRate 0.000026   Epoch: 0   Global Step: 16030   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:05:25,935-Speed 139.78 samples/sec   Loss 1.2279   LearningRate 0.000026   Epoch: 0   Global Step: 16040   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:05:28,229-Speed 139.55 samples/sec   Loss 1.2161   LearningRate 0.000026   Epoch: 0   Global Step: 16050   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:05:30,516-Speed 139.94 samples/sec   Loss 1.2221   LearningRate 0.000026   Epoch: 0   Global Step: 16060   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:05:32,807-Speed 139.74 samples/sec   Loss 1.2110   LearningRate 0.000026   Epoch: 0   Global Step: 16070   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:05:35,069-Speed 141.49 samples/sec   Loss 1.1863   LearningRate 0.000026   Epoch: 0   Global Step: 16080   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:05:37,331-Speed 141.54 samples/sec   Loss 1.2021   LearningRate 0.000026   Epoch: 0   Global Step: 16090   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:05:39,600-Speed 141.07 samples/sec   Loss 1.2305   LearningRate 0.000026   Epoch: 0   Global Step: 16100   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:05:41,874-Speed 140.77 samples/sec   Loss 1.2267   LearningRate 0.000026   Epoch: 0   Global Step: 16110   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:05:44,162-Speed 139.85 samples/sec   Loss 1.2035   LearningRate 0.000026   Epoch: 0   Global Step: 16120   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:05:46,419-Speed 141.85 samples/sec   Loss 1.2122   LearningRate 0.000026   Epoch: 0   Global Step: 16130   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:05:48,678-Speed 141.67 samples/sec   Loss 1.2091   LearningRate 0.000026   Epoch: 0   Global Step: 16140   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:05:50,960-Speed 140.25 samples/sec   Loss 1.2370   LearningRate 0.000026   Epoch: 0   Global Step: 16150   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:05:53,241-Speed 140.32 samples/sec   Loss 1.1935   LearningRate 0.000026   Epoch: 0   Global Step: 16160   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:05:55,521-Speed 140.41 samples/sec   Loss 1.1931   LearningRate 0.000026   Epoch: 0   Global Step: 16170   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:05:57,801-Speed 140.42 samples/sec   Loss 1.1991   LearningRate 0.000026   Epoch: 0   Global Step: 16180   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:06:00,082-Speed 140.31 samples/sec   Loss 1.2167   LearningRate 0.000026   Epoch: 0   Global Step: 16190   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:06:02,367-Speed 140.07 samples/sec   Loss 1.2265   LearningRate 0.000026   Epoch: 0   Global Step: 16200   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:06:04,651-Speed 140.15 samples/sec   Loss 1.2164   LearningRate 0.000026   Epoch: 0   Global Step: 16210   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:06:06,941-Speed 139.74 samples/sec   Loss 1.1733   LearningRate 0.000026   Epoch: 0   Global Step: 16220   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:06:09,228-Speed 139.96 samples/sec   Loss 1.2083   LearningRate 0.000026   Epoch: 0   Global Step: 16230   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:06:11,503-Speed 140.73 samples/sec   Loss 1.2336   LearningRate 0.000026   Epoch: 0   Global Step: 16240   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:06:13,809-Speed 138.79 samples/sec   Loss 1.2192   LearningRate 0.000026   Epoch: 0   Global Step: 16250   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:06:16,109-Speed 139.14 samples/sec   Loss 1.2196   LearningRate 0.000026   Epoch: 0   Global Step: 16260   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:06:18,391-Speed 140.29 samples/sec   Loss 1.1998   LearningRate 0.000026   Epoch: 0   Global Step: 16270   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:06:20,689-Speed 139.30 samples/sec   Loss 1.1923   LearningRate 0.000026   Epoch: 0   Global Step: 16280   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:06:22,998-Speed 138.58 samples/sec   Loss 1.2491   LearningRate 0.000026   Epoch: 0   Global Step: 16290   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:06:25,289-Speed 139.74 samples/sec   Loss 1.2241   LearningRate 0.000026   Epoch: 0   Global Step: 16300   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:06:27,554-Speed 141.34 samples/sec   Loss 1.2274   LearningRate 0.000026   Epoch: 0   Global Step: 16310   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:06:29,829-Speed 140.70 samples/sec   Loss 1.1922   LearningRate 0.000026   Epoch: 0   Global Step: 16320   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:06:32,101-Speed 140.88 samples/sec   Loss 1.2212   LearningRate 0.000026   Epoch: 0   Global Step: 16330   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:06:34,383-Speed 140.23 samples/sec   Loss 1.1990   LearningRate 0.000026   Epoch: 0   Global Step: 16340   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:06:36,672-Speed 139.84 samples/sec   Loss 1.2385   LearningRate 0.000026   Epoch: 0   Global Step: 16350   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:06:38,973-Speed 139.13 samples/sec   Loss 1.2083   LearningRate 0.000026   Epoch: 0   Global Step: 16360   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:06:41,272-Speed 139.22 samples/sec   Loss 1.2096   LearningRate 0.000026   Epoch: 0   Global Step: 16370   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:06:43,555-Speed 140.18 samples/sec   Loss 1.1939   LearningRate 0.000026   Epoch: 0   Global Step: 16380   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:06:45,855-Speed 139.18 samples/sec   Loss 1.1904   LearningRate 0.000026   Epoch: 0   Global Step: 16390   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:06:48,170-Speed 138.25 samples/sec   Loss 1.1930   LearningRate 0.000026   Epoch: 0   Global Step: 16400   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:06:50,462-Speed 139.65 samples/sec   Loss 1.2270   LearningRate 0.000026   Epoch: 0   Global Step: 16410   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:06:52,749-Speed 139.95 samples/sec   Loss 1.2173   LearningRate 0.000026   Epoch: 0   Global Step: 16420   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:06:55,046-Speed 139.37 samples/sec   Loss 1.2012   LearningRate 0.000026   Epoch: 0   Global Step: 16430   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:06:57,328-Speed 140.27 samples/sec   Loss 1.2364   LearningRate 0.000026   Epoch: 0   Global Step: 16440   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:06:59,617-Speed 139.82 samples/sec   Loss 1.1720   LearningRate 0.000026   Epoch: 0   Global Step: 16450   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:07:01,901-Speed 140.13 samples/sec   Loss 1.2080   LearningRate 0.000026   Epoch: 0   Global Step: 16460   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:07:04,185-Speed 140.13 samples/sec   Loss 1.1836   LearningRate 0.000026   Epoch: 0   Global Step: 16470   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:07:06,467-Speed 140.29 samples/sec   Loss 1.2141   LearningRate 0.000026   Epoch: 0   Global Step: 16480   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:07:08,761-Speed 139.53 samples/sec   Loss 1.2092   LearningRate 0.000026   Epoch: 0   Global Step: 16490   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:07:11,045-Speed 140.10 samples/sec   Loss 1.2595   LearningRate 0.000026   Epoch: 0   Global Step: 16500   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:07:13,328-Speed 140.22 samples/sec   Loss 1.2355   LearningRate 0.000026   Epoch: 0   Global Step: 16510   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:07:15,627-Speed 139.20 samples/sec   Loss 1.1943   LearningRate 0.000026   Epoch: 0   Global Step: 16520   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:07:17,929-Speed 139.05 samples/sec   Loss 1.2002   LearningRate 0.000026   Epoch: 0   Global Step: 16530   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:07:20,210-Speed 140.34 samples/sec   Loss 1.1847   LearningRate 0.000026   Epoch: 0   Global Step: 16540   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:07:22,509-Speed 139.23 samples/sec   Loss 1.2012   LearningRate 0.000026   Epoch: 0   Global Step: 16550   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:07:24,807-Speed 139.31 samples/sec   Loss 1.1958   LearningRate 0.000026   Epoch: 0   Global Step: 16560   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:07:27,089-Speed 140.26 samples/sec   Loss 1.2348   LearningRate 0.000026   Epoch: 0   Global Step: 16570   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:07:29,397-Speed 138.69 samples/sec   Loss 1.2015   LearningRate 0.000026   Epoch: 0   Global Step: 16580   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:07:31,683-Speed 139.98 samples/sec   Loss 1.2397   LearningRate 0.000026   Epoch: 0   Global Step: 16590   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:07:33,982-Speed 139.28 samples/sec   Loss 1.1743   LearningRate 0.000026   Epoch: 0   Global Step: 16600   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:07:36,285-Speed 138.93 samples/sec   Loss 1.2013   LearningRate 0.000026   Epoch: 0   Global Step: 16610   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:07:38,573-Speed 139.90 samples/sec   Loss 1.2005   LearningRate 0.000026   Epoch: 0   Global Step: 16620   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:07:40,871-Speed 139.30 samples/sec   Loss 1.2115   LearningRate 0.000026   Epoch: 0   Global Step: 16630   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:07:43,167-Speed 139.39 samples/sec   Loss 1.2168   LearningRate 0.000026   Epoch: 0   Global Step: 16640   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:07:45,446-Speed 140.49 samples/sec   Loss 1.2097   LearningRate 0.000026   Epoch: 0   Global Step: 16650   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:07:47,724-Speed 140.48 samples/sec   Loss 1.2144   LearningRate 0.000026   Epoch: 0   Global Step: 16660   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:07:50,013-Speed 139.84 samples/sec   Loss 1.2453   LearningRate 0.000026   Epoch: 0   Global Step: 16670   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:07:52,290-Speed 140.60 samples/sec   Loss 1.2068   LearningRate 0.000026   Epoch: 0   Global Step: 16680   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:07:54,579-Speed 139.79 samples/sec   Loss 1.2022   LearningRate 0.000026   Epoch: 0   Global Step: 16690   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:07:56,869-Speed 139.82 samples/sec   Loss 1.2136   LearningRate 0.000026   Epoch: 0   Global Step: 16700   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:07:59,157-Speed 139.88 samples/sec   Loss 1.1867   LearningRate 0.000026   Epoch: 0   Global Step: 16710   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:08:01,439-Speed 140.30 samples/sec   Loss 1.1972   LearningRate 0.000026   Epoch: 0   Global Step: 16720   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:08:03,727-Speed 139.87 samples/sec   Loss 1.2088   LearningRate 0.000026   Epoch: 0   Global Step: 16730   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:08:06,015-Speed 139.89 samples/sec   Loss 1.1995   LearningRate 0.000026   Epoch: 0   Global Step: 16740   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:08:08,300-Speed 140.07 samples/sec   Loss 1.1896   LearningRate 0.000026   Epoch: 0   Global Step: 16750   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:08:10,586-Speed 140.08 samples/sec   Loss 1.2567   LearningRate 0.000026   Epoch: 0   Global Step: 16760   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:08:12,883-Speed 139.31 samples/sec   Loss 1.1960   LearningRate 0.000026   Epoch: 0   Global Step: 16770   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:08:15,170-Speed 139.95 samples/sec   Loss 1.2411   LearningRate 0.000026   Epoch: 0   Global Step: 16780   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:08:17,462-Speed 139.67 samples/sec   Loss 1.2135   LearningRate 0.000026   Epoch: 0   Global Step: 16790   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:08:19,732-Speed 141.01 samples/sec   Loss 1.1972   LearningRate 0.000026   Epoch: 0   Global Step: 16800   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:08:22,017-Speed 140.11 samples/sec   Loss 1.1650   LearningRate 0.000026   Epoch: 0   Global Step: 16810   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:08:24,293-Speed 140.64 samples/sec   Loss 1.2001   LearningRate 0.000026   Epoch: 0   Global Step: 16820   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:08:26,568-Speed 140.71 samples/sec   Loss 1.1989   LearningRate 0.000026   Epoch: 0   Global Step: 16830   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:08:28,834-Speed 141.27 samples/sec   Loss 1.2171   LearningRate 0.000026   Epoch: 0   Global Step: 16840   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:08:31,097-Speed 141.40 samples/sec   Loss 1.1754   LearningRate 0.000026   Epoch: 0   Global Step: 16850   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:08:33,367-Speed 141.04 samples/sec   Loss 1.2071   LearningRate 0.000026   Epoch: 0   Global Step: 16860   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:08:35,647-Speed 140.37 samples/sec   Loss 1.2091   LearningRate 0.000026   Epoch: 0   Global Step: 16870   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:08:37,917-Speed 141.05 samples/sec   Loss 1.2232   LearningRate 0.000026   Epoch: 0   Global Step: 16880   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:08:40,218-Speed 139.05 samples/sec   Loss 1.2305   LearningRate 0.000026   Epoch: 0   Global Step: 16890   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:08:42,519-Speed 139.12 samples/sec   Loss 1.1846   LearningRate 0.000026   Epoch: 0   Global Step: 16900   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:08:44,826-Speed 138.77 samples/sec   Loss 1.2017   LearningRate 0.000026   Epoch: 0   Global Step: 16910   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:08:47,109-Speed 140.17 samples/sec   Loss 1.2572   LearningRate 0.000026   Epoch: 0   Global Step: 16920   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:08:49,419-Speed 138.59 samples/sec   Loss 1.1922   LearningRate 0.000026   Epoch: 0   Global Step: 16930   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:08:51,722-Speed 139.01 samples/sec   Loss 1.1973   LearningRate 0.000026   Epoch: 0   Global Step: 16940   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:08:54,037-Speed 138.29 samples/sec   Loss 1.1848   LearningRate 0.000026   Epoch: 0   Global Step: 16950   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:08:56,309-Speed 140.87 samples/sec   Loss 1.1982   LearningRate 0.000026   Epoch: 0   Global Step: 16960   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:08:58,591-Speed 140.25 samples/sec   Loss 1.1987   LearningRate 0.000026   Epoch: 0   Global Step: 16970   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:09:00,885-Speed 139.53 samples/sec   Loss 1.2253   LearningRate 0.000026   Epoch: 0   Global Step: 16980   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:09:03,176-Speed 139.69 samples/sec   Loss 1.1788   LearningRate 0.000026   Epoch: 0   Global Step: 16990   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:09:05,232-Val on RAF/AffectNet:
Training: 2023-08-17 22:09:05,339-Test: [0/48]	Time 0.107 (0.107)	Loss 0.6006 (0.6006)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-17 22:09:06,400-Test: [10/48]	Time 0.108 (0.106)	Loss 0.4963 (0.5480)	Acc@1 95.312 (92.898)	Acc@5 98.438 (98.864)	Mem 5268MB
Training: 2023-08-17 22:09:07,479-Test: [20/48]	Time 0.106 (0.107)	Loss 0.5393 (0.5427)	Acc@1 90.625 (92.783)	Acc@5 100.000 (98.884)	Mem 5268MB
Training: 2023-08-17 22:09:08,551-Test: [30/48]	Time 0.107 (0.107)	Loss 0.5026 (0.5389)	Acc@1 93.750 (92.742)	Acc@5 100.000 (98.942)	Mem 5268MB
Training: 2023-08-17 22:09:09,629-Test: [40/48]	Time 0.106 (0.107)	Loss 0.4335 (0.5522)	Acc@1 98.438 (92.188)	Acc@5 100.000 (98.666)	Mem 5268MB
Training: 2023-08-17 22:09:10,345-[16999]Expression Loss: 0.55071
Training: 2023-08-17 22:09:10,345-[16999]Expression Acc@1: 92.37288
Training: 2023-08-17 22:09:10,345-[16999]Expression Acc@1-Highest: 92.37288
Training: 2023-08-17 22:09:10,345-[16999]Expression Acc@5: 98.66362
Training: 2023-08-17 22:09:10,345-[16999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 22:09:10,345-[16999]10 Times Expression Acc@1: 91.52868
Training: 2023-08-17 22:09:10,345-[16999]10 Times Expression Acc@1-Highest: 91.52868
Training: 2023-08-17 22:09:10,573-Speed 43.27 samples/sec   Loss 1.2347   LearningRate 0.000026   Epoch: 0   Global Step: 17000   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:09:12,864-Speed 139.70 samples/sec   Loss 1.1826   LearningRate 0.000026   Epoch: 0   Global Step: 17010   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:09:15,145-Speed 140.35 samples/sec   Loss 1.2062   LearningRate 0.000026   Epoch: 0   Global Step: 17020   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:09:17,425-Speed 140.36 samples/sec   Loss 1.2426   LearningRate 0.000025   Epoch: 0   Global Step: 17030   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:09:19,723-Speed 139.28 samples/sec   Loss 1.2186   LearningRate 0.000025   Epoch: 0   Global Step: 17040   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:09:22,018-Speed 139.50 samples/sec   Loss 1.2057   LearningRate 0.000025   Epoch: 0   Global Step: 17050   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:09:24,320-Speed 139.06 samples/sec   Loss 1.1912   LearningRate 0.000025   Epoch: 0   Global Step: 17060   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:09:26,605-Speed 140.03 samples/sec   Loss 1.2218   LearningRate 0.000025   Epoch: 0   Global Step: 17070   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:09:28,896-Speed 139.74 samples/sec   Loss 1.2025   LearningRate 0.000025   Epoch: 0   Global Step: 17080   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:09:31,177-Speed 140.35 samples/sec   Loss 1.2134   LearningRate 0.000025   Epoch: 0   Global Step: 17090   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:09:33,468-Speed 139.73 samples/sec   Loss 1.1863   LearningRate 0.000025   Epoch: 0   Global Step: 17100   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:09:35,752-Speed 140.09 samples/sec   Loss 1.2163   LearningRate 0.000025   Epoch: 0   Global Step: 17110   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:09:38,035-Speed 140.28 samples/sec   Loss 1.2052   LearningRate 0.000025   Epoch: 0   Global Step: 17120   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:09:40,319-Speed 140.11 samples/sec   Loss 1.1934   LearningRate 0.000025   Epoch: 0   Global Step: 17130   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:09:42,597-Speed 140.49 samples/sec   Loss 1.2089   LearningRate 0.000025   Epoch: 0   Global Step: 17140   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:09:44,886-Speed 139.86 samples/sec   Loss 1.1760   LearningRate 0.000025   Epoch: 0   Global Step: 17150   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:09:47,180-Speed 139.52 samples/sec   Loss 1.2324   LearningRate 0.000025   Epoch: 0   Global Step: 17160   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:09:49,469-Speed 139.85 samples/sec   Loss 1.2266   LearningRate 0.000025   Epoch: 0   Global Step: 17170   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:09:51,752-Speed 140.23 samples/sec   Loss 1.2121   LearningRate 0.000025   Epoch: 0   Global Step: 17180   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:09:54,038-Speed 140.02 samples/sec   Loss 1.2325   LearningRate 0.000025   Epoch: 0   Global Step: 17190   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:09:56,324-Speed 140.03 samples/sec   Loss 1.2062   LearningRate 0.000025   Epoch: 0   Global Step: 17200   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:09:58,605-Speed 140.30 samples/sec   Loss 1.1862   LearningRate 0.000025   Epoch: 0   Global Step: 17210   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:10:00,891-Speed 140.06 samples/sec   Loss 1.2148   LearningRate 0.000025   Epoch: 0   Global Step: 17220   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:10:03,179-Speed 139.89 samples/sec   Loss 1.2253   LearningRate 0.000025   Epoch: 0   Global Step: 17230   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:10:05,481-Speed 139.02 samples/sec   Loss 1.2186   LearningRate 0.000025   Epoch: 0   Global Step: 17240   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:10:07,765-Speed 140.15 samples/sec   Loss 1.1905   LearningRate 0.000025   Epoch: 0   Global Step: 17250   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:10:10,056-Speed 139.74 samples/sec   Loss 1.2031   LearningRate 0.000025   Epoch: 0   Global Step: 17260   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:10:12,362-Speed 138.80 samples/sec   Loss 1.2208   LearningRate 0.000025   Epoch: 0   Global Step: 17270   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:10:14,658-Speed 139.39 samples/sec   Loss 1.2117   LearningRate 0.000025   Epoch: 0   Global Step: 17280   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:10:16,981-Speed 137.82 samples/sec   Loss 1.2427   LearningRate 0.000025   Epoch: 0   Global Step: 17290   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:10:19,304-Speed 137.81 samples/sec   Loss 1.2278   LearningRate 0.000025   Epoch: 0   Global Step: 17300   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:10:21,604-Speed 139.16 samples/sec   Loss 1.2206   LearningRate 0.000025   Epoch: 0   Global Step: 17310   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:10:23,924-Speed 137.96 samples/sec   Loss 1.2188   LearningRate 0.000025   Epoch: 0   Global Step: 17320   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:10:26,248-Speed 137.75 samples/sec   Loss 1.1975   LearningRate 0.000025   Epoch: 0   Global Step: 17330   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:10:28,581-Speed 137.18 samples/sec   Loss 1.2219   LearningRate 0.000025   Epoch: 0   Global Step: 17340   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:10:30,913-Speed 137.25 samples/sec   Loss 1.2081   LearningRate 0.000025   Epoch: 0   Global Step: 17350   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:10:33,237-Speed 137.75 samples/sec   Loss 1.2097   LearningRate 0.000025   Epoch: 0   Global Step: 17360   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:10:35,547-Speed 138.56 samples/sec   Loss 1.2067   LearningRate 0.000025   Epoch: 0   Global Step: 17370   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:10:37,870-Speed 137.82 samples/sec   Loss 1.2186   LearningRate 0.000025   Epoch: 0   Global Step: 17380   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:10:40,197-Speed 137.56 samples/sec   Loss 1.1758   LearningRate 0.000025   Epoch: 0   Global Step: 17390   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:10:42,517-Speed 137.93 samples/sec   Loss 1.2260   LearningRate 0.000025   Epoch: 0   Global Step: 17400   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:10:44,834-Speed 138.19 samples/sec   Loss 1.1828   LearningRate 0.000025   Epoch: 0   Global Step: 17410   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:10:47,158-Speed 137.74 samples/sec   Loss 1.2366   LearningRate 0.000025   Epoch: 0   Global Step: 17420   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:10:49,481-Speed 137.75 samples/sec   Loss 1.1945   LearningRate 0.000025   Epoch: 0   Global Step: 17430   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:10:51,807-Speed 137.65 samples/sec   Loss 1.2130   LearningRate 0.000025   Epoch: 0   Global Step: 17440   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:10:54,132-Speed 137.67 samples/sec   Loss 1.1738   LearningRate 0.000025   Epoch: 0   Global Step: 17450   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:10:56,438-Speed 138.79 samples/sec   Loss 1.2441   LearningRate 0.000025   Epoch: 0   Global Step: 17460   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:10:58,734-Speed 139.42 samples/sec   Loss 1.1834   LearningRate 0.000025   Epoch: 0   Global Step: 17470   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:11:01,025-Speed 139.73 samples/sec   Loss 1.1988   LearningRate 0.000025   Epoch: 0   Global Step: 17480   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:11:03,326-Speed 139.10 samples/sec   Loss 1.1942   LearningRate 0.000025   Epoch: 0   Global Step: 17490   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:11:05,630-Speed 138.94 samples/sec   Loss 1.2078   LearningRate 0.000025   Epoch: 0   Global Step: 17500   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:11:07,949-Speed 137.99 samples/sec   Loss 1.2451   LearningRate 0.000025   Epoch: 0   Global Step: 17510   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:11:10,252-Speed 139.01 samples/sec   Loss 1.2117   LearningRate 0.000025   Epoch: 0   Global Step: 17520   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:11:12,552-Speed 139.17 samples/sec   Loss 1.1925   LearningRate 0.000025   Epoch: 0   Global Step: 17530   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:11:14,876-Speed 137.77 samples/sec   Loss 1.2277   LearningRate 0.000025   Epoch: 0   Global Step: 17540   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:11:17,190-Speed 138.34 samples/sec   Loss 1.1931   LearningRate 0.000025   Epoch: 0   Global Step: 17550   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:11:19,494-Speed 138.93 samples/sec   Loss 1.1816   LearningRate 0.000025   Epoch: 0   Global Step: 17560   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:11:21,795-Speed 139.06 samples/sec   Loss 1.1819   LearningRate 0.000025   Epoch: 0   Global Step: 17570   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:11:24,106-Speed 138.55 samples/sec   Loss 1.2207   LearningRate 0.000025   Epoch: 0   Global Step: 17580   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:11:26,410-Speed 138.92 samples/sec   Loss 1.1837   LearningRate 0.000025   Epoch: 0   Global Step: 17590   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:11:28,710-Speed 139.16 samples/sec   Loss 1.2112   LearningRate 0.000025   Epoch: 0   Global Step: 17600   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:11:30,983-Speed 140.81 samples/sec   Loss 1.2033   LearningRate 0.000025   Epoch: 0   Global Step: 17610   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:11:33,256-Speed 140.83 samples/sec   Loss 1.2209   LearningRate 0.000025   Epoch: 0   Global Step: 17620   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:11:35,563-Speed 138.75 samples/sec   Loss 1.2141   LearningRate 0.000025   Epoch: 0   Global Step: 17630   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:11:37,877-Speed 138.32 samples/sec   Loss 1.1899   LearningRate 0.000025   Epoch: 0   Global Step: 17640   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:11:40,198-Speed 137.93 samples/sec   Loss 1.1714   LearningRate 0.000025   Epoch: 0   Global Step: 17650   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:11:42,489-Speed 139.70 samples/sec   Loss 1.1937   LearningRate 0.000025   Epoch: 0   Global Step: 17660   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:11:44,779-Speed 139.80 samples/sec   Loss 1.2167   LearningRate 0.000025   Epoch: 0   Global Step: 17670   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:11:47,067-Speed 139.94 samples/sec   Loss 1.1995   LearningRate 0.000025   Epoch: 0   Global Step: 17680   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:11:49,345-Speed 140.48 samples/sec   Loss 1.1910   LearningRate 0.000025   Epoch: 0   Global Step: 17690   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:11:51,639-Speed 139.52 samples/sec   Loss 1.2025   LearningRate 0.000025   Epoch: 0   Global Step: 17700   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:11:53,939-Speed 139.20 samples/sec   Loss 1.2155   LearningRate 0.000025   Epoch: 0   Global Step: 17710   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:11:56,232-Speed 139.62 samples/sec   Loss 1.1851   LearningRate 0.000025   Epoch: 0   Global Step: 17720   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:11:58,517-Speed 140.10 samples/sec   Loss 1.1800   LearningRate 0.000025   Epoch: 0   Global Step: 17730   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:12:00,815-Speed 139.27 samples/sec   Loss 1.1967   LearningRate 0.000025   Epoch: 0   Global Step: 17740   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:12:03,102-Speed 139.97 samples/sec   Loss 1.1707   LearningRate 0.000025   Epoch: 0   Global Step: 17750   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:12:05,400-Speed 139.25 samples/sec   Loss 1.2250   LearningRate 0.000025   Epoch: 0   Global Step: 17760   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:12:07,694-Speed 139.58 samples/sec   Loss 1.1696   LearningRate 0.000025   Epoch: 0   Global Step: 17770   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:12:09,997-Speed 138.96 samples/sec   Loss 1.2254   LearningRate 0.000025   Epoch: 0   Global Step: 17780   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:12:12,289-Speed 139.69 samples/sec   Loss 1.2136   LearningRate 0.000025   Epoch: 0   Global Step: 17790   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:12:14,591-Speed 139.05 samples/sec   Loss 1.1790   LearningRate 0.000025   Epoch: 0   Global Step: 17800   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:12:16,887-Speed 139.42 samples/sec   Loss 1.2184   LearningRate 0.000025   Epoch: 0   Global Step: 17810   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:12:19,175-Speed 139.91 samples/sec   Loss 1.1956   LearningRate 0.000025   Epoch: 0   Global Step: 17820   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:12:21,462-Speed 139.93 samples/sec   Loss 1.1757   LearningRate 0.000025   Epoch: 0   Global Step: 17830   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:12:23,756-Speed 139.55 samples/sec   Loss 1.2292   LearningRate 0.000025   Epoch: 0   Global Step: 17840   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:12:26,055-Speed 139.21 samples/sec   Loss 1.2041   LearningRate 0.000025   Epoch: 0   Global Step: 17850   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:12:28,356-Speed 139.11 samples/sec   Loss 1.2277   LearningRate 0.000025   Epoch: 0   Global Step: 17860   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:12:30,629-Speed 140.85 samples/sec   Loss 1.2249   LearningRate 0.000025   Epoch: 0   Global Step: 17870   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:12:32,924-Speed 139.44 samples/sec   Loss 1.2095   LearningRate 0.000025   Epoch: 0   Global Step: 17880   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:12:35,225-Speed 139.14 samples/sec   Loss 1.2116   LearningRate 0.000025   Epoch: 0   Global Step: 17890   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:12:37,529-Speed 138.94 samples/sec   Loss 1.2066   LearningRate 0.000025   Epoch: 0   Global Step: 17900   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:12:39,824-Speed 139.43 samples/sec   Loss 1.1951   LearningRate 0.000025   Epoch: 0   Global Step: 17910   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:12:42,117-Speed 139.64 samples/sec   Loss 1.2274   LearningRate 0.000025   Epoch: 0   Global Step: 17920   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:12:44,396-Speed 140.46 samples/sec   Loss 1.2056   LearningRate 0.000025   Epoch: 0   Global Step: 17930   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:12:46,724-Speed 137.43 samples/sec   Loss 1.2187   LearningRate 0.000025   Epoch: 0   Global Step: 17940   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:12:49,045-Speed 137.94 samples/sec   Loss 1.2196   LearningRate 0.000025   Epoch: 0   Global Step: 17950   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:12:51,345-Speed 139.17 samples/sec   Loss 1.2226   LearningRate 0.000025   Epoch: 0   Global Step: 17960   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:12:53,672-Speed 137.58 samples/sec   Loss 1.2443   LearningRate 0.000025   Epoch: 0   Global Step: 17970   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:12:55,978-Speed 138.81 samples/sec   Loss 1.1961   LearningRate 0.000025   Epoch: 0   Global Step: 17980   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:12:58,281-Speed 138.98 samples/sec   Loss 1.1983   LearningRate 0.000025   Epoch: 0   Global Step: 17990   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:13:00,361-Val on RAF/AffectNet:
Training: 2023-08-17 22:13:00,467-Test: [0/48]	Time 0.105 (0.105)	Loss 0.4611 (0.4611)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-17 22:13:01,519-Test: [10/48]	Time 0.103 (0.105)	Loss 0.5215 (0.5251)	Acc@1 90.625 (92.188)	Acc@5 100.000 (99.574)	Mem 5268MB
Training: 2023-08-17 22:13:02,566-Test: [20/48]	Time 0.104 (0.105)	Loss 0.4918 (0.5431)	Acc@1 93.750 (91.741)	Acc@5 100.000 (99.182)	Mem 5268MB
Training: 2023-08-17 22:13:03,617-Test: [30/48]	Time 0.103 (0.105)	Loss 0.6810 (0.5483)	Acc@1 85.938 (91.583)	Acc@5 98.438 (98.942)	Mem 5268MB
Training: 2023-08-17 22:13:04,714-Test: [40/48]	Time 0.104 (0.106)	Loss 0.6076 (0.5529)	Acc@1 89.062 (91.540)	Acc@5 96.875 (98.742)	Mem 5268MB
Training: 2023-08-17 22:13:05,452-[17999]Expression Loss: 0.55001
Training: 2023-08-17 22:13:05,453-[17999]Expression Acc@1: 91.52542
Training: 2023-08-17 22:13:05,453-[17999]Expression Acc@1-Highest: 92.37288
Training: 2023-08-17 22:13:05,453-[17999]Expression Acc@5: 98.79400
Training: 2023-08-17 22:13:05,453-[17999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 22:13:05,453-[17999]10 Times Expression Acc@1: 91.51565
Training: 2023-08-17 22:13:05,453-[17999]10 Times Expression Acc@1-Highest: 91.52868
Training: 2023-08-17 22:13:06,057-Speed 41.16 samples/sec   Loss 1.2199   LearningRate 0.000025   Epoch: 0   Global Step: 18000   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:13:08,338-Speed 140.33 samples/sec   Loss 1.2193   LearningRate 0.000025   Epoch: 0   Global Step: 18010   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:13:10,629-Speed 139.68 samples/sec   Loss 1.2076   LearningRate 0.000025   Epoch: 0   Global Step: 18020   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:13:12,920-Speed 139.76 samples/sec   Loss 1.2168   LearningRate 0.000025   Epoch: 0   Global Step: 18030   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:13:15,198-Speed 140.49 samples/sec   Loss 1.2063   LearningRate 0.000025   Epoch: 0   Global Step: 18040   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:13:17,482-Speed 140.14 samples/sec   Loss 1.1982   LearningRate 0.000025   Epoch: 0   Global Step: 18050   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:13:19,754-Speed 140.88 samples/sec   Loss 1.1902   LearningRate 0.000025   Epoch: 0   Global Step: 18060   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:13:22,036-Speed 140.30 samples/sec   Loss 1.2022   LearningRate 0.000025   Epoch: 0   Global Step: 18070   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:13:24,312-Speed 140.62 samples/sec   Loss 1.2121   LearningRate 0.000025   Epoch: 0   Global Step: 18080   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:13:26,593-Speed 140.33 samples/sec   Loss 1.2033   LearningRate 0.000025   Epoch: 0   Global Step: 18090   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:13:28,883-Speed 139.76 samples/sec   Loss 1.1872   LearningRate 0.000025   Epoch: 0   Global Step: 18100   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:13:31,178-Speed 139.50 samples/sec   Loss 1.1977   LearningRate 0.000025   Epoch: 0   Global Step: 18110   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:13:33,481-Speed 138.97 samples/sec   Loss 1.2501   LearningRate 0.000025   Epoch: 0   Global Step: 18120   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:13:35,770-Speed 139.83 samples/sec   Loss 1.1873   LearningRate 0.000025   Epoch: 0   Global Step: 18130   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:13:38,069-Speed 139.27 samples/sec   Loss 1.2139   LearningRate 0.000025   Epoch: 0   Global Step: 18140   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:13:40,351-Speed 140.28 samples/sec   Loss 1.2164   LearningRate 0.000025   Epoch: 0   Global Step: 18150   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:13:42,642-Speed 139.72 samples/sec   Loss 1.2453   LearningRate 0.000025   Epoch: 0   Global Step: 18160   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:13:44,948-Speed 138.80 samples/sec   Loss 1.1775   LearningRate 0.000025   Epoch: 0   Global Step: 18170   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:13:47,237-Speed 139.81 samples/sec   Loss 1.1998   LearningRate 0.000025   Epoch: 0   Global Step: 18180   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:13:49,532-Speed 139.47 samples/sec   Loss 1.2078   LearningRate 0.000025   Epoch: 0   Global Step: 18190   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:13:51,828-Speed 139.42 samples/sec   Loss 1.1973   LearningRate 0.000025   Epoch: 0   Global Step: 18200   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:13:54,126-Speed 139.34 samples/sec   Loss 1.2132   LearningRate 0.000025   Epoch: 0   Global Step: 18210   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:13:56,424-Speed 139.24 samples/sec   Loss 1.1948   LearningRate 0.000025   Epoch: 0   Global Step: 18220   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:13:58,703-Speed 140.46 samples/sec   Loss 1.2026   LearningRate 0.000025   Epoch: 0   Global Step: 18230   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:14:01,004-Speed 139.13 samples/sec   Loss 1.2234   LearningRate 0.000025   Epoch: 0   Global Step: 18240   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:14:03,314-Speed 138.56 samples/sec   Loss 1.1952   LearningRate 0.000025   Epoch: 0   Global Step: 18250   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:14:05,614-Speed 139.20 samples/sec   Loss 1.2207   LearningRate 0.000025   Epoch: 0   Global Step: 18260   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:14:07,917-Speed 138.98 samples/sec   Loss 1.2127   LearningRate 0.000025   Epoch: 0   Global Step: 18270   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:14:10,220-Speed 139.00 samples/sec   Loss 1.2271   LearningRate 0.000025   Epoch: 0   Global Step: 18280   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:14:12,528-Speed 138.68 samples/sec   Loss 1.1883   LearningRate 0.000025   Epoch: 0   Global Step: 18290   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:14:14,823-Speed 139.45 samples/sec   Loss 1.2118   LearningRate 0.000025   Epoch: 0   Global Step: 18300   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:14:17,129-Speed 138.81 samples/sec   Loss 1.2218   LearningRate 0.000025   Epoch: 0   Global Step: 18310   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:14:19,427-Speed 139.30 samples/sec   Loss 1.2572   LearningRate 0.000025   Epoch: 0   Global Step: 18320   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:14:21,735-Speed 138.70 samples/sec   Loss 1.1918   LearningRate 0.000025   Epoch: 0   Global Step: 18330   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:14:24,043-Speed 138.72 samples/sec   Loss 1.2206   LearningRate 0.000025   Epoch: 0   Global Step: 18340   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:14:26,328-Speed 140.06 samples/sec   Loss 1.1827   LearningRate 0.000025   Epoch: 0   Global Step: 18350   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:14:28,627-Speed 139.26 samples/sec   Loss 1.1925   LearningRate 0.000025   Epoch: 0   Global Step: 18360   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:14:30,931-Speed 138.88 samples/sec   Loss 1.1932   LearningRate 0.000025   Epoch: 0   Global Step: 18370   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:14:33,228-Speed 139.38 samples/sec   Loss 1.1616   LearningRate 0.000025   Epoch: 0   Global Step: 18380   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:14:35,527-Speed 139.21 samples/sec   Loss 1.2355   LearningRate 0.000025   Epoch: 0   Global Step: 18390   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:14:37,811-Speed 140.12 samples/sec   Loss 1.1932   LearningRate 0.000025   Epoch: 0   Global Step: 18400   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:14:40,104-Speed 139.62 samples/sec   Loss 1.1804   LearningRate 0.000025   Epoch: 0   Global Step: 18410   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:14:42,382-Speed 140.57 samples/sec   Loss 1.1855   LearningRate 0.000025   Epoch: 0   Global Step: 18420   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:14:44,681-Speed 139.21 samples/sec   Loss 1.2120   LearningRate 0.000025   Epoch: 0   Global Step: 18430   Fp16 Grad Scale: 131072   Required: 3 hours
Training: 2023-08-17 22:14:46,965-Speed 140.15 samples/sec   Loss 1.2188   LearningRate 0.000025   Epoch: 0   Global Step: 18440   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:14:49,266-Speed 139.09 samples/sec   Loss 1.2167   LearningRate 0.000025   Epoch: 0   Global Step: 18450   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:14:51,589-Speed 137.79 samples/sec   Loss 1.2376   LearningRate 0.000025   Epoch: 0   Global Step: 18460   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:14:53,901-Speed 138.43 samples/sec   Loss 1.1897   LearningRate 0.000025   Epoch: 0   Global Step: 18470   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:14:56,193-Speed 139.73 samples/sec   Loss 1.2087   LearningRate 0.000025   Epoch: 0   Global Step: 18480   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:14:58,497-Speed 138.89 samples/sec   Loss 1.2150   LearningRate 0.000025   Epoch: 0   Global Step: 18490   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:15:00,792-Speed 139.48 samples/sec   Loss 1.2117   LearningRate 0.000025   Epoch: 0   Global Step: 18500   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:15:03,073-Speed 140.40 samples/sec   Loss 1.1779   LearningRate 0.000025   Epoch: 0   Global Step: 18510   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:15:05,353-Speed 140.38 samples/sec   Loss 1.1819   LearningRate 0.000025   Epoch: 0   Global Step: 18520   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:15:07,637-Speed 140.18 samples/sec   Loss 1.2073   LearningRate 0.000025   Epoch: 0   Global Step: 18530   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:15:09,933-Speed 139.39 samples/sec   Loss 1.1976   LearningRate 0.000025   Epoch: 0   Global Step: 18540   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:15:12,210-Speed 140.54 samples/sec   Loss 1.2052   LearningRate 0.000025   Epoch: 0   Global Step: 18550   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:15:14,476-Speed 141.28 samples/sec   Loss 1.1927   LearningRate 0.000025   Epoch: 0   Global Step: 18560   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:15:16,766-Speed 139.77 samples/sec   Loss 1.1817   LearningRate 0.000024   Epoch: 0   Global Step: 18570   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:15:19,051-Speed 140.13 samples/sec   Loss 1.2119   LearningRate 0.000024   Epoch: 0   Global Step: 18580   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:15:21,326-Speed 140.70 samples/sec   Loss 1.1849   LearningRate 0.000024   Epoch: 0   Global Step: 18590   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:15:23,599-Speed 140.81 samples/sec   Loss 1.2031   LearningRate 0.000024   Epoch: 0   Global Step: 18600   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:15:25,877-Speed 140.49 samples/sec   Loss 1.1954   LearningRate 0.000024   Epoch: 0   Global Step: 18610   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:15:28,148-Speed 140.93 samples/sec   Loss 1.2327   LearningRate 0.000024   Epoch: 0   Global Step: 18620   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:15:30,454-Speed 138.84 samples/sec   Loss 1.2168   LearningRate 0.000024   Epoch: 0   Global Step: 18630   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:15:32,738-Speed 140.13 samples/sec   Loss 1.2121   LearningRate 0.000024   Epoch: 0   Global Step: 18640   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:15:35,022-Speed 140.13 samples/sec   Loss 1.1918   LearningRate 0.000024   Epoch: 0   Global Step: 18650   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:15:37,317-Speed 139.52 samples/sec   Loss 1.2125   LearningRate 0.000024   Epoch: 0   Global Step: 18660   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:15:39,598-Speed 140.28 samples/sec   Loss 1.2167   LearningRate 0.000024   Epoch: 0   Global Step: 18670   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:15:41,892-Speed 139.55 samples/sec   Loss 1.1794   LearningRate 0.000024   Epoch: 0   Global Step: 18680   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:15:44,169-Speed 140.57 samples/sec   Loss 1.1970   LearningRate 0.000024   Epoch: 0   Global Step: 18690   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:15:46,465-Speed 139.41 samples/sec   Loss 1.2033   LearningRate 0.000024   Epoch: 0   Global Step: 18700   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:15:48,747-Speed 140.29 samples/sec   Loss 1.2216   LearningRate 0.000024   Epoch: 0   Global Step: 18710   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:15:51,044-Speed 139.37 samples/sec   Loss 1.2162   LearningRate 0.000024   Epoch: 0   Global Step: 18720   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:15:53,331-Speed 139.95 samples/sec   Loss 1.2162   LearningRate 0.000024   Epoch: 0   Global Step: 18730   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:15:55,618-Speed 139.96 samples/sec   Loss 1.2012   LearningRate 0.000024   Epoch: 0   Global Step: 18740   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:15:57,904-Speed 140.06 samples/sec   Loss 1.1853   LearningRate 0.000024   Epoch: 0   Global Step: 18750   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:16:00,197-Speed 139.54 samples/sec   Loss 1.2072   LearningRate 0.000024   Epoch: 0   Global Step: 18760   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:16:02,500-Speed 138.99 samples/sec   Loss 1.2610   LearningRate 0.000024   Epoch: 0   Global Step: 18770   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:16:04,798-Speed 139.32 samples/sec   Loss 1.1924   LearningRate 0.000024   Epoch: 0   Global Step: 18780   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:16:07,080-Speed 140.22 samples/sec   Loss 1.1968   LearningRate 0.000024   Epoch: 0   Global Step: 18790   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:16:09,359-Speed 140.51 samples/sec   Loss 1.1953   LearningRate 0.000024   Epoch: 0   Global Step: 18800   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:16:11,658-Speed 139.19 samples/sec   Loss 1.1890   LearningRate 0.000024   Epoch: 0   Global Step: 18810   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:16:13,975-Speed 138.15 samples/sec   Loss 1.2242   LearningRate 0.000024   Epoch: 0   Global Step: 18820   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:16:16,252-Speed 140.59 samples/sec   Loss 1.2187   LearningRate 0.000024   Epoch: 0   Global Step: 18830   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:16:18,534-Speed 140.25 samples/sec   Loss 1.1939   LearningRate 0.000024   Epoch: 0   Global Step: 18840   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:16:20,826-Speed 139.69 samples/sec   Loss 1.2182   LearningRate 0.000024   Epoch: 0   Global Step: 18850   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:16:23,140-Speed 138.32 samples/sec   Loss 1.2036   LearningRate 0.000024   Epoch: 0   Global Step: 18860   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:16:25,423-Speed 140.19 samples/sec   Loss 1.2119   LearningRate 0.000024   Epoch: 0   Global Step: 18870   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:16:27,711-Speed 139.89 samples/sec   Loss 1.2230   LearningRate 0.000024   Epoch: 0   Global Step: 18880   Fp16 Grad Scale: 8192   Required: 3 hours
Training: 2023-08-17 22:16:29,989-Speed 140.50 samples/sec   Loss 1.1919   LearningRate 0.000024   Epoch: 0   Global Step: 18890   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:16:32,267-Speed 140.51 samples/sec   Loss 1.1962   LearningRate 0.000024   Epoch: 0   Global Step: 18900   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:16:34,539-Speed 140.90 samples/sec   Loss 1.2328   LearningRate 0.000024   Epoch: 0   Global Step: 18910   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:16:36,810-Speed 140.93 samples/sec   Loss 1.1691   LearningRate 0.000024   Epoch: 0   Global Step: 18920   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:16:39,090-Speed 140.40 samples/sec   Loss 1.1772   LearningRate 0.000024   Epoch: 0   Global Step: 18930   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:16:41,378-Speed 139.87 samples/sec   Loss 1.2196   LearningRate 0.000024   Epoch: 0   Global Step: 18940   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:16:43,661-Speed 140.24 samples/sec   Loss 1.1836   LearningRate 0.000024   Epoch: 0   Global Step: 18950   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:16:45,929-Speed 141.12 samples/sec   Loss 1.2126   LearningRate 0.000024   Epoch: 0   Global Step: 18960   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:16:48,210-Speed 140.32 samples/sec   Loss 1.2330   LearningRate 0.000024   Epoch: 0   Global Step: 18970   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:16:50,481-Speed 140.92 samples/sec   Loss 1.2028   LearningRate 0.000024   Epoch: 0   Global Step: 18980   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:16:52,770-Speed 139.88 samples/sec   Loss 1.2078   LearningRate 0.000024   Epoch: 0   Global Step: 18990   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:16:54,839-Val on RAF/AffectNet:
Training: 2023-08-17 22:16:54,945-Test: [0/48]	Time 0.106 (0.106)	Loss 0.5299 (0.5299)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-17 22:16:56,016-Test: [10/48]	Time 0.106 (0.107)	Loss 0.5580 (0.5308)	Acc@1 92.188 (93.182)	Acc@5 96.875 (98.864)	Mem 5268MB
Training: 2023-08-17 22:16:57,083-Test: [20/48]	Time 0.105 (0.107)	Loss 0.6690 (0.5500)	Acc@1 89.062 (92.039)	Acc@5 96.875 (99.182)	Mem 5268MB
Training: 2023-08-17 22:16:58,173-Test: [30/48]	Time 0.107 (0.108)	Loss 0.5690 (0.5401)	Acc@1 92.188 (92.692)	Acc@5 100.000 (99.194)	Mem 5268MB
Training: 2023-08-17 22:16:59,231-Test: [40/48]	Time 0.105 (0.107)	Loss 0.5908 (0.5450)	Acc@1 87.500 (92.607)	Acc@5 100.000 (99.085)	Mem 5268MB
Training: 2023-08-17 22:16:59,981-[18999]Expression Loss: 0.55101
Training: 2023-08-17 22:16:59,981-[18999]Expression Acc@1: 92.47067
Training: 2023-08-17 22:16:59,982-[18999]Expression Acc@1-Highest: 92.47067
Training: 2023-08-17 22:16:59,982-[18999]Expression Acc@5: 99.02216
Training: 2023-08-17 22:16:59,982-[18999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 22:16:59,982-[18999]10 Times Expression Acc@1: 91.73729
Training: 2023-08-17 22:16:59,982-[18999]10 Times Expression Acc@1-Highest: 91.73729
Training: 2023-08-17 22:17:00,209-Speed 43.02 samples/sec   Loss 1.1898   LearningRate 0.000024   Epoch: 0   Global Step: 19000   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:17:02,476-Speed 141.17 samples/sec   Loss 1.2376   LearningRate 0.000024   Epoch: 0   Global Step: 19010   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:17:04,734-Speed 141.75 samples/sec   Loss 1.1906   LearningRate 0.000024   Epoch: 0   Global Step: 19020   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:17:07,009-Speed 140.69 samples/sec   Loss 1.2126   LearningRate 0.000024   Epoch: 0   Global Step: 19030   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:17:09,291-Speed 140.24 samples/sec   Loss 1.1975   LearningRate 0.000024   Epoch: 0   Global Step: 19040   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:17:11,576-Speed 140.12 samples/sec   Loss 1.2053   LearningRate 0.000024   Epoch: 0   Global Step: 19050   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:17:13,872-Speed 139.41 samples/sec   Loss 1.2143   LearningRate 0.000024   Epoch: 0   Global Step: 19060   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:17:16,164-Speed 139.61 samples/sec   Loss 1.2025   LearningRate 0.000024   Epoch: 0   Global Step: 19070   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:17:18,493-Speed 137.46 samples/sec   Loss 1.1894   LearningRate 0.000024   Epoch: 0   Global Step: 19080   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:17:20,793-Speed 139.19 samples/sec   Loss 1.2338   LearningRate 0.000024   Epoch: 0   Global Step: 19090   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:17:23,068-Speed 140.69 samples/sec   Loss 1.1693   LearningRate 0.000024   Epoch: 0   Global Step: 19100   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:17:25,353-Speed 140.07 samples/sec   Loss 1.2208   LearningRate 0.000024   Epoch: 0   Global Step: 19110   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:17:27,643-Speed 139.78 samples/sec   Loss 1.1955   LearningRate 0.000024   Epoch: 0   Global Step: 19120   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:17:29,921-Speed 140.50 samples/sec   Loss 1.2027   LearningRate 0.000024   Epoch: 0   Global Step: 19130   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:17:32,191-Speed 140.99 samples/sec   Loss 1.2144   LearningRate 0.000024   Epoch: 0   Global Step: 19140   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:17:34,465-Speed 140.75 samples/sec   Loss 1.1780   LearningRate 0.000024   Epoch: 0   Global Step: 19150   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:17:36,749-Speed 140.18 samples/sec   Loss 1.2418   LearningRate 0.000024   Epoch: 0   Global Step: 19160   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:17:39,033-Speed 140.09 samples/sec   Loss 1.2040   LearningRate 0.000024   Epoch: 0   Global Step: 19170   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:17:41,309-Speed 140.66 samples/sec   Loss 1.2086   LearningRate 0.000024   Epoch: 0   Global Step: 19180   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:17:43,595-Speed 140.04 samples/sec   Loss 1.2082   LearningRate 0.000024   Epoch: 0   Global Step: 19190   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:17:45,858-Speed 141.44 samples/sec   Loss 1.2213   LearningRate 0.000024   Epoch: 0   Global Step: 19200   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:17:48,151-Speed 139.59 samples/sec   Loss 1.1771   LearningRate 0.000024   Epoch: 0   Global Step: 19210   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:17:50,412-Speed 141.54 samples/sec   Loss 1.2060   LearningRate 0.000024   Epoch: 0   Global Step: 19220   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:17:52,702-Speed 139.75 samples/sec   Loss 1.1914   LearningRate 0.000024   Epoch: 0   Global Step: 19230   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:17:54,992-Speed 139.81 samples/sec   Loss 1.1788   LearningRate 0.000024   Epoch: 0   Global Step: 19240   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:17:57,294-Speed 139.05 samples/sec   Loss 1.2058   LearningRate 0.000024   Epoch: 0   Global Step: 19250   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:17:59,590-Speed 139.36 samples/sec   Loss 1.1906   LearningRate 0.000024   Epoch: 0   Global Step: 19260   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:18:01,889-Speed 139.27 samples/sec   Loss 1.1813   LearningRate 0.000024   Epoch: 0   Global Step: 19270   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:18:04,176-Speed 139.95 samples/sec   Loss 1.1946   LearningRate 0.000024   Epoch: 0   Global Step: 19280   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:18:06,443-Speed 141.20 samples/sec   Loss 1.2119   LearningRate 0.000024   Epoch: 0   Global Step: 19290   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:18:08,712-Speed 141.02 samples/sec   Loss 1.2003   LearningRate 0.000024   Epoch: 0   Global Step: 19300   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:18:10,998-Speed 140.00 samples/sec   Loss 1.1824   LearningRate 0.000024   Epoch: 0   Global Step: 19310   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:18:13,258-Speed 141.66 samples/sec   Loss 1.2369   LearningRate 0.000024   Epoch: 0   Global Step: 19320   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:18:15,521-Speed 141.41 samples/sec   Loss 1.2578   LearningRate 0.000024   Epoch: 0   Global Step: 19330   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:18:17,790-Speed 141.08 samples/sec   Loss 1.2059   LearningRate 0.000024   Epoch: 0   Global Step: 19340   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:18:20,057-Speed 141.22 samples/sec   Loss 1.2005   LearningRate 0.000024   Epoch: 0   Global Step: 19350   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:18:22,325-Speed 141.09 samples/sec   Loss 1.1853   LearningRate 0.000024   Epoch: 0   Global Step: 19360   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:18:24,606-Speed 140.36 samples/sec   Loss 1.1852   LearningRate 0.000024   Epoch: 0   Global Step: 19370   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:18:26,885-Speed 140.45 samples/sec   Loss 1.1861   LearningRate 0.000024   Epoch: 0   Global Step: 19380   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:18:29,174-Speed 139.80 samples/sec   Loss 1.2031   LearningRate 0.000024   Epoch: 0   Global Step: 19390   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:18:31,466-Speed 139.66 samples/sec   Loss 1.2108   LearningRate 0.000024   Epoch: 0   Global Step: 19400   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:18:33,744-Speed 140.52 samples/sec   Loss 1.2069   LearningRate 0.000024   Epoch: 0   Global Step: 19410   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:18:36,061-Speed 138.13 samples/sec   Loss 1.1992   LearningRate 0.000024   Epoch: 0   Global Step: 19420   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:18:38,376-Speed 138.27 samples/sec   Loss 1.1948   LearningRate 0.000024   Epoch: 0   Global Step: 19430   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:18:40,689-Speed 138.41 samples/sec   Loss 1.2347   LearningRate 0.000024   Epoch: 0   Global Step: 19440   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:18:42,995-Speed 138.80 samples/sec   Loss 1.2012   LearningRate 0.000024   Epoch: 0   Global Step: 19450   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:18:45,291-Speed 139.41 samples/sec   Loss 1.2172   LearningRate 0.000024   Epoch: 0   Global Step: 19460   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:18:47,575-Speed 140.13 samples/sec   Loss 1.1736   LearningRate 0.000024   Epoch: 0   Global Step: 19470   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:18:49,877-Speed 139.08 samples/sec   Loss 1.2448   LearningRate 0.000024   Epoch: 0   Global Step: 19480   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:18:52,160-Speed 140.17 samples/sec   Loss 1.1962   LearningRate 0.000024   Epoch: 0   Global Step: 19490   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:18:54,457-Speed 139.37 samples/sec   Loss 1.1879   LearningRate 0.000024   Epoch: 0   Global Step: 19500   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:18:56,767-Speed 138.58 samples/sec   Loss 1.1993   LearningRate 0.000024   Epoch: 0   Global Step: 19510   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:18:59,063-Speed 139.39 samples/sec   Loss 1.1911   LearningRate 0.000024   Epoch: 0   Global Step: 19520   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:19:01,349-Speed 140.05 samples/sec   Loss 1.2045   LearningRate 0.000024   Epoch: 0   Global Step: 19530   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:19:03,656-Speed 138.76 samples/sec   Loss 1.2022   LearningRate 0.000024   Epoch: 0   Global Step: 19540   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:19:05,951-Speed 139.48 samples/sec   Loss 1.2003   LearningRate 0.000024   Epoch: 0   Global Step: 19550   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:19:08,223-Speed 140.86 samples/sec   Loss 1.2108   LearningRate 0.000024   Epoch: 0   Global Step: 19560   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:19:10,499-Speed 140.64 samples/sec   Loss 1.1964   LearningRate 0.000024   Epoch: 0   Global Step: 19570   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:19:12,770-Speed 140.94 samples/sec   Loss 1.2075   LearningRate 0.000024   Epoch: 0   Global Step: 19580   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:19:15,051-Speed 140.36 samples/sec   Loss 1.2045   LearningRate 0.000024   Epoch: 0   Global Step: 19590   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:19:17,340-Speed 139.79 samples/sec   Loss 1.2050   LearningRate 0.000024   Epoch: 0   Global Step: 19600   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:19:19,612-Speed 140.92 samples/sec   Loss 1.1993   LearningRate 0.000024   Epoch: 0   Global Step: 19610   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:19:21,890-Speed 140.50 samples/sec   Loss 1.2045   LearningRate 0.000024   Epoch: 0   Global Step: 19620   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:19:24,190-Speed 139.18 samples/sec   Loss 1.2008   LearningRate 0.000024   Epoch: 0   Global Step: 19630   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:19:26,483-Speed 139.57 samples/sec   Loss 1.2212   LearningRate 0.000024   Epoch: 0   Global Step: 19640   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:19:28,770-Speed 139.97 samples/sec   Loss 1.1935   LearningRate 0.000024   Epoch: 0   Global Step: 19650   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:19:31,053-Speed 140.21 samples/sec   Loss 1.2488   LearningRate 0.000024   Epoch: 0   Global Step: 19660   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:19:33,345-Speed 139.64 samples/sec   Loss 1.1559   LearningRate 0.000024   Epoch: 0   Global Step: 19670   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:19:35,634-Speed 139.88 samples/sec   Loss 1.2007   LearningRate 0.000024   Epoch: 0   Global Step: 19680   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:19:37,930-Speed 139.41 samples/sec   Loss 1.2038   LearningRate 0.000024   Epoch: 0   Global Step: 19690   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:19:40,213-Speed 140.21 samples/sec   Loss 1.2160   LearningRate 0.000024   Epoch: 0   Global Step: 19700   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:19:42,505-Speed 139.65 samples/sec   Loss 1.2100   LearningRate 0.000024   Epoch: 0   Global Step: 19710   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:19:44,803-Speed 139.32 samples/sec   Loss 1.1818   LearningRate 0.000024   Epoch: 0   Global Step: 19720   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:19:47,100-Speed 139.34 samples/sec   Loss 1.1904   LearningRate 0.000024   Epoch: 0   Global Step: 19730   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:19:49,407-Speed 138.76 samples/sec   Loss 1.2433   LearningRate 0.000024   Epoch: 0   Global Step: 19740   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:19:51,712-Speed 138.84 samples/sec   Loss 1.2226   LearningRate 0.000024   Epoch: 0   Global Step: 19750   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:19:54,026-Speed 138.32 samples/sec   Loss 1.2105   LearningRate 0.000024   Epoch: 0   Global Step: 19760   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:19:56,316-Speed 139.79 samples/sec   Loss 1.2337   LearningRate 0.000024   Epoch: 0   Global Step: 19770   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:19:58,610-Speed 139.56 samples/sec   Loss 1.1916   LearningRate 0.000024   Epoch: 0   Global Step: 19780   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:20:00,900-Speed 139.78 samples/sec   Loss 1.1867   LearningRate 0.000024   Epoch: 0   Global Step: 19790   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:20:03,194-Speed 139.53 samples/sec   Loss 1.1932   LearningRate 0.000024   Epoch: 0   Global Step: 19800   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:20:05,492-Speed 139.31 samples/sec   Loss 1.2097   LearningRate 0.000024   Epoch: 0   Global Step: 19810   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:20:07,778-Speed 140.00 samples/sec   Loss 1.1797   LearningRate 0.000024   Epoch: 0   Global Step: 19820   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:20:10,054-Speed 140.66 samples/sec   Loss 1.1786   LearningRate 0.000024   Epoch: 0   Global Step: 19830   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:20:12,342-Speed 139.88 samples/sec   Loss 1.2095   LearningRate 0.000024   Epoch: 0   Global Step: 19840   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:20:14,637-Speed 139.47 samples/sec   Loss 1.1955   LearningRate 0.000024   Epoch: 0   Global Step: 19850   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:20:16,922-Speed 140.08 samples/sec   Loss 1.2051   LearningRate 0.000024   Epoch: 0   Global Step: 19860   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:20:19,205-Speed 140.18 samples/sec   Loss 1.2043   LearningRate 0.000024   Epoch: 0   Global Step: 19870   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:20:21,489-Speed 140.19 samples/sec   Loss 1.1998   LearningRate 0.000024   Epoch: 0   Global Step: 19880   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:20:23,781-Speed 139.64 samples/sec   Loss 1.1822   LearningRate 0.000024   Epoch: 0   Global Step: 19890   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:20:26,100-Speed 138.01 samples/sec   Loss 1.1950   LearningRate 0.000024   Epoch: 0   Global Step: 19900   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:20:28,396-Speed 139.45 samples/sec   Loss 1.1844   LearningRate 0.000024   Epoch: 0   Global Step: 19910   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:20:30,719-Speed 137.77 samples/sec   Loss 1.1672   LearningRate 0.000024   Epoch: 0   Global Step: 19920   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:20:33,023-Speed 138.91 samples/sec   Loss 1.1776   LearningRate 0.000024   Epoch: 0   Global Step: 19930   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:20:35,334-Speed 138.54 samples/sec   Loss 1.1840   LearningRate 0.000024   Epoch: 0   Global Step: 19940   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:20:37,636-Speed 139.03 samples/sec   Loss 1.1858   LearningRate 0.000024   Epoch: 0   Global Step: 19950   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:20:39,936-Speed 139.18 samples/sec   Loss 1.2113   LearningRate 0.000024   Epoch: 0   Global Step: 19960   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:20:42,228-Speed 139.69 samples/sec   Loss 1.1804   LearningRate 0.000024   Epoch: 0   Global Step: 19970   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:20:44,535-Speed 138.72 samples/sec   Loss 1.1757   LearningRate 0.000024   Epoch: 0   Global Step: 19980   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:20:46,829-Speed 139.51 samples/sec   Loss 1.2197   LearningRate 0.000024   Epoch: 0   Global Step: 19990   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:20:48,885-Val on RAF/AffectNet:
Training: 2023-08-17 22:20:48,998-Test: [0/48]	Time 0.112 (0.112)	Loss 0.6589 (0.6589)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)	Mem 5268MB
Training: 2023-08-17 22:20:50,120-Test: [10/48]	Time 0.113 (0.112)	Loss 0.7111 (0.5667)	Acc@1 85.938 (91.477)	Acc@5 96.875 (98.153)	Mem 5268MB
Training: 2023-08-17 22:20:51,189-Test: [20/48]	Time 0.104 (0.110)	Loss 0.5317 (0.5609)	Acc@1 90.625 (91.592)	Acc@5 98.438 (98.438)	Mem 5268MB
Training: 2023-08-17 22:20:52,257-Test: [30/48]	Time 0.108 (0.109)	Loss 0.5105 (0.5596)	Acc@1 95.312 (91.885)	Acc@5 98.438 (98.639)	Mem 5268MB
Training: 2023-08-17 22:20:53,339-Test: [40/48]	Time 0.107 (0.109)	Loss 0.5760 (0.5593)	Acc@1 90.625 (92.111)	Acc@5 95.312 (98.590)	Mem 5268MB
Training: 2023-08-17 22:20:54,073-[19999]Expression Loss: 0.55927
Training: 2023-08-17 22:20:54,074-[19999]Expression Acc@1: 92.20991
Training: 2023-08-17 22:20:54,074-[19999]Expression Acc@1-Highest: 92.47067
Training: 2023-08-17 22:20:54,074-[19999]Expression Acc@5: 98.66362
Training: 2023-08-17 22:20:54,074-[19999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 22:20:54,074-[19999]10 Times Expression Acc@1: 91.87744
Training: 2023-08-17 22:20:54,074-[19999]10 Times Expression Acc@1-Highest: 91.87744
Training: 2023-08-17 22:20:54,302-Speed 42.83 samples/sec   Loss 1.1715   LearningRate 0.000024   Epoch: 0   Global Step: 20000   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:20:56,590-Speed 139.91 samples/sec   Loss 1.1991   LearningRate 0.000024   Epoch: 0   Global Step: 20010   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:20:58,896-Speed 138.77 samples/sec   Loss 1.1926   LearningRate 0.000024   Epoch: 0   Global Step: 20020   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:21:01,212-Speed 138.23 samples/sec   Loss 1.1781   LearningRate 0.000023   Epoch: 0   Global Step: 20030   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:21:03,524-Speed 138.42 samples/sec   Loss 1.2110   LearningRate 0.000023   Epoch: 0   Global Step: 20040   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:21:05,845-Speed 137.95 samples/sec   Loss 1.2100   LearningRate 0.000023   Epoch: 0   Global Step: 20050   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:21:08,157-Speed 138.46 samples/sec   Loss 1.2068   LearningRate 0.000023   Epoch: 0   Global Step: 20060   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:21:10,477-Speed 137.96 samples/sec   Loss 1.1829   LearningRate 0.000023   Epoch: 0   Global Step: 20070   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:21:12,798-Speed 137.91 samples/sec   Loss 1.2024   LearningRate 0.000023   Epoch: 0   Global Step: 20080   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:21:15,116-Speed 138.04 samples/sec   Loss 1.1914   LearningRate 0.000023   Epoch: 0   Global Step: 20090   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:21:17,432-Speed 138.20 samples/sec   Loss 1.1982   LearningRate 0.000023   Epoch: 0   Global Step: 20100   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:21:19,752-Speed 137.98 samples/sec   Loss 1.1856   LearningRate 0.000023   Epoch: 0   Global Step: 20110   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:21:22,069-Speed 138.15 samples/sec   Loss 1.2084   LearningRate 0.000023   Epoch: 0   Global Step: 20120   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:21:24,385-Speed 138.18 samples/sec   Loss 1.2142   LearningRate 0.000023   Epoch: 0   Global Step: 20130   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:21:26,710-Speed 137.70 samples/sec   Loss 1.2065   LearningRate 0.000023   Epoch: 0   Global Step: 20140   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:21:29,025-Speed 138.27 samples/sec   Loss 1.1764   LearningRate 0.000023   Epoch: 0   Global Step: 20150   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:21:31,352-Speed 137.53 samples/sec   Loss 1.1944   LearningRate 0.000023   Epoch: 0   Global Step: 20160   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:21:33,681-Speed 137.47 samples/sec   Loss 1.2142   LearningRate 0.000023   Epoch: 0   Global Step: 20170   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:21:35,998-Speed 138.12 samples/sec   Loss 1.2099   LearningRate 0.000023   Epoch: 0   Global Step: 20180   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:21:38,316-Speed 138.10 samples/sec   Loss 1.2232   LearningRate 0.000023   Epoch: 0   Global Step: 20190   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:21:40,635-Speed 138.01 samples/sec   Loss 1.2245   LearningRate 0.000023   Epoch: 0   Global Step: 20200   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:21:42,949-Speed 138.38 samples/sec   Loss 1.1796   LearningRate 0.000023   Epoch: 0   Global Step: 20210   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:21:45,265-Speed 138.20 samples/sec   Loss 1.1906   LearningRate 0.000023   Epoch: 0   Global Step: 20220   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:21:47,586-Speed 137.90 samples/sec   Loss 1.1824   LearningRate 0.000023   Epoch: 0   Global Step: 20230   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:21:49,875-Speed 139.81 samples/sec   Loss 1.1941   LearningRate 0.000023   Epoch: 0   Global Step: 20240   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:21:52,162-Speed 139.97 samples/sec   Loss 1.2306   LearningRate 0.000023   Epoch: 0   Global Step: 20250   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:21:54,423-Speed 141.56 samples/sec   Loss 1.2132   LearningRate 0.000023   Epoch: 0   Global Step: 20260   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:21:56,695-Speed 140.88 samples/sec   Loss 1.1813   LearningRate 0.000023   Epoch: 0   Global Step: 20270   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:21:58,957-Speed 141.50 samples/sec   Loss 1.2106   LearningRate 0.000023   Epoch: 0   Global Step: 20280   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:22:01,235-Speed 140.52 samples/sec   Loss 1.1866   LearningRate 0.000023   Epoch: 0   Global Step: 20290   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:22:03,503-Speed 141.14 samples/sec   Loss 1.2126   LearningRate 0.000023   Epoch: 0   Global Step: 20300   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:22:05,782-Speed 140.46 samples/sec   Loss 1.2211   LearningRate 0.000023   Epoch: 0   Global Step: 20310   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:22:08,065-Speed 140.25 samples/sec   Loss 1.1967   LearningRate 0.000023   Epoch: 0   Global Step: 20320   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:22:10,362-Speed 139.29 samples/sec   Loss 1.2202   LearningRate 0.000023   Epoch: 0   Global Step: 20330   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:22:12,647-Speed 140.07 samples/sec   Loss 1.2120   LearningRate 0.000023   Epoch: 0   Global Step: 20340   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:22:14,947-Speed 139.19 samples/sec   Loss 1.1956   LearningRate 0.000023   Epoch: 0   Global Step: 20350   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:22:17,232-Speed 140.10 samples/sec   Loss 1.2108   LearningRate 0.000023   Epoch: 0   Global Step: 20360   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:22:19,527-Speed 139.44 samples/sec   Loss 1.1819   LearningRate 0.000023   Epoch: 0   Global Step: 20370   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:22:21,828-Speed 139.16 samples/sec   Loss 1.1983   LearningRate 0.000023   Epoch: 0   Global Step: 20380   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:22:24,109-Speed 140.31 samples/sec   Loss 1.2054   LearningRate 0.000023   Epoch: 0   Global Step: 20390   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:22:26,409-Speed 139.16 samples/sec   Loss 1.2126   LearningRate 0.000023   Epoch: 0   Global Step: 20400   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:22:28,710-Speed 139.11 samples/sec   Loss 1.1752   LearningRate 0.000023   Epoch: 0   Global Step: 20410   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:22:31,010-Speed 139.17 samples/sec   Loss 1.2162   LearningRate 0.000023   Epoch: 0   Global Step: 20420   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:22:33,298-Speed 139.87 samples/sec   Loss 1.1725   LearningRate 0.000023   Epoch: 0   Global Step: 20430   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:22:35,609-Speed 138.54 samples/sec   Loss 1.1913   LearningRate 0.000023   Epoch: 0   Global Step: 20440   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:22:37,912-Speed 139.00 samples/sec   Loss 1.2098   LearningRate 0.000023   Epoch: 0   Global Step: 20450   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:22:40,201-Speed 139.83 samples/sec   Loss 1.1700   LearningRate 0.000023   Epoch: 0   Global Step: 20460   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:22:42,488-Speed 139.93 samples/sec   Loss 1.1914   LearningRate 0.000023   Epoch: 0   Global Step: 20470   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:22:44,769-Speed 140.34 samples/sec   Loss 1.2266   LearningRate 0.000023   Epoch: 0   Global Step: 20480   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:22:47,055-Speed 140.04 samples/sec   Loss 1.2021   LearningRate 0.000023   Epoch: 0   Global Step: 20490   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:22:49,328-Speed 140.82 samples/sec   Loss 1.1797   LearningRate 0.000023   Epoch: 0   Global Step: 20500   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:22:51,610-Speed 140.24 samples/sec   Loss 1.1919   LearningRate 0.000023   Epoch: 0   Global Step: 20510   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:22:53,892-Speed 140.31 samples/sec   Loss 1.1910   LearningRate 0.000023   Epoch: 0   Global Step: 20520   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:22:56,188-Speed 139.40 samples/sec   Loss 1.2186   LearningRate 0.000023   Epoch: 0   Global Step: 20530   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:22:58,471-Speed 140.20 samples/sec   Loss 1.1825   LearningRate 0.000023   Epoch: 0   Global Step: 20540   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:23:00,768-Speed 139.32 samples/sec   Loss 1.1783   LearningRate 0.000023   Epoch: 0   Global Step: 20550   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:23:03,068-Speed 139.21 samples/sec   Loss 1.1919   LearningRate 0.000023   Epoch: 0   Global Step: 20560   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:23:05,359-Speed 139.68 samples/sec   Loss 1.1735   LearningRate 0.000023   Epoch: 0   Global Step: 20570   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:23:07,649-Speed 139.78 samples/sec   Loss 1.1954   LearningRate 0.000023   Epoch: 0   Global Step: 20580   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:23:09,955-Speed 138.84 samples/sec   Loss 1.1730   LearningRate 0.000023   Epoch: 0   Global Step: 20590   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:23:12,261-Speed 138.79 samples/sec   Loss 1.1937   LearningRate 0.000023   Epoch: 0   Global Step: 20600   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:23:14,543-Speed 140.28 samples/sec   Loss 1.2313   LearningRate 0.000023   Epoch: 0   Global Step: 20610   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:23:16,820-Speed 140.56 samples/sec   Loss 1.1770   LearningRate 0.000023   Epoch: 0   Global Step: 20620   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:23:19,122-Speed 139.09 samples/sec   Loss 1.2461   LearningRate 0.000023   Epoch: 0   Global Step: 20630   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:23:21,417-Speed 139.47 samples/sec   Loss 1.1623   LearningRate 0.000023   Epoch: 0   Global Step: 20640   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:23:23,706-Speed 139.82 samples/sec   Loss 1.1787   LearningRate 0.000023   Epoch: 0   Global Step: 20650   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:23:26,031-Speed 137.68 samples/sec   Loss 1.1913   LearningRate 0.000023   Epoch: 0   Global Step: 20660   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:23:28,350-Speed 138.03 samples/sec   Loss 1.2162   LearningRate 0.000023   Epoch: 0   Global Step: 20670   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:23:30,643-Speed 139.57 samples/sec   Loss 1.2217   LearningRate 0.000023   Epoch: 0   Global Step: 20680   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:23:32,952-Speed 138.61 samples/sec   Loss 1.1730   LearningRate 0.000023   Epoch: 0   Global Step: 20690   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:23:35,258-Speed 138.84 samples/sec   Loss 1.1833   LearningRate 0.000023   Epoch: 0   Global Step: 20700   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:23:37,552-Speed 139.52 samples/sec   Loss 1.1987   LearningRate 0.000023   Epoch: 0   Global Step: 20710   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:23:39,849-Speed 139.36 samples/sec   Loss 1.1990   LearningRate 0.000023   Epoch: 0   Global Step: 20720   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:23:42,147-Speed 139.31 samples/sec   Loss 1.2151   LearningRate 0.000023   Epoch: 0   Global Step: 20730   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:23:44,445-Speed 139.25 samples/sec   Loss 1.1698   LearningRate 0.000023   Epoch: 0   Global Step: 20740   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:23:46,748-Speed 139.02 samples/sec   Loss 1.2155   LearningRate 0.000023   Epoch: 0   Global Step: 20750   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:23:49,049-Speed 139.09 samples/sec   Loss 1.1873   LearningRate 0.000023   Epoch: 0   Global Step: 20760   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:23:51,354-Speed 138.84 samples/sec   Loss 1.2025   LearningRate 0.000023   Epoch: 0   Global Step: 20770   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:23:53,665-Speed 138.56 samples/sec   Loss 1.2144   LearningRate 0.000023   Epoch: 0   Global Step: 20780   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:23:55,977-Speed 138.44 samples/sec   Loss 1.2083   LearningRate 0.000023   Epoch: 0   Global Step: 20790   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:23:58,291-Speed 138.32 samples/sec   Loss 1.2154   LearningRate 0.000023   Epoch: 0   Global Step: 20800   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:24:00,600-Speed 138.63 samples/sec   Loss 1.1675   LearningRate 0.000023   Epoch: 0   Global Step: 20810   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:24:02,891-Speed 139.70 samples/sec   Loss 1.1966   LearningRate 0.000023   Epoch: 0   Global Step: 20820   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:24:05,191-Speed 139.16 samples/sec   Loss 1.1873   LearningRate 0.000023   Epoch: 0   Global Step: 20830   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:24:07,486-Speed 139.43 samples/sec   Loss 1.1937   LearningRate 0.000023   Epoch: 0   Global Step: 20840   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:24:09,762-Speed 140.66 samples/sec   Loss 1.2128   LearningRate 0.000023   Epoch: 0   Global Step: 20850   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:24:12,067-Speed 138.91 samples/sec   Loss 1.2281   LearningRate 0.000023   Epoch: 0   Global Step: 20860   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:24:14,374-Speed 138.69 samples/sec   Loss 1.1694   LearningRate 0.000023   Epoch: 0   Global Step: 20870   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:24:16,674-Speed 139.17 samples/sec   Loss 1.2175   LearningRate 0.000023   Epoch: 0   Global Step: 20880   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:24:18,964-Speed 139.81 samples/sec   Loss 1.1781   LearningRate 0.000023   Epoch: 0   Global Step: 20890   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:24:21,260-Speed 139.39 samples/sec   Loss 1.2095   LearningRate 0.000023   Epoch: 0   Global Step: 20900   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:24:23,551-Speed 139.72 samples/sec   Loss 1.1893   LearningRate 0.000023   Epoch: 0   Global Step: 20910   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:24:25,846-Speed 139.50 samples/sec   Loss 1.1957   LearningRate 0.000023   Epoch: 0   Global Step: 20920   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:24:28,117-Speed 140.92 samples/sec   Loss 1.1877   LearningRate 0.000023   Epoch: 0   Global Step: 20930   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:24:30,401-Speed 140.14 samples/sec   Loss 1.1812   LearningRate 0.000023   Epoch: 0   Global Step: 20940   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:24:32,688-Speed 139.95 samples/sec   Loss 1.1951   LearningRate 0.000023   Epoch: 0   Global Step: 20950   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:24:34,973-Speed 140.05 samples/sec   Loss 1.1853   LearningRate 0.000023   Epoch: 0   Global Step: 20960   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:24:37,264-Speed 139.72 samples/sec   Loss 1.1937   LearningRate 0.000023   Epoch: 0   Global Step: 20970   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:24:39,550-Speed 140.07 samples/sec   Loss 1.2201   LearningRate 0.000023   Epoch: 0   Global Step: 20980   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:24:41,842-Speed 139.62 samples/sec   Loss 1.2002   LearningRate 0.000023   Epoch: 0   Global Step: 20990   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:24:43,904-Val on RAF/AffectNet:
Training: 2023-08-17 22:24:44,015-Test: [0/48]	Time 0.111 (0.111)	Loss 0.7148 (0.7148)	Acc@1 81.250 (81.250)	Acc@5 96.875 (96.875)	Mem 5268MB
Training: 2023-08-17 22:24:45,087-Test: [10/48]	Time 0.105 (0.107)	Loss 0.5049 (0.5386)	Acc@1 90.625 (92.188)	Acc@5 100.000 (99.006)	Mem 5268MB
Training: 2023-08-17 22:24:46,164-Test: [20/48]	Time 0.108 (0.108)	Loss 0.4500 (0.5395)	Acc@1 98.438 (92.560)	Acc@5 98.438 (98.586)	Mem 5268MB
Training: 2023-08-17 22:24:47,230-Test: [30/48]	Time 0.107 (0.107)	Loss 0.6344 (0.5417)	Acc@1 92.188 (92.591)	Acc@5 95.312 (98.690)	Mem 5268MB
Training: 2023-08-17 22:24:48,292-Test: [40/48]	Time 0.106 (0.107)	Loss 0.5532 (0.5501)	Acc@1 93.750 (92.378)	Acc@5 98.438 (98.704)	Mem 5268MB
Training: 2023-08-17 22:24:49,036-[20999]Expression Loss: 0.56039
Training: 2023-08-17 22:24:49,037-[20999]Expression Acc@1: 91.78618
Training: 2023-08-17 22:24:49,037-[20999]Expression Acc@1-Highest: 92.47067
Training: 2023-08-17 22:24:49,037-[20999]Expression Acc@5: 98.72881
Training: 2023-08-17 22:24:49,037-[20999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 22:24:49,037-[20999]10 Times Expression Acc@1: 91.93286
Training: 2023-08-17 22:24:49,037-[20999]10 Times Expression Acc@1-Highest: 91.93286
Training: 2023-08-17 22:24:49,265-Speed 43.11 samples/sec   Loss 1.2053   LearningRate 0.000023   Epoch: 0   Global Step: 21000   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:24:51,537-Speed 140.89 samples/sec   Loss 1.2129   LearningRate 0.000023   Epoch: 0   Global Step: 21010   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:24:53,815-Speed 140.50 samples/sec   Loss 1.1778   LearningRate 0.000023   Epoch: 0   Global Step: 21020   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:24:56,107-Speed 139.67 samples/sec   Loss 1.1860   LearningRate 0.000023   Epoch: 0   Global Step: 21030   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:24:58,375-Speed 141.13 samples/sec   Loss 1.2324   LearningRate 0.000023   Epoch: 0   Global Step: 21040   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:25:00,647-Speed 140.88 samples/sec   Loss 1.1986   LearningRate 0.000023   Epoch: 0   Global Step: 21050   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:25:02,925-Speed 140.49 samples/sec   Loss 1.1820   LearningRate 0.000023   Epoch: 0   Global Step: 21060   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:25:05,194-Speed 141.07 samples/sec   Loss 1.1718   LearningRate 0.000023   Epoch: 0   Global Step: 21070   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:25:07,473-Speed 140.47 samples/sec   Loss 1.2052   LearningRate 0.000023   Epoch: 0   Global Step: 21080   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:25:09,740-Speed 141.18 samples/sec   Loss 1.2116   LearningRate 0.000023   Epoch: 0   Global Step: 21090   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:25:12,017-Speed 140.55 samples/sec   Loss 1.2012   LearningRate 0.000023   Epoch: 0   Global Step: 21100   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:25:14,299-Speed 140.29 samples/sec   Loss 1.2038   LearningRate 0.000023   Epoch: 0   Global Step: 21110   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:25:16,588-Speed 139.82 samples/sec   Loss 1.2093   LearningRate 0.000023   Epoch: 0   Global Step: 21120   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:25:18,876-Speed 139.88 samples/sec   Loss 1.1995   LearningRate 0.000023   Epoch: 0   Global Step: 21130   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:25:21,146-Speed 141.03 samples/sec   Loss 1.2213   LearningRate 0.000023   Epoch: 0   Global Step: 21140   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:25:23,421-Speed 140.72 samples/sec   Loss 1.2150   LearningRate 0.000023   Epoch: 0   Global Step: 21150   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:25:25,718-Speed 139.33 samples/sec   Loss 1.1847   LearningRate 0.000023   Epoch: 0   Global Step: 21160   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:25:28,013-Speed 139.46 samples/sec   Loss 1.1873   LearningRate 0.000023   Epoch: 0   Global Step: 21170   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:25:30,309-Speed 139.39 samples/sec   Loss 1.1870   LearningRate 0.000023   Epoch: 0   Global Step: 21180   Fp16 Grad Scale: 16384   Required: 3 hours
Training: 2023-08-17 22:25:32,595-Speed 140.06 samples/sec   Loss 1.1977   LearningRate 0.000023   Epoch: 0   Global Step: 21190   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:25:34,874-Speed 140.45 samples/sec   Loss 1.2042   LearningRate 0.000023   Epoch: 0   Global Step: 21200   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:25:37,168-Speed 139.54 samples/sec   Loss 1.2041   LearningRate 0.000023   Epoch: 0   Global Step: 21210   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:25:39,442-Speed 140.73 samples/sec   Loss 1.1981   LearningRate 0.000023   Epoch: 0   Global Step: 21220   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:25:41,725-Speed 140.21 samples/sec   Loss 1.1979   LearningRate 0.000023   Epoch: 0   Global Step: 21230   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:25:44,010-Speed 140.08 samples/sec   Loss 1.1971   LearningRate 0.000023   Epoch: 0   Global Step: 21240   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:25:46,291-Speed 140.32 samples/sec   Loss 1.2149   LearningRate 0.000023   Epoch: 0   Global Step: 21250   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:25:48,569-Speed 140.50 samples/sec   Loss 1.1748   LearningRate 0.000023   Epoch: 0   Global Step: 21260   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:25:50,860-Speed 139.74 samples/sec   Loss 1.1788   LearningRate 0.000023   Epoch: 0   Global Step: 21270   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:25:53,142-Speed 140.26 samples/sec   Loss 1.2091   LearningRate 0.000023   Epoch: 0   Global Step: 21280   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:25:55,416-Speed 140.77 samples/sec   Loss 1.2100   LearningRate 0.000023   Epoch: 0   Global Step: 21290   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:25:57,695-Speed 140.39 samples/sec   Loss 1.1794   LearningRate 0.000023   Epoch: 0   Global Step: 21300   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:25:59,973-Speed 140.52 samples/sec   Loss 1.2040   LearningRate 0.000023   Epoch: 0   Global Step: 21310   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:26:02,263-Speed 139.77 samples/sec   Loss 1.2045   LearningRate 0.000023   Epoch: 0   Global Step: 21320   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:26:04,544-Speed 140.35 samples/sec   Loss 1.2111   LearningRate 0.000023   Epoch: 0   Global Step: 21330   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:26:06,827-Speed 140.20 samples/sec   Loss 1.2046   LearningRate 0.000023   Epoch: 0   Global Step: 21340   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:26:09,104-Speed 140.56 samples/sec   Loss 1.2070   LearningRate 0.000023   Epoch: 0   Global Step: 21350   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:26:11,367-Speed 141.46 samples/sec   Loss 1.2058   LearningRate 0.000023   Epoch: 0   Global Step: 21360   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:26:13,649-Speed 140.27 samples/sec   Loss 1.1889   LearningRate 0.000023   Epoch: 0   Global Step: 21370   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:26:15,934-Speed 140.09 samples/sec   Loss 1.1789   LearningRate 0.000023   Epoch: 0   Global Step: 21380   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:26:18,241-Speed 138.71 samples/sec   Loss 1.2154   LearningRate 0.000023   Epoch: 0   Global Step: 21390   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:26:20,539-Speed 139.27 samples/sec   Loss 1.2062   LearningRate 0.000023   Epoch: 0   Global Step: 21400   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:26:22,832-Speed 139.62 samples/sec   Loss 1.2064   LearningRate 0.000023   Epoch: 0   Global Step: 21410   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:26:25,125-Speed 139.62 samples/sec   Loss 1.1735   LearningRate 0.000022   Epoch: 0   Global Step: 21420   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:26:27,417-Speed 139.61 samples/sec   Loss 1.2096   LearningRate 0.000022   Epoch: 0   Global Step: 21430   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:26:29,711-Speed 139.59 samples/sec   Loss 1.2248   LearningRate 0.000022   Epoch: 0   Global Step: 21440   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:26:32,037-Speed 137.58 samples/sec   Loss 1.1803   LearningRate 0.000022   Epoch: 0   Global Step: 21450   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:26:34,360-Speed 137.78 samples/sec   Loss 1.2062   LearningRate 0.000022   Epoch: 0   Global Step: 21460   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:26:36,668-Speed 138.69 samples/sec   Loss 1.1632   LearningRate 0.000022   Epoch: 0   Global Step: 21470   Fp16 Grad Scale: 65536   Required: 3 hours
Training: 2023-08-17 22:26:38,973-Speed 138.89 samples/sec   Loss 1.2174   LearningRate 0.000022   Epoch: 0   Global Step: 21480   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:26:41,288-Speed 138.22 samples/sec   Loss 1.1719   LearningRate 0.000022   Epoch: 0   Global Step: 21490   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:26:43,608-Speed 137.94 samples/sec   Loss 1.2005   LearningRate 0.000022   Epoch: 0   Global Step: 21500   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:26:45,929-Speed 137.95 samples/sec   Loss 1.1876   LearningRate 0.000022   Epoch: 0   Global Step: 21510   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:26:48,254-Speed 137.68 samples/sec   Loss 1.1719   LearningRate 0.000022   Epoch: 0   Global Step: 21520   Fp16 Grad Scale: 32768   Required: 3 hours
Training: 2023-08-17 22:26:50,594-Speed 136.74 samples/sec   Loss 1.1976   LearningRate 0.000022   Epoch: 0   Global Step: 21530   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:26:52,906-Speed 138.47 samples/sec   Loss 1.1772   LearningRate 0.000022   Epoch: 0   Global Step: 21540   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:26:55,232-Speed 137.62 samples/sec   Loss 1.1905   LearningRate 0.000022   Epoch: 0   Global Step: 21550   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:26:57,553-Speed 137.92 samples/sec   Loss 1.2192   LearningRate 0.000022   Epoch: 0   Global Step: 21560   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:26:59,876-Speed 137.78 samples/sec   Loss 1.1981   LearningRate 0.000022   Epoch: 0   Global Step: 21570   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:27:02,200-Speed 137.76 samples/sec   Loss 1.2134   LearningRate 0.000022   Epoch: 0   Global Step: 21580   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:27:04,493-Speed 139.56 samples/sec   Loss 1.2191   LearningRate 0.000022   Epoch: 0   Global Step: 21590   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:27:06,822-Speed 137.46 samples/sec   Loss 1.2154   LearningRate 0.000022   Epoch: 0   Global Step: 21600   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:27:09,141-Speed 138.05 samples/sec   Loss 1.2092   LearningRate 0.000022   Epoch: 0   Global Step: 21610   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:27:11,457-Speed 138.19 samples/sec   Loss 1.2178   LearningRate 0.000022   Epoch: 0   Global Step: 21620   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:27:13,768-Speed 138.52 samples/sec   Loss 1.1891   LearningRate 0.000022   Epoch: 0   Global Step: 21630   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:27:16,072-Speed 138.91 samples/sec   Loss 1.1998   LearningRate 0.000022   Epoch: 0   Global Step: 21640   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:27:18,367-Speed 139.48 samples/sec   Loss 1.1843   LearningRate 0.000022   Epoch: 0   Global Step: 21650   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:27:20,651-Speed 140.10 samples/sec   Loss 1.1843   LearningRate 0.000022   Epoch: 0   Global Step: 21660   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:27:22,943-Speed 139.69 samples/sec   Loss 1.1867   LearningRate 0.000022   Epoch: 0   Global Step: 21670   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:27:25,254-Speed 138.48 samples/sec   Loss 1.1583   LearningRate 0.000022   Epoch: 0   Global Step: 21680   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:27:27,549-Speed 139.49 samples/sec   Loss 1.2181   LearningRate 0.000022   Epoch: 0   Global Step: 21690   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:27:29,872-Speed 137.77 samples/sec   Loss 1.1819   LearningRate 0.000022   Epoch: 0   Global Step: 21700   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:27:32,199-Speed 137.53 samples/sec   Loss 1.2359   LearningRate 0.000022   Epoch: 0   Global Step: 21710   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:27:34,525-Speed 137.66 samples/sec   Loss 1.1980   LearningRate 0.000022   Epoch: 0   Global Step: 21720   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:27:36,834-Speed 138.59 samples/sec   Loss 1.1979   LearningRate 0.000022   Epoch: 0   Global Step: 21730   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:27:39,157-Speed 137.79 samples/sec   Loss 1.1860   LearningRate 0.000022   Epoch: 0   Global Step: 21740   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:27:41,480-Speed 137.79 samples/sec   Loss 1.1981   LearningRate 0.000022   Epoch: 0   Global Step: 21750   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:27:43,797-Speed 138.18 samples/sec   Loss 1.1576   LearningRate 0.000022   Epoch: 0   Global Step: 21760   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:27:46,108-Speed 138.47 samples/sec   Loss 1.1926   LearningRate 0.000022   Epoch: 0   Global Step: 21770   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:27:48,424-Speed 138.24 samples/sec   Loss 1.1832   LearningRate 0.000022   Epoch: 0   Global Step: 21780   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:27:50,737-Speed 138.40 samples/sec   Loss 1.2039   LearningRate 0.000022   Epoch: 0   Global Step: 21790   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:27:53,059-Speed 137.81 samples/sec   Loss 1.2028   LearningRate 0.000022   Epoch: 0   Global Step: 21800   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:27:55,368-Speed 138.67 samples/sec   Loss 1.1924   LearningRate 0.000022   Epoch: 0   Global Step: 21810   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:27:57,673-Speed 138.83 samples/sec   Loss 1.1807   LearningRate 0.000022   Epoch: 0   Global Step: 21820   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:27:59,988-Speed 138.27 samples/sec   Loss 1.1772   LearningRate 0.000022   Epoch: 0   Global Step: 21830   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:28:02,309-Speed 137.94 samples/sec   Loss 1.1990   LearningRate 0.000022   Epoch: 0   Global Step: 21840   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:28:04,637-Speed 137.45 samples/sec   Loss 1.1665   LearningRate 0.000022   Epoch: 0   Global Step: 21850   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:28:06,920-Speed 140.21 samples/sec   Loss 1.1982   LearningRate 0.000022   Epoch: 0   Global Step: 21860   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:28:09,197-Speed 140.61 samples/sec   Loss 1.1943   LearningRate 0.000022   Epoch: 0   Global Step: 21870   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:28:11,483-Speed 140.00 samples/sec   Loss 1.1993   LearningRate 0.000022   Epoch: 0   Global Step: 21880   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:28:13,769-Speed 140.07 samples/sec   Loss 1.1889   LearningRate 0.000022   Epoch: 0   Global Step: 21890   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:28:16,054-Speed 140.08 samples/sec   Loss 1.1704   LearningRate 0.000022   Epoch: 0   Global Step: 21900   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:28:18,336-Speed 140.22 samples/sec   Loss 1.2139   LearningRate 0.000022   Epoch: 0   Global Step: 21910   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:28:20,620-Speed 140.16 samples/sec   Loss 1.1422   LearningRate 0.000022   Epoch: 0   Global Step: 21920   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:28:22,909-Speed 139.83 samples/sec   Loss 1.2113   LearningRate 0.000022   Epoch: 0   Global Step: 21930   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:28:25,199-Speed 139.80 samples/sec   Loss 1.2101   LearningRate 0.000022   Epoch: 0   Global Step: 21940   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:28:27,487-Speed 139.88 samples/sec   Loss 1.1793   LearningRate 0.000022   Epoch: 0   Global Step: 21950   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:28:29,771-Speed 140.18 samples/sec   Loss 1.1937   LearningRate 0.000022   Epoch: 0   Global Step: 21960   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:28:32,071-Speed 139.13 samples/sec   Loss 1.2154   LearningRate 0.000022   Epoch: 0   Global Step: 21970   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:28:34,376-Speed 138.90 samples/sec   Loss 1.1668   LearningRate 0.000022   Epoch: 0   Global Step: 21980   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:28:36,662-Speed 140.03 samples/sec   Loss 1.2099   LearningRate 0.000022   Epoch: 0   Global Step: 21990   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:28:38,738-Val on RAF/AffectNet:
Training: 2023-08-17 22:28:38,861-Test: [0/48]	Time 0.123 (0.123)	Loss 0.4880 (0.4880)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-17 22:28:39,960-Test: [10/48]	Time 0.109 (0.111)	Loss 0.7406 (0.5544)	Acc@1 85.938 (91.761)	Acc@5 95.312 (98.864)	Mem 5268MB
Training: 2023-08-17 22:28:41,026-Test: [20/48]	Time 0.106 (0.109)	Loss 0.5112 (0.5596)	Acc@1 93.750 (91.667)	Acc@5 100.000 (98.884)	Mem 5268MB
Training: 2023-08-17 22:28:42,090-Test: [30/48]	Time 0.105 (0.108)	Loss 0.6123 (0.5591)	Acc@1 87.500 (91.583)	Acc@5 100.000 (98.891)	Mem 5268MB
Training: 2023-08-17 22:28:43,159-Test: [40/48]	Time 0.110 (0.108)	Loss 0.6869 (0.5632)	Acc@1 85.938 (91.502)	Acc@5 98.438 (98.819)	Mem 5268MB
Training: 2023-08-17 22:28:43,912-[21999]Expression Loss: 0.55936
Training: 2023-08-17 22:28:43,912-[21999]Expression Acc@1: 91.59061
Training: 2023-08-17 22:28:43,912-[21999]Expression Acc@1-Highest: 92.47067
Training: 2023-08-17 22:28:43,912-[21999]Expression Acc@5: 98.95698
Training: 2023-08-17 22:28:43,912-[21999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 22:28:43,912-[21999]10 Times Expression Acc@1: 91.93937
Training: 2023-08-17 22:28:43,912-[21999]10 Times Expression Acc@1-Highest: 91.93937
Training: 2023-08-17 22:28:44,142-Speed 42.78 samples/sec   Loss 1.1699   LearningRate 0.000022   Epoch: 0   Global Step: 22000   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:28:46,412-Speed 141.05 samples/sec   Loss 1.2049   LearningRate 0.000022   Epoch: 0   Global Step: 22010   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:28:48,704-Speed 139.60 samples/sec   Loss 1.2069   LearningRate 0.000022   Epoch: 0   Global Step: 22020   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:28:50,995-Speed 139.76 samples/sec   Loss 1.1956   LearningRate 0.000022   Epoch: 0   Global Step: 22030   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:28:53,273-Speed 140.47 samples/sec   Loss 1.1775   LearningRate 0.000022   Epoch: 0   Global Step: 22040   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:28:55,572-Speed 139.26 samples/sec   Loss 1.2246   LearningRate 0.000022   Epoch: 0   Global Step: 22050   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:28:57,872-Speed 139.13 samples/sec   Loss 1.2025   LearningRate 0.000022   Epoch: 0   Global Step: 22060   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:29:00,163-Speed 139.73 samples/sec   Loss 1.2123   LearningRate 0.000022   Epoch: 0   Global Step: 22070   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:29:02,462-Speed 139.23 samples/sec   Loss 1.1943   LearningRate 0.000022   Epoch: 0   Global Step: 22080   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:29:04,763-Speed 139.13 samples/sec   Loss 1.1623   LearningRate 0.000022   Epoch: 0   Global Step: 22090   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:29:07,056-Speed 139.57 samples/sec   Loss 1.1960   LearningRate 0.000022   Epoch: 0   Global Step: 22100   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:29:09,352-Speed 139.41 samples/sec   Loss 1.1713   LearningRate 0.000022   Epoch: 0   Global Step: 22110   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:29:11,645-Speed 139.64 samples/sec   Loss 1.1976   LearningRate 0.000022   Epoch: 0   Global Step: 22120   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:29:13,954-Speed 138.62 samples/sec   Loss 1.1633   LearningRate 0.000022   Epoch: 0   Global Step: 22130   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:29:16,239-Speed 140.08 samples/sec   Loss 1.1815   LearningRate 0.000022   Epoch: 0   Global Step: 22140   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:29:18,541-Speed 139.04 samples/sec   Loss 1.1761   LearningRate 0.000022   Epoch: 0   Global Step: 22150   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:29:20,849-Speed 138.65 samples/sec   Loss 1.2013   LearningRate 0.000022   Epoch: 0   Global Step: 22160   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:29:23,156-Speed 138.77 samples/sec   Loss 1.2033   LearningRate 0.000022   Epoch: 0   Global Step: 22170   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:29:25,462-Speed 138.84 samples/sec   Loss 1.1758   LearningRate 0.000022   Epoch: 0   Global Step: 22180   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:29:27,751-Speed 139.80 samples/sec   Loss 1.2174   LearningRate 0.000022   Epoch: 0   Global Step: 22190   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:29:30,050-Speed 139.20 samples/sec   Loss 1.1666   LearningRate 0.000022   Epoch: 0   Global Step: 22200   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:29:32,343-Speed 139.62 samples/sec   Loss 1.1886   LearningRate 0.000022   Epoch: 0   Global Step: 22210   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:29:34,645-Speed 139.02 samples/sec   Loss 1.1660   LearningRate 0.000022   Epoch: 0   Global Step: 22220   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:29:36,943-Speed 139.30 samples/sec   Loss 1.2210   LearningRate 0.000022   Epoch: 0   Global Step: 22230   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:29:39,235-Speed 139.65 samples/sec   Loss 1.2164   LearningRate 0.000022   Epoch: 0   Global Step: 22240   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:29:41,525-Speed 139.75 samples/sec   Loss 1.2082   LearningRate 0.000022   Epoch: 0   Global Step: 22250   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:29:43,831-Speed 138.79 samples/sec   Loss 1.1637   LearningRate 0.000022   Epoch: 0   Global Step: 22260   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:29:46,135-Speed 138.93 samples/sec   Loss 1.1626   LearningRate 0.000022   Epoch: 0   Global Step: 22270   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:29:48,412-Speed 140.60 samples/sec   Loss 1.2191   LearningRate 0.000022   Epoch: 0   Global Step: 22280   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:29:50,695-Speed 140.22 samples/sec   Loss 1.1995   LearningRate 0.000022   Epoch: 0   Global Step: 22290   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:29:52,994-Speed 139.20 samples/sec   Loss 1.1806   LearningRate 0.000022   Epoch: 0   Global Step: 22300   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:29:55,284-Speed 139.78 samples/sec   Loss 1.1706   LearningRate 0.000022   Epoch: 0   Global Step: 22310   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:29:57,590-Speed 138.82 samples/sec   Loss 1.1909   LearningRate 0.000022   Epoch: 0   Global Step: 22320   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:29:59,892-Speed 139.05 samples/sec   Loss 1.1853   LearningRate 0.000022   Epoch: 0   Global Step: 22330   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:30:02,189-Speed 139.35 samples/sec   Loss 1.1652   LearningRate 0.000022   Epoch: 0   Global Step: 22340   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:30:04,492-Speed 138.97 samples/sec   Loss 1.1778   LearningRate 0.000022   Epoch: 0   Global Step: 22350   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:30:06,811-Speed 138.07 samples/sec   Loss 1.1788   LearningRate 0.000022   Epoch: 0   Global Step: 22360   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:30:09,099-Speed 139.86 samples/sec   Loss 1.1748   LearningRate 0.000022   Epoch: 0   Global Step: 22370   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:30:11,428-Speed 137.44 samples/sec   Loss 1.1958   LearningRate 0.000022   Epoch: 0   Global Step: 22380   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:30:13,710-Speed 140.27 samples/sec   Loss 1.1970   LearningRate 0.000022   Epoch: 0   Global Step: 22390   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:30:16,003-Speed 139.64 samples/sec   Loss 1.2042   LearningRate 0.000022   Epoch: 0   Global Step: 22400   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:30:18,293-Speed 139.73 samples/sec   Loss 1.1318   LearningRate 0.000022   Epoch: 0   Global Step: 22410   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:30:20,590-Speed 139.38 samples/sec   Loss 1.1681   LearningRate 0.000022   Epoch: 0   Global Step: 22420   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:30:22,878-Speed 139.90 samples/sec   Loss 1.1651   LearningRate 0.000022   Epoch: 0   Global Step: 22430   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:30:25,186-Speed 138.65 samples/sec   Loss 1.1967   LearningRate 0.000022   Epoch: 0   Global Step: 22440   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:30:27,489-Speed 139.00 samples/sec   Loss 1.2308   LearningRate 0.000022   Epoch: 0   Global Step: 22450   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:30:29,817-Speed 137.49 samples/sec   Loss 1.2001   LearningRate 0.000022   Epoch: 0   Global Step: 22460   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:30:32,111-Speed 139.55 samples/sec   Loss 1.1850   LearningRate 0.000022   Epoch: 0   Global Step: 22470   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:30:34,412-Speed 139.10 samples/sec   Loss 1.1564   LearningRate 0.000022   Epoch: 0   Global Step: 22480   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:30:36,729-Speed 138.15 samples/sec   Loss 1.2078   LearningRate 0.000022   Epoch: 0   Global Step: 22490   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:30:39,039-Speed 138.56 samples/sec   Loss 1.1668   LearningRate 0.000022   Epoch: 0   Global Step: 22500   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:30:41,326-Speed 139.99 samples/sec   Loss 1.1912   LearningRate 0.000022   Epoch: 0   Global Step: 22510   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:30:43,620-Speed 139.53 samples/sec   Loss 1.1974   LearningRate 0.000022   Epoch: 0   Global Step: 22520   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:30:45,922-Speed 139.03 samples/sec   Loss 1.2020   LearningRate 0.000022   Epoch: 0   Global Step: 22530   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:30:48,222-Speed 139.16 samples/sec   Loss 1.1877   LearningRate 0.000022   Epoch: 0   Global Step: 22540   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:30:50,525-Speed 139.02 samples/sec   Loss 1.1940   LearningRate 0.000022   Epoch: 0   Global Step: 22550   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:30:52,838-Speed 138.41 samples/sec   Loss 1.1778   LearningRate 0.000022   Epoch: 0   Global Step: 22560   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:30:55,138-Speed 139.12 samples/sec   Loss 1.2038   LearningRate 0.000022   Epoch: 0   Global Step: 22570   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:30:57,436-Speed 139.30 samples/sec   Loss 1.1478   LearningRate 0.000022   Epoch: 0   Global Step: 22580   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:30:59,748-Speed 138.46 samples/sec   Loss 1.1929   LearningRate 0.000022   Epoch: 0   Global Step: 22590   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:31:02,045-Speed 139.36 samples/sec   Loss 1.1932   LearningRate 0.000022   Epoch: 0   Global Step: 22600   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:31:04,343-Speed 139.29 samples/sec   Loss 1.1967   LearningRate 0.000022   Epoch: 0   Global Step: 22610   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:31:06,635-Speed 139.68 samples/sec   Loss 1.1758   LearningRate 0.000022   Epoch: 0   Global Step: 22620   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:31:08,922-Speed 139.94 samples/sec   Loss 1.2067   LearningRate 0.000022   Epoch: 0   Global Step: 22630   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:31:11,237-Speed 138.26 samples/sec   Loss 1.1925   LearningRate 0.000022   Epoch: 0   Global Step: 22640   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:31:13,545-Speed 138.64 samples/sec   Loss 1.2235   LearningRate 0.000022   Epoch: 0   Global Step: 22650   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:31:15,860-Speed 138.34 samples/sec   Loss 1.1927   LearningRate 0.000022   Epoch: 0   Global Step: 22660   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:31:18,164-Speed 138.92 samples/sec   Loss 1.1645   LearningRate 0.000022   Epoch: 0   Global Step: 22670   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:31:20,464-Speed 139.16 samples/sec   Loss 1.1490   LearningRate 0.000022   Epoch: 0   Global Step: 22680   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:31:22,760-Speed 139.37 samples/sec   Loss 1.1846   LearningRate 0.000022   Epoch: 0   Global Step: 22690   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:31:25,070-Speed 138.57 samples/sec   Loss 1.1510   LearningRate 0.000022   Epoch: 0   Global Step: 22700   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:31:27,373-Speed 138.98 samples/sec   Loss 1.1830   LearningRate 0.000022   Epoch: 0   Global Step: 22710   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:31:29,678-Speed 138.89 samples/sec   Loss 1.2054   LearningRate 0.000022   Epoch: 0   Global Step: 22720   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:31:31,979-Speed 139.15 samples/sec   Loss 1.1805   LearningRate 0.000022   Epoch: 0   Global Step: 22730   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:31:34,283-Speed 138.87 samples/sec   Loss 1.1935   LearningRate 0.000022   Epoch: 0   Global Step: 22740   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:31:36,582-Speed 139.25 samples/sec   Loss 1.2111   LearningRate 0.000022   Epoch: 0   Global Step: 22750   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:31:38,886-Speed 138.95 samples/sec   Loss 1.1963   LearningRate 0.000022   Epoch: 0   Global Step: 22760   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:31:41,184-Speed 139.30 samples/sec   Loss 1.1766   LearningRate 0.000021   Epoch: 0   Global Step: 22770   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:31:43,513-Speed 137.45 samples/sec   Loss 1.1889   LearningRate 0.000021   Epoch: 0   Global Step: 22780   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:31:45,828-Speed 138.25 samples/sec   Loss 1.1891   LearningRate 0.000021   Epoch: 0   Global Step: 22790   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:31:48,142-Speed 138.33 samples/sec   Loss 1.1960   LearningRate 0.000021   Epoch: 0   Global Step: 22800   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:31:50,442-Speed 139.17 samples/sec   Loss 1.2027   LearningRate 0.000021   Epoch: 0   Global Step: 22810   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:31:52,758-Speed 138.22 samples/sec   Loss 1.1795   LearningRate 0.000021   Epoch: 0   Global Step: 22820   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:31:55,054-Speed 139.38 samples/sec   Loss 1.1850   LearningRate 0.000021   Epoch: 0   Global Step: 22830   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:31:57,351-Speed 139.40 samples/sec   Loss 1.1976   LearningRate 0.000021   Epoch: 0   Global Step: 22840   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:31:59,662-Speed 138.50 samples/sec   Loss 1.2033   LearningRate 0.000021   Epoch: 0   Global Step: 22850   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:32:01,936-Speed 140.73 samples/sec   Loss 1.1695   LearningRate 0.000021   Epoch: 0   Global Step: 22860   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:32:04,213-Speed 140.58 samples/sec   Loss 1.1909   LearningRate 0.000021   Epoch: 0   Global Step: 22870   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:32:06,487-Speed 140.76 samples/sec   Loss 1.2080   LearningRate 0.000021   Epoch: 0   Global Step: 22880   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:32:08,771-Speed 140.14 samples/sec   Loss 1.1503   LearningRate 0.000021   Epoch: 0   Global Step: 22890   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:32:11,052-Speed 140.34 samples/sec   Loss 1.1918   LearningRate 0.000021   Epoch: 0   Global Step: 22900   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:32:13,335-Speed 140.24 samples/sec   Loss 1.1571   LearningRate 0.000021   Epoch: 0   Global Step: 22910   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:32:15,610-Speed 140.65 samples/sec   Loss 1.1811   LearningRate 0.000021   Epoch: 0   Global Step: 22920   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:32:17,889-Speed 140.48 samples/sec   Loss 1.1621   LearningRate 0.000021   Epoch: 0   Global Step: 22930   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:32:20,167-Speed 140.53 samples/sec   Loss 1.1909   LearningRate 0.000021   Epoch: 0   Global Step: 22940   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:32:22,456-Speed 139.79 samples/sec   Loss 1.2007   LearningRate 0.000021   Epoch: 0   Global Step: 22950   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:32:24,735-Speed 140.51 samples/sec   Loss 1.1853   LearningRate 0.000021   Epoch: 0   Global Step: 22960   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:32:27,015-Speed 140.36 samples/sec   Loss 1.1909   LearningRate 0.000021   Epoch: 0   Global Step: 22970   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:32:29,305-Speed 139.80 samples/sec   Loss 1.1943   LearningRate 0.000021   Epoch: 0   Global Step: 22980   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:32:31,591-Speed 140.03 samples/sec   Loss 1.1580   LearningRate 0.000021   Epoch: 0   Global Step: 22990   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:32:33,645-Val on RAF/AffectNet:
Training: 2023-08-17 22:32:33,754-Test: [0/48]	Time 0.109 (0.109)	Loss 0.5977 (0.5977)	Acc@1 85.938 (85.938)	Acc@5 98.438 (98.438)	Mem 5268MB
Training: 2023-08-17 22:32:34,841-Test: [10/48]	Time 0.107 (0.109)	Loss 0.5831 (0.5328)	Acc@1 89.062 (92.045)	Acc@5 98.438 (99.006)	Mem 5268MB
Training: 2023-08-17 22:32:35,912-Test: [20/48]	Time 0.107 (0.108)	Loss 0.5878 (0.5509)	Acc@1 87.500 (91.443)	Acc@5 100.000 (98.884)	Mem 5268MB
Training: 2023-08-17 22:32:36,988-Test: [30/48]	Time 0.105 (0.108)	Loss 0.4891 (0.5500)	Acc@1 93.750 (91.633)	Acc@5 100.000 (98.891)	Mem 5268MB
Training: 2023-08-17 22:32:38,088-Test: [40/48]	Time 0.114 (0.108)	Loss 0.5180 (0.5433)	Acc@1 89.062 (91.921)	Acc@5 100.000 (98.857)	Mem 5268MB
Training: 2023-08-17 22:32:38,835-[22999]Expression Loss: 0.54242
Training: 2023-08-17 22:32:38,835-[22999]Expression Acc@1: 91.75359
Training: 2023-08-17 22:32:38,835-[22999]Expression Acc@1-Highest: 92.47067
Training: 2023-08-17 22:32:38,835-[22999]Expression Acc@5: 98.85919
Training: 2023-08-17 22:32:38,835-[22999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 22:32:38,835-[22999]10 Times Expression Acc@1: 91.91982
Training: 2023-08-17 22:32:38,835-[22999]10 Times Expression Acc@1-Highest: 91.93937
Training: 2023-08-17 22:32:39,062-Speed 42.83 samples/sec   Loss 1.1749   LearningRate 0.000021   Epoch: 0   Global Step: 23000   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:32:41,317-Speed 141.94 samples/sec   Loss 1.1934   LearningRate 0.000021   Epoch: 0   Global Step: 23010   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:32:43,604-Speed 140.00 samples/sec   Loss 1.2090   LearningRate 0.000021   Epoch: 0   Global Step: 23020   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:32:45,894-Speed 139.77 samples/sec   Loss 1.2294   LearningRate 0.000021   Epoch: 0   Global Step: 23030   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:32:48,173-Speed 140.47 samples/sec   Loss 1.1772   LearningRate 0.000021   Epoch: 0   Global Step: 23040   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:32:50,463-Speed 139.78 samples/sec   Loss 1.1939   LearningRate 0.000021   Epoch: 0   Global Step: 23050   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:32:52,743-Speed 140.38 samples/sec   Loss 1.1814   LearningRate 0.000021   Epoch: 0   Global Step: 23060   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:32:55,030-Speed 139.95 samples/sec   Loss 1.1462   LearningRate 0.000021   Epoch: 0   Global Step: 23070   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:32:57,303-Speed 140.85 samples/sec   Loss 1.2168   LearningRate 0.000021   Epoch: 0   Global Step: 23080   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:32:59,583-Speed 140.39 samples/sec   Loss 1.2120   LearningRate 0.000021   Epoch: 0   Global Step: 23090   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:33:01,862-Speed 140.41 samples/sec   Loss 1.1900   LearningRate 0.000021   Epoch: 0   Global Step: 23100   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:33:04,151-Speed 139.85 samples/sec   Loss 1.1997   LearningRate 0.000021   Epoch: 0   Global Step: 23110   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:33:06,440-Speed 139.84 samples/sec   Loss 1.1559   LearningRate 0.000021   Epoch: 0   Global Step: 23120   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:33:08,741-Speed 139.13 samples/sec   Loss 1.1719   LearningRate 0.000021   Epoch: 0   Global Step: 23130   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:33:11,025-Speed 140.10 samples/sec   Loss 1.1755   LearningRate 0.000021   Epoch: 0   Global Step: 23140   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:33:13,313-Speed 139.90 samples/sec   Loss 1.1981   LearningRate 0.000021   Epoch: 0   Global Step: 23150   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:33:15,598-Speed 140.08 samples/sec   Loss 1.1798   LearningRate 0.000021   Epoch: 0   Global Step: 23160   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:33:17,884-Speed 140.05 samples/sec   Loss 1.1547   LearningRate 0.000021   Epoch: 0   Global Step: 23170   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:33:20,154-Speed 140.99 samples/sec   Loss 1.1709   LearningRate 0.000021   Epoch: 0   Global Step: 23180   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:33:22,458-Speed 138.95 samples/sec   Loss 1.2154   LearningRate 0.000021   Epoch: 0   Global Step: 23190   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:33:24,759-Speed 139.11 samples/sec   Loss 1.2066   LearningRate 0.000021   Epoch: 0   Global Step: 23200   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:33:27,054-Speed 139.48 samples/sec   Loss 1.1878   LearningRate 0.000021   Epoch: 0   Global Step: 23210   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:33:29,344-Speed 139.75 samples/sec   Loss 1.2266   LearningRate 0.000021   Epoch: 0   Global Step: 23220   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:33:31,644-Speed 139.20 samples/sec   Loss 1.2181   LearningRate 0.000021   Epoch: 0   Global Step: 23230   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:33:33,925-Speed 140.29 samples/sec   Loss 1.2291   LearningRate 0.000021   Epoch: 0   Global Step: 23240   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:33:36,207-Speed 140.27 samples/sec   Loss 1.1801   LearningRate 0.000021   Epoch: 0   Global Step: 23250   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:33:38,503-Speed 139.43 samples/sec   Loss 1.1978   LearningRate 0.000021   Epoch: 0   Global Step: 23260   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:33:40,784-Speed 140.33 samples/sec   Loss 1.1587   LearningRate 0.000021   Epoch: 0   Global Step: 23270   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:33:43,067-Speed 140.19 samples/sec   Loss 1.1725   LearningRate 0.000021   Epoch: 0   Global Step: 23280   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:33:45,342-Speed 140.67 samples/sec   Loss 1.2028   LearningRate 0.000021   Epoch: 0   Global Step: 23290   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:33:47,626-Speed 140.17 samples/sec   Loss 1.1954   LearningRate 0.000021   Epoch: 0   Global Step: 23300   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:33:49,914-Speed 139.91 samples/sec   Loss 1.1774   LearningRate 0.000021   Epoch: 0   Global Step: 23310   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:33:52,192-Speed 140.49 samples/sec   Loss 1.2196   LearningRate 0.000021   Epoch: 0   Global Step: 23320   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:33:54,473-Speed 140.37 samples/sec   Loss 1.1611   LearningRate 0.000021   Epoch: 0   Global Step: 23330   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:33:56,757-Speed 140.13 samples/sec   Loss 1.2003   LearningRate 0.000021   Epoch: 0   Global Step: 23340   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:33:59,049-Speed 139.63 samples/sec   Loss 1.1952   LearningRate 0.000021   Epoch: 0   Global Step: 23350   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:34:01,326-Speed 140.58 samples/sec   Loss 1.1644   LearningRate 0.000021   Epoch: 0   Global Step: 23360   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:34:03,602-Speed 140.63 samples/sec   Loss 1.2027   LearningRate 0.000021   Epoch: 0   Global Step: 23370   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:34:05,895-Speed 139.59 samples/sec   Loss 1.1785   LearningRate 0.000021   Epoch: 0   Global Step: 23380   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:34:08,188-Speed 139.62 samples/sec   Loss 1.1863   LearningRate 0.000021   Epoch: 0   Global Step: 23390   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:34:10,457-Speed 141.09 samples/sec   Loss 1.1720   LearningRate 0.000021   Epoch: 0   Global Step: 23400   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:34:12,730-Speed 140.80 samples/sec   Loss 1.2026   LearningRate 0.000021   Epoch: 0   Global Step: 23410   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:34:15,011-Speed 140.37 samples/sec   Loss 1.1934   LearningRate 0.000021   Epoch: 0   Global Step: 23420   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:34:17,308-Speed 139.34 samples/sec   Loss 1.1646   LearningRate 0.000021   Epoch: 0   Global Step: 23430   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:34:19,591-Speed 140.19 samples/sec   Loss 1.1828   LearningRate 0.000021   Epoch: 0   Global Step: 23440   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:34:21,890-Speed 139.26 samples/sec   Loss 1.1617   LearningRate 0.000021   Epoch: 0   Global Step: 23450   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:34:24,183-Speed 139.58 samples/sec   Loss 1.1419   LearningRate 0.000021   Epoch: 0   Global Step: 23460   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:34:26,462-Speed 140.44 samples/sec   Loss 1.1935   LearningRate 0.000021   Epoch: 0   Global Step: 23470   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:34:28,752-Speed 139.76 samples/sec   Loss 1.2009   LearningRate 0.000021   Epoch: 0   Global Step: 23480   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:34:31,057-Speed 138.88 samples/sec   Loss 1.1820   LearningRate 0.000021   Epoch: 0   Global Step: 23490   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:34:33,349-Speed 139.68 samples/sec   Loss 1.1912   LearningRate 0.000021   Epoch: 0   Global Step: 23500   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:34:35,649-Speed 139.15 samples/sec   Loss 1.1456   LearningRate 0.000021   Epoch: 0   Global Step: 23510   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:34:37,965-Speed 138.20 samples/sec   Loss 1.1920   LearningRate 0.000021   Epoch: 0   Global Step: 23520   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:34:40,264-Speed 139.26 samples/sec   Loss 1.1866   LearningRate 0.000021   Epoch: 0   Global Step: 23530   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:34:42,545-Speed 140.28 samples/sec   Loss 1.1897   LearningRate 0.000021   Epoch: 0   Global Step: 23540   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:34:44,848-Speed 138.99 samples/sec   Loss 1.2228   LearningRate 0.000021   Epoch: 0   Global Step: 23550   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:34:47,139-Speed 139.72 samples/sec   Loss 1.2046   LearningRate 0.000021   Epoch: 0   Global Step: 23560   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:34:49,420-Speed 140.36 samples/sec   Loss 1.2401   LearningRate 0.000021   Epoch: 0   Global Step: 23570   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:34:51,716-Speed 139.38 samples/sec   Loss 1.1817   LearningRate 0.000021   Epoch: 0   Global Step: 23580   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:34:54,008-Speed 139.69 samples/sec   Loss 1.1754   LearningRate 0.000021   Epoch: 0   Global Step: 23590   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:34:56,297-Speed 139.84 samples/sec   Loss 1.1632   LearningRate 0.000021   Epoch: 0   Global Step: 23600   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:34:58,580-Speed 140.17 samples/sec   Loss 1.2071   LearningRate 0.000021   Epoch: 0   Global Step: 23610   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:35:00,884-Speed 138.95 samples/sec   Loss 1.1804   LearningRate 0.000021   Epoch: 0   Global Step: 23620   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:35:03,161-Speed 140.57 samples/sec   Loss 1.1943   LearningRate 0.000021   Epoch: 0   Global Step: 23630   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:35:05,461-Speed 139.21 samples/sec   Loss 1.1835   LearningRate 0.000021   Epoch: 0   Global Step: 23640   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:35:07,754-Speed 139.55 samples/sec   Loss 1.1809   LearningRate 0.000021   Epoch: 0   Global Step: 23650   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:35:10,037-Speed 140.21 samples/sec   Loss 1.1747   LearningRate 0.000021   Epoch: 0   Global Step: 23660   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:35:12,324-Speed 139.97 samples/sec   Loss 1.2120   LearningRate 0.000021   Epoch: 0   Global Step: 23670   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:35:14,605-Speed 140.32 samples/sec   Loss 1.1731   LearningRate 0.000021   Epoch: 0   Global Step: 23680   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:35:16,888-Speed 140.21 samples/sec   Loss 1.1724   LearningRate 0.000021   Epoch: 0   Global Step: 23690   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:35:19,176-Speed 139.89 samples/sec   Loss 1.1599   LearningRate 0.000021   Epoch: 0   Global Step: 23700   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:35:21,468-Speed 139.71 samples/sec   Loss 1.1730   LearningRate 0.000021   Epoch: 0   Global Step: 23710   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:35:23,750-Speed 140.21 samples/sec   Loss 1.1933   LearningRate 0.000021   Epoch: 0   Global Step: 23720   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 22:35:26,037-Speed 139.96 samples/sec   Loss 1.1882   LearningRate 0.000021   Epoch: 0   Global Step: 23730   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 22:35:28,328-Speed 139.73 samples/sec   Loss 1.1952   LearningRate 0.000021   Epoch: 0   Global Step: 23740   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 22:35:30,615-Speed 139.95 samples/sec   Loss 1.2026   LearningRate 0.000021   Epoch: 0   Global Step: 23750   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 22:35:32,908-Speed 139.60 samples/sec   Loss 1.1951   LearningRate 0.000021   Epoch: 0   Global Step: 23760   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 22:35:35,191-Speed 140.20 samples/sec   Loss 1.1670   LearningRate 0.000021   Epoch: 0   Global Step: 23770   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 22:35:37,491-Speed 139.22 samples/sec   Loss 1.1946   LearningRate 0.000021   Epoch: 0   Global Step: 23780   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 22:35:39,781-Speed 139.76 samples/sec   Loss 1.1896   LearningRate 0.000021   Epoch: 0   Global Step: 23790   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 22:35:42,054-Speed 140.84 samples/sec   Loss 1.1962   LearningRate 0.000021   Epoch: 0   Global Step: 23800   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 22:35:44,342-Speed 139.87 samples/sec   Loss 1.1793   LearningRate 0.000021   Epoch: 0   Global Step: 23810   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 22:35:46,633-Speed 139.70 samples/sec   Loss 1.1822   LearningRate 0.000021   Epoch: 0   Global Step: 23820   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:35:48,925-Speed 139.67 samples/sec   Loss 1.1851   LearningRate 0.000021   Epoch: 0   Global Step: 23830   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:35:51,201-Speed 140.64 samples/sec   Loss 1.1929   LearningRate 0.000021   Epoch: 0   Global Step: 23840   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:35:53,507-Speed 138.81 samples/sec   Loss 1.1924   LearningRate 0.000021   Epoch: 0   Global Step: 23850   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:35:55,802-Speed 139.50 samples/sec   Loss 1.2029   LearningRate 0.000021   Epoch: 0   Global Step: 23860   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:35:58,100-Speed 139.28 samples/sec   Loss 1.1929   LearningRate 0.000021   Epoch: 0   Global Step: 23870   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:36:00,405-Speed 138.90 samples/sec   Loss 1.1699   LearningRate 0.000021   Epoch: 0   Global Step: 23880   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:36:02,702-Speed 139.35 samples/sec   Loss 1.1745   LearningRate 0.000021   Epoch: 0   Global Step: 23890   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:36:04,986-Speed 140.15 samples/sec   Loss 1.1953   LearningRate 0.000021   Epoch: 0   Global Step: 23900   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:36:07,270-Speed 140.10 samples/sec   Loss 1.1536   LearningRate 0.000021   Epoch: 0   Global Step: 23910   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:36:09,573-Speed 138.99 samples/sec   Loss 1.2117   LearningRate 0.000021   Epoch: 0   Global Step: 23920   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:36:11,859-Speed 140.01 samples/sec   Loss 1.1926   LearningRate 0.000021   Epoch: 0   Global Step: 23930   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:36:14,154-Speed 139.52 samples/sec   Loss 1.1978   LearningRate 0.000021   Epoch: 0   Global Step: 23940   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:36:16,460-Speed 138.78 samples/sec   Loss 1.1986   LearningRate 0.000021   Epoch: 0   Global Step: 23950   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:36:18,749-Speed 139.88 samples/sec   Loss 1.1721   LearningRate 0.000021   Epoch: 0   Global Step: 23960   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:36:21,036-Speed 139.97 samples/sec   Loss 1.1974   LearningRate 0.000021   Epoch: 0   Global Step: 23970   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:36:23,333-Speed 139.32 samples/sec   Loss 1.1759   LearningRate 0.000021   Epoch: 0   Global Step: 23980   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:36:25,637-Speed 138.92 samples/sec   Loss 1.1822   LearningRate 0.000021   Epoch: 0   Global Step: 23990   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:36:27,714-Val on RAF/AffectNet:
Training: 2023-08-17 22:36:27,828-Test: [0/48]	Time 0.113 (0.113)	Loss 0.4969 (0.4969)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-17 22:36:28,899-Test: [10/48]	Time 0.109 (0.108)	Loss 0.4961 (0.5444)	Acc@1 96.875 (92.614)	Acc@5 100.000 (98.580)	Mem 5268MB
Training: 2023-08-17 22:36:29,988-Test: [20/48]	Time 0.111 (0.108)	Loss 0.5252 (0.5522)	Acc@1 90.625 (92.783)	Acc@5 100.000 (98.438)	Mem 5268MB
Training: 2023-08-17 22:36:31,117-Test: [30/48]	Time 0.113 (0.110)	Loss 0.5376 (0.5572)	Acc@1 93.750 (92.339)	Acc@5 98.438 (98.538)	Mem 5268MB
Training: 2023-08-17 22:36:32,195-Test: [40/48]	Time 0.104 (0.109)	Loss 0.5616 (0.5661)	Acc@1 92.188 (91.730)	Acc@5 96.875 (98.666)	Mem 5268MB
Training: 2023-08-17 22:36:32,923-[23999]Expression Loss: 0.56195
Training: 2023-08-17 22:36:32,923-[23999]Expression Acc@1: 92.01434
Training: 2023-08-17 22:36:32,923-[23999]Expression Acc@1-Highest: 92.47067
Training: 2023-08-17 22:36:32,924-[23999]Expression Acc@5: 98.76141
Training: 2023-08-17 22:36:32,924-[23999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 22:36:32,924-[23999]10 Times Expression Acc@1: 91.99153
Training: 2023-08-17 22:36:32,924-[23999]10 Times Expression Acc@1-Highest: 91.99153
Training: 2023-08-17 22:36:33,509-Speed 40.65 samples/sec   Loss 1.2064   LearningRate 0.000021   Epoch: 0   Global Step: 24000   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:36:35,774-Speed 141.36 samples/sec   Loss 1.1819   LearningRate 0.000021   Epoch: 0   Global Step: 24010   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:36:38,056-Speed 140.26 samples/sec   Loss 1.1859   LearningRate 0.000021   Epoch: 0   Global Step: 24020   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:36:40,339-Speed 140.24 samples/sec   Loss 1.1787   LearningRate 0.000021   Epoch: 0   Global Step: 24030   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:36:42,623-Speed 140.10 samples/sec   Loss 1.1927   LearningRate 0.000021   Epoch: 0   Global Step: 24040   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:36:44,909-Speed 140.05 samples/sec   Loss 1.1860   LearningRate 0.000021   Epoch: 0   Global Step: 24050   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:36:47,196-Speed 139.96 samples/sec   Loss 1.1723   LearningRate 0.000021   Epoch: 0   Global Step: 24060   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:36:49,487-Speed 139.73 samples/sec   Loss 1.1992   LearningRate 0.000021   Epoch: 0   Global Step: 24070   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:36:51,773-Speed 139.98 samples/sec   Loss 1.1688   LearningRate 0.000020   Epoch: 0   Global Step: 24080   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:36:54,054-Speed 140.33 samples/sec   Loss 1.1561   LearningRate 0.000020   Epoch: 0   Global Step: 24090   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:36:56,332-Speed 140.54 samples/sec   Loss 1.1555   LearningRate 0.000020   Epoch: 0   Global Step: 24100   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:36:58,601-Speed 141.05 samples/sec   Loss 1.1931   LearningRate 0.000020   Epoch: 0   Global Step: 24110   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:37:00,889-Speed 139.93 samples/sec   Loss 1.1883   LearningRate 0.000020   Epoch: 0   Global Step: 24120   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:37:03,177-Speed 139.90 samples/sec   Loss 1.1678   LearningRate 0.000020   Epoch: 0   Global Step: 24130   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:37:05,463-Speed 139.97 samples/sec   Loss 1.1837   LearningRate 0.000020   Epoch: 0   Global Step: 24140   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:37:07,760-Speed 139.39 samples/sec   Loss 1.2022   LearningRate 0.000020   Epoch: 0   Global Step: 24150   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:37:10,045-Speed 140.06 samples/sec   Loss 1.2145   LearningRate 0.000020   Epoch: 0   Global Step: 24160   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:37:12,324-Speed 140.46 samples/sec   Loss 1.1988   LearningRate 0.000020   Epoch: 0   Global Step: 24170   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:37:14,617-Speed 139.56 samples/sec   Loss 1.1936   LearningRate 0.000020   Epoch: 0   Global Step: 24180   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:37:16,912-Speed 139.47 samples/sec   Loss 1.1878   LearningRate 0.000020   Epoch: 0   Global Step: 24190   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:37:19,194-Speed 140.26 samples/sec   Loss 1.2014   LearningRate 0.000020   Epoch: 0   Global Step: 24200   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:37:21,468-Speed 140.79 samples/sec   Loss 1.2048   LearningRate 0.000020   Epoch: 0   Global Step: 24210   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:37:23,752-Speed 140.13 samples/sec   Loss 1.2107   LearningRate 0.000020   Epoch: 0   Global Step: 24220   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:37:26,043-Speed 139.70 samples/sec   Loss 1.1903   LearningRate 0.000020   Epoch: 0   Global Step: 24230   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:37:28,310-Speed 141.22 samples/sec   Loss 1.1918   LearningRate 0.000020   Epoch: 0   Global Step: 24240   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:37:30,594-Speed 140.13 samples/sec   Loss 1.1580   LearningRate 0.000020   Epoch: 0   Global Step: 24250   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:37:32,889-Speed 139.48 samples/sec   Loss 1.1595   LearningRate 0.000020   Epoch: 0   Global Step: 24260   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:37:35,178-Speed 139.80 samples/sec   Loss 1.1750   LearningRate 0.000020   Epoch: 0   Global Step: 24270   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:37:37,480-Speed 139.03 samples/sec   Loss 1.1992   LearningRate 0.000020   Epoch: 0   Global Step: 24280   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:37:39,767-Speed 139.96 samples/sec   Loss 1.1743   LearningRate 0.000020   Epoch: 0   Global Step: 24290   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:37:42,036-Speed 141.10 samples/sec   Loss 1.1790   LearningRate 0.000020   Epoch: 0   Global Step: 24300   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:37:44,332-Speed 139.42 samples/sec   Loss 1.1650   LearningRate 0.000020   Epoch: 0   Global Step: 24310   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:37:46,618-Speed 139.99 samples/sec   Loss 1.1981   LearningRate 0.000020   Epoch: 0   Global Step: 24320   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:37:48,917-Speed 139.22 samples/sec   Loss 1.1576   LearningRate 0.000020   Epoch: 0   Global Step: 24330   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:37:51,213-Speed 139.46 samples/sec   Loss 1.1632   LearningRate 0.000020   Epoch: 0   Global Step: 24340   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:37:53,489-Speed 140.57 samples/sec   Loss 1.1782   LearningRate 0.000020   Epoch: 0   Global Step: 24350   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:37:55,768-Speed 140.48 samples/sec   Loss 1.1912   LearningRate 0.000020   Epoch: 0   Global Step: 24360   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:37:58,043-Speed 140.71 samples/sec   Loss 1.2068   LearningRate 0.000020   Epoch: 0   Global Step: 24370   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:38:00,335-Speed 139.65 samples/sec   Loss 1.1946   LearningRate 0.000020   Epoch: 0   Global Step: 24380   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:38:02,614-Speed 140.43 samples/sec   Loss 1.1957   LearningRate 0.000020   Epoch: 0   Global Step: 24390   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:38:04,912-Speed 139.30 samples/sec   Loss 1.2213   LearningRate 0.000020   Epoch: 0   Global Step: 24400   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:38:07,209-Speed 139.36 samples/sec   Loss 1.1856   LearningRate 0.000020   Epoch: 0   Global Step: 24410   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:38:09,495-Speed 140.00 samples/sec   Loss 1.2046   LearningRate 0.000020   Epoch: 0   Global Step: 24420   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:38:11,788-Speed 139.63 samples/sec   Loss 1.1853   LearningRate 0.000020   Epoch: 0   Global Step: 24430   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:38:14,070-Speed 140.29 samples/sec   Loss 1.1574   LearningRate 0.000020   Epoch: 0   Global Step: 24440   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:38:16,359-Speed 139.82 samples/sec   Loss 1.1723   LearningRate 0.000020   Epoch: 0   Global Step: 24450   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:38:18,654-Speed 139.48 samples/sec   Loss 1.1896   LearningRate 0.000020   Epoch: 0   Global Step: 24460   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:38:20,946-Speed 139.66 samples/sec   Loss 1.1851   LearningRate 0.000020   Epoch: 0   Global Step: 24470   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:38:23,212-Speed 141.22 samples/sec   Loss 1.2002   LearningRate 0.000020   Epoch: 0   Global Step: 24480   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:38:25,481-Speed 141.09 samples/sec   Loss 1.1610   LearningRate 0.000020   Epoch: 0   Global Step: 24490   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:38:27,768-Speed 139.94 samples/sec   Loss 1.1804   LearningRate 0.000020   Epoch: 0   Global Step: 24500   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:38:30,066-Speed 139.32 samples/sec   Loss 1.1772   LearningRate 0.000020   Epoch: 0   Global Step: 24510   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:38:32,381-Speed 138.27 samples/sec   Loss 1.1825   LearningRate 0.000020   Epoch: 0   Global Step: 24520   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:38:34,693-Speed 138.41 samples/sec   Loss 1.1874   LearningRate 0.000020   Epoch: 0   Global Step: 24530   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:38:37,018-Speed 137.67 samples/sec   Loss 1.1699   LearningRate 0.000020   Epoch: 0   Global Step: 24540   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:38:39,337-Speed 138.03 samples/sec   Loss 1.1771   LearningRate 0.000020   Epoch: 0   Global Step: 24550   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:38:41,645-Speed 138.68 samples/sec   Loss 1.1639   LearningRate 0.000020   Epoch: 0   Global Step: 24560   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:38:43,931-Speed 140.04 samples/sec   Loss 1.1972   LearningRate 0.000020   Epoch: 0   Global Step: 24570   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:38:46,191-Speed 141.60 samples/sec   Loss 1.1588   LearningRate 0.000020   Epoch: 0   Global Step: 24580   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:38:48,473-Speed 140.30 samples/sec   Loss 1.1667   LearningRate 0.000020   Epoch: 0   Global Step: 24590   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:38:50,760-Speed 139.93 samples/sec   Loss 1.2230   LearningRate 0.000020   Epoch: 0   Global Step: 24600   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:38:53,065-Speed 138.86 samples/sec   Loss 1.1792   LearningRate 0.000020   Epoch: 0   Global Step: 24610   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:38:55,343-Speed 140.51 samples/sec   Loss 1.1909   LearningRate 0.000020   Epoch: 0   Global Step: 24620   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:38:57,635-Speed 139.66 samples/sec   Loss 1.1852   LearningRate 0.000020   Epoch: 0   Global Step: 24630   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:38:59,917-Speed 140.27 samples/sec   Loss 1.1709   LearningRate 0.000020   Epoch: 0   Global Step: 24640   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:39:02,208-Speed 139.74 samples/sec   Loss 1.1828   LearningRate 0.000020   Epoch: 0   Global Step: 24650   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:39:04,491-Speed 140.18 samples/sec   Loss 1.1964   LearningRate 0.000020   Epoch: 0   Global Step: 24660   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:39:06,764-Speed 140.81 samples/sec   Loss 1.1840   LearningRate 0.000020   Epoch: 0   Global Step: 24670   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:39:09,044-Speed 140.41 samples/sec   Loss 1.1691   LearningRate 0.000020   Epoch: 0   Global Step: 24680   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:39:11,317-Speed 140.81 samples/sec   Loss 1.1910   LearningRate 0.000020   Epoch: 0   Global Step: 24690   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:39:13,588-Speed 140.95 samples/sec   Loss 1.1689   LearningRate 0.000020   Epoch: 0   Global Step: 24700   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 22:39:15,885-Speed 139.39 samples/sec   Loss 1.1812   LearningRate 0.000020   Epoch: 0   Global Step: 24710   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 22:39:18,172-Speed 139.92 samples/sec   Loss 1.2026   LearningRate 0.000020   Epoch: 0   Global Step: 24720   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 22:39:20,461-Speed 139.86 samples/sec   Loss 1.2017   LearningRate 0.000020   Epoch: 0   Global Step: 24730   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 22:39:22,740-Speed 140.45 samples/sec   Loss 1.2038   LearningRate 0.000020   Epoch: 0   Global Step: 24740   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 22:39:25,032-Speed 139.64 samples/sec   Loss 1.1704   LearningRate 0.000020   Epoch: 0   Global Step: 24750   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 22:39:27,323-Speed 139.75 samples/sec   Loss 1.1867   LearningRate 0.000020   Epoch: 0   Global Step: 24760   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 22:39:29,629-Speed 138.76 samples/sec   Loss 1.2078   LearningRate 0.000020   Epoch: 0   Global Step: 24770   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 22:39:31,953-Speed 137.75 samples/sec   Loss 1.1705   LearningRate 0.000020   Epoch: 0   Global Step: 24780   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 22:39:34,269-Speed 138.20 samples/sec   Loss 1.1812   LearningRate 0.000020   Epoch: 0   Global Step: 24790   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 22:39:36,590-Speed 137.91 samples/sec   Loss 1.1758   LearningRate 0.000020   Epoch: 0   Global Step: 24800   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:39:38,915-Speed 137.68 samples/sec   Loss 1.1746   LearningRate 0.000020   Epoch: 0   Global Step: 24810   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:39:41,256-Speed 136.77 samples/sec   Loss 1.1781   LearningRate 0.000020   Epoch: 0   Global Step: 24820   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:39:43,589-Speed 137.17 samples/sec   Loss 1.1917   LearningRate 0.000020   Epoch: 0   Global Step: 24830   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:39:45,901-Speed 138.44 samples/sec   Loss 1.1909   LearningRate 0.000020   Epoch: 0   Global Step: 24840   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:39:48,178-Speed 140.57 samples/sec   Loss 1.1858   LearningRate 0.000020   Epoch: 0   Global Step: 24850   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:39:50,461-Speed 140.25 samples/sec   Loss 1.1767   LearningRate 0.000020   Epoch: 0   Global Step: 24860   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:39:52,743-Speed 140.24 samples/sec   Loss 1.1720   LearningRate 0.000020   Epoch: 0   Global Step: 24870   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:39:55,033-Speed 139.80 samples/sec   Loss 1.1602   LearningRate 0.000020   Epoch: 0   Global Step: 24880   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:39:57,311-Speed 140.47 samples/sec   Loss 1.1818   LearningRate 0.000020   Epoch: 0   Global Step: 24890   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:39:59,584-Speed 140.83 samples/sec   Loss 1.2083   LearningRate 0.000020   Epoch: 0   Global Step: 24900   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:40:01,877-Speed 139.58 samples/sec   Loss 1.1804   LearningRate 0.000020   Epoch: 0   Global Step: 24910   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:40:04,176-Speed 139.26 samples/sec   Loss 1.1944   LearningRate 0.000020   Epoch: 0   Global Step: 24920   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:40:06,477-Speed 139.08 samples/sec   Loss 1.1622   LearningRate 0.000020   Epoch: 0   Global Step: 24930   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:40:08,752-Speed 140.74 samples/sec   Loss 1.2070   LearningRate 0.000020   Epoch: 0   Global Step: 24940   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:40:11,045-Speed 139.59 samples/sec   Loss 1.1846   LearningRate 0.000020   Epoch: 0   Global Step: 24950   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:40:13,327-Speed 140.27 samples/sec   Loss 1.1930   LearningRate 0.000020   Epoch: 0   Global Step: 24960   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:40:15,633-Speed 138.78 samples/sec   Loss 1.1860   LearningRate 0.000020   Epoch: 0   Global Step: 24970   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:40:17,943-Speed 138.56 samples/sec   Loss 1.1878   LearningRate 0.000020   Epoch: 0   Global Step: 24980   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:40:20,253-Speed 138.60 samples/sec   Loss 1.1631   LearningRate 0.000020   Epoch: 0   Global Step: 24990   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:40:22,333-Val on RAF/AffectNet:
Training: 2023-08-17 22:40:22,441-Test: [0/48]	Time 0.108 (0.108)	Loss 0.4835 (0.4835)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-17 22:40:23,498-Test: [10/48]	Time 0.104 (0.106)	Loss 0.5894 (0.5334)	Acc@1 90.625 (92.756)	Acc@5 100.000 (99.574)	Mem 5268MB
Training: 2023-08-17 22:40:24,577-Test: [20/48]	Time 0.105 (0.107)	Loss 0.5248 (0.5298)	Acc@1 93.750 (92.932)	Acc@5 100.000 (99.330)	Mem 5268MB
Training: 2023-08-17 22:40:25,632-Test: [30/48]	Time 0.104 (0.106)	Loss 0.5968 (0.5428)	Acc@1 90.625 (92.540)	Acc@5 100.000 (99.143)	Mem 5268MB
Training: 2023-08-17 22:40:26,704-Test: [40/48]	Time 0.106 (0.107)	Loss 0.4181 (0.5460)	Acc@1 96.875 (92.416)	Acc@5 100.000 (98.971)	Mem 5268MB
Training: 2023-08-17 22:40:27,450-[24999]Expression Loss: 0.54832
Training: 2023-08-17 22:40:27,450-[24999]Expression Acc@1: 92.30769
Training: 2023-08-17 22:40:27,451-[24999]Expression Acc@1-Highest: 92.47067
Training: 2023-08-17 22:40:27,451-[24999]Expression Acc@5: 98.85919
Training: 2023-08-17 22:40:27,451-[24999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 22:40:27,451-[24999]10 Times Expression Acc@1: 92.02738
Training: 2023-08-17 22:40:27,451-[24999]10 Times Expression Acc@1-Highest: 92.02738
Training: 2023-08-17 22:40:27,679-Speed 43.09 samples/sec   Loss 1.1822   LearningRate 0.000020   Epoch: 0   Global Step: 25000   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:40:29,948-Speed 141.06 samples/sec   Loss 1.1913   LearningRate 0.000020   Epoch: 0   Global Step: 25010   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:40:32,229-Speed 140.33 samples/sec   Loss 1.1631   LearningRate 0.000020   Epoch: 0   Global Step: 25020   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:40:34,510-Speed 140.36 samples/sec   Loss 1.1585   LearningRate 0.000020   Epoch: 0   Global Step: 25030   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:40:36,798-Speed 139.84 samples/sec   Loss 1.2014   LearningRate 0.000020   Epoch: 0   Global Step: 25040   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:40:39,085-Speed 140.02 samples/sec   Loss 1.1911   LearningRate 0.000020   Epoch: 0   Global Step: 25050   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:40:41,359-Speed 140.75 samples/sec   Loss 1.1998   LearningRate 0.000020   Epoch: 0   Global Step: 25060   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:40:43,657-Speed 139.27 samples/sec   Loss 1.1536   LearningRate 0.000020   Epoch: 0   Global Step: 25070   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:40:45,949-Speed 139.67 samples/sec   Loss 1.1711   LearningRate 0.000020   Epoch: 0   Global Step: 25080   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:40:48,243-Speed 139.52 samples/sec   Loss 1.1781   LearningRate 0.000020   Epoch: 0   Global Step: 25090   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:40:50,536-Speed 139.63 samples/sec   Loss 1.1869   LearningRate 0.000020   Epoch: 0   Global Step: 25100   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:40:52,842-Speed 138.78 samples/sec   Loss 1.1892   LearningRate 0.000020   Epoch: 0   Global Step: 25110   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:40:55,157-Speed 138.28 samples/sec   Loss 1.1594   LearningRate 0.000020   Epoch: 0   Global Step: 25120   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:40:57,442-Speed 140.10 samples/sec   Loss 1.1862   LearningRate 0.000020   Epoch: 0   Global Step: 25130   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:40:59,734-Speed 139.63 samples/sec   Loss 1.1980   LearningRate 0.000020   Epoch: 0   Global Step: 25140   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:41:02,018-Speed 140.16 samples/sec   Loss 1.1765   LearningRate 0.000020   Epoch: 0   Global Step: 25150   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:41:04,314-Speed 139.37 samples/sec   Loss 1.1948   LearningRate 0.000020   Epoch: 0   Global Step: 25160   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:41:06,613-Speed 139.27 samples/sec   Loss 1.1921   LearningRate 0.000020   Epoch: 0   Global Step: 25170   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:41:08,914-Speed 139.11 samples/sec   Loss 1.1884   LearningRate 0.000020   Epoch: 0   Global Step: 25180   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:41:11,190-Speed 140.66 samples/sec   Loss 1.1912   LearningRate 0.000020   Epoch: 0   Global Step: 25190   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:41:13,478-Speed 139.86 samples/sec   Loss 1.2031   LearningRate 0.000020   Epoch: 0   Global Step: 25200   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:41:15,755-Speed 140.59 samples/sec   Loss 1.1623   LearningRate 0.000020   Epoch: 0   Global Step: 25210   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:41:18,048-Speed 139.62 samples/sec   Loss 1.1750   LearningRate 0.000020   Epoch: 0   Global Step: 25220   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:41:20,341-Speed 139.58 samples/sec   Loss 1.1897   LearningRate 0.000020   Epoch: 0   Global Step: 25230   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:41:22,618-Speed 140.56 samples/sec   Loss 1.1652   LearningRate 0.000020   Epoch: 0   Global Step: 25240   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:41:24,918-Speed 139.20 samples/sec   Loss 1.1602   LearningRate 0.000020   Epoch: 0   Global Step: 25250   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:41:27,180-Speed 141.49 samples/sec   Loss 1.1773   LearningRate 0.000020   Epoch: 0   Global Step: 25260   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:41:29,449-Speed 141.07 samples/sec   Loss 1.1861   LearningRate 0.000020   Epoch: 0   Global Step: 25270   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:41:31,728-Speed 140.45 samples/sec   Loss 1.2111   LearningRate 0.000020   Epoch: 0   Global Step: 25280   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:41:34,004-Speed 140.60 samples/sec   Loss 1.1734   LearningRate 0.000020   Epoch: 0   Global Step: 25290   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:41:36,270-Speed 141.29 samples/sec   Loss 1.2080   LearningRate 0.000020   Epoch: 0   Global Step: 25300   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:41:38,539-Speed 141.09 samples/sec   Loss 1.1686   LearningRate 0.000020   Epoch: 0   Global Step: 25310   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:41:40,808-Speed 141.05 samples/sec   Loss 1.1857   LearningRate 0.000020   Epoch: 0   Global Step: 25320   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:41:43,079-Speed 140.93 samples/sec   Loss 1.2092   LearningRate 0.000020   Epoch: 0   Global Step: 25330   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:41:45,360-Speed 140.37 samples/sec   Loss 1.2139   LearningRate 0.000020   Epoch: 0   Global Step: 25340   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:41:47,655-Speed 139.45 samples/sec   Loss 1.2068   LearningRate 0.000020   Epoch: 0   Global Step: 25350   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:41:49,962-Speed 138.76 samples/sec   Loss 1.1704   LearningRate 0.000020   Epoch: 0   Global Step: 25360   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:41:52,239-Speed 140.60 samples/sec   Loss 1.1797   LearningRate 0.000019   Epoch: 0   Global Step: 25370   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:41:54,528-Speed 139.82 samples/sec   Loss 1.1786   LearningRate 0.000019   Epoch: 0   Global Step: 25380   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:41:56,825-Speed 139.38 samples/sec   Loss 1.1770   LearningRate 0.000019   Epoch: 0   Global Step: 25390   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:41:59,107-Speed 140.27 samples/sec   Loss 1.1963   LearningRate 0.000019   Epoch: 0   Global Step: 25400   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:42:01,400-Speed 139.57 samples/sec   Loss 1.1885   LearningRate 0.000019   Epoch: 0   Global Step: 25410   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:42:03,668-Speed 141.12 samples/sec   Loss 1.1885   LearningRate 0.000019   Epoch: 0   Global Step: 25420   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:42:05,950-Speed 140.28 samples/sec   Loss 1.1564   LearningRate 0.000019   Epoch: 0   Global Step: 25430   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:42:08,227-Speed 140.57 samples/sec   Loss 1.2139   LearningRate 0.000019   Epoch: 0   Global Step: 25440   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:42:10,504-Speed 140.56 samples/sec   Loss 1.1845   LearningRate 0.000019   Epoch: 0   Global Step: 25450   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:42:12,808-Speed 138.93 samples/sec   Loss 1.1731   LearningRate 0.000019   Epoch: 0   Global Step: 25460   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:42:15,077-Speed 141.07 samples/sec   Loss 1.1750   LearningRate 0.000019   Epoch: 0   Global Step: 25470   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:42:17,363-Speed 140.04 samples/sec   Loss 1.2228   LearningRate 0.000019   Epoch: 0   Global Step: 25480   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:42:19,641-Speed 140.54 samples/sec   Loss 1.1572   LearningRate 0.000019   Epoch: 0   Global Step: 25490   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:42:21,918-Speed 140.54 samples/sec   Loss 1.1645   LearningRate 0.000019   Epoch: 0   Global Step: 25500   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:42:24,201-Speed 140.22 samples/sec   Loss 1.2013   LearningRate 0.000019   Epoch: 0   Global Step: 25510   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:42:26,486-Speed 140.08 samples/sec   Loss 1.1904   LearningRate 0.000019   Epoch: 0   Global Step: 25520   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:42:28,766-Speed 140.40 samples/sec   Loss 1.2132   LearningRate 0.000019   Epoch: 0   Global Step: 25530   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:42:31,044-Speed 140.49 samples/sec   Loss 1.1978   LearningRate 0.000019   Epoch: 0   Global Step: 25540   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:42:33,342-Speed 139.33 samples/sec   Loss 1.2079   LearningRate 0.000019   Epoch: 0   Global Step: 25550   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:42:35,627-Speed 140.05 samples/sec   Loss 1.1902   LearningRate 0.000019   Epoch: 0   Global Step: 25560   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:42:37,893-Speed 141.28 samples/sec   Loss 1.1816   LearningRate 0.000019   Epoch: 0   Global Step: 25570   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:42:40,168-Speed 140.70 samples/sec   Loss 1.2270   LearningRate 0.000019   Epoch: 0   Global Step: 25580   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:42:42,459-Speed 139.73 samples/sec   Loss 1.1825   LearningRate 0.000019   Epoch: 0   Global Step: 25590   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:42:44,745-Speed 140.01 samples/sec   Loss 1.1972   LearningRate 0.000019   Epoch: 0   Global Step: 25600   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:42:47,044-Speed 139.25 samples/sec   Loss 1.2123   LearningRate 0.000019   Epoch: 0   Global Step: 25610   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:42:49,324-Speed 140.34 samples/sec   Loss 1.1736   LearningRate 0.000019   Epoch: 0   Global Step: 25620   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:42:51,610-Speed 140.07 samples/sec   Loss 1.1772   LearningRate 0.000019   Epoch: 0   Global Step: 25630   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:42:53,902-Speed 139.61 samples/sec   Loss 1.1845   LearningRate 0.000019   Epoch: 0   Global Step: 25640   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:42:56,170-Speed 141.16 samples/sec   Loss 1.1534   LearningRate 0.000019   Epoch: 0   Global Step: 25650   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:42:58,448-Speed 140.49 samples/sec   Loss 1.1921   LearningRate 0.000019   Epoch: 0   Global Step: 25660   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:43:00,731-Speed 140.21 samples/sec   Loss 1.1895   LearningRate 0.000019   Epoch: 0   Global Step: 25670   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:43:03,025-Speed 139.57 samples/sec   Loss 1.1704   LearningRate 0.000019   Epoch: 0   Global Step: 25680   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:43:05,283-Speed 141.75 samples/sec   Loss 1.1868   LearningRate 0.000019   Epoch: 0   Global Step: 25690   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:43:07,559-Speed 140.65 samples/sec   Loss 1.1817   LearningRate 0.000019   Epoch: 0   Global Step: 25700   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:43:09,828-Speed 141.05 samples/sec   Loss 1.1855   LearningRate 0.000019   Epoch: 0   Global Step: 25710   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:43:12,126-Speed 139.30 samples/sec   Loss 1.1716   LearningRate 0.000019   Epoch: 0   Global Step: 25720   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:43:14,402-Speed 140.63 samples/sec   Loss 1.2272   LearningRate 0.000019   Epoch: 0   Global Step: 25730   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:43:16,668-Speed 141.26 samples/sec   Loss 1.1930   LearningRate 0.000019   Epoch: 0   Global Step: 25740   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:43:18,949-Speed 140.36 samples/sec   Loss 1.2032   LearningRate 0.000019   Epoch: 0   Global Step: 25750   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:43:21,229-Speed 140.39 samples/sec   Loss 1.1618   LearningRate 0.000019   Epoch: 0   Global Step: 25760   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:43:23,505-Speed 140.63 samples/sec   Loss 1.2107   LearningRate 0.000019   Epoch: 0   Global Step: 25770   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:43:25,779-Speed 140.75 samples/sec   Loss 1.1885   LearningRate 0.000019   Epoch: 0   Global Step: 25780   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:43:28,064-Speed 140.07 samples/sec   Loss 1.1806   LearningRate 0.000019   Epoch: 0   Global Step: 25790   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:43:30,354-Speed 139.82 samples/sec   Loss 1.1961   LearningRate 0.000019   Epoch: 0   Global Step: 25800   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:43:32,643-Speed 139.80 samples/sec   Loss 1.1814   LearningRate 0.000019   Epoch: 0   Global Step: 25810   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:43:34,922-Speed 140.47 samples/sec   Loss 1.1908   LearningRate 0.000019   Epoch: 0   Global Step: 25820   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:43:37,199-Speed 140.57 samples/sec   Loss 1.1905   LearningRate 0.000019   Epoch: 0   Global Step: 25830   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:43:39,483-Speed 140.14 samples/sec   Loss 1.1882   LearningRate 0.000019   Epoch: 0   Global Step: 25840   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:43:41,761-Speed 140.49 samples/sec   Loss 1.1567   LearningRate 0.000019   Epoch: 0   Global Step: 25850   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:43:44,038-Speed 140.62 samples/sec   Loss 1.1756   LearningRate 0.000019   Epoch: 0   Global Step: 25860   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:43:46,317-Speed 140.42 samples/sec   Loss 1.1548   LearningRate 0.000019   Epoch: 0   Global Step: 25870   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:43:48,580-Speed 141.47 samples/sec   Loss 1.1802   LearningRate 0.000019   Epoch: 0   Global Step: 25880   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:43:50,846-Speed 141.27 samples/sec   Loss 1.1905   LearningRate 0.000019   Epoch: 0   Global Step: 25890   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:43:53,107-Speed 141.52 samples/sec   Loss 1.1648   LearningRate 0.000019   Epoch: 0   Global Step: 25900   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:43:55,353-Speed 142.57 samples/sec   Loss 1.2110   LearningRate 0.000019   Epoch: 0   Global Step: 25910   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:43:57,625-Speed 140.84 samples/sec   Loss 1.1926   LearningRate 0.000019   Epoch: 0   Global Step: 25920   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:43:59,884-Speed 141.70 samples/sec   Loss 1.1764   LearningRate 0.000019   Epoch: 0   Global Step: 25930   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:44:02,133-Speed 142.33 samples/sec   Loss 1.1657   LearningRate 0.000019   Epoch: 0   Global Step: 25940   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:44:04,407-Speed 140.79 samples/sec   Loss 1.1660   LearningRate 0.000019   Epoch: 0   Global Step: 25950   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:44:06,693-Speed 140.02 samples/sec   Loss 1.2128   LearningRate 0.000019   Epoch: 0   Global Step: 25960   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:44:08,975-Speed 140.26 samples/sec   Loss 1.1697   LearningRate 0.000019   Epoch: 0   Global Step: 25970   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:44:11,244-Speed 141.05 samples/sec   Loss 1.1788   LearningRate 0.000019   Epoch: 0   Global Step: 25980   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:44:13,536-Speed 139.64 samples/sec   Loss 1.1710   LearningRate 0.000019   Epoch: 0   Global Step: 25990   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:44:15,592-Val on RAF/AffectNet:
Training: 2023-08-17 22:44:15,707-Test: [0/48]	Time 0.115 (0.115)	Loss 0.5487 (0.5487)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-17 22:44:16,831-Test: [10/48]	Time 0.111 (0.113)	Loss 0.6424 (0.5440)	Acc@1 90.625 (93.182)	Acc@5 98.438 (99.148)	Mem 5268MB
Training: 2023-08-17 22:44:17,928-Test: [20/48]	Time 0.108 (0.111)	Loss 0.6699 (0.5654)	Acc@1 87.500 (92.262)	Acc@5 96.875 (98.661)	Mem 5268MB
Training: 2023-08-17 22:44:19,007-Test: [30/48]	Time 0.105 (0.110)	Loss 0.5564 (0.5739)	Acc@1 93.750 (91.784)	Acc@5 98.438 (98.538)	Mem 5268MB
Training: 2023-08-17 22:44:20,074-Test: [40/48]	Time 0.108 (0.109)	Loss 0.5108 (0.5745)	Acc@1 96.875 (91.921)	Acc@5 100.000 (98.476)	Mem 5268MB
Training: 2023-08-17 22:44:20,826-[25999]Expression Loss: 0.56859
Training: 2023-08-17 22:44:20,826-[25999]Expression Acc@1: 92.07953
Training: 2023-08-17 22:44:20,827-[25999]Expression Acc@1-Highest: 92.47067
Training: 2023-08-17 22:44:20,827-[25999]Expression Acc@5: 98.56584
Training: 2023-08-17 22:44:20,827-[25999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 22:44:20,827-[25999]10 Times Expression Acc@1: 92.01108
Training: 2023-08-17 22:44:20,827-[25999]10 Times Expression Acc@1-Highest: 92.02738
Training: 2023-08-17 22:44:21,057-Speed 42.56 samples/sec   Loss 1.1828   LearningRate 0.000019   Epoch: 0   Global Step: 26000   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:44:23,341-Speed 140.12 samples/sec   Loss 1.1627   LearningRate 0.000019   Epoch: 0   Global Step: 26010   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:44:25,612-Speed 140.92 samples/sec   Loss 1.1832   LearningRate 0.000019   Epoch: 0   Global Step: 26020   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:44:27,908-Speed 139.40 samples/sec   Loss 1.1910   LearningRate 0.000019   Epoch: 0   Global Step: 26030   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:44:30,192-Speed 140.14 samples/sec   Loss 1.1772   LearningRate 0.000019   Epoch: 0   Global Step: 26040   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:44:32,482-Speed 139.77 samples/sec   Loss 1.2034   LearningRate 0.000019   Epoch: 0   Global Step: 26050   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:44:34,774-Speed 139.67 samples/sec   Loss 1.1526   LearningRate 0.000019   Epoch: 0   Global Step: 26060   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:44:37,066-Speed 139.67 samples/sec   Loss 1.1874   LearningRate 0.000019   Epoch: 0   Global Step: 26070   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:44:39,341-Speed 140.68 samples/sec   Loss 1.2076   LearningRate 0.000019   Epoch: 0   Global Step: 26080   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:44:41,618-Speed 140.58 samples/sec   Loss 1.1628   LearningRate 0.000019   Epoch: 0   Global Step: 26090   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:44:43,906-Speed 139.93 samples/sec   Loss 1.1848   LearningRate 0.000019   Epoch: 0   Global Step: 26100   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:44:46,184-Speed 140.51 samples/sec   Loss 1.1785   LearningRate 0.000019   Epoch: 0   Global Step: 26110   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:44:48,463-Speed 140.46 samples/sec   Loss 1.1726   LearningRate 0.000019   Epoch: 0   Global Step: 26120   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:44:50,750-Speed 139.95 samples/sec   Loss 1.1531   LearningRate 0.000019   Epoch: 0   Global Step: 26130   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:44:53,062-Speed 138.43 samples/sec   Loss 1.1550   LearningRate 0.000019   Epoch: 0   Global Step: 26140   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:44:55,374-Speed 138.45 samples/sec   Loss 1.1981   LearningRate 0.000019   Epoch: 0   Global Step: 26150   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:44:57,677-Speed 139.02 samples/sec   Loss 1.2097   LearningRate 0.000019   Epoch: 0   Global Step: 26160   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:45:00,014-Speed 136.95 samples/sec   Loss 1.2034   LearningRate 0.000019   Epoch: 0   Global Step: 26170   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:45:02,321-Speed 138.74 samples/sec   Loss 1.1805   LearningRate 0.000019   Epoch: 0   Global Step: 26180   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:45:04,625-Speed 138.94 samples/sec   Loss 1.1996   LearningRate 0.000019   Epoch: 0   Global Step: 26190   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:45:06,920-Speed 139.47 samples/sec   Loss 1.1879   LearningRate 0.000019   Epoch: 0   Global Step: 26200   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:45:09,203-Speed 140.16 samples/sec   Loss 1.2093   LearningRate 0.000019   Epoch: 0   Global Step: 26210   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:45:11,497-Speed 139.59 samples/sec   Loss 1.1641   LearningRate 0.000019   Epoch: 0   Global Step: 26220   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:45:13,790-Speed 139.56 samples/sec   Loss 1.1760   LearningRate 0.000019   Epoch: 0   Global Step: 26230   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:45:16,093-Speed 138.98 samples/sec   Loss 1.1632   LearningRate 0.000019   Epoch: 0   Global Step: 26240   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:45:18,381-Speed 139.94 samples/sec   Loss 1.1577   LearningRate 0.000019   Epoch: 0   Global Step: 26250   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:45:20,682-Speed 139.10 samples/sec   Loss 1.1930   LearningRate 0.000019   Epoch: 0   Global Step: 26260   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:45:22,974-Speed 139.70 samples/sec   Loss 1.1751   LearningRate 0.000019   Epoch: 0   Global Step: 26270   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:45:25,290-Speed 138.18 samples/sec   Loss 1.1807   LearningRate 0.000019   Epoch: 0   Global Step: 26280   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:45:27,575-Speed 140.12 samples/sec   Loss 1.1713   LearningRate 0.000019   Epoch: 0   Global Step: 26290   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:45:29,858-Speed 140.15 samples/sec   Loss 1.1728   LearningRate 0.000019   Epoch: 0   Global Step: 26300   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:45:32,155-Speed 139.41 samples/sec   Loss 1.1938   LearningRate 0.000019   Epoch: 0   Global Step: 26310   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:45:34,445-Speed 139.74 samples/sec   Loss 1.1623   LearningRate 0.000019   Epoch: 0   Global Step: 26320   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:45:36,740-Speed 139.50 samples/sec   Loss 1.1865   LearningRate 0.000019   Epoch: 0   Global Step: 26330   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:45:39,027-Speed 139.93 samples/sec   Loss 1.1595   LearningRate 0.000019   Epoch: 0   Global Step: 26340   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:45:41,304-Speed 140.59 samples/sec   Loss 1.2085   LearningRate 0.000019   Epoch: 0   Global Step: 26350   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:45:43,589-Speed 140.06 samples/sec   Loss 1.1711   LearningRate 0.000019   Epoch: 0   Global Step: 26360   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:45:45,873-Speed 140.18 samples/sec   Loss 1.2081   LearningRate 0.000019   Epoch: 0   Global Step: 26370   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:45:48,144-Speed 140.95 samples/sec   Loss 1.2179   LearningRate 0.000019   Epoch: 0   Global Step: 26380   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:45:50,412-Speed 141.12 samples/sec   Loss 1.2055   LearningRate 0.000019   Epoch: 0   Global Step: 26390   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:45:52,682-Speed 140.97 samples/sec   Loss 1.1874   LearningRate 0.000019   Epoch: 0   Global Step: 26400   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:45:54,963-Speed 140.38 samples/sec   Loss 1.1993   LearningRate 0.000019   Epoch: 0   Global Step: 26410   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:45:57,243-Speed 140.37 samples/sec   Loss 1.1822   LearningRate 0.000019   Epoch: 0   Global Step: 26420   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:45:59,519-Speed 140.65 samples/sec   Loss 1.1692   LearningRate 0.000019   Epoch: 0   Global Step: 26430   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:46:01,796-Speed 140.59 samples/sec   Loss 1.2093   LearningRate 0.000019   Epoch: 0   Global Step: 26440   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:46:04,071-Speed 140.70 samples/sec   Loss 1.2095   LearningRate 0.000019   Epoch: 0   Global Step: 26450   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:46:06,329-Speed 141.73 samples/sec   Loss 1.1781   LearningRate 0.000019   Epoch: 0   Global Step: 26460   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:46:08,601-Speed 140.88 samples/sec   Loss 1.1525   LearningRate 0.000019   Epoch: 0   Global Step: 26470   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:46:10,867-Speed 141.30 samples/sec   Loss 1.1744   LearningRate 0.000019   Epoch: 0   Global Step: 26480   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:46:13,130-Speed 141.41 samples/sec   Loss 1.1766   LearningRate 0.000019   Epoch: 0   Global Step: 26490   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:46:15,425-Speed 139.50 samples/sec   Loss 1.1604   LearningRate 0.000019   Epoch: 0   Global Step: 26500   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:46:17,728-Speed 138.97 samples/sec   Loss 1.1859   LearningRate 0.000019   Epoch: 0   Global Step: 26510   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:46:20,053-Speed 137.71 samples/sec   Loss 1.2003   LearningRate 0.000019   Epoch: 0   Global Step: 26520   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:46:22,324-Speed 140.94 samples/sec   Loss 1.1701   LearningRate 0.000019   Epoch: 0   Global Step: 26530   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:46:24,596-Speed 140.88 samples/sec   Loss 1.1892   LearningRate 0.000019   Epoch: 0   Global Step: 26540   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:46:26,877-Speed 140.35 samples/sec   Loss 1.1733   LearningRate 0.000019   Epoch: 0   Global Step: 26550   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:46:29,170-Speed 139.54 samples/sec   Loss 1.1784   LearningRate 0.000019   Epoch: 0   Global Step: 26560   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:46:31,446-Speed 140.65 samples/sec   Loss 1.1961   LearningRate 0.000019   Epoch: 0   Global Step: 26570   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:46:33,724-Speed 140.52 samples/sec   Loss 1.1933   LearningRate 0.000019   Epoch: 0   Global Step: 26580   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:46:36,013-Speed 139.85 samples/sec   Loss 1.1926   LearningRate 0.000019   Epoch: 0   Global Step: 26590   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:46:38,285-Speed 140.89 samples/sec   Loss 1.1810   LearningRate 0.000019   Epoch: 0   Global Step: 26600   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:46:40,593-Speed 138.66 samples/sec   Loss 1.1929   LearningRate 0.000019   Epoch: 0   Global Step: 26610   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:46:42,891-Speed 139.33 samples/sec   Loss 1.1793   LearningRate 0.000019   Epoch: 0   Global Step: 26620   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:46:45,177-Speed 140.00 samples/sec   Loss 1.2035   LearningRate 0.000018   Epoch: 0   Global Step: 26630   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:46:47,463-Speed 140.06 samples/sec   Loss 1.1860   LearningRate 0.000018   Epoch: 0   Global Step: 26640   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:46:49,734-Speed 140.90 samples/sec   Loss 1.1671   LearningRate 0.000018   Epoch: 0   Global Step: 26650   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:46:52,012-Speed 140.49 samples/sec   Loss 1.1542   LearningRate 0.000018   Epoch: 0   Global Step: 26660   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:46:54,299-Speed 140.02 samples/sec   Loss 1.2053   LearningRate 0.000018   Epoch: 0   Global Step: 26670   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:46:56,575-Speed 140.63 samples/sec   Loss 1.1632   LearningRate 0.000018   Epoch: 0   Global Step: 26680   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:46:58,851-Speed 140.59 samples/sec   Loss 1.1567   LearningRate 0.000018   Epoch: 0   Global Step: 26690   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:47:01,124-Speed 140.83 samples/sec   Loss 1.1569   LearningRate 0.000018   Epoch: 0   Global Step: 26700   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:47:03,411-Speed 140.01 samples/sec   Loss 1.1867   LearningRate 0.000018   Epoch: 0   Global Step: 26710   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:47:05,686-Speed 140.70 samples/sec   Loss 1.1785   LearningRate 0.000018   Epoch: 0   Global Step: 26720   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:47:07,956-Speed 140.96 samples/sec   Loss 1.1833   LearningRate 0.000018   Epoch: 0   Global Step: 26730   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:47:10,252-Speed 139.40 samples/sec   Loss 1.1589   LearningRate 0.000018   Epoch: 0   Global Step: 26740   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:47:12,511-Speed 141.71 samples/sec   Loss 1.1697   LearningRate 0.000018   Epoch: 0   Global Step: 26750   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:47:14,791-Speed 140.44 samples/sec   Loss 1.1814   LearningRate 0.000018   Epoch: 0   Global Step: 26760   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:47:17,074-Speed 140.20 samples/sec   Loss 1.1802   LearningRate 0.000018   Epoch: 0   Global Step: 26770   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:47:19,352-Speed 140.49 samples/sec   Loss 1.1734   LearningRate 0.000018   Epoch: 0   Global Step: 26780   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:47:21,634-Speed 140.27 samples/sec   Loss 1.1623   LearningRate 0.000018   Epoch: 0   Global Step: 26790   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:47:23,902-Speed 141.12 samples/sec   Loss 1.2070   LearningRate 0.000018   Epoch: 0   Global Step: 26800   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:47:26,173-Speed 140.93 samples/sec   Loss 1.2195   LearningRate 0.000018   Epoch: 0   Global Step: 26810   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:47:28,434-Speed 141.55 samples/sec   Loss 1.1651   LearningRate 0.000018   Epoch: 0   Global Step: 26820   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:47:30,708-Speed 140.80 samples/sec   Loss 1.1728   LearningRate 0.000018   Epoch: 0   Global Step: 26830   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:47:32,978-Speed 140.99 samples/sec   Loss 1.1809   LearningRate 0.000018   Epoch: 0   Global Step: 26840   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:47:35,265-Speed 139.94 samples/sec   Loss 1.2148   LearningRate 0.000018   Epoch: 0   Global Step: 26850   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:47:37,572-Speed 138.79 samples/sec   Loss 1.1823   LearningRate 0.000018   Epoch: 0   Global Step: 26860   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:47:39,850-Speed 140.50 samples/sec   Loss 1.2011   LearningRate 0.000018   Epoch: 0   Global Step: 26870   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:47:42,124-Speed 140.75 samples/sec   Loss 1.1922   LearningRate 0.000018   Epoch: 0   Global Step: 26880   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:47:44,407-Speed 140.25 samples/sec   Loss 1.1647   LearningRate 0.000018   Epoch: 0   Global Step: 26890   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:47:46,686-Speed 140.44 samples/sec   Loss 1.1794   LearningRate 0.000018   Epoch: 0   Global Step: 26900   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:47:48,972-Speed 139.99 samples/sec   Loss 1.1650   LearningRate 0.000018   Epoch: 0   Global Step: 26910   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:47:51,254-Speed 140.32 samples/sec   Loss 1.1938   LearningRate 0.000018   Epoch: 0   Global Step: 26920   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:47:53,522-Speed 141.14 samples/sec   Loss 1.1567   LearningRate 0.000018   Epoch: 0   Global Step: 26930   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:47:55,845-Speed 137.79 samples/sec   Loss 1.1766   LearningRate 0.000018   Epoch: 0   Global Step: 26940   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:47:58,181-Speed 137.02 samples/sec   Loss 1.1981   LearningRate 0.000018   Epoch: 0   Global Step: 26950   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:48:00,513-Speed 137.23 samples/sec   Loss 1.1668   LearningRate 0.000018   Epoch: 0   Global Step: 26960   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:48:02,802-Speed 139.84 samples/sec   Loss 1.1534   LearningRate 0.000018   Epoch: 0   Global Step: 26970   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:48:05,074-Speed 140.88 samples/sec   Loss 1.1556   LearningRate 0.000018   Epoch: 0   Global Step: 26980   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:48:07,351-Speed 140.62 samples/sec   Loss 1.1815   LearningRate 0.000018   Epoch: 0   Global Step: 26990   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:48:09,420-Val on RAF/AffectNet:
Training: 2023-08-17 22:48:09,526-Test: [0/48]	Time 0.106 (0.106)	Loss 0.6830 (0.6830)	Acc@1 85.938 (85.938)	Acc@5 98.438 (98.438)	Mem 5268MB
Training: 2023-08-17 22:48:10,588-Test: [10/48]	Time 0.105 (0.106)	Loss 0.5144 (0.5581)	Acc@1 95.312 (91.477)	Acc@5 98.438 (99.148)	Mem 5268MB
Training: 2023-08-17 22:48:11,669-Test: [20/48]	Time 0.105 (0.107)	Loss 0.5924 (0.5650)	Acc@1 92.188 (91.592)	Acc@5 96.875 (98.661)	Mem 5268MB
Training: 2023-08-17 22:48:12,735-Test: [30/48]	Time 0.106 (0.107)	Loss 0.5848 (0.5448)	Acc@1 90.625 (92.440)	Acc@5 98.438 (98.891)	Mem 5268MB
Training: 2023-08-17 22:48:13,840-Test: [40/48]	Time 0.107 (0.108)	Loss 0.5571 (0.5483)	Acc@1 90.625 (92.264)	Acc@5 98.438 (98.780)	Mem 5268MB
Training: 2023-08-17 22:48:14,598-[26999]Expression Loss: 0.54333
Training: 2023-08-17 22:48:14,599-[26999]Expression Acc@1: 92.43807
Training: 2023-08-17 22:48:14,599-[26999]Expression Acc@1-Highest: 92.47067
Training: 2023-08-17 22:48:14,599-[26999]Expression Acc@5: 98.82660
Training: 2023-08-17 22:48:14,599-[26999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 22:48:14,599-[26999]10 Times Expression Acc@1: 92.01760
Training: 2023-08-17 22:48:14,599-[26999]10 Times Expression Acc@1-Highest: 92.02738
Training: 2023-08-17 22:48:14,829-Speed 42.79 samples/sec   Loss 1.2060   LearningRate 0.000018   Epoch: 0   Global Step: 27000   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:48:17,112-Speed 140.20 samples/sec   Loss 1.1777   LearningRate 0.000018   Epoch: 0   Global Step: 27010   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:48:19,414-Speed 139.03 samples/sec   Loss 1.1981   LearningRate 0.000018   Epoch: 0   Global Step: 27020   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:48:21,699-Speed 140.10 samples/sec   Loss 1.1631   LearningRate 0.000018   Epoch: 0   Global Step: 27030   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:48:23,985-Speed 140.03 samples/sec   Loss 1.1793   LearningRate 0.000018   Epoch: 0   Global Step: 27040   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:48:26,264-Speed 140.47 samples/sec   Loss 1.1968   LearningRate 0.000018   Epoch: 0   Global Step: 27050   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:48:28,565-Speed 139.10 samples/sec   Loss 1.1720   LearningRate 0.000018   Epoch: 0   Global Step: 27060   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:48:30,857-Speed 139.64 samples/sec   Loss 1.1819   LearningRate 0.000018   Epoch: 0   Global Step: 27070   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:48:33,146-Speed 139.83 samples/sec   Loss 1.1914   LearningRate 0.000018   Epoch: 0   Global Step: 27080   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:48:35,420-Speed 140.74 samples/sec   Loss 1.1645   LearningRate 0.000018   Epoch: 0   Global Step: 27090   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:48:37,701-Speed 140.38 samples/sec   Loss 1.2068   LearningRate 0.000018   Epoch: 0   Global Step: 27100   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:48:39,999-Speed 139.27 samples/sec   Loss 1.1688   LearningRate 0.000018   Epoch: 0   Global Step: 27110   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:48:42,283-Speed 140.16 samples/sec   Loss 1.1516   LearningRate 0.000018   Epoch: 0   Global Step: 27120   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:48:44,578-Speed 139.47 samples/sec   Loss 1.1735   LearningRate 0.000018   Epoch: 0   Global Step: 27130   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:48:46,878-Speed 139.16 samples/sec   Loss 1.1940   LearningRate 0.000018   Epoch: 0   Global Step: 27140   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:48:49,198-Speed 137.96 samples/sec   Loss 1.1836   LearningRate 0.000018   Epoch: 0   Global Step: 27150   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:48:51,502-Speed 138.96 samples/sec   Loss 1.1792   LearningRate 0.000018   Epoch: 0   Global Step: 27160   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:48:53,789-Speed 139.95 samples/sec   Loss 1.1844   LearningRate 0.000018   Epoch: 0   Global Step: 27170   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:48:56,070-Speed 140.33 samples/sec   Loss 1.2097   LearningRate 0.000018   Epoch: 0   Global Step: 27180   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:48:58,360-Speed 139.77 samples/sec   Loss 1.1739   LearningRate 0.000018   Epoch: 0   Global Step: 27190   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:49:00,635-Speed 140.67 samples/sec   Loss 1.1585   LearningRate 0.000018   Epoch: 0   Global Step: 27200   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:49:02,925-Speed 139.76 samples/sec   Loss 1.1656   LearningRate 0.000018   Epoch: 0   Global Step: 27210   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:49:05,211-Speed 140.02 samples/sec   Loss 1.1604   LearningRate 0.000018   Epoch: 0   Global Step: 27220   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:49:07,493-Speed 140.27 samples/sec   Loss 1.1627   LearningRate 0.000018   Epoch: 0   Global Step: 27230   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:49:09,789-Speed 139.46 samples/sec   Loss 1.1779   LearningRate 0.000018   Epoch: 0   Global Step: 27240   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:49:12,067-Speed 140.49 samples/sec   Loss 1.1690   LearningRate 0.000018   Epoch: 0   Global Step: 27250   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:49:14,342-Speed 140.74 samples/sec   Loss 1.1762   LearningRate 0.000018   Epoch: 0   Global Step: 27260   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:49:16,652-Speed 138.56 samples/sec   Loss 1.1893   LearningRate 0.000018   Epoch: 0   Global Step: 27270   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:49:18,949-Speed 139.33 samples/sec   Loss 1.1642   LearningRate 0.000018   Epoch: 0   Global Step: 27280   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:49:21,227-Speed 140.50 samples/sec   Loss 1.1686   LearningRate 0.000018   Epoch: 0   Global Step: 27290   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:49:23,498-Speed 140.94 samples/sec   Loss 1.1892   LearningRate 0.000018   Epoch: 0   Global Step: 27300   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:49:25,773-Speed 140.71 samples/sec   Loss 1.2028   LearningRate 0.000018   Epoch: 0   Global Step: 27310   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:49:28,051-Speed 140.50 samples/sec   Loss 1.1766   LearningRate 0.000018   Epoch: 0   Global Step: 27320   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:49:30,324-Speed 140.85 samples/sec   Loss 1.1789   LearningRate 0.000018   Epoch: 0   Global Step: 27330   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:49:32,605-Speed 140.29 samples/sec   Loss 1.1937   LearningRate 0.000018   Epoch: 0   Global Step: 27340   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:49:34,880-Speed 140.71 samples/sec   Loss 1.1755   LearningRate 0.000018   Epoch: 0   Global Step: 27350   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:49:37,201-Speed 137.92 samples/sec   Loss 1.1605   LearningRate 0.000018   Epoch: 0   Global Step: 27360   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:49:39,502-Speed 139.13 samples/sec   Loss 1.1912   LearningRate 0.000018   Epoch: 0   Global Step: 27370   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:49:41,805-Speed 138.95 samples/sec   Loss 1.1669   LearningRate 0.000018   Epoch: 0   Global Step: 27380   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:49:44,120-Speed 138.25 samples/sec   Loss 1.1930   LearningRate 0.000018   Epoch: 0   Global Step: 27390   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:49:46,422-Speed 139.08 samples/sec   Loss 1.1894   LearningRate 0.000018   Epoch: 0   Global Step: 27400   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:49:48,726-Speed 138.93 samples/sec   Loss 1.1762   LearningRate 0.000018   Epoch: 0   Global Step: 27410   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:49:51,039-Speed 138.37 samples/sec   Loss 1.1845   LearningRate 0.000018   Epoch: 0   Global Step: 27420   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:49:53,344-Speed 138.87 samples/sec   Loss 1.1745   LearningRate 0.000018   Epoch: 0   Global Step: 27430   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:49:55,652-Speed 138.69 samples/sec   Loss 1.1833   LearningRate 0.000018   Epoch: 0   Global Step: 27440   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:49:57,970-Speed 138.12 samples/sec   Loss 1.1779   LearningRate 0.000018   Epoch: 0   Global Step: 27450   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:50:00,269-Speed 139.20 samples/sec   Loss 1.1550   LearningRate 0.000018   Epoch: 0   Global Step: 27460   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:50:02,557-Speed 139.93 samples/sec   Loss 1.1545   LearningRate 0.000018   Epoch: 0   Global Step: 27470   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:50:04,863-Speed 138.79 samples/sec   Loss 1.1567   LearningRate 0.000018   Epoch: 0   Global Step: 27480   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:50:07,191-Speed 137.51 samples/sec   Loss 1.1795   LearningRate 0.000018   Epoch: 0   Global Step: 27490   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:50:09,496-Speed 138.85 samples/sec   Loss 1.1721   LearningRate 0.000018   Epoch: 0   Global Step: 27500   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:50:11,789-Speed 139.59 samples/sec   Loss 1.1660   LearningRate 0.000018   Epoch: 0   Global Step: 27510   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:50:14,079-Speed 139.79 samples/sec   Loss 1.1714   LearningRate 0.000018   Epoch: 0   Global Step: 27520   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:50:16,382-Speed 138.97 samples/sec   Loss 1.1911   LearningRate 0.000018   Epoch: 0   Global Step: 27530   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:50:18,675-Speed 139.63 samples/sec   Loss 1.1581   LearningRate 0.000018   Epoch: 0   Global Step: 27540   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:50:20,967-Speed 139.64 samples/sec   Loss 1.1797   LearningRate 0.000018   Epoch: 0   Global Step: 27550   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:50:23,281-Speed 138.31 samples/sec   Loss 1.1566   LearningRate 0.000018   Epoch: 0   Global Step: 27560   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:50:25,575-Speed 139.56 samples/sec   Loss 1.1542   LearningRate 0.000018   Epoch: 0   Global Step: 27570   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:50:27,881-Speed 138.83 samples/sec   Loss 1.1314   LearningRate 0.000018   Epoch: 0   Global Step: 27580   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:50:30,206-Speed 137.62 samples/sec   Loss 1.1814   LearningRate 0.000018   Epoch: 0   Global Step: 27590   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:50:32,530-Speed 137.74 samples/sec   Loss 1.1690   LearningRate 0.000018   Epoch: 0   Global Step: 27600   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:50:34,857-Speed 137.60 samples/sec   Loss 1.1683   LearningRate 0.000018   Epoch: 0   Global Step: 27610   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:50:37,187-Speed 137.36 samples/sec   Loss 1.1779   LearningRate 0.000018   Epoch: 0   Global Step: 27620   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:50:39,508-Speed 137.88 samples/sec   Loss 1.1812   LearningRate 0.000018   Epoch: 0   Global Step: 27630   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:50:41,824-Speed 138.22 samples/sec   Loss 1.1629   LearningRate 0.000018   Epoch: 0   Global Step: 27640   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:50:44,133-Speed 138.63 samples/sec   Loss 1.1570   LearningRate 0.000018   Epoch: 0   Global Step: 27650   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:50:46,462-Speed 137.45 samples/sec   Loss 1.1810   LearningRate 0.000018   Epoch: 0   Global Step: 27660   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:50:48,792-Speed 137.34 samples/sec   Loss 1.1874   LearningRate 0.000018   Epoch: 0   Global Step: 27670   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:50:51,109-Speed 138.20 samples/sec   Loss 1.1602   LearningRate 0.000018   Epoch: 0   Global Step: 27680   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:50:53,409-Speed 139.15 samples/sec   Loss 1.1911   LearningRate 0.000018   Epoch: 0   Global Step: 27690   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:50:55,722-Speed 138.42 samples/sec   Loss 1.2058   LearningRate 0.000018   Epoch: 0   Global Step: 27700   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:50:58,004-Speed 140.26 samples/sec   Loss 1.1872   LearningRate 0.000018   Epoch: 0   Global Step: 27710   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:51:00,315-Speed 138.48 samples/sec   Loss 1.1764   LearningRate 0.000018   Epoch: 0   Global Step: 27720   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:51:02,628-Speed 138.38 samples/sec   Loss 1.1949   LearningRate 0.000018   Epoch: 0   Global Step: 27730   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:51:04,922-Speed 139.59 samples/sec   Loss 1.1865   LearningRate 0.000018   Epoch: 0   Global Step: 27740   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:51:07,219-Speed 139.31 samples/sec   Loss 1.1738   LearningRate 0.000018   Epoch: 0   Global Step: 27750   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:51:09,526-Speed 138.78 samples/sec   Loss 1.1773   LearningRate 0.000018   Epoch: 0   Global Step: 27760   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:51:11,815-Speed 139.85 samples/sec   Loss 1.2009   LearningRate 0.000018   Epoch: 0   Global Step: 27770   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:51:14,113-Speed 139.27 samples/sec   Loss 1.1730   LearningRate 0.000018   Epoch: 0   Global Step: 27780   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:51:16,413-Speed 139.17 samples/sec   Loss 1.1716   LearningRate 0.000018   Epoch: 0   Global Step: 27790   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:51:18,714-Speed 139.07 samples/sec   Loss 1.1964   LearningRate 0.000018   Epoch: 0   Global Step: 27800   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:51:21,024-Speed 138.57 samples/sec   Loss 1.1628   LearningRate 0.000018   Epoch: 0   Global Step: 27810   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:51:23,329-Speed 138.88 samples/sec   Loss 1.1542   LearningRate 0.000018   Epoch: 0   Global Step: 27820   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:51:25,638-Speed 138.66 samples/sec   Loss 1.1719   LearningRate 0.000018   Epoch: 0   Global Step: 27830   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:51:27,962-Speed 137.73 samples/sec   Loss 1.1555   LearningRate 0.000018   Epoch: 0   Global Step: 27840   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:51:30,265-Speed 139.00 samples/sec   Loss 1.1661   LearningRate 0.000018   Epoch: 0   Global Step: 27850   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:51:32,570-Speed 138.87 samples/sec   Loss 1.1747   LearningRate 0.000018   Epoch: 0   Global Step: 27860   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:51:34,886-Speed 138.21 samples/sec   Loss 1.1925   LearningRate 0.000018   Epoch: 0   Global Step: 27870   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:51:37,205-Speed 138.00 samples/sec   Loss 1.1871   LearningRate 0.000017   Epoch: 0   Global Step: 27880   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:51:39,517-Speed 138.46 samples/sec   Loss 1.1804   LearningRate 0.000017   Epoch: 0   Global Step: 27890   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:51:41,830-Speed 138.40 samples/sec   Loss 1.1822   LearningRate 0.000017   Epoch: 0   Global Step: 27900   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:51:44,153-Speed 137.76 samples/sec   Loss 1.1856   LearningRate 0.000017   Epoch: 0   Global Step: 27910   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:51:46,451-Speed 139.33 samples/sec   Loss 1.1943   LearningRate 0.000017   Epoch: 0   Global Step: 27920   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:51:48,759-Speed 138.69 samples/sec   Loss 1.1633   LearningRate 0.000017   Epoch: 0   Global Step: 27930   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:51:51,036-Speed 140.57 samples/sec   Loss 1.1727   LearningRate 0.000017   Epoch: 0   Global Step: 27940   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:51:53,362-Speed 137.64 samples/sec   Loss 1.1905   LearningRate 0.000017   Epoch: 0   Global Step: 27950   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:51:55,666-Speed 138.91 samples/sec   Loss 1.1676   LearningRate 0.000017   Epoch: 0   Global Step: 27960   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:51:57,969-Speed 138.98 samples/sec   Loss 1.1552   LearningRate 0.000017   Epoch: 0   Global Step: 27970   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:52:00,297-Speed 137.47 samples/sec   Loss 1.1671   LearningRate 0.000017   Epoch: 0   Global Step: 27980   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:52:02,594-Speed 139.36 samples/sec   Loss 1.1732   LearningRate 0.000017   Epoch: 0   Global Step: 27990   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:52:04,673-Val on RAF/AffectNet:
Training: 2023-08-17 22:52:04,782-Test: [0/48]	Time 0.109 (0.109)	Loss 0.5358 (0.5358)	Acc@1 90.625 (90.625)	Acc@5 98.438 (98.438)	Mem 5268MB
Training: 2023-08-17 22:52:05,868-Test: [10/48]	Time 0.111 (0.109)	Loss 0.5616 (0.5667)	Acc@1 93.750 (91.477)	Acc@5 100.000 (98.864)	Mem 5268MB
Training: 2023-08-17 22:52:06,957-Test: [20/48]	Time 0.108 (0.109)	Loss 0.6008 (0.5514)	Acc@1 92.188 (92.485)	Acc@5 95.312 (98.512)	Mem 5268MB
Training: 2023-08-17 22:52:08,038-Test: [30/48]	Time 0.107 (0.109)	Loss 0.4654 (0.5468)	Acc@1 95.312 (92.591)	Acc@5 100.000 (98.538)	Mem 5268MB
Training: 2023-08-17 22:52:09,125-Test: [40/48]	Time 0.112 (0.109)	Loss 0.6559 (0.5551)	Acc@1 87.500 (92.378)	Acc@5 96.875 (98.361)	Mem 5268MB
Training: 2023-08-17 22:52:09,868-[27999]Expression Loss: 0.55654
Training: 2023-08-17 22:52:09,868-[27999]Expression Acc@1: 92.11213
Training: 2023-08-17 22:52:09,868-[27999]Expression Acc@1-Highest: 92.47067
Training: 2023-08-17 22:52:09,868-[27999]Expression Acc@5: 98.56584
Training: 2023-08-17 22:52:09,868-[27999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 22:52:09,868-[27999]10 Times Expression Acc@1: 92.07627
Training: 2023-08-17 22:52:09,868-[27999]10 Times Expression Acc@1-Highest: 92.07627
Training: 2023-08-17 22:52:10,097-Speed 42.65 samples/sec   Loss 1.1793   LearningRate 0.000017   Epoch: 0   Global Step: 28000   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:52:12,368-Speed 140.94 samples/sec   Loss 1.2019   LearningRate 0.000017   Epoch: 0   Global Step: 28010   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:52:14,645-Speed 140.61 samples/sec   Loss 1.1426   LearningRate 0.000017   Epoch: 0   Global Step: 28020   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:52:16,938-Speed 139.61 samples/sec   Loss 1.1763   LearningRate 0.000017   Epoch: 0   Global Step: 28030   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:52:19,212-Speed 140.74 samples/sec   Loss 1.1811   LearningRate 0.000017   Epoch: 0   Global Step: 28040   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:52:21,503-Speed 139.70 samples/sec   Loss 1.1746   LearningRate 0.000017   Epoch: 0   Global Step: 28050   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:52:23,798-Speed 139.49 samples/sec   Loss 1.1941   LearningRate 0.000017   Epoch: 0   Global Step: 28060   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:52:26,095-Speed 139.35 samples/sec   Loss 1.1768   LearningRate 0.000017   Epoch: 0   Global Step: 28070   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:52:28,405-Speed 138.58 samples/sec   Loss 1.1679   LearningRate 0.000017   Epoch: 0   Global Step: 28080   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:52:30,710-Speed 138.87 samples/sec   Loss 1.1864   LearningRate 0.000017   Epoch: 0   Global Step: 28090   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:52:33,017-Speed 138.76 samples/sec   Loss 1.1777   LearningRate 0.000017   Epoch: 0   Global Step: 28100   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:52:35,329-Speed 138.43 samples/sec   Loss 1.1608   LearningRate 0.000017   Epoch: 0   Global Step: 28110   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:52:37,637-Speed 138.71 samples/sec   Loss 1.1998   LearningRate 0.000017   Epoch: 0   Global Step: 28120   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:52:39,942-Speed 138.85 samples/sec   Loss 1.1595   LearningRate 0.000017   Epoch: 0   Global Step: 28130   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:52:42,251-Speed 138.59 samples/sec   Loss 1.1942   LearningRate 0.000017   Epoch: 0   Global Step: 28140   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:52:44,559-Speed 138.71 samples/sec   Loss 1.1665   LearningRate 0.000017   Epoch: 0   Global Step: 28150   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:52:46,850-Speed 139.73 samples/sec   Loss 1.2113   LearningRate 0.000017   Epoch: 0   Global Step: 28160   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:52:49,128-Speed 140.53 samples/sec   Loss 1.1655   LearningRate 0.000017   Epoch: 0   Global Step: 28170   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:52:51,412-Speed 140.14 samples/sec   Loss 1.1557   LearningRate 0.000017   Epoch: 0   Global Step: 28180   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:52:53,707-Speed 139.47 samples/sec   Loss 1.1916   LearningRate 0.000017   Epoch: 0   Global Step: 28190   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:52:55,998-Speed 139.72 samples/sec   Loss 1.1923   LearningRate 0.000017   Epoch: 0   Global Step: 28200   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:52:58,297-Speed 139.17 samples/sec   Loss 1.2029   LearningRate 0.000017   Epoch: 0   Global Step: 28210   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:53:00,582-Speed 140.13 samples/sec   Loss 1.1769   LearningRate 0.000017   Epoch: 0   Global Step: 28220   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:53:02,875-Speed 139.59 samples/sec   Loss 1.1819   LearningRate 0.000017   Epoch: 0   Global Step: 28230   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:53:05,170-Speed 139.45 samples/sec   Loss 1.1636   LearningRate 0.000017   Epoch: 0   Global Step: 28240   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:53:07,465-Speed 139.46 samples/sec   Loss 1.1706   LearningRate 0.000017   Epoch: 0   Global Step: 28250   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:53:09,763-Speed 139.32 samples/sec   Loss 1.1597   LearningRate 0.000017   Epoch: 0   Global Step: 28260   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:53:12,052-Speed 139.83 samples/sec   Loss 1.1946   LearningRate 0.000017   Epoch: 0   Global Step: 28270   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:53:14,336-Speed 140.14 samples/sec   Loss 1.1776   LearningRate 0.000017   Epoch: 0   Global Step: 28280   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:53:16,635-Speed 139.24 samples/sec   Loss 1.1769   LearningRate 0.000017   Epoch: 0   Global Step: 28290   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:53:18,941-Speed 138.79 samples/sec   Loss 1.1644   LearningRate 0.000017   Epoch: 0   Global Step: 28300   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:53:21,237-Speed 139.42 samples/sec   Loss 1.1558   LearningRate 0.000017   Epoch: 0   Global Step: 28310   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:53:23,541-Speed 138.94 samples/sec   Loss 1.1757   LearningRate 0.000017   Epoch: 0   Global Step: 28320   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:53:25,842-Speed 139.09 samples/sec   Loss 1.1395   LearningRate 0.000017   Epoch: 0   Global Step: 28330   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:53:28,133-Speed 139.73 samples/sec   Loss 1.1680   LearningRate 0.000017   Epoch: 0   Global Step: 28340   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:53:30,433-Speed 139.15 samples/sec   Loss 1.1775   LearningRate 0.000017   Epoch: 0   Global Step: 28350   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:53:32,730-Speed 139.37 samples/sec   Loss 1.1637   LearningRate 0.000017   Epoch: 0   Global Step: 28360   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:53:35,036-Speed 138.79 samples/sec   Loss 1.1809   LearningRate 0.000017   Epoch: 0   Global Step: 28370   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:53:37,342-Speed 138.82 samples/sec   Loss 1.1725   LearningRate 0.000017   Epoch: 0   Global Step: 28380   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:53:39,640-Speed 139.26 samples/sec   Loss 1.1760   LearningRate 0.000017   Epoch: 0   Global Step: 28390   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:53:41,903-Speed 141.48 samples/sec   Loss 1.1854   LearningRate 0.000017   Epoch: 0   Global Step: 28400   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:53:44,212-Speed 138.60 samples/sec   Loss 1.2008   LearningRate 0.000017   Epoch: 0   Global Step: 28410   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:53:46,490-Speed 140.56 samples/sec   Loss 1.1872   LearningRate 0.000017   Epoch: 0   Global Step: 28420   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:53:48,791-Speed 139.11 samples/sec   Loss 1.1886   LearningRate 0.000017   Epoch: 0   Global Step: 28430   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:53:51,071-Speed 140.39 samples/sec   Loss 1.1757   LearningRate 0.000017   Epoch: 0   Global Step: 28440   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:53:53,354-Speed 140.17 samples/sec   Loss 1.1764   LearningRate 0.000017   Epoch: 0   Global Step: 28450   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:53:55,652-Speed 139.33 samples/sec   Loss 1.1776   LearningRate 0.000017   Epoch: 0   Global Step: 28460   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:53:57,938-Speed 140.03 samples/sec   Loss 1.1624   LearningRate 0.000017   Epoch: 0   Global Step: 28470   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:54:00,210-Speed 140.83 samples/sec   Loss 1.1594   LearningRate 0.000017   Epoch: 0   Global Step: 28480   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:54:02,506-Speed 139.46 samples/sec   Loss 1.1328   LearningRate 0.000017   Epoch: 0   Global Step: 28490   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:54:04,799-Speed 139.59 samples/sec   Loss 1.2158   LearningRate 0.000017   Epoch: 0   Global Step: 28500   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:54:07,080-Speed 140.32 samples/sec   Loss 1.1748   LearningRate 0.000017   Epoch: 0   Global Step: 28510   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:54:09,353-Speed 140.83 samples/sec   Loss 1.1534   LearningRate 0.000017   Epoch: 0   Global Step: 28520   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:54:11,638-Speed 140.09 samples/sec   Loss 1.1805   LearningRate 0.000017   Epoch: 0   Global Step: 28530   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:54:13,924-Speed 139.99 samples/sec   Loss 1.1822   LearningRate 0.000017   Epoch: 0   Global Step: 28540   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:54:16,207-Speed 140.21 samples/sec   Loss 1.2002   LearningRate 0.000017   Epoch: 0   Global Step: 28550   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:54:18,490-Speed 140.24 samples/sec   Loss 1.1929   LearningRate 0.000017   Epoch: 0   Global Step: 28560   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:54:20,775-Speed 140.02 samples/sec   Loss 1.1986   LearningRate 0.000017   Epoch: 0   Global Step: 28570   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:54:23,080-Speed 138.88 samples/sec   Loss 1.1940   LearningRate 0.000017   Epoch: 0   Global Step: 28580   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:54:25,367-Speed 139.95 samples/sec   Loss 1.1770   LearningRate 0.000017   Epoch: 0   Global Step: 28590   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:54:27,660-Speed 139.61 samples/sec   Loss 1.1855   LearningRate 0.000017   Epoch: 0   Global Step: 28600   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:54:29,954-Speed 139.56 samples/sec   Loss 1.1863   LearningRate 0.000017   Epoch: 0   Global Step: 28610   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:54:32,241-Speed 139.93 samples/sec   Loss 1.1688   LearningRate 0.000017   Epoch: 0   Global Step: 28620   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:54:34,542-Speed 139.14 samples/sec   Loss 1.1798   LearningRate 0.000017   Epoch: 0   Global Step: 28630   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:54:36,844-Speed 139.02 samples/sec   Loss 1.1550   LearningRate 0.000017   Epoch: 0   Global Step: 28640   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:54:39,133-Speed 139.80 samples/sec   Loss 1.1758   LearningRate 0.000017   Epoch: 0   Global Step: 28650   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:54:41,433-Speed 139.18 samples/sec   Loss 1.1594   LearningRate 0.000017   Epoch: 0   Global Step: 28660   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:54:43,735-Speed 139.09 samples/sec   Loss 1.1808   LearningRate 0.000017   Epoch: 0   Global Step: 28670   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:54:46,040-Speed 138.86 samples/sec   Loss 1.1490   LearningRate 0.000017   Epoch: 0   Global Step: 28680   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:54:48,337-Speed 139.35 samples/sec   Loss 1.1964   LearningRate 0.000017   Epoch: 0   Global Step: 28690   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:54:50,638-Speed 139.08 samples/sec   Loss 1.1631   LearningRate 0.000017   Epoch: 0   Global Step: 28700   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:54:52,945-Speed 138.78 samples/sec   Loss 1.1814   LearningRate 0.000017   Epoch: 0   Global Step: 28710   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:54:55,238-Speed 139.57 samples/sec   Loss 1.1471   LearningRate 0.000017   Epoch: 0   Global Step: 28720   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:54:57,542-Speed 138.94 samples/sec   Loss 1.1686   LearningRate 0.000017   Epoch: 0   Global Step: 28730   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:54:59,842-Speed 139.18 samples/sec   Loss 1.1683   LearningRate 0.000017   Epoch: 0   Global Step: 28740   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:55:02,133-Speed 139.67 samples/sec   Loss 1.1552   LearningRate 0.000017   Epoch: 0   Global Step: 28750   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:55:04,441-Speed 138.72 samples/sec   Loss 1.1787   LearningRate 0.000017   Epoch: 0   Global Step: 28760   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:55:06,740-Speed 139.22 samples/sec   Loss 1.1599   LearningRate 0.000017   Epoch: 0   Global Step: 28770   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:55:09,039-Speed 139.23 samples/sec   Loss 1.1921   LearningRate 0.000017   Epoch: 0   Global Step: 28780   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:55:11,343-Speed 138.94 samples/sec   Loss 1.1628   LearningRate 0.000017   Epoch: 0   Global Step: 28790   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:55:13,628-Speed 140.06 samples/sec   Loss 1.1550   LearningRate 0.000017   Epoch: 0   Global Step: 28800   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:55:15,923-Speed 139.47 samples/sec   Loss 1.1707   LearningRate 0.000017   Epoch: 0   Global Step: 28810   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:55:18,222-Speed 139.27 samples/sec   Loss 1.1452   LearningRate 0.000017   Epoch: 0   Global Step: 28820   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:55:20,510-Speed 139.87 samples/sec   Loss 1.1690   LearningRate 0.000017   Epoch: 0   Global Step: 28830   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:55:22,797-Speed 139.92 samples/sec   Loss 1.1845   LearningRate 0.000017   Epoch: 0   Global Step: 28840   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:55:25,105-Speed 138.72 samples/sec   Loss 1.1486   LearningRate 0.000017   Epoch: 0   Global Step: 28850   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:55:27,408-Speed 138.97 samples/sec   Loss 1.1623   LearningRate 0.000017   Epoch: 0   Global Step: 28860   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:55:29,712-Speed 138.93 samples/sec   Loss 1.2120   LearningRate 0.000017   Epoch: 0   Global Step: 28870   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:55:32,021-Speed 138.65 samples/sec   Loss 1.1586   LearningRate 0.000017   Epoch: 0   Global Step: 28880   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:55:34,326-Speed 138.83 samples/sec   Loss 1.1536   LearningRate 0.000017   Epoch: 0   Global Step: 28890   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:55:36,618-Speed 139.69 samples/sec   Loss 1.1552   LearningRate 0.000017   Epoch: 0   Global Step: 28900   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:55:38,913-Speed 139.46 samples/sec   Loss 1.1784   LearningRate 0.000017   Epoch: 0   Global Step: 28910   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:55:41,207-Speed 139.53 samples/sec   Loss 1.1739   LearningRate 0.000017   Epoch: 0   Global Step: 28920   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:55:43,484-Speed 140.55 samples/sec   Loss 1.1809   LearningRate 0.000017   Epoch: 0   Global Step: 28930   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:55:45,783-Speed 139.26 samples/sec   Loss 1.1677   LearningRate 0.000017   Epoch: 0   Global Step: 28940   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:55:48,093-Speed 138.53 samples/sec   Loss 1.2048   LearningRate 0.000017   Epoch: 0   Global Step: 28950   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:55:50,392-Speed 139.28 samples/sec   Loss 1.1830   LearningRate 0.000017   Epoch: 0   Global Step: 28960   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:55:52,687-Speed 139.42 samples/sec   Loss 1.1898   LearningRate 0.000017   Epoch: 0   Global Step: 28970   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:55:54,998-Speed 138.52 samples/sec   Loss 1.1764   LearningRate 0.000017   Epoch: 0   Global Step: 28980   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:55:57,313-Speed 138.24 samples/sec   Loss 1.1671   LearningRate 0.000017   Epoch: 0   Global Step: 28990   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:55:59,387-Val on RAF/AffectNet:
Training: 2023-08-17 22:55:59,496-Test: [0/48]	Time 0.108 (0.108)	Loss 0.6234 (0.6234)	Acc@1 89.062 (89.062)	Acc@5 96.875 (96.875)	Mem 5268MB
Training: 2023-08-17 22:56:00,564-Test: [10/48]	Time 0.111 (0.107)	Loss 0.5993 (0.6037)	Acc@1 90.625 (90.625)	Acc@5 96.875 (98.153)	Mem 5268MB
Training: 2023-08-17 22:56:01,608-Test: [20/48]	Time 0.104 (0.106)	Loss 0.4887 (0.6015)	Acc@1 93.750 (90.625)	Acc@5 100.000 (98.140)	Mem 5268MB
Training: 2023-08-17 22:56:02,640-Test: [30/48]	Time 0.104 (0.105)	Loss 0.6598 (0.5905)	Acc@1 89.062 (91.179)	Acc@5 98.438 (98.488)	Mem 5268MB
Training: 2023-08-17 22:56:03,694-Test: [40/48]	Time 0.104 (0.105)	Loss 0.6124 (0.5764)	Acc@1 92.188 (91.768)	Acc@5 95.312 (98.514)	Mem 5268MB
Training: 2023-08-17 22:56:04,428-[28999]Expression Loss: 0.57693
Training: 2023-08-17 22:56:04,428-[28999]Expression Acc@1: 91.72099
Training: 2023-08-17 22:56:04,428-[28999]Expression Acc@1-Highest: 92.47067
Training: 2023-08-17 22:56:04,428-[28999]Expression Acc@5: 98.53325
Training: 2023-08-17 22:56:04,428-[28999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 22:56:04,428-[28999]10 Times Expression Acc@1: 92.00130
Training: 2023-08-17 22:56:04,428-[28999]10 Times Expression Acc@1-Highest: 92.07627
Training: 2023-08-17 22:56:04,657-Speed 43.58 samples/sec   Loss 1.1844   LearningRate 0.000017   Epoch: 0   Global Step: 29000   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:56:06,962-Speed 138.90 samples/sec   Loss 1.1817   LearningRate 0.000017   Epoch: 0   Global Step: 29010   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:56:09,285-Speed 137.78 samples/sec   Loss 1.1602   LearningRate 0.000017   Epoch: 0   Global Step: 29020   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:56:11,600-Speed 138.25 samples/sec   Loss 1.1789   LearningRate 0.000017   Epoch: 0   Global Step: 29030   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:56:13,911-Speed 138.54 samples/sec   Loss 1.1829   LearningRate 0.000017   Epoch: 0   Global Step: 29040   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:56:16,232-Speed 137.88 samples/sec   Loss 1.1590   LearningRate 0.000017   Epoch: 0   Global Step: 29050   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:56:18,549-Speed 138.17 samples/sec   Loss 1.1622   LearningRate 0.000017   Epoch: 0   Global Step: 29060   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:56:20,868-Speed 138.02 samples/sec   Loss 1.1606   LearningRate 0.000017   Epoch: 0   Global Step: 29070   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:56:23,166-Speed 139.31 samples/sec   Loss 1.1416   LearningRate 0.000017   Epoch: 0   Global Step: 29080   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:56:25,442-Speed 140.62 samples/sec   Loss 1.1740   LearningRate 0.000017   Epoch: 0   Global Step: 29090   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:56:27,732-Speed 139.76 samples/sec   Loss 1.1681   LearningRate 0.000017   Epoch: 0   Global Step: 29100   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:56:30,020-Speed 139.91 samples/sec   Loss 1.1690   LearningRate 0.000017   Epoch: 0   Global Step: 29110   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:56:32,305-Speed 140.10 samples/sec   Loss 1.2002   LearningRate 0.000016   Epoch: 0   Global Step: 29120   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 22:56:34,578-Speed 140.81 samples/sec   Loss 1.1649   LearningRate 0.000016   Epoch: 0   Global Step: 29130   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:56:36,877-Speed 139.23 samples/sec   Loss 1.1768   LearningRate 0.000016   Epoch: 0   Global Step: 29140   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:56:39,167-Speed 139.82 samples/sec   Loss 1.1909   LearningRate 0.000016   Epoch: 0   Global Step: 29150   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:56:41,465-Speed 139.27 samples/sec   Loss 1.1871   LearningRate 0.000016   Epoch: 0   Global Step: 29160   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:56:43,763-Speed 139.32 samples/sec   Loss 1.1708   LearningRate 0.000016   Epoch: 0   Global Step: 29170   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:56:46,052-Speed 139.83 samples/sec   Loss 1.2336   LearningRate 0.000016   Epoch: 0   Global Step: 29180   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:56:48,352-Speed 139.16 samples/sec   Loss 1.1763   LearningRate 0.000016   Epoch: 0   Global Step: 29190   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:56:50,643-Speed 139.73 samples/sec   Loss 1.1789   LearningRate 0.000016   Epoch: 0   Global Step: 29200   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:56:52,934-Speed 139.72 samples/sec   Loss 1.1830   LearningRate 0.000016   Epoch: 0   Global Step: 29210   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:56:55,225-Speed 139.66 samples/sec   Loss 1.1781   LearningRate 0.000016   Epoch: 0   Global Step: 29220   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:56:57,525-Speed 139.23 samples/sec   Loss 1.1670   LearningRate 0.000016   Epoch: 0   Global Step: 29230   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:56:59,822-Speed 139.34 samples/sec   Loss 1.1778   LearningRate 0.000016   Epoch: 0   Global Step: 29240   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:57:02,140-Speed 138.06 samples/sec   Loss 1.1779   LearningRate 0.000016   Epoch: 0   Global Step: 29250   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:57:04,465-Speed 137.67 samples/sec   Loss 1.1639   LearningRate 0.000016   Epoch: 0   Global Step: 29260   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:57:06,786-Speed 137.91 samples/sec   Loss 1.1920   LearningRate 0.000016   Epoch: 0   Global Step: 29270   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:57:09,113-Speed 137.52 samples/sec   Loss 1.1304   LearningRate 0.000016   Epoch: 0   Global Step: 29280   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:57:11,440-Speed 137.56 samples/sec   Loss 1.1865   LearningRate 0.000016   Epoch: 0   Global Step: 29290   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:57:13,761-Speed 137.93 samples/sec   Loss 1.1500   LearningRate 0.000016   Epoch: 0   Global Step: 29300   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:57:16,089-Speed 137.49 samples/sec   Loss 1.1753   LearningRate 0.000016   Epoch: 0   Global Step: 29310   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:57:18,418-Speed 137.42 samples/sec   Loss 1.1640   LearningRate 0.000016   Epoch: 0   Global Step: 29320   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:57:20,740-Speed 137.86 samples/sec   Loss 1.1607   LearningRate 0.000016   Epoch: 0   Global Step: 29330   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:57:23,042-Speed 139.05 samples/sec   Loss 1.1616   LearningRate 0.000016   Epoch: 0   Global Step: 29340   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:57:25,341-Speed 139.26 samples/sec   Loss 1.1771   LearningRate 0.000016   Epoch: 0   Global Step: 29350   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:57:27,632-Speed 139.69 samples/sec   Loss 1.1633   LearningRate 0.000016   Epoch: 0   Global Step: 29360   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:57:29,918-Speed 140.02 samples/sec   Loss 1.1589   LearningRate 0.000016   Epoch: 0   Global Step: 29370   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:57:32,211-Speed 139.59 samples/sec   Loss 1.1767   LearningRate 0.000016   Epoch: 0   Global Step: 29380   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:57:34,492-Speed 140.31 samples/sec   Loss 1.1634   LearningRate 0.000016   Epoch: 0   Global Step: 29390   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:57:36,802-Speed 138.60 samples/sec   Loss 1.1852   LearningRate 0.000016   Epoch: 0   Global Step: 29400   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:57:39,085-Speed 140.20 samples/sec   Loss 1.1686   LearningRate 0.000016   Epoch: 0   Global Step: 29410   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:57:41,380-Speed 139.49 samples/sec   Loss 1.1853   LearningRate 0.000016   Epoch: 0   Global Step: 29420   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:57:43,680-Speed 139.18 samples/sec   Loss 1.1780   LearningRate 0.000016   Epoch: 0   Global Step: 29430   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:57:45,980-Speed 139.14 samples/sec   Loss 1.1970   LearningRate 0.000016   Epoch: 0   Global Step: 29440   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:57:48,292-Speed 138.46 samples/sec   Loss 1.1693   LearningRate 0.000016   Epoch: 0   Global Step: 29450   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:57:50,590-Speed 139.31 samples/sec   Loss 1.1635   LearningRate 0.000016   Epoch: 0   Global Step: 29460   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:57:52,882-Speed 139.66 samples/sec   Loss 1.2216   LearningRate 0.000016   Epoch: 0   Global Step: 29470   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:57:55,174-Speed 139.68 samples/sec   Loss 1.1814   LearningRate 0.000016   Epoch: 0   Global Step: 29480   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:57:57,472-Speed 139.30 samples/sec   Loss 1.1405   LearningRate 0.000016   Epoch: 0   Global Step: 29490   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:57:59,766-Speed 139.53 samples/sec   Loss 1.1828   LearningRate 0.000016   Epoch: 0   Global Step: 29500   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:58:02,053-Speed 139.97 samples/sec   Loss 1.1953   LearningRate 0.000016   Epoch: 0   Global Step: 29510   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:58:04,352-Speed 139.18 samples/sec   Loss 1.1816   LearningRate 0.000016   Epoch: 0   Global Step: 29520   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:58:06,637-Speed 140.09 samples/sec   Loss 1.1891   LearningRate 0.000016   Epoch: 0   Global Step: 29530   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:58:08,910-Speed 140.85 samples/sec   Loss 1.1892   LearningRate 0.000016   Epoch: 0   Global Step: 29540   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:58:11,190-Speed 140.36 samples/sec   Loss 1.1842   LearningRate 0.000016   Epoch: 0   Global Step: 29550   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:58:13,486-Speed 139.40 samples/sec   Loss 1.1499   LearningRate 0.000016   Epoch: 0   Global Step: 29560   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:58:15,755-Speed 141.10 samples/sec   Loss 1.1485   LearningRate 0.000016   Epoch: 0   Global Step: 29570   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:58:18,034-Speed 140.48 samples/sec   Loss 1.1470   LearningRate 0.000016   Epoch: 0   Global Step: 29580   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:58:20,312-Speed 140.47 samples/sec   Loss 1.1727   LearningRate 0.000016   Epoch: 0   Global Step: 29590   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:58:22,614-Speed 139.08 samples/sec   Loss 1.1649   LearningRate 0.000016   Epoch: 0   Global Step: 29600   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:58:24,879-Speed 141.32 samples/sec   Loss 1.1698   LearningRate 0.000016   Epoch: 0   Global Step: 29610   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:58:27,126-Speed 142.43 samples/sec   Loss 1.1540   LearningRate 0.000016   Epoch: 0   Global Step: 29620   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:58:29,369-Speed 142.69 samples/sec   Loss 1.1584   LearningRate 0.000016   Epoch: 0   Global Step: 29630   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:58:31,624-Speed 141.97 samples/sec   Loss 1.1549   LearningRate 0.000016   Epoch: 0   Global Step: 29640   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:58:33,917-Speed 139.55 samples/sec   Loss 1.2028   LearningRate 0.000016   Epoch: 0   Global Step: 29650   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:58:36,231-Speed 138.34 samples/sec   Loss 1.1866   LearningRate 0.000016   Epoch: 0   Global Step: 29660   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:58:38,544-Speed 138.42 samples/sec   Loss 1.1949   LearningRate 0.000016   Epoch: 0   Global Step: 29670   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:58:40,844-Speed 139.14 samples/sec   Loss 1.1912   LearningRate 0.000016   Epoch: 0   Global Step: 29680   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:58:43,157-Speed 138.40 samples/sec   Loss 1.1774   LearningRate 0.000016   Epoch: 0   Global Step: 29690   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:58:45,459-Speed 139.00 samples/sec   Loss 1.1660   LearningRate 0.000016   Epoch: 0   Global Step: 29700   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:58:47,761-Speed 139.07 samples/sec   Loss 1.1733   LearningRate 0.000016   Epoch: 0   Global Step: 29710   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:58:50,077-Speed 138.21 samples/sec   Loss 1.1795   LearningRate 0.000016   Epoch: 0   Global Step: 29720   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:58:52,391-Speed 138.29 samples/sec   Loss 1.1622   LearningRate 0.000016   Epoch: 0   Global Step: 29730   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:58:54,704-Speed 138.40 samples/sec   Loss 1.1478   LearningRate 0.000016   Epoch: 0   Global Step: 29740   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:58:57,009-Speed 138.91 samples/sec   Loss 1.1783   LearningRate 0.000016   Epoch: 0   Global Step: 29750   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:58:59,328-Speed 138.03 samples/sec   Loss 1.1520   LearningRate 0.000016   Epoch: 0   Global Step: 29760   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:59:01,632-Speed 138.87 samples/sec   Loss 1.1921   LearningRate 0.000016   Epoch: 0   Global Step: 29770   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:59:03,938-Speed 138.84 samples/sec   Loss 1.1940   LearningRate 0.000016   Epoch: 0   Global Step: 29780   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:59:06,240-Speed 139.06 samples/sec   Loss 1.1598   LearningRate 0.000016   Epoch: 0   Global Step: 29790   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:59:08,539-Speed 139.21 samples/sec   Loss 1.1769   LearningRate 0.000016   Epoch: 0   Global Step: 29800   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:59:10,837-Speed 139.32 samples/sec   Loss 1.1701   LearningRate 0.000016   Epoch: 0   Global Step: 29810   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:59:13,123-Speed 140.03 samples/sec   Loss 1.1656   LearningRate 0.000016   Epoch: 0   Global Step: 29820   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:59:15,410-Speed 139.96 samples/sec   Loss 1.1774   LearningRate 0.000016   Epoch: 0   Global Step: 29830   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:59:17,710-Speed 139.13 samples/sec   Loss 1.1544   LearningRate 0.000016   Epoch: 0   Global Step: 29840   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:59:20,013-Speed 138.99 samples/sec   Loss 1.1605   LearningRate 0.000016   Epoch: 0   Global Step: 29850   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:59:22,320-Speed 138.75 samples/sec   Loss 1.1953   LearningRate 0.000016   Epoch: 0   Global Step: 29860   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:59:24,627-Speed 138.77 samples/sec   Loss 1.1961   LearningRate 0.000016   Epoch: 0   Global Step: 29870   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:59:26,924-Speed 139.32 samples/sec   Loss 1.1405   LearningRate 0.000016   Epoch: 0   Global Step: 29880   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:59:29,208-Speed 140.19 samples/sec   Loss 1.2167   LearningRate 0.000016   Epoch: 0   Global Step: 29890   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:59:31,515-Speed 138.70 samples/sec   Loss 1.1475   LearningRate 0.000016   Epoch: 0   Global Step: 29900   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:59:33,817-Speed 139.08 samples/sec   Loss 1.1749   LearningRate 0.000016   Epoch: 0   Global Step: 29910   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 22:59:36,104-Speed 139.93 samples/sec   Loss 1.1225   LearningRate 0.000016   Epoch: 0   Global Step: 29920   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:59:38,405-Speed 139.14 samples/sec   Loss 1.2146   LearningRate 0.000016   Epoch: 0   Global Step: 29930   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:59:40,729-Speed 137.71 samples/sec   Loss 1.1744   LearningRate 0.000016   Epoch: 0   Global Step: 29940   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:59:43,053-Speed 137.70 samples/sec   Loss 1.2003   LearningRate 0.000016   Epoch: 0   Global Step: 29950   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:59:45,385-Speed 137.27 samples/sec   Loss 1.2166   LearningRate 0.000016   Epoch: 0   Global Step: 29960   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:59:47,717-Speed 137.29 samples/sec   Loss 1.1638   LearningRate 0.000016   Epoch: 0   Global Step: 29970   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:59:50,037-Speed 137.96 samples/sec   Loss 1.1621   LearningRate 0.000016   Epoch: 0   Global Step: 29980   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:59:52,362-Speed 137.70 samples/sec   Loss 1.1794   LearningRate 0.000016   Epoch: 0   Global Step: 29990   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 22:59:54,444-Val on RAF/AffectNet:
Training: 2023-08-17 22:59:54,552-Test: [0/48]	Time 0.108 (0.108)	Loss 0.5686 (0.5686)	Acc@1 93.750 (93.750)	Acc@5 96.875 (96.875)	Mem 5268MB
Training: 2023-08-17 22:59:55,623-Test: [10/48]	Time 0.106 (0.107)	Loss 0.5627 (0.5200)	Acc@1 87.500 (92.614)	Acc@5 100.000 (98.864)	Mem 5268MB
Training: 2023-08-17 22:59:56,694-Test: [20/48]	Time 0.104 (0.107)	Loss 0.5736 (0.5294)	Acc@1 92.188 (92.336)	Acc@5 98.438 (98.735)	Mem 5268MB
Training: 2023-08-17 22:59:57,767-Test: [30/48]	Time 0.107 (0.107)	Loss 0.5516 (0.5388)	Acc@1 92.188 (91.835)	Acc@5 98.438 (98.538)	Mem 5268MB
Training: 2023-08-17 22:59:58,838-Test: [40/48]	Time 0.105 (0.107)	Loss 0.5988 (0.5440)	Acc@1 85.938 (91.502)	Acc@5 100.000 (98.514)	Mem 5268MB
Training: 2023-08-17 22:59:59,587-[29999]Expression Loss: 0.54166
Training: 2023-08-17 22:59:59,587-[29999]Expression Acc@1: 91.85137
Training: 2023-08-17 22:59:59,587-[29999]Expression Acc@1-Highest: 92.47067
Training: 2023-08-17 22:59:59,587-[29999]Expression Acc@5: 98.50065
Training: 2023-08-17 22:59:59,587-[29999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 22:59:59,587-[29999]10 Times Expression Acc@1: 91.96545
Training: 2023-08-17 22:59:59,587-[29999]10 Times Expression Acc@1-Highest: 92.07627
Training: 2023-08-17 23:00:00,190-Speed 40.88 samples/sec   Loss 1.1583   LearningRate 0.000016   Epoch: 0   Global Step: 30000   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:00:02,482-Speed 139.63 samples/sec   Loss 1.1776   LearningRate 0.000016   Epoch: 0   Global Step: 30010   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:00:04,758-Speed 140.65 samples/sec   Loss 1.1763   LearningRate 0.000016   Epoch: 0   Global Step: 30020   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:00:07,030-Speed 140.83 samples/sec   Loss 1.1936   LearningRate 0.000016   Epoch: 0   Global Step: 30030   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:00:09,319-Speed 139.86 samples/sec   Loss 1.1447   LearningRate 0.000016   Epoch: 0   Global Step: 30040   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:00:11,608-Speed 139.87 samples/sec   Loss 1.1867   LearningRate 0.000016   Epoch: 0   Global Step: 30050   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:00:13,900-Speed 139.66 samples/sec   Loss 1.1873   LearningRate 0.000016   Epoch: 0   Global Step: 30060   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:00:16,186-Speed 140.01 samples/sec   Loss 1.1737   LearningRate 0.000016   Epoch: 0   Global Step: 30070   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:00:18,481-Speed 139.48 samples/sec   Loss 1.1826   LearningRate 0.000016   Epoch: 0   Global Step: 30080   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:00:20,768-Speed 139.96 samples/sec   Loss 1.1598   LearningRate 0.000016   Epoch: 0   Global Step: 30090   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:00:23,058-Speed 139.78 samples/sec   Loss 1.1521   LearningRate 0.000016   Epoch: 0   Global Step: 30100   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:00:25,342-Speed 140.11 samples/sec   Loss 1.1489   LearningRate 0.000016   Epoch: 0   Global Step: 30110   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:00:27,638-Speed 139.44 samples/sec   Loss 1.1526   LearningRate 0.000016   Epoch: 0   Global Step: 30120   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:00:29,970-Speed 137.26 samples/sec   Loss 1.1846   LearningRate 0.000016   Epoch: 0   Global Step: 30130   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:00:32,259-Speed 139.83 samples/sec   Loss 1.1729   LearningRate 0.000016   Epoch: 0   Global Step: 30140   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:00:34,564-Speed 138.87 samples/sec   Loss 1.1633   LearningRate 0.000016   Epoch: 0   Global Step: 30150   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:00:36,874-Speed 138.59 samples/sec   Loss 1.1548   LearningRate 0.000016   Epoch: 0   Global Step: 30160   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:00:39,173-Speed 139.19 samples/sec   Loss 1.1592   LearningRate 0.000016   Epoch: 0   Global Step: 30170   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:00:41,494-Speed 137.96 samples/sec   Loss 1.2096   LearningRate 0.000016   Epoch: 0   Global Step: 30180   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:00:43,767-Speed 140.80 samples/sec   Loss 1.1583   LearningRate 0.000016   Epoch: 0   Global Step: 30190   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:00:46,047-Speed 140.38 samples/sec   Loss 1.1710   LearningRate 0.000016   Epoch: 0   Global Step: 30200   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:00:48,326-Speed 140.45 samples/sec   Loss 1.1645   LearningRate 0.000016   Epoch: 0   Global Step: 30210   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:00:50,601-Speed 140.71 samples/sec   Loss 1.1782   LearningRate 0.000016   Epoch: 0   Global Step: 30220   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:00:52,882-Speed 140.32 samples/sec   Loss 1.1860   LearningRate 0.000016   Epoch: 0   Global Step: 30230   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:00:55,172-Speed 139.77 samples/sec   Loss 1.1593   LearningRate 0.000016   Epoch: 0   Global Step: 30240   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:00:57,460-Speed 139.95 samples/sec   Loss 1.1607   LearningRate 0.000016   Epoch: 0   Global Step: 30250   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:00:59,735-Speed 140.69 samples/sec   Loss 1.1776   LearningRate 0.000016   Epoch: 0   Global Step: 30260   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:01:02,000-Speed 141.33 samples/sec   Loss 1.1597   LearningRate 0.000016   Epoch: 0   Global Step: 30270   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:01:04,290-Speed 139.75 samples/sec   Loss 1.1925   LearningRate 0.000016   Epoch: 0   Global Step: 30280   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:01:06,570-Speed 140.39 samples/sec   Loss 1.1552   LearningRate 0.000016   Epoch: 0   Global Step: 30290   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:01:08,859-Speed 139.85 samples/sec   Loss 1.1631   LearningRate 0.000016   Epoch: 0   Global Step: 30300   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:01:11,119-Speed 141.65 samples/sec   Loss 1.1663   LearningRate 0.000016   Epoch: 0   Global Step: 30310   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:01:13,421-Speed 139.04 samples/sec   Loss 1.1917   LearningRate 0.000016   Epoch: 0   Global Step: 30320   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:01:15,707-Speed 140.04 samples/sec   Loss 1.1856   LearningRate 0.000016   Epoch: 0   Global Step: 30330   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:01:17,993-Speed 140.01 samples/sec   Loss 1.1813   LearningRate 0.000016   Epoch: 0   Global Step: 30340   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:01:20,280-Speed 139.96 samples/sec   Loss 1.1654   LearningRate 0.000015   Epoch: 0   Global Step: 30350   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:01:22,567-Speed 139.93 samples/sec   Loss 1.1757   LearningRate 0.000015   Epoch: 0   Global Step: 30360   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:01:24,858-Speed 139.71 samples/sec   Loss 1.1769   LearningRate 0.000015   Epoch: 0   Global Step: 30370   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:01:27,145-Speed 139.98 samples/sec   Loss 1.1411   LearningRate 0.000015   Epoch: 0   Global Step: 30380   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:01:29,427-Speed 140.26 samples/sec   Loss 1.1567   LearningRate 0.000015   Epoch: 0   Global Step: 30390   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:01:31,715-Speed 139.93 samples/sec   Loss 1.1871   LearningRate 0.000015   Epoch: 0   Global Step: 30400   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:01:33,994-Speed 140.39 samples/sec   Loss 1.1833   LearningRate 0.000015   Epoch: 0   Global Step: 30410   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:01:36,262-Speed 141.19 samples/sec   Loss 1.1791   LearningRate 0.000015   Epoch: 0   Global Step: 30420   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:01:38,556-Speed 139.50 samples/sec   Loss 1.1628   LearningRate 0.000015   Epoch: 0   Global Step: 30430   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:01:40,848-Speed 139.67 samples/sec   Loss 1.2038   LearningRate 0.000015   Epoch: 0   Global Step: 30440   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:01:43,144-Speed 139.44 samples/sec   Loss 1.1810   LearningRate 0.000015   Epoch: 0   Global Step: 30450   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:01:45,431-Speed 139.92 samples/sec   Loss 1.1719   LearningRate 0.000015   Epoch: 0   Global Step: 30460   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:01:47,724-Speed 139.62 samples/sec   Loss 1.1892   LearningRate 0.000015   Epoch: 0   Global Step: 30470   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:01:50,030-Speed 138.81 samples/sec   Loss 1.1859   LearningRate 0.000015   Epoch: 0   Global Step: 30480   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:01:52,318-Speed 139.91 samples/sec   Loss 1.1826   LearningRate 0.000015   Epoch: 0   Global Step: 30490   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:01:54,620-Speed 139.03 samples/sec   Loss 1.1701   LearningRate 0.000015   Epoch: 0   Global Step: 30500   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:01:56,920-Speed 139.16 samples/sec   Loss 1.1873   LearningRate 0.000015   Epoch: 0   Global Step: 30510   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:01:59,221-Speed 139.12 samples/sec   Loss 1.1658   LearningRate 0.000015   Epoch: 0   Global Step: 30520   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:02:01,521-Speed 139.18 samples/sec   Loss 1.1559   LearningRate 0.000015   Epoch: 0   Global Step: 30530   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:02:03,813-Speed 139.63 samples/sec   Loss 1.1706   LearningRate 0.000015   Epoch: 0   Global Step: 30540   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:02:06,098-Speed 140.09 samples/sec   Loss 1.1903   LearningRate 0.000015   Epoch: 0   Global Step: 30550   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:02:08,404-Speed 138.86 samples/sec   Loss 1.1646   LearningRate 0.000015   Epoch: 0   Global Step: 30560   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:02:10,699-Speed 139.42 samples/sec   Loss 1.1767   LearningRate 0.000015   Epoch: 0   Global Step: 30570   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:02:12,973-Speed 140.82 samples/sec   Loss 1.1679   LearningRate 0.000015   Epoch: 0   Global Step: 30580   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:02:15,244-Speed 140.91 samples/sec   Loss 1.1565   LearningRate 0.000015   Epoch: 0   Global Step: 30590   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:02:17,516-Speed 140.87 samples/sec   Loss 1.1619   LearningRate 0.000015   Epoch: 0   Global Step: 30600   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:02:19,805-Speed 139.86 samples/sec   Loss 1.1647   LearningRate 0.000015   Epoch: 0   Global Step: 30610   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:02:22,076-Speed 140.98 samples/sec   Loss 1.1630   LearningRate 0.000015   Epoch: 0   Global Step: 30620   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:02:24,367-Speed 139.70 samples/sec   Loss 1.1716   LearningRate 0.000015   Epoch: 0   Global Step: 30630   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:02:26,642-Speed 140.71 samples/sec   Loss 1.1397   LearningRate 0.000015   Epoch: 0   Global Step: 30640   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:02:28,929-Speed 139.91 samples/sec   Loss 1.1708   LearningRate 0.000015   Epoch: 0   Global Step: 30650   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:02:31,186-Speed 141.83 samples/sec   Loss 1.1898   LearningRate 0.000015   Epoch: 0   Global Step: 30660   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:02:33,457-Speed 140.93 samples/sec   Loss 1.1625   LearningRate 0.000015   Epoch: 0   Global Step: 30670   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:02:35,722-Speed 141.35 samples/sec   Loss 1.1697   LearningRate 0.000015   Epoch: 0   Global Step: 30680   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:02:38,000-Speed 140.46 samples/sec   Loss 1.1768   LearningRate 0.000015   Epoch: 0   Global Step: 30690   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:02:40,267-Speed 141.22 samples/sec   Loss 1.1769   LearningRate 0.000015   Epoch: 0   Global Step: 30700   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:02:42,545-Speed 140.49 samples/sec   Loss 1.1802   LearningRate 0.000015   Epoch: 0   Global Step: 30710   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:02:44,823-Speed 140.52 samples/sec   Loss 1.1601   LearningRate 0.000015   Epoch: 0   Global Step: 30720   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:02:47,103-Speed 140.39 samples/sec   Loss 1.1639   LearningRate 0.000015   Epoch: 0   Global Step: 30730   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:02:49,382-Speed 140.46 samples/sec   Loss 1.1589   LearningRate 0.000015   Epoch: 0   Global Step: 30740   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:02:51,657-Speed 140.69 samples/sec   Loss 1.1743   LearningRate 0.000015   Epoch: 0   Global Step: 30750   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:02:53,938-Speed 140.36 samples/sec   Loss 1.1876   LearningRate 0.000015   Epoch: 0   Global Step: 30760   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:02:56,230-Speed 139.64 samples/sec   Loss 1.2189   LearningRate 0.000015   Epoch: 0   Global Step: 30770   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:02:58,526-Speed 139.37 samples/sec   Loss 1.1772   LearningRate 0.000015   Epoch: 0   Global Step: 30780   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:03:00,811-Speed 140.10 samples/sec   Loss 1.1581   LearningRate 0.000015   Epoch: 0   Global Step: 30790   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:03:03,096-Speed 140.10 samples/sec   Loss 1.1455   LearningRate 0.000015   Epoch: 0   Global Step: 30800   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:03:05,400-Speed 138.93 samples/sec   Loss 1.1795   LearningRate 0.000015   Epoch: 0   Global Step: 30810   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:03:07,711-Speed 138.47 samples/sec   Loss 1.1866   LearningRate 0.000015   Epoch: 0   Global Step: 30820   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:03:10,015-Speed 138.94 samples/sec   Loss 1.1727   LearningRate 0.000015   Epoch: 0   Global Step: 30830   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:03:12,322-Speed 138.77 samples/sec   Loss 1.1736   LearningRate 0.000015   Epoch: 0   Global Step: 30840   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:03:14,617-Speed 139.48 samples/sec   Loss 1.1646   LearningRate 0.000015   Epoch: 0   Global Step: 30850   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:03:16,920-Speed 139.01 samples/sec   Loss 1.1483   LearningRate 0.000015   Epoch: 0   Global Step: 30860   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:03:19,230-Speed 138.54 samples/sec   Loss 1.1614   LearningRate 0.000015   Epoch: 0   Global Step: 30870   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:03:21,529-Speed 139.25 samples/sec   Loss 1.1605   LearningRate 0.000015   Epoch: 0   Global Step: 30880   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:03:23,830-Speed 139.10 samples/sec   Loss 1.1455   LearningRate 0.000015   Epoch: 0   Global Step: 30890   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:03:26,129-Speed 139.23 samples/sec   Loss 1.1600   LearningRate 0.000015   Epoch: 0   Global Step: 30900   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:03:28,444-Speed 138.25 samples/sec   Loss 1.1731   LearningRate 0.000015   Epoch: 0   Global Step: 30910   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:03:30,747-Speed 139.04 samples/sec   Loss 1.1653   LearningRate 0.000015   Epoch: 0   Global Step: 30920   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:03:33,064-Speed 138.13 samples/sec   Loss 1.1625   LearningRate 0.000015   Epoch: 0   Global Step: 30930   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:03:35,359-Speed 139.45 samples/sec   Loss 1.1753   LearningRate 0.000015   Epoch: 0   Global Step: 30940   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:03:37,666-Speed 138.76 samples/sec   Loss 1.1547   LearningRate 0.000015   Epoch: 0   Global Step: 30950   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:03:39,959-Speed 139.60 samples/sec   Loss 1.1616   LearningRate 0.000015   Epoch: 0   Global Step: 30960   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:03:42,250-Speed 139.70 samples/sec   Loss 1.1532   LearningRate 0.000015   Epoch: 0   Global Step: 30970   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:03:44,547-Speed 139.38 samples/sec   Loss 1.1873   LearningRate 0.000015   Epoch: 0   Global Step: 30980   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:03:46,856-Speed 138.64 samples/sec   Loss 1.1892   LearningRate 0.000015   Epoch: 0   Global Step: 30990   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:03:48,916-Val on RAF/AffectNet:
Training: 2023-08-17 23:03:49,024-Test: [0/48]	Time 0.108 (0.108)	Loss 0.5907 (0.5907)	Acc@1 92.188 (92.188)	Acc@5 96.875 (96.875)	Mem 5268MB
Training: 2023-08-17 23:03:50,090-Test: [10/48]	Time 0.107 (0.107)	Loss 0.5165 (0.5614)	Acc@1 93.750 (92.188)	Acc@5 100.000 (98.722)	Mem 5268MB
Training: 2023-08-17 23:03:51,150-Test: [20/48]	Time 0.109 (0.106)	Loss 0.6559 (0.5621)	Acc@1 87.500 (91.741)	Acc@5 98.438 (98.735)	Mem 5268MB
Training: 2023-08-17 23:03:52,216-Test: [30/48]	Time 0.106 (0.106)	Loss 0.4759 (0.5742)	Acc@1 96.875 (91.482)	Acc@5 98.438 (98.387)	Mem 5268MB
Training: 2023-08-17 23:03:53,299-Test: [40/48]	Time 0.105 (0.107)	Loss 0.5210 (0.5644)	Acc@1 95.312 (91.768)	Acc@5 100.000 (98.552)	Mem 5268MB
Training: 2023-08-17 23:03:54,033-[30999]Expression Loss: 0.56307
Training: 2023-08-17 23:03:54,033-[30999]Expression Acc@1: 91.85137
Training: 2023-08-17 23:03:54,033-[30999]Expression Acc@1-Highest: 92.47067
Training: 2023-08-17 23:03:54,034-[30999]Expression Acc@5: 98.56584
Training: 2023-08-17 23:03:54,034-[30999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 23:03:54,034-[30999]10 Times Expression Acc@1: 91.97197
Training: 2023-08-17 23:03:54,034-[30999]10 Times Expression Acc@1-Highest: 92.07627
Training: 2023-08-17 23:03:54,263-Speed 43.21 samples/sec   Loss 1.1819   LearningRate 0.000015   Epoch: 0   Global Step: 31000   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:03:56,551-Speed 139.92 samples/sec   Loss 1.1712   LearningRate 0.000015   Epoch: 0   Global Step: 31010   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:03:58,836-Speed 140.05 samples/sec   Loss 1.1530   LearningRate 0.000015   Epoch: 0   Global Step: 31020   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:04:01,127-Speed 139.75 samples/sec   Loss 1.1526   LearningRate 0.000015   Epoch: 0   Global Step: 31030   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:04:03,405-Speed 140.50 samples/sec   Loss 1.1811   LearningRate 0.000015   Epoch: 0   Global Step: 31040   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:04:05,692-Speed 139.95 samples/sec   Loss 1.1754   LearningRate 0.000015   Epoch: 0   Global Step: 31050   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:04:08,004-Speed 138.41 samples/sec   Loss 1.1625   LearningRate 0.000015   Epoch: 0   Global Step: 31060   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:04:10,326-Speed 137.92 samples/sec   Loss 1.1659   LearningRate 0.000015   Epoch: 0   Global Step: 31070   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:04:12,649-Speed 137.79 samples/sec   Loss 1.1647   LearningRate 0.000015   Epoch: 0   Global Step: 31080   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:04:14,969-Speed 137.92 samples/sec   Loss 1.1699   LearningRate 0.000015   Epoch: 0   Global Step: 31090   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:04:17,290-Speed 137.95 samples/sec   Loss 1.1584   LearningRate 0.000015   Epoch: 0   Global Step: 31100   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:04:19,611-Speed 137.90 samples/sec   Loss 1.1849   LearningRate 0.000015   Epoch: 0   Global Step: 31110   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:04:21,936-Speed 137.65 samples/sec   Loss 1.1702   LearningRate 0.000015   Epoch: 0   Global Step: 31120   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:04:24,270-Speed 137.16 samples/sec   Loss 1.1619   LearningRate 0.000015   Epoch: 0   Global Step: 31130   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:04:26,578-Speed 138.67 samples/sec   Loss 1.1912   LearningRate 0.000015   Epoch: 0   Global Step: 31140   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:04:28,911-Speed 137.23 samples/sec   Loss 1.1595   LearningRate 0.000015   Epoch: 0   Global Step: 31150   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:04:31,233-Speed 137.84 samples/sec   Loss 1.1803   LearningRate 0.000015   Epoch: 0   Global Step: 31160   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:04:33,557-Speed 137.72 samples/sec   Loss 1.1718   LearningRate 0.000015   Epoch: 0   Global Step: 31170   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:04:35,890-Speed 137.24 samples/sec   Loss 1.1692   LearningRate 0.000015   Epoch: 0   Global Step: 31180   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:04:38,177-Speed 139.93 samples/sec   Loss 1.1601   LearningRate 0.000015   Epoch: 0   Global Step: 31190   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:04:40,457-Speed 140.42 samples/sec   Loss 1.1825   LearningRate 0.000015   Epoch: 0   Global Step: 31200   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:04:42,768-Speed 138.48 samples/sec   Loss 1.1683   LearningRate 0.000015   Epoch: 0   Global Step: 31210   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:04:45,072-Speed 138.93 samples/sec   Loss 1.1782   LearningRate 0.000015   Epoch: 0   Global Step: 31220   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:04:47,362-Speed 139.81 samples/sec   Loss 1.1582   LearningRate 0.000015   Epoch: 0   Global Step: 31230   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:04:49,660-Speed 139.25 samples/sec   Loss 1.1632   LearningRate 0.000015   Epoch: 0   Global Step: 31240   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:04:52,273-Speed 122.52 samples/sec   Loss 1.1442   LearningRate 0.000015   Epoch: 1   Global Step: 31250   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:04:54,568-Speed 139.51 samples/sec   Loss 1.1791   LearningRate 0.000015   Epoch: 1   Global Step: 31260   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:04:56,866-Speed 139.28 samples/sec   Loss 1.1562   LearningRate 0.000015   Epoch: 1   Global Step: 31270   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:04:59,152-Speed 140.03 samples/sec   Loss 1.1828   LearningRate 0.000015   Epoch: 1   Global Step: 31280   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:05:01,440-Speed 139.87 samples/sec   Loss 1.1559   LearningRate 0.000015   Epoch: 1   Global Step: 31290   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:05:03,732-Speed 139.70 samples/sec   Loss 1.1900   LearningRate 0.000015   Epoch: 1   Global Step: 31300   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:05:06,024-Speed 139.61 samples/sec   Loss 1.1487   LearningRate 0.000015   Epoch: 1   Global Step: 31310   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:05:08,309-Speed 140.08 samples/sec   Loss 1.1831   LearningRate 0.000015   Epoch: 1   Global Step: 31320   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:05:10,601-Speed 139.70 samples/sec   Loss 1.1710   LearningRate 0.000015   Epoch: 1   Global Step: 31330   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:05:12,894-Speed 139.55 samples/sec   Loss 1.1305   LearningRate 0.000015   Epoch: 1   Global Step: 31340   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:05:15,197-Speed 139.00 samples/sec   Loss 1.1813   LearningRate 0.000015   Epoch: 1   Global Step: 31350   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:05:17,497-Speed 139.16 samples/sec   Loss 1.1890   LearningRate 0.000015   Epoch: 1   Global Step: 31360   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:05:19,792-Speed 139.48 samples/sec   Loss 1.1837   LearningRate 0.000015   Epoch: 1   Global Step: 31370   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:05:22,103-Speed 138.52 samples/sec   Loss 1.1939   LearningRate 0.000015   Epoch: 1   Global Step: 31380   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:05:24,396-Speed 139.58 samples/sec   Loss 1.1912   LearningRate 0.000015   Epoch: 1   Global Step: 31390   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:05:26,675-Speed 140.46 samples/sec   Loss 1.1969   LearningRate 0.000015   Epoch: 1   Global Step: 31400   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:05:28,963-Speed 139.90 samples/sec   Loss 1.1761   LearningRate 0.000015   Epoch: 1   Global Step: 31410   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:05:31,246-Speed 140.19 samples/sec   Loss 1.1587   LearningRate 0.000015   Epoch: 1   Global Step: 31420   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:05:33,514-Speed 141.17 samples/sec   Loss 1.1648   LearningRate 0.000015   Epoch: 1   Global Step: 31430   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:05:35,784-Speed 140.99 samples/sec   Loss 1.1620   LearningRate 0.000015   Epoch: 1   Global Step: 31440   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:05:38,077-Speed 139.63 samples/sec   Loss 1.1859   LearningRate 0.000015   Epoch: 1   Global Step: 31450   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:05:40,361-Speed 140.11 samples/sec   Loss 1.1385   LearningRate 0.000015   Epoch: 1   Global Step: 31460   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:05:42,640-Speed 140.49 samples/sec   Loss 1.1519   LearningRate 0.000015   Epoch: 1   Global Step: 31470   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:05:44,938-Speed 139.24 samples/sec   Loss 1.1860   LearningRate 0.000015   Epoch: 1   Global Step: 31480   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:05:47,220-Speed 140.27 samples/sec   Loss 1.1531   LearningRate 0.000015   Epoch: 1   Global Step: 31490   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:05:49,524-Speed 138.95 samples/sec   Loss 1.1655   LearningRate 0.000015   Epoch: 1   Global Step: 31500   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:05:51,823-Speed 139.22 samples/sec   Loss 1.2007   LearningRate 0.000015   Epoch: 1   Global Step: 31510   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:05:54,109-Speed 140.02 samples/sec   Loss 1.1664   LearningRate 0.000015   Epoch: 1   Global Step: 31520   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:05:56,395-Speed 140.04 samples/sec   Loss 1.2160   LearningRate 0.000015   Epoch: 1   Global Step: 31530   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:05:58,663-Speed 141.12 samples/sec   Loss 1.1902   LearningRate 0.000015   Epoch: 1   Global Step: 31540   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:06:00,937-Speed 140.75 samples/sec   Loss 1.1435   LearningRate 0.000015   Epoch: 1   Global Step: 31550   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:06:03,202-Speed 141.30 samples/sec   Loss 1.1469   LearningRate 0.000015   Epoch: 1   Global Step: 31560   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:06:05,493-Speed 139.75 samples/sec   Loss 1.1972   LearningRate 0.000015   Epoch: 1   Global Step: 31570   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:06:07,774-Speed 140.30 samples/sec   Loss 1.1710   LearningRate 0.000015   Epoch: 1   Global Step: 31580   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:06:10,057-Speed 140.20 samples/sec   Loss 1.1359   LearningRate 0.000014   Epoch: 1   Global Step: 31590   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:06:12,339-Speed 140.29 samples/sec   Loss 1.1633   LearningRate 0.000014   Epoch: 1   Global Step: 31600   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:06:14,623-Speed 140.14 samples/sec   Loss 1.1584   LearningRate 0.000014   Epoch: 1   Global Step: 31610   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:06:16,907-Speed 140.10 samples/sec   Loss 1.1726   LearningRate 0.000014   Epoch: 1   Global Step: 31620   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:06:19,180-Speed 140.84 samples/sec   Loss 1.1475   LearningRate 0.000014   Epoch: 1   Global Step: 31630   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:06:21,438-Speed 141.79 samples/sec   Loss 1.1585   LearningRate 0.000014   Epoch: 1   Global Step: 31640   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:06:23,715-Speed 140.53 samples/sec   Loss 1.1402   LearningRate 0.000014   Epoch: 1   Global Step: 31650   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:06:25,993-Speed 140.48 samples/sec   Loss 1.1630   LearningRate 0.000014   Epoch: 1   Global Step: 31660   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:06:28,283-Speed 139.79 samples/sec   Loss 1.1826   LearningRate 0.000014   Epoch: 1   Global Step: 31670   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:06:30,562-Speed 140.45 samples/sec   Loss 1.1396   LearningRate 0.000014   Epoch: 1   Global Step: 31680   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:06:32,830-Speed 141.18 samples/sec   Loss 1.1687   LearningRate 0.000014   Epoch: 1   Global Step: 31690   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:06:35,099-Speed 141.02 samples/sec   Loss 1.1727   LearningRate 0.000014   Epoch: 1   Global Step: 31700   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:06:37,375-Speed 140.68 samples/sec   Loss 1.1686   LearningRate 0.000014   Epoch: 1   Global Step: 31710   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:06:39,657-Speed 140.24 samples/sec   Loss 1.1471   LearningRate 0.000014   Epoch: 1   Global Step: 31720   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:06:41,943-Speed 140.05 samples/sec   Loss 1.1461   LearningRate 0.000014   Epoch: 1   Global Step: 31730   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:06:44,220-Speed 140.54 samples/sec   Loss 1.1787   LearningRate 0.000014   Epoch: 1   Global Step: 31740   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:06:46,507-Speed 139.96 samples/sec   Loss 1.1788   LearningRate 0.000014   Epoch: 1   Global Step: 31750   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:06:48,776-Speed 141.10 samples/sec   Loss 1.1696   LearningRate 0.000014   Epoch: 1   Global Step: 31760   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:06:51,045-Speed 141.03 samples/sec   Loss 1.1610   LearningRate 0.000014   Epoch: 1   Global Step: 31770   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:06:53,324-Speed 140.46 samples/sec   Loss 1.1468   LearningRate 0.000014   Epoch: 1   Global Step: 31780   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:06:55,594-Speed 141.01 samples/sec   Loss 1.1568   LearningRate 0.000014   Epoch: 1   Global Step: 31790   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:06:57,880-Speed 139.98 samples/sec   Loss 1.1627   LearningRate 0.000014   Epoch: 1   Global Step: 31800   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:07:00,155-Speed 140.72 samples/sec   Loss 1.1644   LearningRate 0.000014   Epoch: 1   Global Step: 31810   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:07:02,449-Speed 139.50 samples/sec   Loss 1.1429   LearningRate 0.000014   Epoch: 1   Global Step: 31820   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:07:04,749-Speed 139.18 samples/sec   Loss 1.1718   LearningRate 0.000014   Epoch: 1   Global Step: 31830   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:07:07,038-Speed 139.83 samples/sec   Loss 1.2031   LearningRate 0.000014   Epoch: 1   Global Step: 31840   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:07:09,325-Speed 140.01 samples/sec   Loss 1.1845   LearningRate 0.000014   Epoch: 1   Global Step: 31850   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:07:11,628-Speed 138.92 samples/sec   Loss 1.1785   LearningRate 0.000014   Epoch: 1   Global Step: 31860   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:07:13,938-Speed 138.60 samples/sec   Loss 1.1756   LearningRate 0.000014   Epoch: 1   Global Step: 31870   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:07:16,234-Speed 139.39 samples/sec   Loss 1.1833   LearningRate 0.000014   Epoch: 1   Global Step: 31880   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:07:18,539-Speed 138.92 samples/sec   Loss 1.1469   LearningRate 0.000014   Epoch: 1   Global Step: 31890   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:07:20,834-Speed 139.45 samples/sec   Loss 1.1406   LearningRate 0.000014   Epoch: 1   Global Step: 31900   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:07:23,130-Speed 139.39 samples/sec   Loss 1.1945   LearningRate 0.000014   Epoch: 1   Global Step: 31910   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:07:25,418-Speed 139.92 samples/sec   Loss 1.1830   LearningRate 0.000014   Epoch: 1   Global Step: 31920   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:07:27,729-Speed 138.46 samples/sec   Loss 1.1723   LearningRate 0.000014   Epoch: 1   Global Step: 31930   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:07:30,020-Speed 139.76 samples/sec   Loss 1.1422   LearningRate 0.000014   Epoch: 1   Global Step: 31940   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:07:32,313-Speed 139.60 samples/sec   Loss 1.1685   LearningRate 0.000014   Epoch: 1   Global Step: 31950   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:07:34,599-Speed 140.00 samples/sec   Loss 1.1807   LearningRate 0.000014   Epoch: 1   Global Step: 31960   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:07:36,901-Speed 139.02 samples/sec   Loss 1.1594   LearningRate 0.000014   Epoch: 1   Global Step: 31970   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:07:39,200-Speed 139.24 samples/sec   Loss 1.1796   LearningRate 0.000014   Epoch: 1   Global Step: 31980   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:07:41,492-Speed 139.66 samples/sec   Loss 1.1739   LearningRate 0.000014   Epoch: 1   Global Step: 31990   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:07:43,569-Val on RAF/AffectNet:
Training: 2023-08-17 23:07:43,746-Test: [0/48]	Time 0.176 (0.176)	Loss 0.4431 (0.4431)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-17 23:07:44,858-Test: [10/48]	Time 0.110 (0.117)	Loss 0.6267 (0.5296)	Acc@1 90.625 (92.614)	Acc@5 98.438 (98.864)	Mem 5268MB
Training: 2023-08-17 23:07:45,940-Test: [20/48]	Time 0.107 (0.113)	Loss 0.5329 (0.5506)	Acc@1 92.188 (91.592)	Acc@5 98.438 (98.810)	Mem 5268MB
Training: 2023-08-17 23:07:47,002-Test: [30/48]	Time 0.107 (0.111)	Loss 0.5140 (0.5502)	Acc@1 95.312 (91.885)	Acc@5 98.438 (98.589)	Mem 5268MB
Training: 2023-08-17 23:07:48,079-Test: [40/48]	Time 0.110 (0.110)	Loss 0.4777 (0.5525)	Acc@1 96.875 (91.692)	Acc@5 98.438 (98.552)	Mem 5268MB
Training: 2023-08-17 23:07:48,835-[31999]Expression Loss: 0.54651
Training: 2023-08-17 23:07:48,836-[31999]Expression Acc@1: 91.88396
Training: 2023-08-17 23:07:48,836-[31999]Expression Acc@1-Highest: 92.47067
Training: 2023-08-17 23:07:48,836-[31999]Expression Acc@5: 98.59844
Training: 2023-08-17 23:07:48,836-[31999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 23:07:48,836-[31999]10 Times Expression Acc@1: 92.00130
Training: 2023-08-17 23:07:48,836-[31999]10 Times Expression Acc@1-Highest: 92.07627
Training: 2023-08-17 23:07:49,066-Speed 42.25 samples/sec   Loss 1.1627   LearningRate 0.000014   Epoch: 1   Global Step: 32000   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:07:51,354-Speed 139.87 samples/sec   Loss 1.1658   LearningRate 0.000014   Epoch: 1   Global Step: 32010   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:07:53,648-Speed 139.54 samples/sec   Loss 1.1618   LearningRate 0.000014   Epoch: 1   Global Step: 32020   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:07:55,962-Speed 138.33 samples/sec   Loss 1.1555   LearningRate 0.000014   Epoch: 1   Global Step: 32030   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:07:58,273-Speed 138.53 samples/sec   Loss 1.1501   LearningRate 0.000014   Epoch: 1   Global Step: 32040   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:08:00,582-Speed 138.59 samples/sec   Loss 1.1542   LearningRate 0.000014   Epoch: 1   Global Step: 32050   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:08:02,866-Speed 140.20 samples/sec   Loss 1.1643   LearningRate 0.000014   Epoch: 1   Global Step: 32060   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:08:05,150-Speed 140.12 samples/sec   Loss 1.1422   LearningRate 0.000014   Epoch: 1   Global Step: 32070   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:08:07,439-Speed 139.82 samples/sec   Loss 1.1565   LearningRate 0.000014   Epoch: 1   Global Step: 32080   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:08:09,745-Speed 138.86 samples/sec   Loss 1.1835   LearningRate 0.000014   Epoch: 1   Global Step: 32090   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:08:12,037-Speed 139.65 samples/sec   Loss 1.1363   LearningRate 0.000014   Epoch: 1   Global Step: 32100   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:08:14,329-Speed 139.64 samples/sec   Loss 1.1398   LearningRate 0.000014   Epoch: 1   Global Step: 32110   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:08:16,624-Speed 139.47 samples/sec   Loss 1.1778   LearningRate 0.000014   Epoch: 1   Global Step: 32120   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:08:18,914-Speed 139.79 samples/sec   Loss 1.1822   LearningRate 0.000014   Epoch: 1   Global Step: 32130   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:08:21,206-Speed 139.64 samples/sec   Loss 1.1559   LearningRate 0.000014   Epoch: 1   Global Step: 32140   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:08:23,505-Speed 139.25 samples/sec   Loss 1.1385   LearningRate 0.000014   Epoch: 1   Global Step: 32150   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:08:25,800-Speed 139.46 samples/sec   Loss 1.1583   LearningRate 0.000014   Epoch: 1   Global Step: 32160   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:08:28,092-Speed 139.63 samples/sec   Loss 1.1486   LearningRate 0.000014   Epoch: 1   Global Step: 32170   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:08:30,369-Speed 140.58 samples/sec   Loss 1.1606   LearningRate 0.000014   Epoch: 1   Global Step: 32180   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:08:32,632-Speed 141.41 samples/sec   Loss 1.1812   LearningRate 0.000014   Epoch: 1   Global Step: 32190   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:08:34,892-Speed 141.68 samples/sec   Loss 1.1661   LearningRate 0.000014   Epoch: 1   Global Step: 32200   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:08:37,173-Speed 140.27 samples/sec   Loss 1.1268   LearningRate 0.000014   Epoch: 1   Global Step: 32210   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:08:39,450-Speed 140.61 samples/sec   Loss 1.1762   LearningRate 0.000014   Epoch: 1   Global Step: 32220   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:08:41,724-Speed 140.73 samples/sec   Loss 1.1916   LearningRate 0.000014   Epoch: 1   Global Step: 32230   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:08:44,017-Speed 139.58 samples/sec   Loss 1.1558   LearningRate 0.000014   Epoch: 1   Global Step: 32240   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:08:46,306-Speed 139.87 samples/sec   Loss 1.1709   LearningRate 0.000014   Epoch: 1   Global Step: 32250   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:08:48,583-Speed 140.55 samples/sec   Loss 1.1701   LearningRate 0.000014   Epoch: 1   Global Step: 32260   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:08:50,861-Speed 140.51 samples/sec   Loss 1.1738   LearningRate 0.000014   Epoch: 1   Global Step: 32270   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:08:53,148-Speed 139.98 samples/sec   Loss 1.1336   LearningRate 0.000014   Epoch: 1   Global Step: 32280   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:08:55,429-Speed 140.33 samples/sec   Loss 1.1578   LearningRate 0.000014   Epoch: 1   Global Step: 32290   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:08:57,690-Speed 141.52 samples/sec   Loss 1.1571   LearningRate 0.000014   Epoch: 1   Global Step: 32300   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:08:59,970-Speed 140.43 samples/sec   Loss 1.1635   LearningRate 0.000014   Epoch: 1   Global Step: 32310   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:09:02,247-Speed 140.55 samples/sec   Loss 1.1743   LearningRate 0.000014   Epoch: 1   Global Step: 32320   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:09:04,517-Speed 141.03 samples/sec   Loss 1.1696   LearningRate 0.000014   Epoch: 1   Global Step: 32330   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:09:06,796-Speed 140.41 samples/sec   Loss 1.1744   LearningRate 0.000014   Epoch: 1   Global Step: 32340   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:09:09,076-Speed 140.43 samples/sec   Loss 1.1166   LearningRate 0.000014   Epoch: 1   Global Step: 32350   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:09:11,370-Speed 139.52 samples/sec   Loss 1.2010   LearningRate 0.000014   Epoch: 1   Global Step: 32360   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:09:13,652-Speed 140.25 samples/sec   Loss 1.1767   LearningRate 0.000014   Epoch: 1   Global Step: 32370   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:09:15,943-Speed 139.68 samples/sec   Loss 1.1760   LearningRate 0.000014   Epoch: 1   Global Step: 32380   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:09:18,208-Speed 141.35 samples/sec   Loss 1.1789   LearningRate 0.000014   Epoch: 1   Global Step: 32390   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:09:20,476-Speed 141.10 samples/sec   Loss 1.1203   LearningRate 0.000014   Epoch: 1   Global Step: 32400   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:09:22,747-Speed 140.98 samples/sec   Loss 1.1446   LearningRate 0.000014   Epoch: 1   Global Step: 32410   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:09:25,016-Speed 141.05 samples/sec   Loss 1.1772   LearningRate 0.000014   Epoch: 1   Global Step: 32420   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:09:27,297-Speed 140.31 samples/sec   Loss 1.1833   LearningRate 0.000014   Epoch: 1   Global Step: 32430   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:09:29,563-Speed 141.22 samples/sec   Loss 1.1795   LearningRate 0.000014   Epoch: 1   Global Step: 32440   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:09:31,853-Speed 139.79 samples/sec   Loss 1.1492   LearningRate 0.000014   Epoch: 1   Global Step: 32450   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:09:34,118-Speed 141.35 samples/sec   Loss 1.1268   LearningRate 0.000014   Epoch: 1   Global Step: 32460   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:09:36,401-Speed 140.17 samples/sec   Loss 1.1651   LearningRate 0.000014   Epoch: 1   Global Step: 32470   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:09:38,687-Speed 140.03 samples/sec   Loss 1.1899   LearningRate 0.000014   Epoch: 1   Global Step: 32480   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:09:40,994-Speed 138.78 samples/sec   Loss 1.1697   LearningRate 0.000014   Epoch: 1   Global Step: 32490   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:09:43,296-Speed 138.99 samples/sec   Loss 1.1471   LearningRate 0.000014   Epoch: 1   Global Step: 32500   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:09:45,595-Speed 139.29 samples/sec   Loss 1.1734   LearningRate 0.000014   Epoch: 1   Global Step: 32510   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:09:47,907-Speed 138.42 samples/sec   Loss 1.2095   LearningRate 0.000014   Epoch: 1   Global Step: 32520   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:09:50,205-Speed 139.34 samples/sec   Loss 1.1748   LearningRate 0.000014   Epoch: 1   Global Step: 32530   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:09:52,503-Speed 139.25 samples/sec   Loss 1.1682   LearningRate 0.000014   Epoch: 1   Global Step: 32540   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:09:54,809-Speed 138.83 samples/sec   Loss 1.1813   LearningRate 0.000014   Epoch: 1   Global Step: 32550   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:09:57,127-Speed 138.08 samples/sec   Loss 1.1878   LearningRate 0.000014   Epoch: 1   Global Step: 32560   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:09:59,427-Speed 139.19 samples/sec   Loss 1.1579   LearningRate 0.000014   Epoch: 1   Global Step: 32570   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:10:01,733-Speed 138.82 samples/sec   Loss 1.1533   LearningRate 0.000014   Epoch: 1   Global Step: 32580   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:10:04,038-Speed 138.83 samples/sec   Loss 1.1644   LearningRate 0.000014   Epoch: 1   Global Step: 32590   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:10:06,339-Speed 139.14 samples/sec   Loss 1.1427   LearningRate 0.000014   Epoch: 1   Global Step: 32600   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:10:08,629-Speed 139.79 samples/sec   Loss 1.2104   LearningRate 0.000014   Epoch: 1   Global Step: 32610   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:10:10,920-Speed 139.71 samples/sec   Loss 1.1760   LearningRate 0.000014   Epoch: 1   Global Step: 32620   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:10:13,193-Speed 140.84 samples/sec   Loss 1.1934   LearningRate 0.000014   Epoch: 1   Global Step: 32630   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:10:15,464-Speed 140.94 samples/sec   Loss 1.1670   LearningRate 0.000014   Epoch: 1   Global Step: 32640   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:10:17,752-Speed 139.88 samples/sec   Loss 1.1411   LearningRate 0.000014   Epoch: 1   Global Step: 32650   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:10:20,038-Speed 140.00 samples/sec   Loss 1.1702   LearningRate 0.000014   Epoch: 1   Global Step: 32660   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:10:22,329-Speed 139.73 samples/sec   Loss 1.1583   LearningRate 0.000014   Epoch: 1   Global Step: 32670   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:10:24,597-Speed 141.15 samples/sec   Loss 1.1619   LearningRate 0.000014   Epoch: 1   Global Step: 32680   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:10:26,890-Speed 139.57 samples/sec   Loss 1.1692   LearningRate 0.000014   Epoch: 1   Global Step: 32690   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:10:29,173-Speed 140.26 samples/sec   Loss 1.1657   LearningRate 0.000014   Epoch: 1   Global Step: 32700   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:10:31,456-Speed 140.21 samples/sec   Loss 1.1449   LearningRate 0.000014   Epoch: 1   Global Step: 32710   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:10:33,731-Speed 140.66 samples/sec   Loss 1.1403   LearningRate 0.000014   Epoch: 1   Global Step: 32720   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:10:36,006-Speed 140.71 samples/sec   Loss 1.1785   LearningRate 0.000014   Epoch: 1   Global Step: 32730   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:10:38,298-Speed 139.64 samples/sec   Loss 1.1756   LearningRate 0.000014   Epoch: 1   Global Step: 32740   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:10:40,580-Speed 140.31 samples/sec   Loss 1.1532   LearningRate 0.000014   Epoch: 1   Global Step: 32750   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:10:42,846-Speed 141.26 samples/sec   Loss 1.1728   LearningRate 0.000014   Epoch: 1   Global Step: 32760   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:10:45,141-Speed 139.46 samples/sec   Loss 1.1502   LearningRate 0.000014   Epoch: 1   Global Step: 32770   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:10:47,442-Speed 139.11 samples/sec   Loss 1.1799   LearningRate 0.000014   Epoch: 1   Global Step: 32780   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:10:49,719-Speed 140.56 samples/sec   Loss 1.1544   LearningRate 0.000014   Epoch: 1   Global Step: 32790   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:10:52,002-Speed 140.16 samples/sec   Loss 1.1577   LearningRate 0.000014   Epoch: 1   Global Step: 32800   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:10:54,308-Speed 138.87 samples/sec   Loss 1.1610   LearningRate 0.000014   Epoch: 1   Global Step: 32810   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:10:56,633-Speed 137.66 samples/sec   Loss 1.1681   LearningRate 0.000014   Epoch: 1   Global Step: 32820   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:10:58,954-Speed 137.87 samples/sec   Loss 1.1386   LearningRate 0.000013   Epoch: 1   Global Step: 32830   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:11:01,259-Speed 138.90 samples/sec   Loss 1.1814   LearningRate 0.000013   Epoch: 1   Global Step: 32840   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:11:03,563-Speed 138.92 samples/sec   Loss 1.1744   LearningRate 0.000013   Epoch: 1   Global Step: 32850   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:11:05,881-Speed 138.13 samples/sec   Loss 1.1391   LearningRate 0.000013   Epoch: 1   Global Step: 32860   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:11:08,199-Speed 138.08 samples/sec   Loss 1.1574   LearningRate 0.000013   Epoch: 1   Global Step: 32870   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:11:10,481-Speed 140.23 samples/sec   Loss 1.1775   LearningRate 0.000013   Epoch: 1   Global Step: 32880   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:11:12,759-Speed 140.55 samples/sec   Loss 1.1418   LearningRate 0.000013   Epoch: 1   Global Step: 32890   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:11:15,035-Speed 140.60 samples/sec   Loss 1.1965   LearningRate 0.000013   Epoch: 1   Global Step: 32900   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:11:17,314-Speed 140.49 samples/sec   Loss 1.1691   LearningRate 0.000013   Epoch: 1   Global Step: 32910   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:11:19,591-Speed 140.55 samples/sec   Loss 1.1800   LearningRate 0.000013   Epoch: 1   Global Step: 32920   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:11:21,879-Speed 139.93 samples/sec   Loss 1.1934   LearningRate 0.000013   Epoch: 1   Global Step: 32930   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:11:24,167-Speed 139.87 samples/sec   Loss 1.1437   LearningRate 0.000013   Epoch: 1   Global Step: 32940   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:11:26,464-Speed 139.34 samples/sec   Loss 1.1552   LearningRate 0.000013   Epoch: 1   Global Step: 32950   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:11:28,731-Speed 141.22 samples/sec   Loss 1.1649   LearningRate 0.000013   Epoch: 1   Global Step: 32960   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:11:31,015-Speed 140.10 samples/sec   Loss 1.1643   LearningRate 0.000013   Epoch: 1   Global Step: 32970   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:11:33,313-Speed 139.35 samples/sec   Loss 1.1935   LearningRate 0.000013   Epoch: 1   Global Step: 32980   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:11:35,629-Speed 138.19 samples/sec   Loss 1.1473   LearningRate 0.000013   Epoch: 1   Global Step: 32990   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:11:37,712-Val on RAF/AffectNet:
Training: 2023-08-17 23:11:37,823-Test: [0/48]	Time 0.111 (0.111)	Loss 0.6463 (0.6463)	Acc@1 90.625 (90.625)	Acc@5 96.875 (96.875)	Mem 5268MB
Training: 2023-08-17 23:11:38,895-Test: [10/48]	Time 0.107 (0.108)	Loss 0.3960 (0.5934)	Acc@1 100.000 (91.761)	Acc@5 100.000 (98.153)	Mem 5268MB
Training: 2023-08-17 23:11:39,956-Test: [20/48]	Time 0.104 (0.107)	Loss 0.5814 (0.5858)	Acc@1 93.750 (91.815)	Acc@5 96.875 (98.065)	Mem 5268MB
Training: 2023-08-17 23:11:41,028-Test: [30/48]	Time 0.108 (0.107)	Loss 0.4019 (0.5843)	Acc@1 98.438 (91.935)	Acc@5 100.000 (98.034)	Mem 5268MB
Training: 2023-08-17 23:11:42,106-Test: [40/48]	Time 0.106 (0.107)	Loss 0.5772 (0.5853)	Acc@1 90.625 (91.616)	Acc@5 98.438 (98.209)	Mem 5268MB
Training: 2023-08-17 23:11:42,855-[32999]Expression Loss: 0.58319
Training: 2023-08-17 23:11:42,855-[32999]Expression Acc@1: 91.65580
Training: 2023-08-17 23:11:42,855-[32999]Expression Acc@1-Highest: 92.47067
Training: 2023-08-17 23:11:42,855-[32999]Expression Acc@5: 98.30508
Training: 2023-08-17 23:11:42,856-[32999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 23:11:42,856-[32999]10 Times Expression Acc@1: 91.99153
Training: 2023-08-17 23:11:42,856-[32999]10 Times Expression Acc@1-Highest: 92.07627
Training: 2023-08-17 23:11:43,089-Speed 42.90 samples/sec   Loss 1.1636   LearningRate 0.000013   Epoch: 1   Global Step: 33000   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:11:45,365-Speed 140.59 samples/sec   Loss 1.1497   LearningRate 0.000013   Epoch: 1   Global Step: 33010   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:11:47,648-Speed 140.20 samples/sec   Loss 1.1600   LearningRate 0.000013   Epoch: 1   Global Step: 33020   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:11:49,925-Speed 140.59 samples/sec   Loss 1.1675   LearningRate 0.000013   Epoch: 1   Global Step: 33030   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:11:52,204-Speed 140.45 samples/sec   Loss 1.1810   LearningRate 0.000013   Epoch: 1   Global Step: 33040   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:11:54,490-Speed 140.04 samples/sec   Loss 1.1637   LearningRate 0.000013   Epoch: 1   Global Step: 33050   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:11:56,772-Speed 140.23 samples/sec   Loss 1.1832   LearningRate 0.000013   Epoch: 1   Global Step: 33060   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:11:59,053-Speed 140.31 samples/sec   Loss 1.1796   LearningRate 0.000013   Epoch: 1   Global Step: 33070   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:12:01,325-Speed 140.87 samples/sec   Loss 1.1404   LearningRate 0.000013   Epoch: 1   Global Step: 33080   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:12:03,592-Speed 141.19 samples/sec   Loss 1.1868   LearningRate 0.000013   Epoch: 1   Global Step: 33090   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:12:05,876-Speed 140.14 samples/sec   Loss 1.1589   LearningRate 0.000013   Epoch: 1   Global Step: 33100   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:12:08,169-Speed 139.62 samples/sec   Loss 1.1963   LearningRate 0.000013   Epoch: 1   Global Step: 33110   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:12:10,461-Speed 139.66 samples/sec   Loss 1.1626   LearningRate 0.000013   Epoch: 1   Global Step: 33120   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:12:12,753-Speed 139.67 samples/sec   Loss 1.1688   LearningRate 0.000013   Epoch: 1   Global Step: 33130   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:12:15,050-Speed 139.33 samples/sec   Loss 1.1896   LearningRate 0.000013   Epoch: 1   Global Step: 33140   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:12:17,344-Speed 139.53 samples/sec   Loss 1.1995   LearningRate 0.000013   Epoch: 1   Global Step: 33150   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:12:19,625-Speed 140.30 samples/sec   Loss 1.1701   LearningRate 0.000013   Epoch: 1   Global Step: 33160   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:12:21,924-Speed 139.24 samples/sec   Loss 1.1738   LearningRate 0.000013   Epoch: 1   Global Step: 33170   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:12:24,224-Speed 139.13 samples/sec   Loss 1.1679   LearningRate 0.000013   Epoch: 1   Global Step: 33180   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:12:26,510-Speed 140.08 samples/sec   Loss 1.1583   LearningRate 0.000013   Epoch: 1   Global Step: 33190   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:12:28,798-Speed 139.84 samples/sec   Loss 1.1441   LearningRate 0.000013   Epoch: 1   Global Step: 33200   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:12:31,093-Speed 139.52 samples/sec   Loss 1.1725   LearningRate 0.000013   Epoch: 1   Global Step: 33210   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:12:33,378-Speed 140.04 samples/sec   Loss 1.1470   LearningRate 0.000013   Epoch: 1   Global Step: 33220   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:12:35,667-Speed 139.84 samples/sec   Loss 1.1502   LearningRate 0.000013   Epoch: 1   Global Step: 33230   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:12:37,947-Speed 140.39 samples/sec   Loss 1.1824   LearningRate 0.000013   Epoch: 1   Global Step: 33240   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:12:40,247-Speed 139.21 samples/sec   Loss 1.1519   LearningRate 0.000013   Epoch: 1   Global Step: 33250   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:12:42,536-Speed 139.79 samples/sec   Loss 1.1664   LearningRate 0.000013   Epoch: 1   Global Step: 33260   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:12:44,824-Speed 139.92 samples/sec   Loss 1.1752   LearningRate 0.000013   Epoch: 1   Global Step: 33270   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:12:47,124-Speed 139.15 samples/sec   Loss 1.1858   LearningRate 0.000013   Epoch: 1   Global Step: 33280   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:12:49,424-Speed 139.19 samples/sec   Loss 1.1353   LearningRate 0.000013   Epoch: 1   Global Step: 33290   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:12:51,714-Speed 139.73 samples/sec   Loss 1.1547   LearningRate 0.000013   Epoch: 1   Global Step: 33300   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:12:53,997-Speed 140.24 samples/sec   Loss 1.1730   LearningRate 0.000013   Epoch: 1   Global Step: 33310   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:12:56,289-Speed 139.63 samples/sec   Loss 1.1646   LearningRate 0.000013   Epoch: 1   Global Step: 33320   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:12:58,589-Speed 139.18 samples/sec   Loss 1.1614   LearningRate 0.000013   Epoch: 1   Global Step: 33330   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:13:00,883-Speed 139.49 samples/sec   Loss 1.1553   LearningRate 0.000013   Epoch: 1   Global Step: 33340   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:13:03,177-Speed 139.53 samples/sec   Loss 1.1703   LearningRate 0.000013   Epoch: 1   Global Step: 33350   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:13:05,463-Speed 140.06 samples/sec   Loss 1.1703   LearningRate 0.000013   Epoch: 1   Global Step: 33360   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:13:07,762-Speed 139.23 samples/sec   Loss 1.1420   LearningRate 0.000013   Epoch: 1   Global Step: 33370   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:13:10,054-Speed 139.61 samples/sec   Loss 1.1468   LearningRate 0.000013   Epoch: 1   Global Step: 33380   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:13:12,345-Speed 139.75 samples/sec   Loss 1.1420   LearningRate 0.000013   Epoch: 1   Global Step: 33390   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:13:14,645-Speed 139.14 samples/sec   Loss 1.1861   LearningRate 0.000013   Epoch: 1   Global Step: 33400   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:13:16,945-Speed 139.19 samples/sec   Loss 1.1769   LearningRate 0.000013   Epoch: 1   Global Step: 33410   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:13:19,236-Speed 139.71 samples/sec   Loss 1.1887   LearningRate 0.000013   Epoch: 1   Global Step: 33420   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:13:21,510-Speed 140.72 samples/sec   Loss 1.1678   LearningRate 0.000013   Epoch: 1   Global Step: 33430   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:13:23,789-Speed 140.47 samples/sec   Loss 1.1473   LearningRate 0.000013   Epoch: 1   Global Step: 33440   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:13:26,061-Speed 140.86 samples/sec   Loss 1.1740   LearningRate 0.000013   Epoch: 1   Global Step: 33450   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:13:28,331-Speed 141.03 samples/sec   Loss 1.1998   LearningRate 0.000013   Epoch: 1   Global Step: 33460   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:13:30,605-Speed 140.77 samples/sec   Loss 1.1588   LearningRate 0.000013   Epoch: 1   Global Step: 33470   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:13:32,880-Speed 140.68 samples/sec   Loss 1.1646   LearningRate 0.000013   Epoch: 1   Global Step: 33480   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:13:35,155-Speed 140.69 samples/sec   Loss 1.1658   LearningRate 0.000013   Epoch: 1   Global Step: 33490   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:13:37,442-Speed 139.95 samples/sec   Loss 1.1575   LearningRate 0.000013   Epoch: 1   Global Step: 33500   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:13:39,725-Speed 140.23 samples/sec   Loss 1.1841   LearningRate 0.000013   Epoch: 1   Global Step: 33510   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:13:42,008-Speed 140.20 samples/sec   Loss 1.1473   LearningRate 0.000013   Epoch: 1   Global Step: 33520   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:13:44,298-Speed 139.72 samples/sec   Loss 1.1788   LearningRate 0.000013   Epoch: 1   Global Step: 33530   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:13:46,578-Speed 140.41 samples/sec   Loss 1.1759   LearningRate 0.000013   Epoch: 1   Global Step: 33540   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:13:48,860-Speed 140.27 samples/sec   Loss 1.1676   LearningRate 0.000013   Epoch: 1   Global Step: 33550   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:13:51,130-Speed 140.98 samples/sec   Loss 1.1719   LearningRate 0.000013   Epoch: 1   Global Step: 33560   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:13:53,406-Speed 140.64 samples/sec   Loss 1.1413   LearningRate 0.000013   Epoch: 1   Global Step: 33570   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:13:55,671-Speed 141.31 samples/sec   Loss 1.1506   LearningRate 0.000013   Epoch: 1   Global Step: 33580   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:13:57,952-Speed 140.37 samples/sec   Loss 1.1788   LearningRate 0.000013   Epoch: 1   Global Step: 33590   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:14:00,234-Speed 140.25 samples/sec   Loss 1.1046   LearningRate 0.000013   Epoch: 1   Global Step: 33600   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:14:02,502-Speed 141.09 samples/sec   Loss 1.1760   LearningRate 0.000013   Epoch: 1   Global Step: 33610   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:14:04,794-Speed 139.66 samples/sec   Loss 1.1616   LearningRate 0.000013   Epoch: 1   Global Step: 33620   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:14:07,076-Speed 140.25 samples/sec   Loss 1.1711   LearningRate 0.000013   Epoch: 1   Global Step: 33630   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:14:09,351-Speed 140.69 samples/sec   Loss 1.1837   LearningRate 0.000013   Epoch: 1   Global Step: 33640   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:14:11,625-Speed 140.79 samples/sec   Loss 1.1551   LearningRate 0.000013   Epoch: 1   Global Step: 33650   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:14:13,904-Speed 140.43 samples/sec   Loss 1.1583   LearningRate 0.000013   Epoch: 1   Global Step: 33660   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:14:16,177-Speed 140.82 samples/sec   Loss 1.1788   LearningRate 0.000013   Epoch: 1   Global Step: 33670   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:14:18,457-Speed 140.38 samples/sec   Loss 1.1574   LearningRate 0.000013   Epoch: 1   Global Step: 33680   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:14:20,736-Speed 140.45 samples/sec   Loss 1.1639   LearningRate 0.000013   Epoch: 1   Global Step: 33690   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:14:23,017-Speed 140.31 samples/sec   Loss 1.1723   LearningRate 0.000013   Epoch: 1   Global Step: 33700   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:14:25,301-Speed 140.15 samples/sec   Loss 1.1722   LearningRate 0.000013   Epoch: 1   Global Step: 33710   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:14:27,579-Speed 140.50 samples/sec   Loss 1.1514   LearningRate 0.000013   Epoch: 1   Global Step: 33720   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:14:29,857-Speed 140.53 samples/sec   Loss 1.1833   LearningRate 0.000013   Epoch: 1   Global Step: 33730   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:14:32,138-Speed 140.33 samples/sec   Loss 1.1613   LearningRate 0.000013   Epoch: 1   Global Step: 33740   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:14:34,425-Speed 139.96 samples/sec   Loss 1.1475   LearningRate 0.000013   Epoch: 1   Global Step: 33750   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:14:36,709-Speed 140.14 samples/sec   Loss 1.1920   LearningRate 0.000013   Epoch: 1   Global Step: 33760   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:14:38,985-Speed 140.60 samples/sec   Loss 1.1649   LearningRate 0.000013   Epoch: 1   Global Step: 33770   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:14:41,260-Speed 140.74 samples/sec   Loss 1.1639   LearningRate 0.000013   Epoch: 1   Global Step: 33780   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:14:43,542-Speed 140.22 samples/sec   Loss 1.1605   LearningRate 0.000013   Epoch: 1   Global Step: 33790   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:14:45,829-Speed 139.95 samples/sec   Loss 1.1579   LearningRate 0.000013   Epoch: 1   Global Step: 33800   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:14:48,113-Speed 140.18 samples/sec   Loss 1.1510   LearningRate 0.000013   Epoch: 1   Global Step: 33810   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:14:50,384-Speed 140.90 samples/sec   Loss 1.1420   LearningRate 0.000013   Epoch: 1   Global Step: 33820   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:14:52,660-Speed 140.62 samples/sec   Loss 1.1557   LearningRate 0.000013   Epoch: 1   Global Step: 33830   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:14:54,941-Speed 140.37 samples/sec   Loss 1.1605   LearningRate 0.000013   Epoch: 1   Global Step: 33840   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:14:57,202-Speed 141.57 samples/sec   Loss 1.1782   LearningRate 0.000013   Epoch: 1   Global Step: 33850   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:14:59,476-Speed 140.76 samples/sec   Loss 1.1349   LearningRate 0.000013   Epoch: 1   Global Step: 33860   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:15:01,743-Speed 141.20 samples/sec   Loss 1.1595   LearningRate 0.000013   Epoch: 1   Global Step: 33870   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:15:04,017-Speed 140.75 samples/sec   Loss 1.1552   LearningRate 0.000013   Epoch: 1   Global Step: 33880   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:15:06,292-Speed 140.69 samples/sec   Loss 1.1886   LearningRate 0.000013   Epoch: 1   Global Step: 33890   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:15:08,570-Speed 140.49 samples/sec   Loss 1.1777   LearningRate 0.000013   Epoch: 1   Global Step: 33900   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:15:10,853-Speed 140.24 samples/sec   Loss 1.1829   LearningRate 0.000013   Epoch: 1   Global Step: 33910   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:15:13,114-Speed 141.54 samples/sec   Loss 1.1421   LearningRate 0.000013   Epoch: 1   Global Step: 33920   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:15:15,396-Speed 140.29 samples/sec   Loss 1.1719   LearningRate 0.000013   Epoch: 1   Global Step: 33930   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:15:17,672-Speed 140.62 samples/sec   Loss 1.1870   LearningRate 0.000013   Epoch: 1   Global Step: 33940   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:15:19,953-Speed 140.29 samples/sec   Loss 1.1310   LearningRate 0.000013   Epoch: 1   Global Step: 33950   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:15:22,221-Speed 141.18 samples/sec   Loss 1.1726   LearningRate 0.000013   Epoch: 1   Global Step: 33960   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:15:24,502-Speed 140.28 samples/sec   Loss 1.1641   LearningRate 0.000013   Epoch: 1   Global Step: 33970   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:15:26,791-Speed 139.86 samples/sec   Loss 1.1593   LearningRate 0.000013   Epoch: 1   Global Step: 33980   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:15:29,067-Speed 140.66 samples/sec   Loss 1.1778   LearningRate 0.000013   Epoch: 1   Global Step: 33990   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:15:31,116-Val on RAF/AffectNet:
Training: 2023-08-17 23:15:31,225-Test: [0/48]	Time 0.109 (0.109)	Loss 0.5741 (0.5741)	Acc@1 89.062 (89.062)	Acc@5 98.438 (98.438)	Mem 5268MB
Training: 2023-08-17 23:15:32,293-Test: [10/48]	Time 0.108 (0.107)	Loss 0.5848 (0.5576)	Acc@1 87.500 (91.335)	Acc@5 100.000 (98.580)	Mem 5268MB
Training: 2023-08-17 23:15:33,361-Test: [20/48]	Time 0.106 (0.107)	Loss 0.5576 (0.5670)	Acc@1 92.188 (91.964)	Acc@5 98.438 (98.438)	Mem 5268MB
Training: 2023-08-17 23:15:34,428-Test: [30/48]	Time 0.107 (0.107)	Loss 0.5772 (0.5810)	Acc@1 92.188 (91.381)	Acc@5 98.438 (98.286)	Mem 5268MB
Training: 2023-08-17 23:15:35,488-Test: [40/48]	Time 0.106 (0.107)	Loss 0.5740 (0.5721)	Acc@1 93.750 (91.883)	Acc@5 98.438 (98.476)	Mem 5268MB
Training: 2023-08-17 23:15:36,226-[33999]Expression Loss: 0.56706
Training: 2023-08-17 23:15:36,226-[33999]Expression Acc@1: 92.11213
Training: 2023-08-17 23:15:36,226-[33999]Expression Acc@1-Highest: 92.47067
Training: 2023-08-17 23:15:36,227-[33999]Expression Acc@5: 98.53325
Training: 2023-08-17 23:15:36,227-[33999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 23:15:36,227-[33999]10 Times Expression Acc@1: 92.00130
Training: 2023-08-17 23:15:36,227-[33999]10 Times Expression Acc@1-Highest: 92.07627
Training: 2023-08-17 23:15:36,455-Speed 43.31 samples/sec   Loss 1.1719   LearningRate 0.000013   Epoch: 1   Global Step: 34000   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:15:38,711-Speed 141.87 samples/sec   Loss 1.1398   LearningRate 0.000013   Epoch: 1   Global Step: 34010   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:15:40,989-Speed 140.50 samples/sec   Loss 1.1766   LearningRate 0.000013   Epoch: 1   Global Step: 34020   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:15:43,258-Speed 141.10 samples/sec   Loss 1.1323   LearningRate 0.000013   Epoch: 1   Global Step: 34030   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:15:45,515-Speed 141.84 samples/sec   Loss 1.1900   LearningRate 0.000013   Epoch: 1   Global Step: 34040   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:15:47,800-Speed 140.06 samples/sec   Loss 1.1485   LearningRate 0.000013   Epoch: 1   Global Step: 34050   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:15:50,072-Speed 140.92 samples/sec   Loss 1.1530   LearningRate 0.000013   Epoch: 1   Global Step: 34060   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:15:52,348-Speed 140.61 samples/sec   Loss 1.1883   LearningRate 0.000013   Epoch: 1   Global Step: 34070   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:15:54,610-Speed 141.51 samples/sec   Loss 1.1948   LearningRate 0.000013   Epoch: 1   Global Step: 34080   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:15:56,881-Speed 140.92 samples/sec   Loss 1.1737   LearningRate 0.000012   Epoch: 1   Global Step: 34090   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:15:59,146-Speed 141.31 samples/sec   Loss 1.1538   LearningRate 0.000012   Epoch: 1   Global Step: 34100   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:16:01,414-Speed 141.21 samples/sec   Loss 1.1789   LearningRate 0.000012   Epoch: 1   Global Step: 34110   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:16:03,666-Speed 142.10 samples/sec   Loss 1.1613   LearningRate 0.000012   Epoch: 1   Global Step: 34120   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:16:05,937-Speed 140.94 samples/sec   Loss 1.1836   LearningRate 0.000012   Epoch: 1   Global Step: 34130   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:16:08,226-Speed 139.83 samples/sec   Loss 1.1761   LearningRate 0.000012   Epoch: 1   Global Step: 34140   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:16:10,504-Speed 140.51 samples/sec   Loss 1.1550   LearningRate 0.000012   Epoch: 1   Global Step: 34150   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:16:12,780-Speed 140.63 samples/sec   Loss 1.1602   LearningRate 0.000012   Epoch: 1   Global Step: 34160   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:16:15,057-Speed 140.57 samples/sec   Loss 1.1162   LearningRate 0.000012   Epoch: 1   Global Step: 34170   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:16:17,331-Speed 140.80 samples/sec   Loss 1.1831   LearningRate 0.000012   Epoch: 1   Global Step: 34180   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:16:19,611-Speed 140.36 samples/sec   Loss 1.1427   LearningRate 0.000012   Epoch: 1   Global Step: 34190   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:16:21,879-Speed 141.14 samples/sec   Loss 1.1836   LearningRate 0.000012   Epoch: 1   Global Step: 34200   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:16:24,159-Speed 140.37 samples/sec   Loss 1.1730   LearningRate 0.000012   Epoch: 1   Global Step: 34210   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:16:26,417-Speed 141.76 samples/sec   Loss 1.1540   LearningRate 0.000012   Epoch: 1   Global Step: 34220   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:16:28,671-Speed 142.04 samples/sec   Loss 1.1799   LearningRate 0.000012   Epoch: 1   Global Step: 34230   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:16:30,951-Speed 140.38 samples/sec   Loss 1.1623   LearningRate 0.000012   Epoch: 1   Global Step: 34240   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:16:33,231-Speed 140.40 samples/sec   Loss 1.1664   LearningRate 0.000012   Epoch: 1   Global Step: 34250   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:16:35,527-Speed 139.39 samples/sec   Loss 1.1651   LearningRate 0.000012   Epoch: 1   Global Step: 34260   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:16:37,814-Speed 139.97 samples/sec   Loss 1.1760   LearningRate 0.000012   Epoch: 1   Global Step: 34270   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:16:40,099-Speed 140.11 samples/sec   Loss 1.1512   LearningRate 0.000012   Epoch: 1   Global Step: 34280   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:16:42,385-Speed 139.99 samples/sec   Loss 1.1471   LearningRate 0.000012   Epoch: 1   Global Step: 34290   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:16:44,686-Speed 139.15 samples/sec   Loss 1.1723   LearningRate 0.000012   Epoch: 1   Global Step: 34300   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:16:46,968-Speed 140.23 samples/sec   Loss 1.1567   LearningRate 0.000012   Epoch: 1   Global Step: 34310   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:16:49,277-Speed 138.64 samples/sec   Loss 1.1180   LearningRate 0.000012   Epoch: 1   Global Step: 34320   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:16:51,588-Speed 138.50 samples/sec   Loss 1.1574   LearningRate 0.000012   Epoch: 1   Global Step: 34330   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:16:53,907-Speed 138.02 samples/sec   Loss 1.1905   LearningRate 0.000012   Epoch: 1   Global Step: 34340   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:16:56,216-Speed 138.62 samples/sec   Loss 1.1623   LearningRate 0.000012   Epoch: 1   Global Step: 34350   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:16:58,520-Speed 138.92 samples/sec   Loss 1.1787   LearningRate 0.000012   Epoch: 1   Global Step: 34360   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:17:00,813-Speed 139.62 samples/sec   Loss 1.1523   LearningRate 0.000012   Epoch: 1   Global Step: 34370   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:17:03,106-Speed 139.59 samples/sec   Loss 1.1705   LearningRate 0.000012   Epoch: 1   Global Step: 34380   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:17:05,378-Speed 140.90 samples/sec   Loss 1.1598   LearningRate 0.000012   Epoch: 1   Global Step: 34390   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:17:07,654-Speed 140.67 samples/sec   Loss 1.1426   LearningRate 0.000012   Epoch: 1   Global Step: 34400   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:17:09,932-Speed 140.49 samples/sec   Loss 1.1916   LearningRate 0.000012   Epoch: 1   Global Step: 34410   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:17:12,218-Speed 140.02 samples/sec   Loss 1.1483   LearningRate 0.000012   Epoch: 1   Global Step: 34420   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:17:14,489-Speed 140.98 samples/sec   Loss 1.1409   LearningRate 0.000012   Epoch: 1   Global Step: 34430   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:17:16,765-Speed 140.63 samples/sec   Loss 1.1787   LearningRate 0.000012   Epoch: 1   Global Step: 34440   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:17:19,028-Speed 141.41 samples/sec   Loss 1.1647   LearningRate 0.000012   Epoch: 1   Global Step: 34450   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:17:21,300-Speed 140.91 samples/sec   Loss 1.1739   LearningRate 0.000012   Epoch: 1   Global Step: 34460   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:17:23,564-Speed 141.35 samples/sec   Loss 1.1999   LearningRate 0.000012   Epoch: 1   Global Step: 34470   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:17:25,846-Speed 140.29 samples/sec   Loss 1.2003   LearningRate 0.000012   Epoch: 1   Global Step: 34480   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:17:28,137-Speed 139.74 samples/sec   Loss 1.1646   LearningRate 0.000012   Epoch: 1   Global Step: 34490   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:17:30,430-Speed 139.60 samples/sec   Loss 1.1896   LearningRate 0.000012   Epoch: 1   Global Step: 34500   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:17:32,705-Speed 140.64 samples/sec   Loss 1.1810   LearningRate 0.000012   Epoch: 1   Global Step: 34510   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:17:35,015-Speed 138.62 samples/sec   Loss 1.1706   LearningRate 0.000012   Epoch: 1   Global Step: 34520   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:17:37,319-Speed 138.90 samples/sec   Loss 1.1703   LearningRate 0.000012   Epoch: 1   Global Step: 34530   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:17:39,650-Speed 137.33 samples/sec   Loss 1.1529   LearningRate 0.000012   Epoch: 1   Global Step: 34540   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:17:41,977-Speed 137.54 samples/sec   Loss 1.1453   LearningRate 0.000012   Epoch: 1   Global Step: 34550   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:17:44,288-Speed 138.51 samples/sec   Loss 1.1702   LearningRate 0.000012   Epoch: 1   Global Step: 34560   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:17:46,580-Speed 139.65 samples/sec   Loss 1.1747   LearningRate 0.000012   Epoch: 1   Global Step: 34570   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:17:48,853-Speed 140.85 samples/sec   Loss 1.1599   LearningRate 0.000012   Epoch: 1   Global Step: 34580   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:17:51,140-Speed 139.93 samples/sec   Loss 1.1636   LearningRate 0.000012   Epoch: 1   Global Step: 34590   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:17:53,449-Speed 138.66 samples/sec   Loss 1.1430   LearningRate 0.000012   Epoch: 1   Global Step: 34600   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:17:55,739-Speed 139.77 samples/sec   Loss 1.1770   LearningRate 0.000012   Epoch: 1   Global Step: 34610   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:17:58,035-Speed 139.39 samples/sec   Loss 1.1717   LearningRate 0.000012   Epoch: 1   Global Step: 34620   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:18:00,330-Speed 139.51 samples/sec   Loss 1.1652   LearningRate 0.000012   Epoch: 1   Global Step: 34630   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:18:02,613-Speed 140.16 samples/sec   Loss 1.1413   LearningRate 0.000012   Epoch: 1   Global Step: 34640   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:18:04,901-Speed 139.89 samples/sec   Loss 1.1544   LearningRate 0.000012   Epoch: 1   Global Step: 34650   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:18:07,190-Speed 139.85 samples/sec   Loss 1.1362   LearningRate 0.000012   Epoch: 1   Global Step: 34660   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:18:09,493-Speed 139.03 samples/sec   Loss 1.1420   LearningRate 0.000012   Epoch: 1   Global Step: 34670   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:18:11,789-Speed 139.42 samples/sec   Loss 1.1709   LearningRate 0.000012   Epoch: 1   Global Step: 34680   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:18:14,084-Speed 139.45 samples/sec   Loss 1.1511   LearningRate 0.000012   Epoch: 1   Global Step: 34690   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:18:16,380-Speed 139.39 samples/sec   Loss 1.1504   LearningRate 0.000012   Epoch: 1   Global Step: 34700   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:18:18,670-Speed 139.84 samples/sec   Loss 1.1649   LearningRate 0.000012   Epoch: 1   Global Step: 34710   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:18:20,956-Speed 139.97 samples/sec   Loss 1.2053   LearningRate 0.000012   Epoch: 1   Global Step: 34720   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:18:23,260-Speed 138.96 samples/sec   Loss 1.1644   LearningRate 0.000012   Epoch: 1   Global Step: 34730   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:18:25,555-Speed 139.44 samples/sec   Loss 1.1643   LearningRate 0.000012   Epoch: 1   Global Step: 34740   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:18:27,857-Speed 139.07 samples/sec   Loss 1.1720   LearningRate 0.000012   Epoch: 1   Global Step: 34750   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:18:30,122-Speed 141.32 samples/sec   Loss 1.1355   LearningRate 0.000012   Epoch: 1   Global Step: 34760   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:18:32,405-Speed 140.20 samples/sec   Loss 1.1526   LearningRate 0.000012   Epoch: 1   Global Step: 34770   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:18:34,695-Speed 139.75 samples/sec   Loss 1.1572   LearningRate 0.000012   Epoch: 1   Global Step: 34780   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:18:36,983-Speed 139.95 samples/sec   Loss 1.1350   LearningRate 0.000012   Epoch: 1   Global Step: 34790   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:18:39,262-Speed 140.42 samples/sec   Loss 1.1551   LearningRate 0.000012   Epoch: 1   Global Step: 34800   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:18:41,572-Speed 138.60 samples/sec   Loss 1.1623   LearningRate 0.000012   Epoch: 1   Global Step: 34810   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:18:43,872-Speed 139.15 samples/sec   Loss 1.1765   LearningRate 0.000012   Epoch: 1   Global Step: 34820   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:18:46,174-Speed 139.06 samples/sec   Loss 1.1366   LearningRate 0.000012   Epoch: 1   Global Step: 34830   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:18:48,466-Speed 139.64 samples/sec   Loss 1.1522   LearningRate 0.000012   Epoch: 1   Global Step: 34840   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:18:50,776-Speed 138.56 samples/sec   Loss 1.1639   LearningRate 0.000012   Epoch: 1   Global Step: 34850   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:18:53,078-Speed 139.06 samples/sec   Loss 1.1535   LearningRate 0.000012   Epoch: 1   Global Step: 34860   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:18:55,377-Speed 139.25 samples/sec   Loss 1.1662   LearningRate 0.000012   Epoch: 1   Global Step: 34870   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:18:57,658-Speed 140.37 samples/sec   Loss 1.1629   LearningRate 0.000012   Epoch: 1   Global Step: 34880   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:18:59,954-Speed 139.37 samples/sec   Loss 1.1622   LearningRate 0.000012   Epoch: 1   Global Step: 34890   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:19:02,250-Speed 139.43 samples/sec   Loss 1.1569   LearningRate 0.000012   Epoch: 1   Global Step: 34900   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:19:04,540-Speed 139.78 samples/sec   Loss 1.1424   LearningRate 0.000012   Epoch: 1   Global Step: 34910   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:19:06,840-Speed 139.21 samples/sec   Loss 1.1530   LearningRate 0.000012   Epoch: 1   Global Step: 34920   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:19:09,136-Speed 139.35 samples/sec   Loss 1.1349   LearningRate 0.000012   Epoch: 1   Global Step: 34930   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:19:11,423-Speed 139.98 samples/sec   Loss 1.1907   LearningRate 0.000012   Epoch: 1   Global Step: 34940   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:19:13,728-Speed 138.89 samples/sec   Loss 1.1539   LearningRate 0.000012   Epoch: 1   Global Step: 34950   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:19:16,019-Speed 139.67 samples/sec   Loss 1.1392   LearningRate 0.000012   Epoch: 1   Global Step: 34960   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:19:18,288-Speed 141.12 samples/sec   Loss 1.1565   LearningRate 0.000012   Epoch: 1   Global Step: 34970   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:19:20,578-Speed 139.77 samples/sec   Loss 1.1721   LearningRate 0.000012   Epoch: 1   Global Step: 34980   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:19:22,865-Speed 139.97 samples/sec   Loss 1.1388   LearningRate 0.000012   Epoch: 1   Global Step: 34990   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:19:24,918-Val on RAF/AffectNet:
Training: 2023-08-17 23:19:25,035-Test: [0/48]	Time 0.116 (0.116)	Loss 0.4866 (0.4866)	Acc@1 93.750 (93.750)	Acc@5 98.438 (98.438)	Mem 5268MB
Training: 2023-08-17 23:19:26,115-Test: [10/48]	Time 0.109 (0.109)	Loss 0.5908 (0.5340)	Acc@1 89.062 (93.040)	Acc@5 98.438 (98.580)	Mem 5268MB
Training: 2023-08-17 23:19:27,190-Test: [20/48]	Time 0.108 (0.108)	Loss 0.4989 (0.5409)	Acc@1 92.188 (92.708)	Acc@5 100.000 (98.661)	Mem 5268MB
Training: 2023-08-17 23:19:28,258-Test: [30/48]	Time 0.106 (0.108)	Loss 0.4310 (0.5476)	Acc@1 96.875 (92.389)	Acc@5 100.000 (98.589)	Mem 5268MB
Training: 2023-08-17 23:19:29,320-Test: [40/48]	Time 0.104 (0.107)	Loss 0.5156 (0.5512)	Acc@1 93.750 (92.188)	Acc@5 98.438 (98.704)	Mem 5268MB
Training: 2023-08-17 23:19:30,059-[34999]Expression Loss: 0.54731
Training: 2023-08-17 23:19:30,059-[34999]Expression Acc@1: 92.37288
Training: 2023-08-17 23:19:30,059-[34999]Expression Acc@1-Highest: 92.47067
Training: 2023-08-17 23:19:30,059-[34999]Expression Acc@5: 98.69622
Training: 2023-08-17 23:19:30,059-[34999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 23:19:30,059-[34999]10 Times Expression Acc@1: 92.00782
Training: 2023-08-17 23:19:30,060-[34999]10 Times Expression Acc@1-Highest: 92.07627
Training: 2023-08-17 23:19:30,287-Speed 43.12 samples/sec   Loss 1.1458   LearningRate 0.000012   Epoch: 1   Global Step: 35000   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:19:32,539-Speed 142.18 samples/sec   Loss 1.1447   LearningRate 0.000012   Epoch: 1   Global Step: 35010   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:19:34,796-Speed 141.77 samples/sec   Loss 1.1769   LearningRate 0.000012   Epoch: 1   Global Step: 35020   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:19:37,068-Speed 140.92 samples/sec   Loss 1.2002   LearningRate 0.000012   Epoch: 1   Global Step: 35030   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:19:39,331-Speed 141.42 samples/sec   Loss 1.1445   LearningRate 0.000012   Epoch: 1   Global Step: 35040   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:19:41,587-Speed 141.90 samples/sec   Loss 1.1522   LearningRate 0.000012   Epoch: 1   Global Step: 35050   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:19:43,858-Speed 140.91 samples/sec   Loss 1.1511   LearningRate 0.000012   Epoch: 1   Global Step: 35060   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:19:46,129-Speed 140.96 samples/sec   Loss 1.1520   LearningRate 0.000012   Epoch: 1   Global Step: 35070   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:19:48,413-Speed 140.13 samples/sec   Loss 1.1731   LearningRate 0.000012   Epoch: 1   Global Step: 35080   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:19:50,737-Speed 137.78 samples/sec   Loss 1.1873   LearningRate 0.000012   Epoch: 1   Global Step: 35090   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:19:53,036-Speed 139.18 samples/sec   Loss 1.1642   LearningRate 0.000012   Epoch: 1   Global Step: 35100   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:19:55,344-Speed 138.69 samples/sec   Loss 1.1955   LearningRate 0.000012   Epoch: 1   Global Step: 35110   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:19:57,654-Speed 138.55 samples/sec   Loss 1.1572   LearningRate 0.000012   Epoch: 1   Global Step: 35120   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:19:59,951-Speed 139.37 samples/sec   Loss 1.1632   LearningRate 0.000012   Epoch: 1   Global Step: 35130   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:20:02,236-Speed 140.08 samples/sec   Loss 1.1716   LearningRate 0.000012   Epoch: 1   Global Step: 35140   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:20:04,502-Speed 141.25 samples/sec   Loss 1.1655   LearningRate 0.000012   Epoch: 1   Global Step: 35150   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:20:06,759-Speed 141.86 samples/sec   Loss 1.1353   LearningRate 0.000012   Epoch: 1   Global Step: 35160   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:20:09,033-Speed 140.71 samples/sec   Loss 1.1727   LearningRate 0.000012   Epoch: 1   Global Step: 35170   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:20:11,296-Speed 141.44 samples/sec   Loss 1.1655   LearningRate 0.000012   Epoch: 1   Global Step: 35180   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:20:13,578-Speed 140.30 samples/sec   Loss 1.1855   LearningRate 0.000012   Epoch: 1   Global Step: 35190   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:20:15,847-Speed 141.02 samples/sec   Loss 1.1545   LearningRate 0.000012   Epoch: 1   Global Step: 35200   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:20:18,123-Speed 140.65 samples/sec   Loss 1.1535   LearningRate 0.000012   Epoch: 1   Global Step: 35210   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:20:20,397-Speed 140.74 samples/sec   Loss 1.1588   LearningRate 0.000012   Epoch: 1   Global Step: 35220   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:20:22,670-Speed 140.85 samples/sec   Loss 1.1372   LearningRate 0.000012   Epoch: 1   Global Step: 35230   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:20:24,946-Speed 140.62 samples/sec   Loss 1.1504   LearningRate 0.000012   Epoch: 1   Global Step: 35240   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:20:27,215-Speed 141.08 samples/sec   Loss 1.1757   LearningRate 0.000012   Epoch: 1   Global Step: 35250   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:20:29,500-Speed 140.07 samples/sec   Loss 1.1462   LearningRate 0.000012   Epoch: 1   Global Step: 35260   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:20:31,775-Speed 140.68 samples/sec   Loss 1.1675   LearningRate 0.000012   Epoch: 1   Global Step: 35270   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:20:34,052-Speed 140.58 samples/sec   Loss 1.1575   LearningRate 0.000012   Epoch: 1   Global Step: 35280   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:20:36,355-Speed 139.01 samples/sec   Loss 1.1517   LearningRate 0.000012   Epoch: 1   Global Step: 35290   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:20:38,658-Speed 138.98 samples/sec   Loss 1.1454   LearningRate 0.000012   Epoch: 1   Global Step: 35300   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:20:40,939-Speed 140.34 samples/sec   Loss 1.1758   LearningRate 0.000012   Epoch: 1   Global Step: 35310   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:20:43,191-Speed 142.09 samples/sec   Loss 1.1507   LearningRate 0.000012   Epoch: 1   Global Step: 35320   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:20:45,452-Speed 141.59 samples/sec   Loss 1.1722   LearningRate 0.000012   Epoch: 1   Global Step: 35330   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:20:47,712-Speed 141.61 samples/sec   Loss 1.1551   LearningRate 0.000012   Epoch: 1   Global Step: 35340   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:20:49,992-Speed 140.40 samples/sec   Loss 1.2055   LearningRate 0.000012   Epoch: 1   Global Step: 35350   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:20:52,250-Speed 141.77 samples/sec   Loss 1.1425   LearningRate 0.000011   Epoch: 1   Global Step: 35360   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:20:54,505-Speed 141.91 samples/sec   Loss 1.1538   LearningRate 0.000011   Epoch: 1   Global Step: 35370   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:20:56,774-Speed 141.07 samples/sec   Loss 1.1227   LearningRate 0.000011   Epoch: 1   Global Step: 35380   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:20:59,030-Speed 141.89 samples/sec   Loss 1.1429   LearningRate 0.000011   Epoch: 1   Global Step: 35390   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:21:01,305-Speed 140.70 samples/sec   Loss 1.1642   LearningRate 0.000011   Epoch: 1   Global Step: 35400   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:21:03,587-Speed 140.27 samples/sec   Loss 1.1541   LearningRate 0.000011   Epoch: 1   Global Step: 35410   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:21:05,844-Speed 141.81 samples/sec   Loss 1.1874   LearningRate 0.000011   Epoch: 1   Global Step: 35420   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:21:08,120-Speed 140.66 samples/sec   Loss 1.1632   LearningRate 0.000011   Epoch: 1   Global Step: 35430   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:21:10,403-Speed 140.21 samples/sec   Loss 1.1717   LearningRate 0.000011   Epoch: 1   Global Step: 35440   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:21:12,677-Speed 140.71 samples/sec   Loss 1.1586   LearningRate 0.000011   Epoch: 1   Global Step: 35450   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:21:14,960-Speed 140.25 samples/sec   Loss 1.1456   LearningRate 0.000011   Epoch: 1   Global Step: 35460   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:21:17,245-Speed 140.05 samples/sec   Loss 1.1497   LearningRate 0.000011   Epoch: 1   Global Step: 35470   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:21:19,532-Speed 139.94 samples/sec   Loss 1.1530   LearningRate 0.000011   Epoch: 1   Global Step: 35480   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:21:21,813-Speed 140.32 samples/sec   Loss 1.1487   LearningRate 0.000011   Epoch: 1   Global Step: 35490   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:21:24,110-Speed 139.35 samples/sec   Loss 1.1717   LearningRate 0.000011   Epoch: 1   Global Step: 35500   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:21:26,377-Speed 141.23 samples/sec   Loss 1.1533   LearningRate 0.000011   Epoch: 1   Global Step: 35510   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:21:28,658-Speed 140.30 samples/sec   Loss 1.1340   LearningRate 0.000011   Epoch: 1   Global Step: 35520   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:21:30,906-Speed 142.43 samples/sec   Loss 1.1663   LearningRate 0.000011   Epoch: 1   Global Step: 35530   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:21:33,192-Speed 139.99 samples/sec   Loss 1.1734   LearningRate 0.000011   Epoch: 1   Global Step: 35540   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:21:35,464-Speed 140.90 samples/sec   Loss 1.1937   LearningRate 0.000011   Epoch: 1   Global Step: 35550   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:21:37,745-Speed 140.31 samples/sec   Loss 1.1472   LearningRate 0.000011   Epoch: 1   Global Step: 35560   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:21:40,023-Speed 140.50 samples/sec   Loss 1.1561   LearningRate 0.000011   Epoch: 1   Global Step: 35570   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:21:42,320-Speed 139.35 samples/sec   Loss 1.1307   LearningRate 0.000011   Epoch: 1   Global Step: 35580   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:21:44,615-Speed 139.46 samples/sec   Loss 1.1491   LearningRate 0.000011   Epoch: 1   Global Step: 35590   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:21:46,887-Speed 140.89 samples/sec   Loss 1.1265   LearningRate 0.000011   Epoch: 1   Global Step: 35600   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:21:49,138-Speed 142.19 samples/sec   Loss 1.1564   LearningRate 0.000011   Epoch: 1   Global Step: 35610   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:21:51,397-Speed 141.69 samples/sec   Loss 1.1430   LearningRate 0.000011   Epoch: 1   Global Step: 35620   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:21:53,661-Speed 141.42 samples/sec   Loss 1.1411   LearningRate 0.000011   Epoch: 1   Global Step: 35630   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:21:55,904-Speed 142.69 samples/sec   Loss 1.1392   LearningRate 0.000011   Epoch: 1   Global Step: 35640   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:21:58,161-Speed 141.83 samples/sec   Loss 1.1631   LearningRate 0.000011   Epoch: 1   Global Step: 35650   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:22:00,421-Speed 141.59 samples/sec   Loss 1.1469   LearningRate 0.000011   Epoch: 1   Global Step: 35660   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:22:02,674-Speed 142.08 samples/sec   Loss 1.1568   LearningRate 0.000011   Epoch: 1   Global Step: 35670   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:22:04,931-Speed 141.84 samples/sec   Loss 1.1726   LearningRate 0.000011   Epoch: 1   Global Step: 35680   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:22:07,186-Speed 141.95 samples/sec   Loss 1.2069   LearningRate 0.000011   Epoch: 1   Global Step: 35690   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:22:09,440-Speed 141.98 samples/sec   Loss 1.1738   LearningRate 0.000011   Epoch: 1   Global Step: 35700   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:22:11,697-Speed 141.79 samples/sec   Loss 1.1418   LearningRate 0.000011   Epoch: 1   Global Step: 35710   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:22:13,949-Speed 142.17 samples/sec   Loss 1.1802   LearningRate 0.000011   Epoch: 1   Global Step: 35720   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:22:16,205-Speed 141.89 samples/sec   Loss 1.1803   LearningRate 0.000011   Epoch: 1   Global Step: 35730   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:22:18,463-Speed 141.75 samples/sec   Loss 1.1496   LearningRate 0.000011   Epoch: 1   Global Step: 35740   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:22:20,708-Speed 142.58 samples/sec   Loss 1.1485   LearningRate 0.000011   Epoch: 1   Global Step: 35750   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:22:22,973-Speed 141.27 samples/sec   Loss 1.1611   LearningRate 0.000011   Epoch: 1   Global Step: 35760   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:22:25,224-Speed 142.21 samples/sec   Loss 1.1410   LearningRate 0.000011   Epoch: 1   Global Step: 35770   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:22:27,494-Speed 141.00 samples/sec   Loss 1.1689   LearningRate 0.000011   Epoch: 1   Global Step: 35780   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:22:29,767-Speed 140.82 samples/sec   Loss 1.1388   LearningRate 0.000011   Epoch: 1   Global Step: 35790   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:22:32,056-Speed 139.85 samples/sec   Loss 1.1499   LearningRate 0.000011   Epoch: 1   Global Step: 35800   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:22:34,345-Speed 139.85 samples/sec   Loss 1.1531   LearningRate 0.000011   Epoch: 1   Global Step: 35810   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:22:36,637-Speed 139.61 samples/sec   Loss 1.1323   LearningRate 0.000011   Epoch: 1   Global Step: 35820   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:22:38,910-Speed 140.83 samples/sec   Loss 1.1609   LearningRate 0.000011   Epoch: 1   Global Step: 35830   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:22:41,195-Speed 140.10 samples/sec   Loss 1.1562   LearningRate 0.000011   Epoch: 1   Global Step: 35840   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:22:43,461-Speed 141.24 samples/sec   Loss 1.1705   LearningRate 0.000011   Epoch: 1   Global Step: 35850   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:22:45,728-Speed 141.17 samples/sec   Loss 1.1822   LearningRate 0.000011   Epoch: 1   Global Step: 35860   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:22:48,024-Speed 139.41 samples/sec   Loss 1.1874   LearningRate 0.000011   Epoch: 1   Global Step: 35870   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:22:50,285-Speed 141.56 samples/sec   Loss 1.1566   LearningRate 0.000011   Epoch: 1   Global Step: 35880   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:22:52,574-Speed 139.82 samples/sec   Loss 1.1379   LearningRate 0.000011   Epoch: 1   Global Step: 35890   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:22:54,859-Speed 140.08 samples/sec   Loss 1.1756   LearningRate 0.000011   Epoch: 1   Global Step: 35900   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:22:57,139-Speed 140.40 samples/sec   Loss 1.1475   LearningRate 0.000011   Epoch: 1   Global Step: 35910   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:22:59,423-Speed 140.15 samples/sec   Loss 1.1749   LearningRate 0.000011   Epoch: 1   Global Step: 35920   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:23:01,703-Speed 140.37 samples/sec   Loss 1.1574   LearningRate 0.000011   Epoch: 1   Global Step: 35930   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:23:03,986-Speed 140.23 samples/sec   Loss 1.1590   LearningRate 0.000011   Epoch: 1   Global Step: 35940   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:23:06,251-Speed 141.29 samples/sec   Loss 1.1552   LearningRate 0.000011   Epoch: 1   Global Step: 35950   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:23:08,524-Speed 140.83 samples/sec   Loss 1.1578   LearningRate 0.000011   Epoch: 1   Global Step: 35960   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:23:10,794-Speed 140.96 samples/sec   Loss 1.1643   LearningRate 0.000011   Epoch: 1   Global Step: 35970   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:23:13,061-Speed 141.22 samples/sec   Loss 1.1674   LearningRate 0.000011   Epoch: 1   Global Step: 35980   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:23:15,333-Speed 140.87 samples/sec   Loss 1.1350   LearningRate 0.000011   Epoch: 1   Global Step: 35990   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:23:17,379-Val on RAF/AffectNet:
Training: 2023-08-17 23:23:17,488-Test: [0/48]	Time 0.108 (0.108)	Loss 0.6062 (0.6062)	Acc@1 90.625 (90.625)	Acc@5 98.438 (98.438)	Mem 5268MB
Training: 2023-08-17 23:23:18,550-Test: [10/48]	Time 0.107 (0.106)	Loss 0.5872 (0.6144)	Acc@1 92.188 (90.341)	Acc@5 98.438 (97.585)	Mem 5268MB
Training: 2023-08-17 23:23:19,623-Test: [20/48]	Time 0.106 (0.107)	Loss 0.5552 (0.5727)	Acc@1 93.750 (91.964)	Acc@5 98.438 (98.289)	Mem 5268MB
Training: 2023-08-17 23:23:20,682-Test: [30/48]	Time 0.106 (0.107)	Loss 0.5224 (0.5705)	Acc@1 92.188 (91.835)	Acc@5 100.000 (98.337)	Mem 5268MB
Training: 2023-08-17 23:23:21,745-Test: [40/48]	Time 0.106 (0.106)	Loss 0.6301 (0.5604)	Acc@1 89.062 (92.111)	Acc@5 95.312 (98.476)	Mem 5268MB
Training: 2023-08-17 23:23:22,485-[35999]Expression Loss: 0.55686
Training: 2023-08-17 23:23:22,485-[35999]Expression Acc@1: 92.27510
Training: 2023-08-17 23:23:22,485-[35999]Expression Acc@1-Highest: 92.47067
Training: 2023-08-17 23:23:22,485-[35999]Expression Acc@5: 98.56584
Training: 2023-08-17 23:23:22,485-[35999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 23:23:22,485-[35999]10 Times Expression Acc@1: 92.02738
Training: 2023-08-17 23:23:22,486-[35999]10 Times Expression Acc@1-Highest: 92.07627
Training: 2023-08-17 23:23:23,089-Speed 41.26 samples/sec   Loss 1.1583   LearningRate 0.000011   Epoch: 1   Global Step: 36000   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:23:25,340-Speed 142.20 samples/sec   Loss 1.1652   LearningRate 0.000011   Epoch: 1   Global Step: 36010   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:23:27,625-Speed 140.07 samples/sec   Loss 1.1557   LearningRate 0.000011   Epoch: 1   Global Step: 36020   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:23:29,926-Speed 139.11 samples/sec   Loss 1.1418   LearningRate 0.000011   Epoch: 1   Global Step: 36030   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:23:32,208-Speed 140.27 samples/sec   Loss 1.1566   LearningRate 0.000011   Epoch: 1   Global Step: 36040   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:23:34,499-Speed 139.72 samples/sec   Loss 1.1966   LearningRate 0.000011   Epoch: 1   Global Step: 36050   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:23:36,768-Speed 141.04 samples/sec   Loss 1.1813   LearningRate 0.000011   Epoch: 1   Global Step: 36060   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:23:39,046-Speed 140.55 samples/sec   Loss 1.1456   LearningRate 0.000011   Epoch: 1   Global Step: 36070   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:23:41,321-Speed 140.70 samples/sec   Loss 1.1735   LearningRate 0.000011   Epoch: 1   Global Step: 36080   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:23:43,601-Speed 140.37 samples/sec   Loss 1.1476   LearningRate 0.000011   Epoch: 1   Global Step: 36090   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:23:45,875-Speed 140.76 samples/sec   Loss 1.1765   LearningRate 0.000011   Epoch: 1   Global Step: 36100   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:23:48,157-Speed 140.27 samples/sec   Loss 1.1518   LearningRate 0.000011   Epoch: 1   Global Step: 36110   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:23:50,443-Speed 140.02 samples/sec   Loss 1.1482   LearningRate 0.000011   Epoch: 1   Global Step: 36120   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:23:52,708-Speed 141.32 samples/sec   Loss 1.1492   LearningRate 0.000011   Epoch: 1   Global Step: 36130   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:23:54,992-Speed 140.14 samples/sec   Loss 1.1176   LearningRate 0.000011   Epoch: 1   Global Step: 36140   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:23:57,266-Speed 140.78 samples/sec   Loss 1.1568   LearningRate 0.000011   Epoch: 1   Global Step: 36150   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:23:59,546-Speed 140.36 samples/sec   Loss 1.1342   LearningRate 0.000011   Epoch: 1   Global Step: 36160   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:24:01,824-Speed 140.53 samples/sec   Loss 1.1929   LearningRate 0.000011   Epoch: 1   Global Step: 36170   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:24:04,107-Speed 140.25 samples/sec   Loss 1.1650   LearningRate 0.000011   Epoch: 1   Global Step: 36180   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:24:06,388-Speed 140.29 samples/sec   Loss 1.1493   LearningRate 0.000011   Epoch: 1   Global Step: 36190   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:24:08,681-Speed 139.60 samples/sec   Loss 1.1790   LearningRate 0.000011   Epoch: 1   Global Step: 36200   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:24:10,976-Speed 139.48 samples/sec   Loss 1.1564   LearningRate 0.000011   Epoch: 1   Global Step: 36210   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:24:13,269-Speed 139.58 samples/sec   Loss 1.1410   LearningRate 0.000011   Epoch: 1   Global Step: 36220   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:24:15,564-Speed 139.49 samples/sec   Loss 1.1564   LearningRate 0.000011   Epoch: 1   Global Step: 36230   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:24:17,863-Speed 139.25 samples/sec   Loss 1.1528   LearningRate 0.000011   Epoch: 1   Global Step: 36240   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:24:20,161-Speed 139.26 samples/sec   Loss 1.1538   LearningRate 0.000011   Epoch: 1   Global Step: 36250   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:24:22,449-Speed 139.93 samples/sec   Loss 1.1776   LearningRate 0.000011   Epoch: 1   Global Step: 36260   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:24:24,730-Speed 140.32 samples/sec   Loss 1.1621   LearningRate 0.000011   Epoch: 1   Global Step: 36270   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:24:27,023-Speed 139.59 samples/sec   Loss 1.1427   LearningRate 0.000011   Epoch: 1   Global Step: 36280   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:24:29,308-Speed 140.07 samples/sec   Loss 1.1699   LearningRate 0.000011   Epoch: 1   Global Step: 36290   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:24:31,598-Speed 139.83 samples/sec   Loss 1.1615   LearningRate 0.000011   Epoch: 1   Global Step: 36300   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:24:33,884-Speed 139.97 samples/sec   Loss 1.1502   LearningRate 0.000011   Epoch: 1   Global Step: 36310   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:24:36,184-Speed 139.19 samples/sec   Loss 1.1694   LearningRate 0.000011   Epoch: 1   Global Step: 36320   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:24:38,459-Speed 140.71 samples/sec   Loss 1.1379   LearningRate 0.000011   Epoch: 1   Global Step: 36330   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:24:40,738-Speed 140.45 samples/sec   Loss 1.1263   LearningRate 0.000011   Epoch: 1   Global Step: 36340   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:24:43,022-Speed 140.13 samples/sec   Loss 1.1524   LearningRate 0.000011   Epoch: 1   Global Step: 36350   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:24:45,311-Speed 139.87 samples/sec   Loss 1.1739   LearningRate 0.000011   Epoch: 1   Global Step: 36360   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:24:47,612-Speed 139.07 samples/sec   Loss 1.1778   LearningRate 0.000011   Epoch: 1   Global Step: 36370   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:24:49,901-Speed 139.86 samples/sec   Loss 1.1275   LearningRate 0.000011   Epoch: 1   Global Step: 36380   Fp16 Grad Scale: 65536   Required: 2 hours
Training: 2023-08-17 23:24:52,179-Speed 140.50 samples/sec   Loss 1.1293   LearningRate 0.000011   Epoch: 1   Global Step: 36390   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:24:54,451-Speed 140.93 samples/sec   Loss 1.1264   LearningRate 0.000011   Epoch: 1   Global Step: 36400   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:24:56,739-Speed 139.88 samples/sec   Loss 1.1900   LearningRate 0.000011   Epoch: 1   Global Step: 36410   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:24:59,034-Speed 139.47 samples/sec   Loss 1.1801   LearningRate 0.000011   Epoch: 1   Global Step: 36420   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:25:01,308-Speed 140.77 samples/sec   Loss 1.1523   LearningRate 0.000011   Epoch: 1   Global Step: 36430   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:25:03,587-Speed 140.43 samples/sec   Loss 1.1475   LearningRate 0.000011   Epoch: 1   Global Step: 36440   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:25:05,857-Speed 141.03 samples/sec   Loss 1.1483   LearningRate 0.000011   Epoch: 1   Global Step: 36450   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:25:08,151-Speed 139.53 samples/sec   Loss 1.1691   LearningRate 0.000011   Epoch: 1   Global Step: 36460   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:25:10,430-Speed 140.44 samples/sec   Loss 1.1733   LearningRate 0.000011   Epoch: 1   Global Step: 36470   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:25:12,724-Speed 139.52 samples/sec   Loss 1.1567   LearningRate 0.000011   Epoch: 1   Global Step: 36480   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:25:15,016-Speed 139.68 samples/sec   Loss 1.1607   LearningRate 0.000011   Epoch: 1   Global Step: 36490   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:25:17,300-Speed 140.15 samples/sec   Loss 1.1726   LearningRate 0.000011   Epoch: 1   Global Step: 36500   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:25:19,591-Speed 139.71 samples/sec   Loss 1.1477   LearningRate 0.000011   Epoch: 1   Global Step: 36510   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:25:21,873-Speed 140.25 samples/sec   Loss 1.1634   LearningRate 0.000011   Epoch: 1   Global Step: 36520   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:25:24,168-Speed 139.46 samples/sec   Loss 1.1614   LearningRate 0.000011   Epoch: 1   Global Step: 36530   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:25:26,443-Speed 140.72 samples/sec   Loss 1.1327   LearningRate 0.000011   Epoch: 1   Global Step: 36540   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:25:28,728-Speed 140.07 samples/sec   Loss 1.1629   LearningRate 0.000011   Epoch: 1   Global Step: 36550   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:25:30,989-Speed 141.56 samples/sec   Loss 1.1645   LearningRate 0.000011   Epoch: 1   Global Step: 36560   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:25:33,275-Speed 140.03 samples/sec   Loss 1.1614   LearningRate 0.000011   Epoch: 1   Global Step: 36570   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:25:35,556-Speed 140.30 samples/sec   Loss 1.1610   LearningRate 0.000011   Epoch: 1   Global Step: 36580   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:25:37,841-Speed 140.12 samples/sec   Loss 1.1612   LearningRate 0.000011   Epoch: 1   Global Step: 36590   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:25:40,117-Speed 140.62 samples/sec   Loss 1.1380   LearningRate 0.000011   Epoch: 1   Global Step: 36600   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:25:42,400-Speed 140.21 samples/sec   Loss 1.1427   LearningRate 0.000011   Epoch: 1   Global Step: 36610   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:25:44,684-Speed 140.12 samples/sec   Loss 1.1577   LearningRate 0.000011   Epoch: 1   Global Step: 36620   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:25:46,960-Speed 140.66 samples/sec   Loss 1.1836   LearningRate 0.000011   Epoch: 1   Global Step: 36630   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:25:49,242-Speed 140.26 samples/sec   Loss 1.1390   LearningRate 0.000011   Epoch: 1   Global Step: 36640   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:25:51,512-Speed 140.97 samples/sec   Loss 1.1606   LearningRate 0.000011   Epoch: 1   Global Step: 36650   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:25:53,788-Speed 140.64 samples/sec   Loss 1.1660   LearningRate 0.000010   Epoch: 1   Global Step: 36660   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:25:56,085-Speed 139.40 samples/sec   Loss 1.1509   LearningRate 0.000010   Epoch: 1   Global Step: 36670   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:25:58,371-Speed 140.01 samples/sec   Loss 1.1713   LearningRate 0.000010   Epoch: 1   Global Step: 36680   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:26:00,659-Speed 139.92 samples/sec   Loss 1.1321   LearningRate 0.000010   Epoch: 1   Global Step: 36690   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:26:02,941-Speed 140.29 samples/sec   Loss 1.1562   LearningRate 0.000010   Epoch: 1   Global Step: 36700   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:26:05,227-Speed 139.99 samples/sec   Loss 1.2066   LearningRate 0.000010   Epoch: 1   Global Step: 36710   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:26:07,517-Speed 139.79 samples/sec   Loss 1.1434   LearningRate 0.000010   Epoch: 1   Global Step: 36720   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:26:09,794-Speed 140.56 samples/sec   Loss 1.1518   LearningRate 0.000010   Epoch: 1   Global Step: 36730   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:26:12,086-Speed 139.70 samples/sec   Loss 1.1589   LearningRate 0.000010   Epoch: 1   Global Step: 36740   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:26:14,346-Speed 141.63 samples/sec   Loss 1.1543   LearningRate 0.000010   Epoch: 1   Global Step: 36750   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:26:16,625-Speed 140.40 samples/sec   Loss 1.1570   LearningRate 0.000010   Epoch: 1   Global Step: 36760   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:26:18,905-Speed 140.42 samples/sec   Loss 1.1459   LearningRate 0.000010   Epoch: 1   Global Step: 36770   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:26:21,193-Speed 139.90 samples/sec   Loss 1.1596   LearningRate 0.000010   Epoch: 1   Global Step: 36780   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:26:23,489-Speed 139.41 samples/sec   Loss 1.2061   LearningRate 0.000010   Epoch: 1   Global Step: 36790   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:26:25,769-Speed 140.41 samples/sec   Loss 1.1987   LearningRate 0.000010   Epoch: 1   Global Step: 36800   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:26:28,056-Speed 139.94 samples/sec   Loss 1.1381   LearningRate 0.000010   Epoch: 1   Global Step: 36810   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:26:30,341-Speed 140.12 samples/sec   Loss 1.1529   LearningRate 0.000010   Epoch: 1   Global Step: 36820   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:26:32,631-Speed 139.74 samples/sec   Loss 1.1849   LearningRate 0.000010   Epoch: 1   Global Step: 36830   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:26:34,900-Speed 141.06 samples/sec   Loss 1.1567   LearningRate 0.000010   Epoch: 1   Global Step: 36840   Fp16 Grad Scale: 16384   Required: 2 hours
Training: 2023-08-17 23:26:37,186-Speed 140.03 samples/sec   Loss 1.1762   LearningRate 0.000010   Epoch: 1   Global Step: 36850   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:26:39,499-Speed 138.37 samples/sec   Loss 1.1559   LearningRate 0.000010   Epoch: 1   Global Step: 36860   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:26:41,797-Speed 139.28 samples/sec   Loss 1.1751   LearningRate 0.000010   Epoch: 1   Global Step: 36870   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:26:44,092-Speed 139.50 samples/sec   Loss 1.1902   LearningRate 0.000010   Epoch: 1   Global Step: 36880   Fp16 Grad Scale: 32768   Required: 2 hours
Training: 2023-08-17 23:26:46,353-Speed 141.53 samples/sec   Loss 1.1735   LearningRate 0.000010   Epoch: 1   Global Step: 36890   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:26:48,661-Speed 138.72 samples/sec   Loss 1.1435   LearningRate 0.000010   Epoch: 1   Global Step: 36900   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:26:50,967-Speed 138.82 samples/sec   Loss 1.1797   LearningRate 0.000010   Epoch: 1   Global Step: 36910   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:26:53,272-Speed 138.86 samples/sec   Loss 1.1445   LearningRate 0.000010   Epoch: 1   Global Step: 36920   Fp16 Grad Scale: 8192   Required: 2 hours
Training: 2023-08-17 23:26:55,555-Speed 140.16 samples/sec   Loss 1.1599   LearningRate 0.000010   Epoch: 1   Global Step: 36930   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:26:57,834-Speed 140.46 samples/sec   Loss 1.1176   LearningRate 0.000010   Epoch: 1   Global Step: 36940   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:27:00,109-Speed 140.72 samples/sec   Loss 1.1360   LearningRate 0.000010   Epoch: 1   Global Step: 36950   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:27:02,407-Speed 139.32 samples/sec   Loss 1.1552   LearningRate 0.000010   Epoch: 1   Global Step: 36960   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:27:04,693-Speed 140.01 samples/sec   Loss 1.1716   LearningRate 0.000010   Epoch: 1   Global Step: 36970   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:27:06,981-Speed 139.89 samples/sec   Loss 1.1447   LearningRate 0.000010   Epoch: 1   Global Step: 36980   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:27:09,277-Speed 139.38 samples/sec   Loss 1.1641   LearningRate 0.000010   Epoch: 1   Global Step: 36990   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:27:11,358-Val on RAF/AffectNet:
Training: 2023-08-17 23:27:11,465-Test: [0/48]	Time 0.107 (0.107)	Loss 0.5742 (0.5742)	Acc@1 92.188 (92.188)	Acc@5 96.875 (96.875)	Mem 5268MB
Training: 2023-08-17 23:27:12,555-Test: [10/48]	Time 0.110 (0.109)	Loss 0.4723 (0.5683)	Acc@1 95.312 (91.619)	Acc@5 98.438 (98.153)	Mem 5268MB
Training: 2023-08-17 23:27:13,609-Test: [20/48]	Time 0.104 (0.107)	Loss 0.6667 (0.5586)	Acc@1 87.500 (92.411)	Acc@5 100.000 (98.289)	Mem 5268MB
Training: 2023-08-17 23:27:14,688-Test: [30/48]	Time 0.109 (0.107)	Loss 0.4794 (0.5552)	Acc@1 95.312 (92.692)	Acc@5 98.438 (98.387)	Mem 5268MB
Training: 2023-08-17 23:27:15,737-Test: [40/48]	Time 0.105 (0.107)	Loss 0.6223 (0.5570)	Acc@1 89.062 (92.264)	Acc@5 96.875 (98.476)	Mem 5268MB
Training: 2023-08-17 23:27:16,465-[36999]Expression Loss: 0.55551
Training: 2023-08-17 23:27:16,466-[36999]Expression Acc@1: 92.43807
Training: 2023-08-17 23:27:16,466-[36999]Expression Acc@1-Highest: 92.47067
Training: 2023-08-17 23:27:16,466-[36999]Expression Acc@5: 98.50065
Training: 2023-08-17 23:27:16,466-[36999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 23:27:16,466-[36999]10 Times Expression Acc@1: 92.02738
Training: 2023-08-17 23:27:16,466-[36999]10 Times Expression Acc@1-Highest: 92.07627
Training: 2023-08-17 23:27:16,694-Speed 43.15 samples/sec   Loss 1.1474   LearningRate 0.000010   Epoch: 1   Global Step: 37000   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:27:18,973-Speed 140.47 samples/sec   Loss 1.1750   LearningRate 0.000010   Epoch: 1   Global Step: 37010   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:27:21,253-Speed 140.42 samples/sec   Loss 1.1440   LearningRate 0.000010   Epoch: 1   Global Step: 37020   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:27:23,541-Speed 139.88 samples/sec   Loss 1.1452   LearningRate 0.000010   Epoch: 1   Global Step: 37030   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:27:25,837-Speed 139.39 samples/sec   Loss 1.1512   LearningRate 0.000010   Epoch: 1   Global Step: 37040   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:27:28,126-Speed 139.81 samples/sec   Loss 1.1663   LearningRate 0.000010   Epoch: 1   Global Step: 37050   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:27:30,453-Speed 137.57 samples/sec   Loss 1.1658   LearningRate 0.000010   Epoch: 1   Global Step: 37060   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:27:32,772-Speed 138.05 samples/sec   Loss 1.1562   LearningRate 0.000010   Epoch: 1   Global Step: 37070   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:27:35,081-Speed 138.61 samples/sec   Loss 1.1623   LearningRate 0.000010   Epoch: 1   Global Step: 37080   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:27:37,384-Speed 138.98 samples/sec   Loss 1.1635   LearningRate 0.000010   Epoch: 1   Global Step: 37090   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:27:39,690-Speed 138.80 samples/sec   Loss 1.1534   LearningRate 0.000010   Epoch: 1   Global Step: 37100   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:27:42,001-Speed 138.53 samples/sec   Loss 1.1568   LearningRate 0.000010   Epoch: 1   Global Step: 37110   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:27:44,310-Speed 138.65 samples/sec   Loss 1.1660   LearningRate 0.000010   Epoch: 1   Global Step: 37120   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:27:46,605-Speed 139.42 samples/sec   Loss 1.1864   LearningRate 0.000010   Epoch: 1   Global Step: 37130   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:27:48,902-Speed 139.39 samples/sec   Loss 1.1441   LearningRate 0.000010   Epoch: 1   Global Step: 37140   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:27:51,213-Speed 138.49 samples/sec   Loss 1.1585   LearningRate 0.000010   Epoch: 1   Global Step: 37150   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:27:53,539-Speed 137.63 samples/sec   Loss 1.1316   LearningRate 0.000010   Epoch: 1   Global Step: 37160   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:27:55,850-Speed 138.54 samples/sec   Loss 1.1416   LearningRate 0.000010   Epoch: 1   Global Step: 37170   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:27:58,151-Speed 139.07 samples/sec   Loss 1.1401   LearningRate 0.000010   Epoch: 1   Global Step: 37180   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:28:00,441-Speed 139.82 samples/sec   Loss 1.1296   LearningRate 0.000010   Epoch: 1   Global Step: 37190   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:28:02,743-Speed 139.01 samples/sec   Loss 1.1360   LearningRate 0.000010   Epoch: 1   Global Step: 37200   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:28:05,052-Speed 138.68 samples/sec   Loss 1.1535   LearningRate 0.000010   Epoch: 1   Global Step: 37210   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:28:07,365-Speed 138.35 samples/sec   Loss 1.1765   LearningRate 0.000010   Epoch: 1   Global Step: 37220   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:28:09,682-Speed 138.18 samples/sec   Loss 1.1447   LearningRate 0.000010   Epoch: 1   Global Step: 37230   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:28:11,961-Speed 140.46 samples/sec   Loss 1.1800   LearningRate 0.000010   Epoch: 1   Global Step: 37240   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:28:14,257-Speed 139.40 samples/sec   Loss 1.1647   LearningRate 0.000010   Epoch: 1   Global Step: 37250   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:28:16,553-Speed 139.38 samples/sec   Loss 1.1714   LearningRate 0.000010   Epoch: 1   Global Step: 37260   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:28:18,844-Speed 139.68 samples/sec   Loss 1.1689   LearningRate 0.000010   Epoch: 1   Global Step: 37270   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:28:21,133-Speed 139.88 samples/sec   Loss 1.1661   LearningRate 0.000010   Epoch: 1   Global Step: 37280   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:28:23,429-Speed 139.41 samples/sec   Loss 1.1700   LearningRate 0.000010   Epoch: 1   Global Step: 37290   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:28:25,736-Speed 138.72 samples/sec   Loss 1.1424   LearningRate 0.000010   Epoch: 1   Global Step: 37300   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:28:28,036-Speed 139.15 samples/sec   Loss 1.1476   LearningRate 0.000010   Epoch: 1   Global Step: 37310   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:28:30,325-Speed 139.87 samples/sec   Loss 1.1948   LearningRate 0.000010   Epoch: 1   Global Step: 37320   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:28:32,623-Speed 139.25 samples/sec   Loss 1.1323   LearningRate 0.000010   Epoch: 1   Global Step: 37330   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:28:34,926-Speed 139.02 samples/sec   Loss 1.1748   LearningRate 0.000010   Epoch: 1   Global Step: 37340   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:28:37,229-Speed 138.99 samples/sec   Loss 1.1521   LearningRate 0.000010   Epoch: 1   Global Step: 37350   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:28:39,525-Speed 139.38 samples/sec   Loss 1.1503   LearningRate 0.000010   Epoch: 1   Global Step: 37360   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:28:41,818-Speed 139.59 samples/sec   Loss 1.1540   LearningRate 0.000010   Epoch: 1   Global Step: 37370   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:28:44,116-Speed 139.30 samples/sec   Loss 1.1725   LearningRate 0.000010   Epoch: 1   Global Step: 37380   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:28:46,429-Speed 138.38 samples/sec   Loss 1.1393   LearningRate 0.000010   Epoch: 1   Global Step: 37390   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:28:48,712-Speed 140.21 samples/sec   Loss 1.1543   LearningRate 0.000010   Epoch: 1   Global Step: 37400   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:28:51,012-Speed 139.15 samples/sec   Loss 1.1380   LearningRate 0.000010   Epoch: 1   Global Step: 37410   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:28:53,313-Speed 139.11 samples/sec   Loss 1.1461   LearningRate 0.000010   Epoch: 1   Global Step: 37420   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:28:55,622-Speed 138.64 samples/sec   Loss 1.1614   LearningRate 0.000010   Epoch: 1   Global Step: 37430   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:28:57,928-Speed 138.78 samples/sec   Loss 1.1277   LearningRate 0.000010   Epoch: 1   Global Step: 37440   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:29:00,212-Speed 140.16 samples/sec   Loss 1.1553   LearningRate 0.000010   Epoch: 1   Global Step: 37450   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:29:02,512-Speed 139.12 samples/sec   Loss 1.1971   LearningRate 0.000010   Epoch: 1   Global Step: 37460   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:29:04,798-Speed 140.03 samples/sec   Loss 1.1719   LearningRate 0.000010   Epoch: 1   Global Step: 37470   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:29:07,096-Speed 139.29 samples/sec   Loss 1.1677   LearningRate 0.000010   Epoch: 1   Global Step: 37480   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:29:09,393-Speed 139.35 samples/sec   Loss 1.1580   LearningRate 0.000010   Epoch: 1   Global Step: 37490   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:29:11,688-Speed 139.46 samples/sec   Loss 1.1540   LearningRate 0.000010   Epoch: 1   Global Step: 37500   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:29:13,984-Speed 139.43 samples/sec   Loss 1.1728   LearningRate 0.000010   Epoch: 1   Global Step: 37510   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:29:16,281-Speed 139.31 samples/sec   Loss 1.1663   LearningRate 0.000010   Epoch: 1   Global Step: 37520   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:29:18,574-Speed 139.58 samples/sec   Loss 1.1671   LearningRate 0.000010   Epoch: 1   Global Step: 37530   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:29:20,875-Speed 139.16 samples/sec   Loss 1.1409   LearningRate 0.000010   Epoch: 1   Global Step: 37540   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:29:23,167-Speed 139.63 samples/sec   Loss 1.1339   LearningRate 0.000010   Epoch: 1   Global Step: 37550   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:29:25,452-Speed 140.06 samples/sec   Loss 1.1704   LearningRate 0.000010   Epoch: 1   Global Step: 37560   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:29:27,751-Speed 139.26 samples/sec   Loss 1.1512   LearningRate 0.000010   Epoch: 1   Global Step: 37570   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:29:30,052-Speed 139.09 samples/sec   Loss 1.1477   LearningRate 0.000010   Epoch: 1   Global Step: 37580   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:29:32,336-Speed 140.16 samples/sec   Loss 1.1837   LearningRate 0.000010   Epoch: 1   Global Step: 37590   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:29:34,637-Speed 139.06 samples/sec   Loss 1.1600   LearningRate 0.000010   Epoch: 1   Global Step: 37600   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:29:36,920-Speed 140.21 samples/sec   Loss 1.1563   LearningRate 0.000010   Epoch: 1   Global Step: 37610   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:29:39,216-Speed 139.41 samples/sec   Loss 1.1691   LearningRate 0.000010   Epoch: 1   Global Step: 37620   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:29:41,503-Speed 139.99 samples/sec   Loss 1.1526   LearningRate 0.000010   Epoch: 1   Global Step: 37630   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:29:43,800-Speed 139.30 samples/sec   Loss 1.1891   LearningRate 0.000010   Epoch: 1   Global Step: 37640   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:29:46,097-Speed 139.36 samples/sec   Loss 1.1883   LearningRate 0.000010   Epoch: 1   Global Step: 37650   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:29:48,405-Speed 138.73 samples/sec   Loss 1.1518   LearningRate 0.000010   Epoch: 1   Global Step: 37660   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:29:50,716-Speed 138.47 samples/sec   Loss 1.1681   LearningRate 0.000010   Epoch: 1   Global Step: 37670   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:29:53,016-Speed 139.18 samples/sec   Loss 1.1504   LearningRate 0.000010   Epoch: 1   Global Step: 37680   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:29:55,303-Speed 139.97 samples/sec   Loss 1.1607   LearningRate 0.000010   Epoch: 1   Global Step: 37690   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:29:57,597-Speed 139.49 samples/sec   Loss 1.1880   LearningRate 0.000010   Epoch: 1   Global Step: 37700   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:29:59,889-Speed 139.68 samples/sec   Loss 1.1624   LearningRate 0.000010   Epoch: 1   Global Step: 37710   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:30:02,195-Speed 138.82 samples/sec   Loss 1.1490   LearningRate 0.000010   Epoch: 1   Global Step: 37720   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:30:04,500-Speed 138.83 samples/sec   Loss 1.1345   LearningRate 0.000010   Epoch: 1   Global Step: 37730   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:30:06,796-Speed 139.46 samples/sec   Loss 1.1435   LearningRate 0.000010   Epoch: 1   Global Step: 37740   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:30:09,092-Speed 139.36 samples/sec   Loss 1.1479   LearningRate 0.000010   Epoch: 1   Global Step: 37750   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:30:11,391-Speed 139.25 samples/sec   Loss 1.1574   LearningRate 0.000010   Epoch: 1   Global Step: 37760   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:30:13,680-Speed 139.81 samples/sec   Loss 1.1436   LearningRate 0.000010   Epoch: 1   Global Step: 37770   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:30:15,959-Speed 140.50 samples/sec   Loss 1.1590   LearningRate 0.000010   Epoch: 1   Global Step: 37780   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:30:18,238-Speed 140.38 samples/sec   Loss 1.2026   LearningRate 0.000010   Epoch: 1   Global Step: 37790   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:30:20,530-Speed 139.69 samples/sec   Loss 1.1234   LearningRate 0.000010   Epoch: 1   Global Step: 37800   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:30:22,821-Speed 139.71 samples/sec   Loss 1.1558   LearningRate 0.000010   Epoch: 1   Global Step: 37810   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:30:25,098-Speed 140.54 samples/sec   Loss 1.1530   LearningRate 0.000010   Epoch: 1   Global Step: 37820   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:30:27,378-Speed 140.37 samples/sec   Loss 1.1673   LearningRate 0.000010   Epoch: 1   Global Step: 37830   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:30:29,664-Speed 140.07 samples/sec   Loss 1.1379   LearningRate 0.000010   Epoch: 1   Global Step: 37840   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:30:31,952-Speed 139.90 samples/sec   Loss 1.1716   LearningRate 0.000010   Epoch: 1   Global Step: 37850   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:30:34,247-Speed 139.46 samples/sec   Loss 1.1673   LearningRate 0.000010   Epoch: 1   Global Step: 37860   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:30:36,540-Speed 139.58 samples/sec   Loss 1.1860   LearningRate 0.000010   Epoch: 1   Global Step: 37870   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:30:38,822-Speed 140.28 samples/sec   Loss 1.1400   LearningRate 0.000010   Epoch: 1   Global Step: 37880   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:30:41,106-Speed 140.13 samples/sec   Loss 1.1389   LearningRate 0.000010   Epoch: 1   Global Step: 37890   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:30:43,383-Speed 140.58 samples/sec   Loss 1.1741   LearningRate 0.000010   Epoch: 1   Global Step: 37900   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:30:45,671-Speed 139.84 samples/sec   Loss 1.1601   LearningRate 0.000010   Epoch: 1   Global Step: 37910   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:30:47,951-Speed 140.41 samples/sec   Loss 1.1578   LearningRate 0.000010   Epoch: 1   Global Step: 37920   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:30:50,231-Speed 140.42 samples/sec   Loss 1.1705   LearningRate 0.000010   Epoch: 1   Global Step: 37930   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:30:52,515-Speed 140.12 samples/sec   Loss 1.1667   LearningRate 0.000010   Epoch: 1   Global Step: 37940   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:30:54,793-Speed 140.55 samples/sec   Loss 1.1515   LearningRate 0.000010   Epoch: 1   Global Step: 37950   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:30:57,061-Speed 141.13 samples/sec   Loss 1.1463   LearningRate 0.000010   Epoch: 1   Global Step: 37960   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:30:59,342-Speed 140.30 samples/sec   Loss 1.1393   LearningRate 0.000010   Epoch: 1   Global Step: 37970   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:31:01,624-Speed 140.29 samples/sec   Loss 1.1534   LearningRate 0.000010   Epoch: 1   Global Step: 37980   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:31:03,940-Speed 138.20 samples/sec   Loss 1.1289   LearningRate 0.000009   Epoch: 1   Global Step: 37990   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:31:06,012-Val on RAF/AffectNet:
Training: 2023-08-17 23:31:06,125-Test: [0/48]	Time 0.113 (0.113)	Loss 0.5960 (0.5960)	Acc@1 90.625 (90.625)	Acc@5 96.875 (96.875)	Mem 5268MB
Training: 2023-08-17 23:31:07,229-Test: [10/48]	Time 0.110 (0.111)	Loss 0.5745 (0.5470)	Acc@1 90.625 (93.182)	Acc@5 100.000 (98.580)	Mem 5268MB
Training: 2023-08-17 23:31:08,319-Test: [20/48]	Time 0.108 (0.110)	Loss 0.6348 (0.5501)	Acc@1 89.062 (92.932)	Acc@5 95.312 (98.438)	Mem 5268MB
Training: 2023-08-17 23:31:09,400-Test: [30/48]	Time 0.107 (0.109)	Loss 0.4898 (0.5500)	Acc@1 95.312 (92.792)	Acc@5 96.875 (98.185)	Mem 5268MB
Training: 2023-08-17 23:31:10,467-Test: [40/48]	Time 0.107 (0.109)	Loss 0.5680 (0.5544)	Acc@1 92.188 (92.302)	Acc@5 100.000 (98.247)	Mem 5268MB
Training: 2023-08-17 23:31:11,217-[37999]Expression Loss: 0.55391
Training: 2023-08-17 23:31:11,217-[37999]Expression Acc@1: 92.30769
Training: 2023-08-17 23:31:11,217-[37999]Expression Acc@1-Highest: 92.47067
Training: 2023-08-17 23:31:11,217-[37999]Expression Acc@5: 98.23990
Training: 2023-08-17 23:31:11,217-[37999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 23:31:11,217-[37999]10 Times Expression Acc@1: 92.04694
Training: 2023-08-17 23:31:11,217-[37999]10 Times Expression Acc@1-Highest: 92.07627
Training: 2023-08-17 23:31:11,447-Speed 42.63 samples/sec   Loss 1.1579   LearningRate 0.000009   Epoch: 1   Global Step: 38000   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:31:13,741-Speed 139.52 samples/sec   Loss 1.1531   LearningRate 0.000009   Epoch: 1   Global Step: 38010   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:31:16,035-Speed 139.52 samples/sec   Loss 1.1702   LearningRate 0.000009   Epoch: 1   Global Step: 38020   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:31:18,315-Speed 140.44 samples/sec   Loss 1.1653   LearningRate 0.000009   Epoch: 1   Global Step: 38030   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:31:20,602-Speed 139.94 samples/sec   Loss 1.1699   LearningRate 0.000009   Epoch: 1   Global Step: 38040   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:31:22,886-Speed 140.14 samples/sec   Loss 1.1362   LearningRate 0.000009   Epoch: 1   Global Step: 38050   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:31:25,167-Speed 140.33 samples/sec   Loss 1.1321   LearningRate 0.000009   Epoch: 1   Global Step: 38060   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:31:27,458-Speed 139.69 samples/sec   Loss 1.1570   LearningRate 0.000009   Epoch: 1   Global Step: 38070   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:31:29,746-Speed 139.94 samples/sec   Loss 1.1518   LearningRate 0.000009   Epoch: 1   Global Step: 38080   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:31:32,037-Speed 139.66 samples/sec   Loss 1.1625   LearningRate 0.000009   Epoch: 1   Global Step: 38090   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:31:34,332-Speed 139.52 samples/sec   Loss 1.1306   LearningRate 0.000009   Epoch: 1   Global Step: 38100   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:31:36,624-Speed 139.60 samples/sec   Loss 1.1515   LearningRate 0.000009   Epoch: 1   Global Step: 38110   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:31:38,935-Speed 138.57 samples/sec   Loss 1.1590   LearningRate 0.000009   Epoch: 1   Global Step: 38120   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:31:41,240-Speed 138.82 samples/sec   Loss 1.1425   LearningRate 0.000009   Epoch: 1   Global Step: 38130   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:31:43,526-Speed 140.05 samples/sec   Loss 1.1549   LearningRate 0.000009   Epoch: 1   Global Step: 38140   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:31:45,806-Speed 140.40 samples/sec   Loss 1.1947   LearningRate 0.000009   Epoch: 1   Global Step: 38150   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:31:48,095-Speed 139.83 samples/sec   Loss 1.1324   LearningRate 0.000009   Epoch: 1   Global Step: 38160   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:31:50,380-Speed 140.09 samples/sec   Loss 1.1643   LearningRate 0.000009   Epoch: 1   Global Step: 38170   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:31:52,666-Speed 140.02 samples/sec   Loss 1.1721   LearningRate 0.000009   Epoch: 1   Global Step: 38180   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:31:54,956-Speed 139.77 samples/sec   Loss 1.1626   LearningRate 0.000009   Epoch: 1   Global Step: 38190   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:31:57,255-Speed 139.22 samples/sec   Loss 1.1686   LearningRate 0.000009   Epoch: 1   Global Step: 38200   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:31:59,548-Speed 139.61 samples/sec   Loss 1.1501   LearningRate 0.000009   Epoch: 1   Global Step: 38210   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:32:01,830-Speed 140.24 samples/sec   Loss 1.1552   LearningRate 0.000009   Epoch: 1   Global Step: 38220   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:32:04,130-Speed 139.16 samples/sec   Loss 1.1443   LearningRate 0.000009   Epoch: 1   Global Step: 38230   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:32:06,421-Speed 139.75 samples/sec   Loss 1.1874   LearningRate 0.000009   Epoch: 1   Global Step: 38240   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:32:08,698-Speed 140.56 samples/sec   Loss 1.1559   LearningRate 0.000009   Epoch: 1   Global Step: 38250   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:32:10,985-Speed 139.94 samples/sec   Loss 1.1645   LearningRate 0.000009   Epoch: 1   Global Step: 38260   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:32:13,284-Speed 139.27 samples/sec   Loss 1.1351   LearningRate 0.000009   Epoch: 1   Global Step: 38270   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:32:15,564-Speed 140.42 samples/sec   Loss 1.1371   LearningRate 0.000009   Epoch: 1   Global Step: 38280   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:32:17,853-Speed 139.84 samples/sec   Loss 1.1852   LearningRate 0.000009   Epoch: 1   Global Step: 38290   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:32:20,147-Speed 139.53 samples/sec   Loss 1.1467   LearningRate 0.000009   Epoch: 1   Global Step: 38300   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:32:22,446-Speed 139.19 samples/sec   Loss 1.1403   LearningRate 0.000009   Epoch: 1   Global Step: 38310   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:32:24,770-Speed 137.76 samples/sec   Loss 1.1592   LearningRate 0.000009   Epoch: 1   Global Step: 38320   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:32:27,095-Speed 137.65 samples/sec   Loss 1.1815   LearningRate 0.000009   Epoch: 1   Global Step: 38330   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:32:29,413-Speed 138.09 samples/sec   Loss 1.1531   LearningRate 0.000009   Epoch: 1   Global Step: 38340   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:32:31,722-Speed 138.65 samples/sec   Loss 1.1442   LearningRate 0.000009   Epoch: 1   Global Step: 38350   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:32:34,039-Speed 138.12 samples/sec   Loss 1.1318   LearningRate 0.000009   Epoch: 1   Global Step: 38360   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:32:36,353-Speed 138.34 samples/sec   Loss 1.1551   LearningRate 0.000009   Epoch: 1   Global Step: 38370   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:32:38,665-Speed 138.44 samples/sec   Loss 1.1421   LearningRate 0.000009   Epoch: 1   Global Step: 38380   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:32:40,974-Speed 138.62 samples/sec   Loss 1.1560   LearningRate 0.000009   Epoch: 1   Global Step: 38390   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:32:43,301-Speed 137.58 samples/sec   Loss 1.1493   LearningRate 0.000009   Epoch: 1   Global Step: 38400   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:32:45,620-Speed 137.98 samples/sec   Loss 1.1562   LearningRate 0.000009   Epoch: 1   Global Step: 38410   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:32:47,929-Speed 138.63 samples/sec   Loss 1.1480   LearningRate 0.000009   Epoch: 1   Global Step: 38420   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:32:50,221-Speed 139.70 samples/sec   Loss 1.1625   LearningRate 0.000009   Epoch: 1   Global Step: 38430   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:32:52,491-Speed 140.95 samples/sec   Loss 1.1527   LearningRate 0.000009   Epoch: 1   Global Step: 38440   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:32:54,753-Speed 141.55 samples/sec   Loss 1.1282   LearningRate 0.000009   Epoch: 1   Global Step: 38450   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:32:57,051-Speed 139.28 samples/sec   Loss 1.1573   LearningRate 0.000009   Epoch: 1   Global Step: 38460   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:32:59,320-Speed 141.08 samples/sec   Loss 1.1627   LearningRate 0.000009   Epoch: 1   Global Step: 38470   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:33:01,597-Speed 140.55 samples/sec   Loss 1.1442   LearningRate 0.000009   Epoch: 1   Global Step: 38480   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:33:03,884-Speed 139.98 samples/sec   Loss 1.1638   LearningRate 0.000009   Epoch: 1   Global Step: 38490   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:33:06,173-Speed 139.85 samples/sec   Loss 1.1329   LearningRate 0.000009   Epoch: 1   Global Step: 38500   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:33:08,453-Speed 140.35 samples/sec   Loss 1.1651   LearningRate 0.000009   Epoch: 1   Global Step: 38510   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:33:10,745-Speed 139.70 samples/sec   Loss 1.1633   LearningRate 0.000009   Epoch: 1   Global Step: 38520   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:33:13,021-Speed 140.61 samples/sec   Loss 1.1294   LearningRate 0.000009   Epoch: 1   Global Step: 38530   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:33:15,288-Speed 141.24 samples/sec   Loss 1.1489   LearningRate 0.000009   Epoch: 1   Global Step: 38540   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:33:17,571-Speed 140.20 samples/sec   Loss 1.1647   LearningRate 0.000009   Epoch: 1   Global Step: 38550   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:33:19,851-Speed 140.33 samples/sec   Loss 1.1618   LearningRate 0.000009   Epoch: 1   Global Step: 38560   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:33:22,125-Speed 140.81 samples/sec   Loss 1.1640   LearningRate 0.000009   Epoch: 1   Global Step: 38570   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:33:24,405-Speed 140.37 samples/sec   Loss 1.1453   LearningRate 0.000009   Epoch: 1   Global Step: 38580   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:33:26,698-Speed 139.60 samples/sec   Loss 1.1480   LearningRate 0.000009   Epoch: 1   Global Step: 38590   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:33:28,973-Speed 140.68 samples/sec   Loss 1.1556   LearningRate 0.000009   Epoch: 1   Global Step: 38600   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:33:31,252-Speed 140.49 samples/sec   Loss 1.1754   LearningRate 0.000009   Epoch: 1   Global Step: 38610   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:33:33,520-Speed 141.10 samples/sec   Loss 1.1779   LearningRate 0.000009   Epoch: 1   Global Step: 38620   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:33:35,798-Speed 140.54 samples/sec   Loss 1.1546   LearningRate 0.000009   Epoch: 1   Global Step: 38630   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:33:38,089-Speed 139.67 samples/sec   Loss 1.1340   LearningRate 0.000009   Epoch: 1   Global Step: 38640   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:33:40,359-Speed 141.06 samples/sec   Loss 1.1605   LearningRate 0.000009   Epoch: 1   Global Step: 38650   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:33:42,639-Speed 140.35 samples/sec   Loss 1.1487   LearningRate 0.000009   Epoch: 1   Global Step: 38660   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:33:44,923-Speed 140.17 samples/sec   Loss 1.1745   LearningRate 0.000009   Epoch: 1   Global Step: 38670   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:33:47,204-Speed 140.33 samples/sec   Loss 1.1919   LearningRate 0.000009   Epoch: 1   Global Step: 38680   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:33:49,512-Speed 138.68 samples/sec   Loss 1.1347   LearningRate 0.000009   Epoch: 1   Global Step: 38690   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:33:51,789-Speed 140.62 samples/sec   Loss 1.1631   LearningRate 0.000009   Epoch: 1   Global Step: 38700   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:33:54,096-Speed 138.70 samples/sec   Loss 1.1410   LearningRate 0.000009   Epoch: 1   Global Step: 38710   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:33:56,404-Speed 138.74 samples/sec   Loss 1.1338   LearningRate 0.000009   Epoch: 1   Global Step: 38720   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:33:58,679-Speed 140.69 samples/sec   Loss 1.1651   LearningRate 0.000009   Epoch: 1   Global Step: 38730   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:34:00,964-Speed 140.04 samples/sec   Loss 1.1656   LearningRate 0.000009   Epoch: 1   Global Step: 38740   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:34:03,260-Speed 139.44 samples/sec   Loss 1.1508   LearningRate 0.000009   Epoch: 1   Global Step: 38750   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:34:05,551-Speed 139.71 samples/sec   Loss 1.1667   LearningRate 0.000009   Epoch: 1   Global Step: 38760   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:34:07,844-Speed 139.60 samples/sec   Loss 1.1502   LearningRate 0.000009   Epoch: 1   Global Step: 38770   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:34:10,126-Speed 140.23 samples/sec   Loss 1.1726   LearningRate 0.000009   Epoch: 1   Global Step: 38780   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:34:12,415-Speed 139.89 samples/sec   Loss 1.1338   LearningRate 0.000009   Epoch: 1   Global Step: 38790   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:34:14,703-Speed 139.91 samples/sec   Loss 1.1247   LearningRate 0.000009   Epoch: 1   Global Step: 38800   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:34:16,998-Speed 139.45 samples/sec   Loss 1.1470   LearningRate 0.000009   Epoch: 1   Global Step: 38810   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:34:19,283-Speed 140.09 samples/sec   Loss 1.1290   LearningRate 0.000009   Epoch: 1   Global Step: 38820   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:34:21,570-Speed 139.92 samples/sec   Loss 1.1488   LearningRate 0.000009   Epoch: 1   Global Step: 38830   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:34:23,851-Speed 140.34 samples/sec   Loss 1.1563   LearningRate 0.000009   Epoch: 1   Global Step: 38840   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:34:26,146-Speed 139.49 samples/sec   Loss 1.1506   LearningRate 0.000009   Epoch: 1   Global Step: 38850   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:34:28,449-Speed 139.00 samples/sec   Loss 1.1477   LearningRate 0.000009   Epoch: 1   Global Step: 38860   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:34:30,746-Speed 139.33 samples/sec   Loss 1.1576   LearningRate 0.000009   Epoch: 1   Global Step: 38870   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:34:33,018-Speed 140.87 samples/sec   Loss 1.1342   LearningRate 0.000009   Epoch: 1   Global Step: 38880   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:34:35,315-Speed 139.39 samples/sec   Loss 1.1338   LearningRate 0.000009   Epoch: 1   Global Step: 38890   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:34:37,615-Speed 139.14 samples/sec   Loss 1.1601   LearningRate 0.000009   Epoch: 1   Global Step: 38900   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:34:39,905-Speed 139.80 samples/sec   Loss 1.1462   LearningRate 0.000009   Epoch: 1   Global Step: 38910   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:34:42,193-Speed 139.87 samples/sec   Loss 1.1651   LearningRate 0.000009   Epoch: 1   Global Step: 38920   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:34:44,502-Speed 138.66 samples/sec   Loss 1.1460   LearningRate 0.000009   Epoch: 1   Global Step: 38930   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:34:46,793-Speed 139.70 samples/sec   Loss 1.1619   LearningRate 0.000009   Epoch: 1   Global Step: 38940   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:34:49,086-Speed 139.60 samples/sec   Loss 1.1449   LearningRate 0.000009   Epoch: 1   Global Step: 38950   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:34:51,384-Speed 139.33 samples/sec   Loss 1.1414   LearningRate 0.000009   Epoch: 1   Global Step: 38960   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:34:53,677-Speed 139.57 samples/sec   Loss 1.1615   LearningRate 0.000009   Epoch: 1   Global Step: 38970   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:34:55,971-Speed 139.52 samples/sec   Loss 1.1446   LearningRate 0.000009   Epoch: 1   Global Step: 38980   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:34:58,261-Speed 139.82 samples/sec   Loss 1.1724   LearningRate 0.000009   Epoch: 1   Global Step: 38990   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:35:00,322-Val on RAF/AffectNet:
Training: 2023-08-17 23:35:00,431-Test: [0/48]	Time 0.109 (0.109)	Loss 0.5443 (0.5443)	Acc@1 93.750 (93.750)	Acc@5 98.438 (98.438)	Mem 5268MB
Training: 2023-08-17 23:35:01,502-Test: [10/48]	Time 0.106 (0.107)	Loss 0.5394 (0.5946)	Acc@1 95.312 (91.335)	Acc@5 96.875 (97.301)	Mem 5268MB
Training: 2023-08-17 23:35:02,559-Test: [20/48]	Time 0.107 (0.106)	Loss 0.5427 (0.5790)	Acc@1 93.750 (91.518)	Acc@5 98.438 (98.065)	Mem 5268MB
Training: 2023-08-17 23:35:03,621-Test: [30/48]	Time 0.106 (0.106)	Loss 0.7762 (0.5836)	Acc@1 87.500 (91.381)	Acc@5 92.188 (98.085)	Mem 5268MB
Training: 2023-08-17 23:35:04,687-Test: [40/48]	Time 0.108 (0.106)	Loss 0.4737 (0.5609)	Acc@1 93.750 (92.264)	Acc@5 100.000 (98.514)	Mem 5268MB
Training: 2023-08-17 23:35:05,443-[38999]Expression Loss: 0.56106
Training: 2023-08-17 23:35:05,443-[38999]Expression Acc@1: 92.30769
Training: 2023-08-17 23:35:05,443-[38999]Expression Acc@1-Highest: 92.47067
Training: 2023-08-17 23:35:05,443-[38999]Expression Acc@5: 98.43546
Training: 2023-08-17 23:35:05,443-[38999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 23:35:05,443-[38999]10 Times Expression Acc@1: 92.10561
Training: 2023-08-17 23:35:05,443-[38999]10 Times Expression Acc@1-Highest: 92.10561
Training: 2023-08-17 23:35:05,676-Speed 43.16 samples/sec   Loss 1.1323   LearningRate 0.000009   Epoch: 1   Global Step: 39000   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:35:07,954-Speed 140.50 samples/sec   Loss 1.1325   LearningRate 0.000009   Epoch: 1   Global Step: 39010   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:35:10,244-Speed 139.75 samples/sec   Loss 1.1499   LearningRate 0.000009   Epoch: 1   Global Step: 39020   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:35:12,517-Speed 140.85 samples/sec   Loss 1.1623   LearningRate 0.000009   Epoch: 1   Global Step: 39030   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:35:14,796-Speed 140.45 samples/sec   Loss 1.1377   LearningRate 0.000009   Epoch: 1   Global Step: 39040   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:35:17,114-Speed 138.06 samples/sec   Loss 1.1439   LearningRate 0.000009   Epoch: 1   Global Step: 39050   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:35:19,438-Speed 137.76 samples/sec   Loss 1.1614   LearningRate 0.000009   Epoch: 1   Global Step: 39060   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:35:21,770-Speed 137.27 samples/sec   Loss 1.1792   LearningRate 0.000009   Epoch: 1   Global Step: 39070   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:35:24,085-Speed 138.23 samples/sec   Loss 1.1294   LearningRate 0.000009   Epoch: 1   Global Step: 39080   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:35:26,394-Speed 138.64 samples/sec   Loss 1.1745   LearningRate 0.000009   Epoch: 1   Global Step: 39090   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:35:28,715-Speed 137.91 samples/sec   Loss 1.1473   LearningRate 0.000009   Epoch: 1   Global Step: 39100   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:35:31,027-Speed 138.46 samples/sec   Loss 1.1699   LearningRate 0.000009   Epoch: 1   Global Step: 39110   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:35:33,299-Speed 140.87 samples/sec   Loss 1.1486   LearningRate 0.000009   Epoch: 1   Global Step: 39120   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:35:35,564-Speed 141.33 samples/sec   Loss 1.1641   LearningRate 0.000009   Epoch: 1   Global Step: 39130   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:35:37,844-Speed 140.37 samples/sec   Loss 1.1293   LearningRate 0.000009   Epoch: 1   Global Step: 39140   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:35:40,136-Speed 139.67 samples/sec   Loss 1.1693   LearningRate 0.000009   Epoch: 1   Global Step: 39150   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:35:42,405-Speed 141.08 samples/sec   Loss 1.1547   LearningRate 0.000009   Epoch: 1   Global Step: 39160   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:35:44,692-Speed 139.97 samples/sec   Loss 1.1327   LearningRate 0.000009   Epoch: 1   Global Step: 39170   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:35:46,974-Speed 140.23 samples/sec   Loss 1.1353   LearningRate 0.000009   Epoch: 1   Global Step: 39180   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:35:49,255-Speed 140.33 samples/sec   Loss 1.1529   LearningRate 0.000009   Epoch: 1   Global Step: 39190   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:35:51,538-Speed 140.23 samples/sec   Loss 1.1859   LearningRate 0.000009   Epoch: 1   Global Step: 39200   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:35:53,811-Speed 140.83 samples/sec   Loss 1.1600   LearningRate 0.000009   Epoch: 1   Global Step: 39210   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:35:56,082-Speed 140.92 samples/sec   Loss 1.1622   LearningRate 0.000009   Epoch: 1   Global Step: 39220   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:35:58,341-Speed 141.75 samples/sec   Loss 1.1546   LearningRate 0.000009   Epoch: 1   Global Step: 39230   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:36:00,627-Speed 139.96 samples/sec   Loss 1.1333   LearningRate 0.000009   Epoch: 1   Global Step: 39240   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:36:02,927-Speed 139.21 samples/sec   Loss 1.1476   LearningRate 0.000009   Epoch: 1   Global Step: 39250   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:36:05,223-Speed 139.42 samples/sec   Loss 1.1347   LearningRate 0.000009   Epoch: 1   Global Step: 39260   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:36:07,507-Speed 140.15 samples/sec   Loss 1.1398   LearningRate 0.000009   Epoch: 1   Global Step: 39270   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:36:09,797-Speed 139.77 samples/sec   Loss 1.1464   LearningRate 0.000009   Epoch: 1   Global Step: 39280   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:36:12,085-Speed 139.91 samples/sec   Loss 1.1434   LearningRate 0.000009   Epoch: 1   Global Step: 39290   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:36:14,346-Speed 141.52 samples/sec   Loss 1.1660   LearningRate 0.000009   Epoch: 1   Global Step: 39300   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:36:16,621-Speed 140.72 samples/sec   Loss 1.1533   LearningRate 0.000009   Epoch: 1   Global Step: 39310   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:36:18,914-Speed 139.56 samples/sec   Loss 1.1105   LearningRate 0.000009   Epoch: 1   Global Step: 39320   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:36:21,196-Speed 140.30 samples/sec   Loss 1.1333   LearningRate 0.000009   Epoch: 1   Global Step: 39330   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:36:23,486-Speed 139.79 samples/sec   Loss 1.1453   LearningRate 0.000009   Epoch: 1   Global Step: 39340   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:36:25,766-Speed 140.35 samples/sec   Loss 1.1455   LearningRate 0.000009   Epoch: 1   Global Step: 39350   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:36:28,068-Speed 139.05 samples/sec   Loss 1.1400   LearningRate 0.000009   Epoch: 1   Global Step: 39360   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:36:30,341-Speed 140.84 samples/sec   Loss 1.1797   LearningRate 0.000008   Epoch: 1   Global Step: 39370   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:36:32,651-Speed 138.59 samples/sec   Loss 1.1558   LearningRate 0.000008   Epoch: 1   Global Step: 39380   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:36:34,952-Speed 139.10 samples/sec   Loss 1.1427   LearningRate 0.000008   Epoch: 1   Global Step: 39390   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:36:37,238-Speed 140.00 samples/sec   Loss 1.1428   LearningRate 0.000008   Epoch: 1   Global Step: 39400   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:36:39,527-Speed 139.87 samples/sec   Loss 1.1360   LearningRate 0.000008   Epoch: 1   Global Step: 39410   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:36:41,824-Speed 139.33 samples/sec   Loss 1.1607   LearningRate 0.000008   Epoch: 1   Global Step: 39420   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:36:44,119-Speed 139.46 samples/sec   Loss 1.1548   LearningRate 0.000008   Epoch: 1   Global Step: 39430   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:36:46,413-Speed 139.54 samples/sec   Loss 1.1803   LearningRate 0.000008   Epoch: 1   Global Step: 39440   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:36:48,722-Speed 138.63 samples/sec   Loss 1.1494   LearningRate 0.000008   Epoch: 1   Global Step: 39450   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:36:50,998-Speed 140.63 samples/sec   Loss 1.1708   LearningRate 0.000008   Epoch: 1   Global Step: 39460   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:36:53,293-Speed 139.45 samples/sec   Loss 1.1541   LearningRate 0.000008   Epoch: 1   Global Step: 39470   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:36:55,596-Speed 139.01 samples/sec   Loss 1.1327   LearningRate 0.000008   Epoch: 1   Global Step: 39480   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:36:57,883-Speed 139.98 samples/sec   Loss 1.1484   LearningRate 0.000008   Epoch: 1   Global Step: 39490   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:37:00,170-Speed 139.91 samples/sec   Loss 1.1493   LearningRate 0.000008   Epoch: 1   Global Step: 39500   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:37:02,450-Speed 140.44 samples/sec   Loss 1.1472   LearningRate 0.000008   Epoch: 1   Global Step: 39510   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:37:04,742-Speed 139.63 samples/sec   Loss 1.1577   LearningRate 0.000008   Epoch: 1   Global Step: 39520   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:37:07,039-Speed 139.38 samples/sec   Loss 1.1335   LearningRate 0.000008   Epoch: 1   Global Step: 39530   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:37:09,329-Speed 139.77 samples/sec   Loss 1.1538   LearningRate 0.000008   Epoch: 1   Global Step: 39540   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:37:11,602-Speed 140.84 samples/sec   Loss 1.1569   LearningRate 0.000008   Epoch: 1   Global Step: 39550   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:37:13,883-Speed 140.30 samples/sec   Loss 1.1563   LearningRate 0.000008   Epoch: 1   Global Step: 39560   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:37:16,167-Speed 140.15 samples/sec   Loss 1.1568   LearningRate 0.000008   Epoch: 1   Global Step: 39570   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:37:18,466-Speed 139.20 samples/sec   Loss 1.1569   LearningRate 0.000008   Epoch: 1   Global Step: 39580   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:37:20,753-Speed 139.99 samples/sec   Loss 1.1348   LearningRate 0.000008   Epoch: 1   Global Step: 39590   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:37:23,031-Speed 140.52 samples/sec   Loss 1.1489   LearningRate 0.000008   Epoch: 1   Global Step: 39600   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:37:25,326-Speed 139.43 samples/sec   Loss 1.1264   LearningRate 0.000008   Epoch: 1   Global Step: 39610   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:37:27,626-Speed 139.21 samples/sec   Loss 1.1449   LearningRate 0.000008   Epoch: 1   Global Step: 39620   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:37:29,909-Speed 140.19 samples/sec   Loss 1.1602   LearningRate 0.000008   Epoch: 1   Global Step: 39630   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:37:32,202-Speed 139.61 samples/sec   Loss 1.1330   LearningRate 0.000008   Epoch: 1   Global Step: 39640   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:37:34,500-Speed 139.26 samples/sec   Loss 1.1558   LearningRate 0.000008   Epoch: 1   Global Step: 39650   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:37:36,805-Speed 138.92 samples/sec   Loss 1.1317   LearningRate 0.000008   Epoch: 1   Global Step: 39660   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:37:39,094-Speed 139.82 samples/sec   Loss 1.1424   LearningRate 0.000008   Epoch: 1   Global Step: 39670   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:37:41,387-Speed 139.59 samples/sec   Loss 1.1387   LearningRate 0.000008   Epoch: 1   Global Step: 39680   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:37:43,681-Speed 139.54 samples/sec   Loss 1.1579   LearningRate 0.000008   Epoch: 1   Global Step: 39690   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:37:45,965-Speed 140.14 samples/sec   Loss 1.1801   LearningRate 0.000008   Epoch: 1   Global Step: 39700   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:37:48,255-Speed 139.80 samples/sec   Loss 1.1698   LearningRate 0.000008   Epoch: 1   Global Step: 39710   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:37:50,557-Speed 139.05 samples/sec   Loss 1.1335   LearningRate 0.000008   Epoch: 1   Global Step: 39720   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:37:52,858-Speed 139.10 samples/sec   Loss 1.1456   LearningRate 0.000008   Epoch: 1   Global Step: 39730   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:37:55,163-Speed 138.84 samples/sec   Loss 1.1372   LearningRate 0.000008   Epoch: 1   Global Step: 39740   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:37:57,466-Speed 139.02 samples/sec   Loss 1.1462   LearningRate 0.000008   Epoch: 1   Global Step: 39750   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:37:59,771-Speed 138.86 samples/sec   Loss 1.1381   LearningRate 0.000008   Epoch: 1   Global Step: 39760   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:38:02,042-Speed 140.90 samples/sec   Loss 1.1455   LearningRate 0.000008   Epoch: 1   Global Step: 39770   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:38:04,336-Speed 139.56 samples/sec   Loss 1.1529   LearningRate 0.000008   Epoch: 1   Global Step: 39780   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:38:06,651-Speed 138.28 samples/sec   Loss 1.1365   LearningRate 0.000008   Epoch: 1   Global Step: 39790   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:38:08,947-Speed 139.39 samples/sec   Loss 1.1509   LearningRate 0.000008   Epoch: 1   Global Step: 39800   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:38:11,249-Speed 139.04 samples/sec   Loss 1.1473   LearningRate 0.000008   Epoch: 1   Global Step: 39810   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:38:13,552-Speed 139.01 samples/sec   Loss 1.1674   LearningRate 0.000008   Epoch: 1   Global Step: 39820   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:38:15,856-Speed 138.90 samples/sec   Loss 1.1462   LearningRate 0.000008   Epoch: 1   Global Step: 39830   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:38:18,155-Speed 139.25 samples/sec   Loss 1.1319   LearningRate 0.000008   Epoch: 1   Global Step: 39840   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:38:20,462-Speed 138.75 samples/sec   Loss 1.1656   LearningRate 0.000008   Epoch: 1   Global Step: 39850   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:38:22,771-Speed 138.64 samples/sec   Loss 1.1374   LearningRate 0.000008   Epoch: 1   Global Step: 39860   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:38:25,075-Speed 138.92 samples/sec   Loss 1.1521   LearningRate 0.000008   Epoch: 1   Global Step: 39870   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:38:27,387-Speed 138.45 samples/sec   Loss 1.1440   LearningRate 0.000008   Epoch: 1   Global Step: 39880   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:38:29,680-Speed 139.57 samples/sec   Loss 1.1481   LearningRate 0.000008   Epoch: 1   Global Step: 39890   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:38:31,976-Speed 139.41 samples/sec   Loss 1.1356   LearningRate 0.000008   Epoch: 1   Global Step: 39900   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:38:34,263-Speed 139.98 samples/sec   Loss 1.1480   LearningRate 0.000008   Epoch: 1   Global Step: 39910   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:38:36,561-Speed 139.27 samples/sec   Loss 1.1425   LearningRate 0.000008   Epoch: 1   Global Step: 39920   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:38:38,862-Speed 139.15 samples/sec   Loss 1.1604   LearningRate 0.000008   Epoch: 1   Global Step: 39930   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:38:41,131-Speed 141.07 samples/sec   Loss 1.1557   LearningRate 0.000008   Epoch: 1   Global Step: 39940   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:38:43,411-Speed 140.40 samples/sec   Loss 1.1226   LearningRate 0.000008   Epoch: 1   Global Step: 39950   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:38:45,703-Speed 139.67 samples/sec   Loss 1.1454   LearningRate 0.000008   Epoch: 1   Global Step: 39960   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:38:48,005-Speed 139.04 samples/sec   Loss 1.1465   LearningRate 0.000008   Epoch: 1   Global Step: 39970   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:38:50,294-Speed 139.84 samples/sec   Loss 1.1491   LearningRate 0.000008   Epoch: 1   Global Step: 39980   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:38:52,579-Speed 140.06 samples/sec   Loss 1.1896   LearningRate 0.000008   Epoch: 1   Global Step: 39990   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:38:54,645-Val on RAF/AffectNet:
Training: 2023-08-17 23:38:54,758-Test: [0/48]	Time 0.113 (0.113)	Loss 0.6381 (0.6381)	Acc@1 90.625 (90.625)	Acc@5 95.312 (95.312)	Mem 5268MB
Training: 2023-08-17 23:38:55,836-Test: [10/48]	Time 0.105 (0.108)	Loss 0.5968 (0.6007)	Acc@1 92.188 (91.051)	Acc@5 96.875 (97.017)	Mem 5268MB
Training: 2023-08-17 23:38:56,892-Test: [20/48]	Time 0.107 (0.107)	Loss 0.5668 (0.5715)	Acc@1 93.750 (91.592)	Acc@5 96.875 (97.991)	Mem 5268MB
Training: 2023-08-17 23:38:57,952-Test: [30/48]	Time 0.106 (0.107)	Loss 0.4494 (0.5504)	Acc@1 98.438 (92.490)	Acc@5 100.000 (98.236)	Mem 5268MB
Training: 2023-08-17 23:38:59,011-Test: [40/48]	Time 0.110 (0.106)	Loss 0.5838 (0.5477)	Acc@1 87.500 (92.340)	Acc@5 100.000 (98.514)	Mem 5268MB
Training: 2023-08-17 23:38:59,737-[39999]Expression Loss: 0.55223
Training: 2023-08-17 23:38:59,738-[39999]Expression Acc@1: 92.24250
Training: 2023-08-17 23:38:59,738-[39999]Expression Acc@1-Highest: 92.47067
Training: 2023-08-17 23:38:59,738-[39999]Expression Acc@5: 98.43546
Training: 2023-08-17 23:38:59,738-[39999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 23:38:59,738-[39999]10 Times Expression Acc@1: 92.14472
Training: 2023-08-17 23:38:59,738-[39999]10 Times Expression Acc@1-Highest: 92.14472
Training: 2023-08-17 23:38:59,967-Speed 43.32 samples/sec   Loss 1.1510   LearningRate 0.000008   Epoch: 1   Global Step: 40000   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:39:02,249-Speed 140.25 samples/sec   Loss 1.1661   LearningRate 0.000008   Epoch: 1   Global Step: 40010   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:39:04,543-Speed 139.58 samples/sec   Loss 1.1602   LearningRate 0.000008   Epoch: 1   Global Step: 40020   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:39:06,842-Speed 139.24 samples/sec   Loss 1.1466   LearningRate 0.000008   Epoch: 1   Global Step: 40030   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:39:09,142-Speed 139.14 samples/sec   Loss 1.1383   LearningRate 0.000008   Epoch: 1   Global Step: 40040   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:39:11,430-Speed 139.93 samples/sec   Loss 1.1621   LearningRate 0.000008   Epoch: 1   Global Step: 40050   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:39:13,710-Speed 140.37 samples/sec   Loss 1.1777   LearningRate 0.000008   Epoch: 1   Global Step: 40060   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:39:16,007-Speed 139.36 samples/sec   Loss 1.1541   LearningRate 0.000008   Epoch: 1   Global Step: 40070   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:39:18,316-Speed 138.58 samples/sec   Loss 1.1368   LearningRate 0.000008   Epoch: 1   Global Step: 40080   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:39:20,590-Speed 140.82 samples/sec   Loss 1.1596   LearningRate 0.000008   Epoch: 1   Global Step: 40090   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:39:22,880-Speed 139.73 samples/sec   Loss 1.1631   LearningRate 0.000008   Epoch: 1   Global Step: 40100   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:39:25,165-Speed 140.09 samples/sec   Loss 1.1446   LearningRate 0.000008   Epoch: 1   Global Step: 40110   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:39:27,473-Speed 138.70 samples/sec   Loss 1.1540   LearningRate 0.000008   Epoch: 1   Global Step: 40120   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:39:29,759-Speed 140.07 samples/sec   Loss 1.1340   LearningRate 0.000008   Epoch: 1   Global Step: 40130   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:39:32,058-Speed 139.22 samples/sec   Loss 1.1511   LearningRate 0.000008   Epoch: 1   Global Step: 40140   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:39:34,350-Speed 139.61 samples/sec   Loss 1.1630   LearningRate 0.000008   Epoch: 1   Global Step: 40150   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:39:36,650-Speed 139.21 samples/sec   Loss 1.1559   LearningRate 0.000008   Epoch: 1   Global Step: 40160   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:39:38,952-Speed 139.02 samples/sec   Loss 1.1566   LearningRate 0.000008   Epoch: 1   Global Step: 40170   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:39:41,252-Speed 139.22 samples/sec   Loss 1.1433   LearningRate 0.000008   Epoch: 1   Global Step: 40180   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:39:43,540-Speed 139.87 samples/sec   Loss 1.1273   LearningRate 0.000008   Epoch: 1   Global Step: 40190   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:39:45,817-Speed 140.56 samples/sec   Loss 1.1465   LearningRate 0.000008   Epoch: 1   Global Step: 40200   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:39:48,110-Speed 139.63 samples/sec   Loss 1.1542   LearningRate 0.000008   Epoch: 1   Global Step: 40210   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:39:50,424-Speed 138.30 samples/sec   Loss 1.1437   LearningRate 0.000008   Epoch: 1   Global Step: 40220   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:39:52,744-Speed 137.96 samples/sec   Loss 1.1702   LearningRate 0.000008   Epoch: 1   Global Step: 40230   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:39:55,041-Speed 139.39 samples/sec   Loss 1.1604   LearningRate 0.000008   Epoch: 1   Global Step: 40240   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:39:57,333-Speed 139.62 samples/sec   Loss 1.1787   LearningRate 0.000008   Epoch: 1   Global Step: 40250   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:39:59,648-Speed 138.27 samples/sec   Loss 1.1549   LearningRate 0.000008   Epoch: 1   Global Step: 40260   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:40:01,940-Speed 139.68 samples/sec   Loss 1.1424   LearningRate 0.000008   Epoch: 1   Global Step: 40270   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:40:04,230-Speed 139.75 samples/sec   Loss 1.1226   LearningRate 0.000008   Epoch: 1   Global Step: 40280   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:40:06,514-Speed 140.16 samples/sec   Loss 1.1472   LearningRate 0.000008   Epoch: 1   Global Step: 40290   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:40:08,793-Speed 140.44 samples/sec   Loss 1.1604   LearningRate 0.000008   Epoch: 1   Global Step: 40300   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:40:11,083-Speed 139.78 samples/sec   Loss 1.1480   LearningRate 0.000008   Epoch: 1   Global Step: 40310   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:40:13,375-Speed 139.67 samples/sec   Loss 1.1354   LearningRate 0.000008   Epoch: 1   Global Step: 40320   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:40:15,650-Speed 140.72 samples/sec   Loss 1.1496   LearningRate 0.000008   Epoch: 1   Global Step: 40330   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:40:17,939-Speed 139.80 samples/sec   Loss 1.1355   LearningRate 0.000008   Epoch: 1   Global Step: 40340   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:40:20,247-Speed 138.69 samples/sec   Loss 1.1521   LearningRate 0.000008   Epoch: 1   Global Step: 40350   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:40:22,542-Speed 139.51 samples/sec   Loss 1.1608   LearningRate 0.000008   Epoch: 1   Global Step: 40360   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:40:24,826-Speed 140.11 samples/sec   Loss 1.1313   LearningRate 0.000008   Epoch: 1   Global Step: 40370   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:40:27,117-Speed 139.69 samples/sec   Loss 1.1621   LearningRate 0.000008   Epoch: 1   Global Step: 40380   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:40:29,419-Speed 139.07 samples/sec   Loss 1.1615   LearningRate 0.000008   Epoch: 1   Global Step: 40390   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:40:31,717-Speed 139.32 samples/sec   Loss 1.1628   LearningRate 0.000008   Epoch: 1   Global Step: 40400   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:40:34,003-Speed 140.01 samples/sec   Loss 1.1859   LearningRate 0.000008   Epoch: 1   Global Step: 40410   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:40:36,288-Speed 140.08 samples/sec   Loss 1.1606   LearningRate 0.000008   Epoch: 1   Global Step: 40420   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:40:38,573-Speed 140.06 samples/sec   Loss 1.1645   LearningRate 0.000008   Epoch: 1   Global Step: 40430   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:40:40,861-Speed 139.92 samples/sec   Loss 1.1568   LearningRate 0.000008   Epoch: 1   Global Step: 40440   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:40:43,151-Speed 139.76 samples/sec   Loss 1.1218   LearningRate 0.000008   Epoch: 1   Global Step: 40450   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:40:45,441-Speed 139.81 samples/sec   Loss 1.1447   LearningRate 0.000008   Epoch: 1   Global Step: 40460   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:40:47,740-Speed 139.21 samples/sec   Loss 1.1484   LearningRate 0.000008   Epoch: 1   Global Step: 40470   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:40:50,028-Speed 139.93 samples/sec   Loss 1.1327   LearningRate 0.000008   Epoch: 1   Global Step: 40480   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:40:52,315-Speed 139.92 samples/sec   Loss 1.1457   LearningRate 0.000008   Epoch: 1   Global Step: 40490   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:40:54,601-Speed 140.06 samples/sec   Loss 1.1788   LearningRate 0.000008   Epoch: 1   Global Step: 40500   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:40:56,897-Speed 139.41 samples/sec   Loss 1.1813   LearningRate 0.000008   Epoch: 1   Global Step: 40510   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:40:59,187-Speed 139.72 samples/sec   Loss 1.1681   LearningRate 0.000008   Epoch: 1   Global Step: 40520   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:41:01,475-Speed 139.91 samples/sec   Loss 1.1486   LearningRate 0.000008   Epoch: 1   Global Step: 40530   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:41:03,767-Speed 139.67 samples/sec   Loss 1.1682   LearningRate 0.000008   Epoch: 1   Global Step: 40540   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:41:06,064-Speed 139.35 samples/sec   Loss 1.1614   LearningRate 0.000008   Epoch: 1   Global Step: 40550   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:41:08,361-Speed 139.34 samples/sec   Loss 1.1507   LearningRate 0.000008   Epoch: 1   Global Step: 40560   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:41:10,649-Speed 139.94 samples/sec   Loss 1.1698   LearningRate 0.000008   Epoch: 1   Global Step: 40570   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:41:12,932-Speed 140.20 samples/sec   Loss 1.1987   LearningRate 0.000008   Epoch: 1   Global Step: 40580   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:41:15,206-Speed 140.74 samples/sec   Loss 1.1381   LearningRate 0.000008   Epoch: 1   Global Step: 40590   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:41:17,498-Speed 139.67 samples/sec   Loss 1.1252   LearningRate 0.000008   Epoch: 1   Global Step: 40600   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:41:19,785-Speed 139.94 samples/sec   Loss 1.1383   LearningRate 0.000008   Epoch: 1   Global Step: 40610   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:41:22,072-Speed 140.03 samples/sec   Loss 1.1724   LearningRate 0.000008   Epoch: 1   Global Step: 40620   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:41:24,376-Speed 138.92 samples/sec   Loss 1.1377   LearningRate 0.000008   Epoch: 1   Global Step: 40630   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:41:26,672-Speed 139.39 samples/sec   Loss 1.1263   LearningRate 0.000008   Epoch: 1   Global Step: 40640   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:41:28,953-Speed 140.34 samples/sec   Loss 1.1643   LearningRate 0.000008   Epoch: 1   Global Step: 40650   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:41:31,250-Speed 139.33 samples/sec   Loss 1.1632   LearningRate 0.000008   Epoch: 1   Global Step: 40660   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:41:33,542-Speed 139.63 samples/sec   Loss 1.1472   LearningRate 0.000008   Epoch: 1   Global Step: 40670   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:41:35,846-Speed 138.97 samples/sec   Loss 1.1831   LearningRate 0.000008   Epoch: 1   Global Step: 40680   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:41:38,132-Speed 139.98 samples/sec   Loss 1.1641   LearningRate 0.000008   Epoch: 1   Global Step: 40690   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:41:40,409-Speed 140.57 samples/sec   Loss 1.1319   LearningRate 0.000008   Epoch: 1   Global Step: 40700   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:41:42,702-Speed 139.63 samples/sec   Loss 1.1404   LearningRate 0.000008   Epoch: 1   Global Step: 40710   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:41:44,994-Speed 139.65 samples/sec   Loss 1.1864   LearningRate 0.000008   Epoch: 1   Global Step: 40720   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:41:47,288-Speed 139.55 samples/sec   Loss 1.1631   LearningRate 0.000008   Epoch: 1   Global Step: 40730   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:41:49,561-Speed 140.79 samples/sec   Loss 1.1665   LearningRate 0.000008   Epoch: 1   Global Step: 40740   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:41:51,851-Speed 139.81 samples/sec   Loss 1.1671   LearningRate 0.000008   Epoch: 1   Global Step: 40750   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:41:54,139-Speed 139.88 samples/sec   Loss 1.1217   LearningRate 0.000008   Epoch: 1   Global Step: 40760   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:41:56,421-Speed 140.25 samples/sec   Loss 1.1452   LearningRate 0.000008   Epoch: 1   Global Step: 40770   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:41:58,700-Speed 140.50 samples/sec   Loss 1.1526   LearningRate 0.000008   Epoch: 1   Global Step: 40780   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:42:00,992-Speed 139.64 samples/sec   Loss 1.1542   LearningRate 0.000007   Epoch: 1   Global Step: 40790   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:42:03,286-Speed 139.53 samples/sec   Loss 1.1280   LearningRate 0.000007   Epoch: 1   Global Step: 40800   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:42:05,567-Speed 140.32 samples/sec   Loss 1.1379   LearningRate 0.000007   Epoch: 1   Global Step: 40810   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:42:07,854-Speed 139.99 samples/sec   Loss 1.1555   LearningRate 0.000007   Epoch: 1   Global Step: 40820   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:42:10,138-Speed 140.12 samples/sec   Loss 1.1403   LearningRate 0.000007   Epoch: 1   Global Step: 40830   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:42:12,428-Speed 139.78 samples/sec   Loss 1.1252   LearningRate 0.000007   Epoch: 1   Global Step: 40840   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:42:14,714-Speed 140.00 samples/sec   Loss 1.1147   LearningRate 0.000007   Epoch: 1   Global Step: 40850   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:42:17,002-Speed 139.92 samples/sec   Loss 1.1470   LearningRate 0.000007   Epoch: 1   Global Step: 40860   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:42:19,293-Speed 139.74 samples/sec   Loss 1.1564   LearningRate 0.000007   Epoch: 1   Global Step: 40870   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:42:21,580-Speed 139.95 samples/sec   Loss 1.1628   LearningRate 0.000007   Epoch: 1   Global Step: 40880   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:42:23,873-Speed 139.59 samples/sec   Loss 1.1330   LearningRate 0.000007   Epoch: 1   Global Step: 40890   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:42:26,169-Speed 139.43 samples/sec   Loss 1.1909   LearningRate 0.000007   Epoch: 1   Global Step: 40900   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:42:28,475-Speed 138.76 samples/sec   Loss 1.1500   LearningRate 0.000007   Epoch: 1   Global Step: 40910   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:42:30,771-Speed 139.41 samples/sec   Loss 1.1587   LearningRate 0.000007   Epoch: 1   Global Step: 40920   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:42:33,064-Speed 139.60 samples/sec   Loss 1.1507   LearningRate 0.000007   Epoch: 1   Global Step: 40930   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:42:35,343-Speed 140.48 samples/sec   Loss 1.1490   LearningRate 0.000007   Epoch: 1   Global Step: 40940   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:42:37,634-Speed 139.69 samples/sec   Loss 1.1673   LearningRate 0.000007   Epoch: 1   Global Step: 40950   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:42:39,921-Speed 140.01 samples/sec   Loss 1.1476   LearningRate 0.000007   Epoch: 1   Global Step: 40960   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:42:42,214-Speed 139.57 samples/sec   Loss 1.1658   LearningRate 0.000007   Epoch: 1   Global Step: 40970   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:42:44,507-Speed 139.57 samples/sec   Loss 1.1733   LearningRate 0.000007   Epoch: 1   Global Step: 40980   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:42:46,775-Speed 141.13 samples/sec   Loss 1.1664   LearningRate 0.000007   Epoch: 1   Global Step: 40990   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:42:48,829-Val on RAF/AffectNet:
Training: 2023-08-17 23:42:48,936-Test: [0/48]	Time 0.107 (0.107)	Loss 0.4973 (0.4973)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-17 23:42:49,998-Test: [10/48]	Time 0.106 (0.106)	Loss 0.6580 (0.5630)	Acc@1 89.062 (92.045)	Acc@5 96.875 (98.722)	Mem 5268MB
Training: 2023-08-17 23:42:51,045-Test: [20/48]	Time 0.105 (0.105)	Loss 0.5791 (0.5679)	Acc@1 90.625 (91.815)	Acc@5 100.000 (98.512)	Mem 5268MB
Training: 2023-08-17 23:42:52,120-Test: [30/48]	Time 0.106 (0.106)	Loss 0.5294 (0.5551)	Acc@1 92.188 (92.238)	Acc@5 100.000 (98.690)	Mem 5268MB
Training: 2023-08-17 23:42:53,184-Test: [40/48]	Time 0.106 (0.106)	Loss 0.4498 (0.5498)	Acc@1 96.875 (92.569)	Acc@5 100.000 (98.666)	Mem 5268MB
Training: 2023-08-17 23:42:53,918-[40999]Expression Loss: 0.55249
Training: 2023-08-17 23:42:53,918-[40999]Expression Acc@1: 92.47066
Training: 2023-08-17 23:42:53,918-[40999]Expression Acc@1-Highest: 92.47067
Training: 2023-08-17 23:42:53,918-[40999]Expression Acc@5: 98.69622
Training: 2023-08-17 23:42:53,918-[40999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 23:42:53,918-[40999]10 Times Expression Acc@1: 92.20665
Training: 2023-08-17 23:42:53,918-[40999]10 Times Expression Acc@1-Highest: 92.20665
Training: 2023-08-17 23:42:54,152-Speed 43.38 samples/sec   Loss 1.1756   LearningRate 0.000007   Epoch: 1   Global Step: 41000   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:42:56,469-Speed 138.18 samples/sec   Loss 1.1603   LearningRate 0.000007   Epoch: 1   Global Step: 41010   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:42:58,770-Speed 139.08 samples/sec   Loss 1.1510   LearningRate 0.000007   Epoch: 1   Global Step: 41020   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:43:01,047-Speed 140.57 samples/sec   Loss 1.1632   LearningRate 0.000007   Epoch: 1   Global Step: 41030   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:43:03,327-Speed 140.43 samples/sec   Loss 1.1172   LearningRate 0.000007   Epoch: 1   Global Step: 41040   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:43:05,615-Speed 139.85 samples/sec   Loss 1.1381   LearningRate 0.000007   Epoch: 1   Global Step: 41050   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:43:07,900-Speed 140.08 samples/sec   Loss 1.1608   LearningRate 0.000007   Epoch: 1   Global Step: 41060   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:43:10,194-Speed 139.55 samples/sec   Loss 1.1474   LearningRate 0.000007   Epoch: 1   Global Step: 41070   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:43:12,493-Speed 139.22 samples/sec   Loss 1.1755   LearningRate 0.000007   Epoch: 1   Global Step: 41080   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:43:14,758-Speed 141.35 samples/sec   Loss 1.1392   LearningRate 0.000007   Epoch: 1   Global Step: 41090   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:43:17,045-Speed 139.91 samples/sec   Loss 1.1419   LearningRate 0.000007   Epoch: 1   Global Step: 41100   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:43:19,344-Speed 139.25 samples/sec   Loss 1.1613   LearningRate 0.000007   Epoch: 1   Global Step: 41110   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:43:21,629-Speed 140.06 samples/sec   Loss 1.1441   LearningRate 0.000007   Epoch: 1   Global Step: 41120   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:43:23,917-Speed 139.94 samples/sec   Loss 1.1180   LearningRate 0.000007   Epoch: 1   Global Step: 41130   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:43:26,197-Speed 140.40 samples/sec   Loss 1.2019   LearningRate 0.000007   Epoch: 1   Global Step: 41140   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:43:28,491-Speed 139.51 samples/sec   Loss 1.1234   LearningRate 0.000007   Epoch: 1   Global Step: 41150   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:43:30,802-Speed 138.52 samples/sec   Loss 1.1528   LearningRate 0.000007   Epoch: 1   Global Step: 41160   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:43:33,085-Speed 140.19 samples/sec   Loss 1.1595   LearningRate 0.000007   Epoch: 1   Global Step: 41170   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:43:35,400-Speed 138.29 samples/sec   Loss 1.1043   LearningRate 0.000007   Epoch: 1   Global Step: 41180   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:43:37,703-Speed 138.97 samples/sec   Loss 1.1553   LearningRate 0.000007   Epoch: 1   Global Step: 41190   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:43:39,994-Speed 139.72 samples/sec   Loss 1.1424   LearningRate 0.000007   Epoch: 1   Global Step: 41200   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:43:42,282-Speed 139.91 samples/sec   Loss 1.1405   LearningRate 0.000007   Epoch: 1   Global Step: 41210   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:43:44,574-Speed 139.67 samples/sec   Loss 1.1494   LearningRate 0.000007   Epoch: 1   Global Step: 41220   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:43:46,865-Speed 139.69 samples/sec   Loss 1.1545   LearningRate 0.000007   Epoch: 1   Global Step: 41230   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:43:49,152-Speed 139.98 samples/sec   Loss 1.1589   LearningRate 0.000007   Epoch: 1   Global Step: 41240   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:43:51,444-Speed 139.62 samples/sec   Loss 1.1381   LearningRate 0.000007   Epoch: 1   Global Step: 41250   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:43:53,747-Speed 138.97 samples/sec   Loss 1.1505   LearningRate 0.000007   Epoch: 1   Global Step: 41260   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:43:56,050-Speed 139.00 samples/sec   Loss 1.1284   LearningRate 0.000007   Epoch: 1   Global Step: 41270   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:43:58,328-Speed 140.52 samples/sec   Loss 1.1415   LearningRate 0.000007   Epoch: 1   Global Step: 41280   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:44:00,618-Speed 139.81 samples/sec   Loss 1.1477   LearningRate 0.000007   Epoch: 1   Global Step: 41290   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:44:02,912-Speed 139.55 samples/sec   Loss 1.1550   LearningRate 0.000007   Epoch: 1   Global Step: 41300   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:44:05,202-Speed 139.77 samples/sec   Loss 1.1403   LearningRate 0.000007   Epoch: 1   Global Step: 41310   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:44:07,502-Speed 139.12 samples/sec   Loss 1.1464   LearningRate 0.000007   Epoch: 1   Global Step: 41320   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:44:09,795-Speed 139.62 samples/sec   Loss 1.1504   LearningRate 0.000007   Epoch: 1   Global Step: 41330   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:44:12,087-Speed 139.69 samples/sec   Loss 1.1625   LearningRate 0.000007   Epoch: 1   Global Step: 41340   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:44:14,364-Speed 140.57 samples/sec   Loss 1.1579   LearningRate 0.000007   Epoch: 1   Global Step: 41350   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:44:16,646-Speed 140.25 samples/sec   Loss 1.1614   LearningRate 0.000007   Epoch: 1   Global Step: 41360   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:44:18,948-Speed 139.08 samples/sec   Loss 1.1393   LearningRate 0.000007   Epoch: 1   Global Step: 41370   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:44:21,238-Speed 139.73 samples/sec   Loss 1.1419   LearningRate 0.000007   Epoch: 1   Global Step: 41380   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:44:23,542-Speed 138.97 samples/sec   Loss 1.1451   LearningRate 0.000007   Epoch: 1   Global Step: 41390   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:44:25,833-Speed 139.71 samples/sec   Loss 1.1539   LearningRate 0.000007   Epoch: 1   Global Step: 41400   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:44:28,121-Speed 139.90 samples/sec   Loss 1.1664   LearningRate 0.000007   Epoch: 1   Global Step: 41410   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:44:30,402-Speed 140.29 samples/sec   Loss 1.1638   LearningRate 0.000007   Epoch: 1   Global Step: 41420   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:44:32,692-Speed 139.81 samples/sec   Loss 1.1534   LearningRate 0.000007   Epoch: 1   Global Step: 41430   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:44:34,983-Speed 139.70 samples/sec   Loss 1.1530   LearningRate 0.000007   Epoch: 1   Global Step: 41440   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:44:37,267-Speed 140.13 samples/sec   Loss 1.1382   LearningRate 0.000007   Epoch: 1   Global Step: 41450   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:44:39,570-Speed 139.02 samples/sec   Loss 1.1411   LearningRate 0.000007   Epoch: 1   Global Step: 41460   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:44:41,865-Speed 139.47 samples/sec   Loss 1.1310   LearningRate 0.000007   Epoch: 1   Global Step: 41470   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:44:44,183-Speed 138.08 samples/sec   Loss 1.1489   LearningRate 0.000007   Epoch: 1   Global Step: 41480   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:44:46,477-Speed 139.52 samples/sec   Loss 1.1390   LearningRate 0.000007   Epoch: 1   Global Step: 41490   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:44:48,773-Speed 139.42 samples/sec   Loss 1.1439   LearningRate 0.000007   Epoch: 1   Global Step: 41500   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:44:51,081-Speed 138.69 samples/sec   Loss 1.1658   LearningRate 0.000007   Epoch: 1   Global Step: 41510   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:44:53,372-Speed 139.72 samples/sec   Loss 1.1687   LearningRate 0.000007   Epoch: 1   Global Step: 41520   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:44:55,665-Speed 139.58 samples/sec   Loss 1.1469   LearningRate 0.000007   Epoch: 1   Global Step: 41530   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:44:57,958-Speed 139.62 samples/sec   Loss 1.1426   LearningRate 0.000007   Epoch: 1   Global Step: 41540   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:45:00,243-Speed 140.07 samples/sec   Loss 1.1442   LearningRate 0.000007   Epoch: 1   Global Step: 41550   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:45:02,533-Speed 139.76 samples/sec   Loss 1.1418   LearningRate 0.000007   Epoch: 1   Global Step: 41560   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:45:04,829-Speed 139.44 samples/sec   Loss 1.1653   LearningRate 0.000007   Epoch: 1   Global Step: 41570   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:45:07,125-Speed 139.39 samples/sec   Loss 1.1533   LearningRate 0.000007   Epoch: 1   Global Step: 41580   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:45:09,418-Speed 139.61 samples/sec   Loss 1.1642   LearningRate 0.000007   Epoch: 1   Global Step: 41590   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:45:11,691-Speed 140.82 samples/sec   Loss 1.1445   LearningRate 0.000007   Epoch: 1   Global Step: 41600   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:45:13,971-Speed 140.40 samples/sec   Loss 1.1582   LearningRate 0.000007   Epoch: 1   Global Step: 41610   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:45:16,266-Speed 139.46 samples/sec   Loss 1.1437   LearningRate 0.000007   Epoch: 1   Global Step: 41620   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:45:18,546-Speed 140.40 samples/sec   Loss 1.1600   LearningRate 0.000007   Epoch: 1   Global Step: 41630   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:45:20,823-Speed 140.54 samples/sec   Loss 1.1574   LearningRate 0.000007   Epoch: 1   Global Step: 41640   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:45:23,096-Speed 140.84 samples/sec   Loss 1.1676   LearningRate 0.000007   Epoch: 1   Global Step: 41650   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:45:25,359-Speed 141.45 samples/sec   Loss 1.1418   LearningRate 0.000007   Epoch: 1   Global Step: 41660   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:45:27,624-Speed 141.33 samples/sec   Loss 1.1363   LearningRate 0.000007   Epoch: 1   Global Step: 41670   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:45:29,908-Speed 140.11 samples/sec   Loss 1.1324   LearningRate 0.000007   Epoch: 1   Global Step: 41680   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:45:32,186-Speed 140.55 samples/sec   Loss 1.1521   LearningRate 0.000007   Epoch: 1   Global Step: 41690   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:45:34,464-Speed 140.52 samples/sec   Loss 1.1440   LearningRate 0.000007   Epoch: 1   Global Step: 41700   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:45:36,734-Speed 140.99 samples/sec   Loss 1.1633   LearningRate 0.000007   Epoch: 1   Global Step: 41710   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:45:39,017-Speed 140.21 samples/sec   Loss 1.1461   LearningRate 0.000007   Epoch: 1   Global Step: 41720   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:45:41,325-Speed 138.67 samples/sec   Loss 1.1465   LearningRate 0.000007   Epoch: 1   Global Step: 41730   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:45:43,625-Speed 139.21 samples/sec   Loss 1.1847   LearningRate 0.000007   Epoch: 1   Global Step: 41740   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:45:45,900-Speed 140.69 samples/sec   Loss 1.1459   LearningRate 0.000007   Epoch: 1   Global Step: 41750   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:45:48,169-Speed 141.05 samples/sec   Loss 1.1735   LearningRate 0.000007   Epoch: 1   Global Step: 41760   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:45:50,448-Speed 140.49 samples/sec   Loss 1.1527   LearningRate 0.000007   Epoch: 1   Global Step: 41770   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:45:52,729-Speed 140.32 samples/sec   Loss 1.1392   LearningRate 0.000007   Epoch: 1   Global Step: 41780   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:45:55,016-Speed 139.95 samples/sec   Loss 1.1610   LearningRate 0.000007   Epoch: 1   Global Step: 41790   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:45:57,294-Speed 140.52 samples/sec   Loss 1.1720   LearningRate 0.000007   Epoch: 1   Global Step: 41800   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:45:59,573-Speed 140.47 samples/sec   Loss 1.1405   LearningRate 0.000007   Epoch: 1   Global Step: 41810   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:46:01,848-Speed 140.69 samples/sec   Loss 1.1463   LearningRate 0.000007   Epoch: 1   Global Step: 41820   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:46:04,125-Speed 140.55 samples/sec   Loss 1.1450   LearningRate 0.000007   Epoch: 1   Global Step: 41830   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:46:06,402-Speed 140.58 samples/sec   Loss 1.1378   LearningRate 0.000007   Epoch: 1   Global Step: 41840   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:46:08,674-Speed 140.88 samples/sec   Loss 1.1489   LearningRate 0.000007   Epoch: 1   Global Step: 41850   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:46:10,958-Speed 140.15 samples/sec   Loss 1.1553   LearningRate 0.000007   Epoch: 1   Global Step: 41860   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:46:13,234-Speed 140.63 samples/sec   Loss 1.1358   LearningRate 0.000007   Epoch: 1   Global Step: 41870   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:46:15,517-Speed 140.24 samples/sec   Loss 1.1641   LearningRate 0.000007   Epoch: 1   Global Step: 41880   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:46:17,817-Speed 139.16 samples/sec   Loss 1.1372   LearningRate 0.000007   Epoch: 1   Global Step: 41890   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:46:20,100-Speed 140.18 samples/sec   Loss 1.1422   LearningRate 0.000007   Epoch: 1   Global Step: 41900   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:46:22,394-Speed 139.54 samples/sec   Loss 1.1172   LearningRate 0.000007   Epoch: 1   Global Step: 41910   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:46:24,689-Speed 139.47 samples/sec   Loss 1.1477   LearningRate 0.000007   Epoch: 1   Global Step: 41920   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:46:26,983-Speed 139.55 samples/sec   Loss 1.1562   LearningRate 0.000007   Epoch: 1   Global Step: 41930   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:46:29,287-Speed 138.93 samples/sec   Loss 1.1678   LearningRate 0.000007   Epoch: 1   Global Step: 41940   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:46:31,569-Speed 140.28 samples/sec   Loss 1.1461   LearningRate 0.000007   Epoch: 1   Global Step: 41950   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:46:33,838-Speed 141.01 samples/sec   Loss 1.1194   LearningRate 0.000007   Epoch: 1   Global Step: 41960   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:46:36,133-Speed 139.54 samples/sec   Loss 1.1539   LearningRate 0.000007   Epoch: 1   Global Step: 41970   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:46:38,420-Speed 139.93 samples/sec   Loss 1.1399   LearningRate 0.000007   Epoch: 1   Global Step: 41980   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:46:40,705-Speed 140.08 samples/sec   Loss 1.1335   LearningRate 0.000007   Epoch: 1   Global Step: 41990   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:46:42,764-Val on RAF/AffectNet:
Training: 2023-08-17 23:46:42,876-Test: [0/48]	Time 0.111 (0.111)	Loss 0.4590 (0.4590)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-17 23:46:43,960-Test: [10/48]	Time 0.105 (0.109)	Loss 0.4538 (0.5353)	Acc@1 95.312 (92.756)	Acc@5 100.000 (99.006)	Mem 5268MB
Training: 2023-08-17 23:46:45,001-Test: [20/48]	Time 0.102 (0.107)	Loss 0.6030 (0.5415)	Acc@1 92.188 (92.783)	Acc@5 98.438 (98.661)	Mem 5268MB
Training: 2023-08-17 23:46:46,040-Test: [30/48]	Time 0.102 (0.106)	Loss 0.4845 (0.5404)	Acc@1 93.750 (92.843)	Acc@5 100.000 (98.589)	Mem 5268MB
Training: 2023-08-17 23:46:47,082-Test: [40/48]	Time 0.104 (0.105)	Loss 0.6098 (0.5548)	Acc@1 89.062 (92.416)	Acc@5 96.875 (98.399)	Mem 5268MB
Training: 2023-08-17 23:46:47,799-[41999]Expression Loss: 0.55525
Training: 2023-08-17 23:46:47,799-[41999]Expression Acc@1: 92.34029
Training: 2023-08-17 23:46:47,799-[41999]Expression Acc@1-Highest: 92.47067
Training: 2023-08-17 23:46:47,799-[41999]Expression Acc@5: 98.33768
Training: 2023-08-17 23:46:47,799-[41999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 23:46:47,799-[41999]10 Times Expression Acc@1: 92.25228
Training: 2023-08-17 23:46:47,799-[41999]10 Times Expression Acc@1-Highest: 92.25228
Training: 2023-08-17 23:46:48,399-Speed 41.59 samples/sec   Loss 1.1455   LearningRate 0.000007   Epoch: 1   Global Step: 42000   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:46:50,659-Speed 141.65 samples/sec   Loss 1.1370   LearningRate 0.000007   Epoch: 1   Global Step: 42010   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:46:52,928-Speed 141.10 samples/sec   Loss 1.1367   LearningRate 0.000007   Epoch: 1   Global Step: 42020   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:46:55,185-Speed 141.77 samples/sec   Loss 1.1492   LearningRate 0.000007   Epoch: 1   Global Step: 42030   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:46:57,448-Speed 141.49 samples/sec   Loss 1.1320   LearningRate 0.000007   Epoch: 1   Global Step: 42040   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:46:59,718-Speed 141.02 samples/sec   Loss 1.1432   LearningRate 0.000007   Epoch: 1   Global Step: 42050   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:47:01,976-Speed 141.70 samples/sec   Loss 1.1403   LearningRate 0.000007   Epoch: 1   Global Step: 42060   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:47:04,246-Speed 141.06 samples/sec   Loss 1.1279   LearningRate 0.000007   Epoch: 1   Global Step: 42070   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:47:06,528-Speed 140.25 samples/sec   Loss 1.1580   LearningRate 0.000007   Epoch: 1   Global Step: 42080   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:47:08,819-Speed 139.68 samples/sec   Loss 1.1374   LearningRate 0.000007   Epoch: 1   Global Step: 42090   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:47:11,132-Speed 138.44 samples/sec   Loss 1.1668   LearningRate 0.000007   Epoch: 1   Global Step: 42100   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:47:13,447-Speed 138.23 samples/sec   Loss 1.1407   LearningRate 0.000007   Epoch: 1   Global Step: 42110   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:47:15,724-Speed 140.60 samples/sec   Loss 1.1680   LearningRate 0.000007   Epoch: 1   Global Step: 42120   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:47:18,008-Speed 140.14 samples/sec   Loss 1.1419   LearningRate 0.000007   Epoch: 1   Global Step: 42130   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:47:20,289-Speed 140.33 samples/sec   Loss 1.1519   LearningRate 0.000007   Epoch: 1   Global Step: 42140   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:47:22,557-Speed 141.17 samples/sec   Loss 1.1249   LearningRate 0.000007   Epoch: 1   Global Step: 42150   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:47:24,850-Speed 139.57 samples/sec   Loss 1.1606   LearningRate 0.000007   Epoch: 1   Global Step: 42160   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:47:27,121-Speed 140.94 samples/sec   Loss 1.1459   LearningRate 0.000007   Epoch: 1   Global Step: 42170   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:47:29,389-Speed 141.17 samples/sec   Loss 1.1073   LearningRate 0.000007   Epoch: 1   Global Step: 42180   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:47:31,661-Speed 140.84 samples/sec   Loss 1.1483   LearningRate 0.000007   Epoch: 1   Global Step: 42190   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:47:33,962-Speed 139.13 samples/sec   Loss 1.1520   LearningRate 0.000007   Epoch: 1   Global Step: 42200   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:47:36,252-Speed 139.79 samples/sec   Loss 1.1486   LearningRate 0.000007   Epoch: 1   Global Step: 42210   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:47:38,527-Speed 140.69 samples/sec   Loss 1.1526   LearningRate 0.000007   Epoch: 1   Global Step: 42220   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:47:40,820-Speed 139.59 samples/sec   Loss 1.1441   LearningRate 0.000007   Epoch: 1   Global Step: 42230   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:47:43,104-Speed 140.16 samples/sec   Loss 1.1534   LearningRate 0.000007   Epoch: 1   Global Step: 42240   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:47:45,372-Speed 141.13 samples/sec   Loss 1.1531   LearningRate 0.000007   Epoch: 1   Global Step: 42250   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:47:47,642-Speed 140.98 samples/sec   Loss 1.1356   LearningRate 0.000007   Epoch: 1   Global Step: 42260   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:47:49,918-Speed 140.64 samples/sec   Loss 1.1489   LearningRate 0.000007   Epoch: 1   Global Step: 42270   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:47:52,204-Speed 140.08 samples/sec   Loss 1.1333   LearningRate 0.000007   Epoch: 1   Global Step: 42280   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:47:54,500-Speed 139.39 samples/sec   Loss 1.1794   LearningRate 0.000006   Epoch: 1   Global Step: 42290   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:47:56,823-Speed 137.78 samples/sec   Loss 1.1571   LearningRate 0.000006   Epoch: 1   Global Step: 42300   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:47:59,143-Speed 137.96 samples/sec   Loss 1.1636   LearningRate 0.000006   Epoch: 1   Global Step: 42310   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:48:01,454-Speed 138.54 samples/sec   Loss 1.1380   LearningRate 0.000006   Epoch: 1   Global Step: 42320   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:48:03,753-Speed 139.19 samples/sec   Loss 1.1627   LearningRate 0.000006   Epoch: 1   Global Step: 42330   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:48:06,077-Speed 137.75 samples/sec   Loss 1.1735   LearningRate 0.000006   Epoch: 1   Global Step: 42340   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:48:08,378-Speed 139.14 samples/sec   Loss 1.1633   LearningRate 0.000006   Epoch: 1   Global Step: 42350   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:48:10,690-Speed 138.43 samples/sec   Loss 1.1407   LearningRate 0.000006   Epoch: 1   Global Step: 42360   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:48:13,001-Speed 138.47 samples/sec   Loss 1.1621   LearningRate 0.000006   Epoch: 1   Global Step: 42370   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:48:15,318-Speed 138.19 samples/sec   Loss 1.1339   LearningRate 0.000006   Epoch: 1   Global Step: 42380   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:48:17,635-Speed 138.14 samples/sec   Loss 1.1757   LearningRate 0.000006   Epoch: 1   Global Step: 42390   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:48:19,959-Speed 137.72 samples/sec   Loss 1.1652   LearningRate 0.000006   Epoch: 1   Global Step: 42400   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:48:22,282-Speed 137.78 samples/sec   Loss 1.1446   LearningRate 0.000006   Epoch: 1   Global Step: 42410   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:48:24,586-Speed 138.90 samples/sec   Loss 1.1239   LearningRate 0.000006   Epoch: 1   Global Step: 42420   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:48:26,901-Speed 138.29 samples/sec   Loss 1.1457   LearningRate 0.000006   Epoch: 1   Global Step: 42430   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:48:29,226-Speed 137.69 samples/sec   Loss 1.1735   LearningRate 0.000006   Epoch: 1   Global Step: 42440   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:48:31,540-Speed 138.29 samples/sec   Loss 1.1502   LearningRate 0.000006   Epoch: 1   Global Step: 42450   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:48:33,853-Speed 138.40 samples/sec   Loss 1.1631   LearningRate 0.000006   Epoch: 1   Global Step: 42460   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:48:36,163-Speed 138.60 samples/sec   Loss 1.1344   LearningRate 0.000006   Epoch: 1   Global Step: 42470   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:48:38,478-Speed 138.24 samples/sec   Loss 1.1342   LearningRate 0.000006   Epoch: 1   Global Step: 42480   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:48:40,746-Speed 141.12 samples/sec   Loss 1.1770   LearningRate 0.000006   Epoch: 1   Global Step: 42490   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:48:43,010-Speed 141.38 samples/sec   Loss 1.1251   LearningRate 0.000006   Epoch: 1   Global Step: 42500   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:48:45,270-Speed 141.64 samples/sec   Loss 1.1434   LearningRate 0.000006   Epoch: 1   Global Step: 42510   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:48:47,545-Speed 140.73 samples/sec   Loss 1.1518   LearningRate 0.000006   Epoch: 1   Global Step: 42520   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:48:49,828-Speed 140.18 samples/sec   Loss 1.1500   LearningRate 0.000006   Epoch: 1   Global Step: 42530   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:48:52,101-Speed 140.83 samples/sec   Loss 1.1781   LearningRate 0.000006   Epoch: 1   Global Step: 42540   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:48:54,386-Speed 140.09 samples/sec   Loss 1.1322   LearningRate 0.000006   Epoch: 1   Global Step: 42550   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:48:56,675-Speed 139.84 samples/sec   Loss 1.1528   LearningRate 0.000006   Epoch: 1   Global Step: 42560   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:48:58,953-Speed 140.51 samples/sec   Loss 1.1444   LearningRate 0.000006   Epoch: 1   Global Step: 42570   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:49:01,231-Speed 140.52 samples/sec   Loss 1.1453   LearningRate 0.000006   Epoch: 1   Global Step: 42580   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:49:03,509-Speed 140.54 samples/sec   Loss 1.1569   LearningRate 0.000006   Epoch: 1   Global Step: 42590   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:49:05,792-Speed 140.17 samples/sec   Loss 1.1229   LearningRate 0.000006   Epoch: 1   Global Step: 42600   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:49:08,069-Speed 140.57 samples/sec   Loss 1.1476   LearningRate 0.000006   Epoch: 1   Global Step: 42610   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:49:10,334-Speed 141.35 samples/sec   Loss 1.1394   LearningRate 0.000006   Epoch: 1   Global Step: 42620   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:49:12,589-Speed 141.94 samples/sec   Loss 1.1501   LearningRate 0.000006   Epoch: 1   Global Step: 42630   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:49:14,884-Speed 139.45 samples/sec   Loss 1.1740   LearningRate 0.000006   Epoch: 1   Global Step: 42640   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:49:17,165-Speed 140.33 samples/sec   Loss 1.1861   LearningRate 0.000006   Epoch: 1   Global Step: 42650   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:49:19,444-Speed 140.49 samples/sec   Loss 1.1534   LearningRate 0.000006   Epoch: 1   Global Step: 42660   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:49:21,729-Speed 140.04 samples/sec   Loss 1.1245   LearningRate 0.000006   Epoch: 1   Global Step: 42670   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:49:23,996-Speed 141.24 samples/sec   Loss 1.1461   LearningRate 0.000006   Epoch: 1   Global Step: 42680   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:49:26,288-Speed 139.64 samples/sec   Loss 1.1436   LearningRate 0.000006   Epoch: 1   Global Step: 42690   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:49:28,590-Speed 139.05 samples/sec   Loss 1.1203   LearningRate 0.000006   Epoch: 1   Global Step: 42700   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:49:30,867-Speed 140.52 samples/sec   Loss 1.1736   LearningRate 0.000006   Epoch: 1   Global Step: 42710   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:49:33,170-Speed 139.00 samples/sec   Loss 1.1616   LearningRate 0.000006   Epoch: 1   Global Step: 42720   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:49:35,452-Speed 140.27 samples/sec   Loss 1.1441   LearningRate 0.000006   Epoch: 1   Global Step: 42730   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:49:37,758-Speed 138.85 samples/sec   Loss 1.1451   LearningRate 0.000006   Epoch: 1   Global Step: 42740   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:49:40,057-Speed 139.21 samples/sec   Loss 1.1540   LearningRate 0.000006   Epoch: 1   Global Step: 42750   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:49:42,353-Speed 139.38 samples/sec   Loss 1.1193   LearningRate 0.000006   Epoch: 1   Global Step: 42760   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:49:44,638-Speed 140.11 samples/sec   Loss 1.1436   LearningRate 0.000006   Epoch: 1   Global Step: 42770   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:49:46,949-Speed 138.52 samples/sec   Loss 1.1594   LearningRate 0.000006   Epoch: 1   Global Step: 42780   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:49:49,230-Speed 140.29 samples/sec   Loss 1.1249   LearningRate 0.000006   Epoch: 1   Global Step: 42790   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:49:51,525-Speed 139.48 samples/sec   Loss 1.1537   LearningRate 0.000006   Epoch: 1   Global Step: 42800   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-17 23:49:53,820-Speed 139.47 samples/sec   Loss 1.1146   LearningRate 0.000006   Epoch: 1   Global Step: 42810   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:49:56,112-Speed 139.65 samples/sec   Loss 1.1467   LearningRate 0.000006   Epoch: 1   Global Step: 42820   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:49:58,406-Speed 139.57 samples/sec   Loss 1.1547   LearningRate 0.000006   Epoch: 1   Global Step: 42830   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:50:00,701-Speed 139.42 samples/sec   Loss 1.1768   LearningRate 0.000006   Epoch: 1   Global Step: 42840   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:50:02,971-Speed 141.01 samples/sec   Loss 1.1289   LearningRate 0.000006   Epoch: 1   Global Step: 42850   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:50:05,261-Speed 139.83 samples/sec   Loss 1.1430   LearningRate 0.000006   Epoch: 1   Global Step: 42860   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:50:07,548-Speed 139.94 samples/sec   Loss 1.1488   LearningRate 0.000006   Epoch: 1   Global Step: 42870   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:50:09,824-Speed 140.66 samples/sec   Loss 1.1472   LearningRate 0.000006   Epoch: 1   Global Step: 42880   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:50:12,109-Speed 140.07 samples/sec   Loss 1.1907   LearningRate 0.000006   Epoch: 1   Global Step: 42890   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:50:14,395-Speed 140.00 samples/sec   Loss 1.1270   LearningRate 0.000006   Epoch: 1   Global Step: 42900   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:50:16,672-Speed 140.58 samples/sec   Loss 1.1226   LearningRate 0.000006   Epoch: 1   Global Step: 42910   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:50:18,965-Speed 139.60 samples/sec   Loss 1.1675   LearningRate 0.000006   Epoch: 1   Global Step: 42920   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:50:21,282-Speed 138.13 samples/sec   Loss 1.1656   LearningRate 0.000006   Epoch: 1   Global Step: 42930   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:50:23,584-Speed 139.06 samples/sec   Loss 1.1293   LearningRate 0.000006   Epoch: 1   Global Step: 42940   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:50:25,906-Speed 137.85 samples/sec   Loss 1.1679   LearningRate 0.000006   Epoch: 1   Global Step: 42950   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:50:28,241-Speed 137.09 samples/sec   Loss 1.1550   LearningRate 0.000006   Epoch: 1   Global Step: 42960   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:50:30,556-Speed 138.24 samples/sec   Loss 1.1486   LearningRate 0.000006   Epoch: 1   Global Step: 42970   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:50:32,893-Speed 137.00 samples/sec   Loss 1.1601   LearningRate 0.000006   Epoch: 1   Global Step: 42980   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:50:35,194-Speed 139.10 samples/sec   Loss 1.1588   LearningRate 0.000006   Epoch: 1   Global Step: 42990   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:50:37,290-Val on RAF/AffectNet:
Training: 2023-08-17 23:50:37,403-Test: [0/48]	Time 0.112 (0.112)	Loss 0.5932 (0.5932)	Acc@1 90.625 (90.625)	Acc@5 98.438 (98.438)	Mem 5268MB
Training: 2023-08-17 23:50:38,464-Test: [10/48]	Time 0.105 (0.107)	Loss 0.5097 (0.5614)	Acc@1 93.750 (91.903)	Acc@5 98.438 (98.295)	Mem 5268MB
Training: 2023-08-17 23:50:39,532-Test: [20/48]	Time 0.109 (0.107)	Loss 0.6658 (0.5611)	Acc@1 87.500 (92.485)	Acc@5 96.875 (98.214)	Mem 5268MB
Training: 2023-08-17 23:50:40,593-Test: [30/48]	Time 0.104 (0.107)	Loss 0.5021 (0.5494)	Acc@1 93.750 (92.692)	Acc@5 100.000 (98.488)	Mem 5268MB
Training: 2023-08-17 23:50:41,646-Test: [40/48]	Time 0.105 (0.106)	Loss 0.6075 (0.5464)	Acc@1 92.188 (92.797)	Acc@5 95.312 (98.590)	Mem 5268MB
Training: 2023-08-17 23:50:42,384-[42999]Expression Loss: 0.54876
Training: 2023-08-17 23:50:42,384-[42999]Expression Acc@1: 92.66623
Training: 2023-08-17 23:50:42,384-[42999]Expression Acc@1-Highest: 92.66623
Training: 2023-08-17 23:50:42,384-[42999]Expression Acc@5: 98.50065
Training: 2023-08-17 23:50:42,384-[42999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 23:50:42,384-[42999]10 Times Expression Acc@1: 92.35332
Training: 2023-08-17 23:50:42,384-[42999]10 Times Expression Acc@1-Highest: 92.35332
Training: 2023-08-17 23:50:42,613-Speed 43.14 samples/sec   Loss 1.1677   LearningRate 0.000006   Epoch: 1   Global Step: 43000   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:50:44,901-Speed 139.85 samples/sec   Loss 1.1352   LearningRate 0.000006   Epoch: 1   Global Step: 43010   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:50:47,182-Speed 140.35 samples/sec   Loss 1.1575   LearningRate 0.000006   Epoch: 1   Global Step: 43020   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:50:49,479-Speed 139.36 samples/sec   Loss 1.1579   LearningRate 0.000006   Epoch: 1   Global Step: 43030   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:50:51,764-Speed 140.10 samples/sec   Loss 1.1247   LearningRate 0.000006   Epoch: 1   Global Step: 43040   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:50:54,048-Speed 140.11 samples/sec   Loss 1.1523   LearningRate 0.000006   Epoch: 1   Global Step: 43050   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:50:56,343-Speed 139.47 samples/sec   Loss 1.1391   LearningRate 0.000006   Epoch: 1   Global Step: 43060   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:50:58,633-Speed 139.76 samples/sec   Loss 1.1521   LearningRate 0.000006   Epoch: 1   Global Step: 43070   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:51:00,927-Speed 139.57 samples/sec   Loss 1.1695   LearningRate 0.000006   Epoch: 1   Global Step: 43080   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:51:03,224-Speed 139.34 samples/sec   Loss 1.1600   LearningRate 0.000006   Epoch: 1   Global Step: 43090   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:51:05,523-Speed 139.27 samples/sec   Loss 1.1364   LearningRate 0.000006   Epoch: 1   Global Step: 43100   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:51:07,811-Speed 139.89 samples/sec   Loss 1.1435   LearningRate 0.000006   Epoch: 1   Global Step: 43110   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:51:10,108-Speed 139.37 samples/sec   Loss 1.1293   LearningRate 0.000006   Epoch: 1   Global Step: 43120   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:51:12,399-Speed 139.66 samples/sec   Loss 1.1699   LearningRate 0.000006   Epoch: 1   Global Step: 43130   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:51:14,684-Speed 140.10 samples/sec   Loss 1.1357   LearningRate 0.000006   Epoch: 1   Global Step: 43140   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:51:16,984-Speed 139.19 samples/sec   Loss 1.1634   LearningRate 0.000006   Epoch: 1   Global Step: 43150   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:51:19,270-Speed 140.04 samples/sec   Loss 1.1277   LearningRate 0.000006   Epoch: 1   Global Step: 43160   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:51:21,566-Speed 139.38 samples/sec   Loss 1.1463   LearningRate 0.000006   Epoch: 1   Global Step: 43170   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:51:23,868-Speed 139.03 samples/sec   Loss 1.1368   LearningRate 0.000006   Epoch: 1   Global Step: 43180   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:51:26,150-Speed 140.27 samples/sec   Loss 1.1511   LearningRate 0.000006   Epoch: 1   Global Step: 43190   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:51:28,447-Speed 139.34 samples/sec   Loss 1.1530   LearningRate 0.000006   Epoch: 1   Global Step: 43200   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:51:30,724-Speed 140.57 samples/sec   Loss 1.1805   LearningRate 0.000006   Epoch: 1   Global Step: 43210   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:51:33,001-Speed 140.57 samples/sec   Loss 1.1420   LearningRate 0.000006   Epoch: 1   Global Step: 43220   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:51:35,298-Speed 139.36 samples/sec   Loss 1.1386   LearningRate 0.000006   Epoch: 1   Global Step: 43230   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:51:37,594-Speed 139.46 samples/sec   Loss 1.1685   LearningRate 0.000006   Epoch: 1   Global Step: 43240   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:51:39,893-Speed 139.22 samples/sec   Loss 1.1467   LearningRate 0.000006   Epoch: 1   Global Step: 43250   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:51:42,184-Speed 139.72 samples/sec   Loss 1.1336   LearningRate 0.000006   Epoch: 1   Global Step: 43260   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:51:44,478-Speed 139.49 samples/sec   Loss 1.1492   LearningRate 0.000006   Epoch: 1   Global Step: 43270   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:51:46,774-Speed 139.41 samples/sec   Loss 1.1301   LearningRate 0.000006   Epoch: 1   Global Step: 43280   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:51:49,071-Speed 139.41 samples/sec   Loss 1.1560   LearningRate 0.000006   Epoch: 1   Global Step: 43290   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:51:51,356-Speed 140.09 samples/sec   Loss 1.1443   LearningRate 0.000006   Epoch: 1   Global Step: 43300   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:51:53,650-Speed 139.52 samples/sec   Loss 1.1580   LearningRate 0.000006   Epoch: 1   Global Step: 43310   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:51:55,945-Speed 139.46 samples/sec   Loss 1.1440   LearningRate 0.000006   Epoch: 1   Global Step: 43320   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:51:58,242-Speed 139.36 samples/sec   Loss 1.1814   LearningRate 0.000006   Epoch: 1   Global Step: 43330   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:52:00,544-Speed 139.02 samples/sec   Loss 1.1433   LearningRate 0.000006   Epoch: 1   Global Step: 43340   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:52:02,842-Speed 139.29 samples/sec   Loss 1.1383   LearningRate 0.000006   Epoch: 1   Global Step: 43350   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:52:05,129-Speed 140.00 samples/sec   Loss 1.1558   LearningRate 0.000006   Epoch: 1   Global Step: 43360   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:52:07,418-Speed 139.83 samples/sec   Loss 1.1317   LearningRate 0.000006   Epoch: 1   Global Step: 43370   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:52:09,717-Speed 139.24 samples/sec   Loss 1.1976   LearningRate 0.000006   Epoch: 1   Global Step: 43380   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:52:12,025-Speed 138.70 samples/sec   Loss 1.1286   LearningRate 0.000006   Epoch: 1   Global Step: 43390   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:52:14,325-Speed 139.10 samples/sec   Loss 1.1526   LearningRate 0.000006   Epoch: 1   Global Step: 43400   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:52:16,625-Speed 139.18 samples/sec   Loss 1.1365   LearningRate 0.000006   Epoch: 1   Global Step: 43410   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:52:18,929-Speed 138.94 samples/sec   Loss 1.1561   LearningRate 0.000006   Epoch: 1   Global Step: 43420   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:52:21,223-Speed 139.55 samples/sec   Loss 1.1473   LearningRate 0.000006   Epoch: 1   Global Step: 43430   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:52:23,520-Speed 139.36 samples/sec   Loss 1.1576   LearningRate 0.000006   Epoch: 1   Global Step: 43440   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:52:25,802-Speed 140.24 samples/sec   Loss 1.1723   LearningRate 0.000006   Epoch: 1   Global Step: 43450   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:52:28,094-Speed 139.65 samples/sec   Loss 1.1229   LearningRate 0.000006   Epoch: 1   Global Step: 43460   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:52:30,395-Speed 139.13 samples/sec   Loss 1.1584   LearningRate 0.000006   Epoch: 1   Global Step: 43470   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:52:32,690-Speed 139.47 samples/sec   Loss 1.1297   LearningRate 0.000006   Epoch: 1   Global Step: 43480   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:52:34,983-Speed 139.56 samples/sec   Loss 1.1416   LearningRate 0.000006   Epoch: 1   Global Step: 43490   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:52:37,287-Speed 138.95 samples/sec   Loss 1.1601   LearningRate 0.000006   Epoch: 1   Global Step: 43500   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:52:39,567-Speed 140.36 samples/sec   Loss 1.1725   LearningRate 0.000006   Epoch: 1   Global Step: 43510   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:52:41,872-Speed 138.91 samples/sec   Loss 1.1344   LearningRate 0.000006   Epoch: 1   Global Step: 43520   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:52:44,178-Speed 138.81 samples/sec   Loss 1.1618   LearningRate 0.000006   Epoch: 1   Global Step: 43530   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:52:46,469-Speed 139.70 samples/sec   Loss 1.1499   LearningRate 0.000006   Epoch: 1   Global Step: 43540   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:52:48,757-Speed 139.93 samples/sec   Loss 1.1489   LearningRate 0.000006   Epoch: 1   Global Step: 43550   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:52:51,042-Speed 140.06 samples/sec   Loss 1.1359   LearningRate 0.000006   Epoch: 1   Global Step: 43560   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:52:53,349-Speed 138.76 samples/sec   Loss 1.1599   LearningRate 0.000006   Epoch: 1   Global Step: 43570   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:52:55,642-Speed 139.61 samples/sec   Loss 1.1415   LearningRate 0.000006   Epoch: 1   Global Step: 43580   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:52:57,946-Speed 138.89 samples/sec   Loss 1.1498   LearningRate 0.000006   Epoch: 1   Global Step: 43590   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:53:00,216-Speed 141.01 samples/sec   Loss 1.1578   LearningRate 0.000006   Epoch: 1   Global Step: 43600   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:53:02,476-Speed 141.67 samples/sec   Loss 1.1510   LearningRate 0.000006   Epoch: 1   Global Step: 43610   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:53:04,761-Speed 140.02 samples/sec   Loss 1.1309   LearningRate 0.000006   Epoch: 1   Global Step: 43620   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:53:07,031-Speed 141.01 samples/sec   Loss 1.1661   LearningRate 0.000006   Epoch: 1   Global Step: 43630   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:53:09,300-Speed 141.11 samples/sec   Loss 1.1618   LearningRate 0.000006   Epoch: 1   Global Step: 43640   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:53:11,568-Speed 141.12 samples/sec   Loss 1.1599   LearningRate 0.000006   Epoch: 1   Global Step: 43650   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:53:13,843-Speed 140.72 samples/sec   Loss 1.1344   LearningRate 0.000006   Epoch: 1   Global Step: 43660   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:53:16,107-Speed 141.33 samples/sec   Loss 1.1371   LearningRate 0.000006   Epoch: 1   Global Step: 43670   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:53:18,383-Speed 140.70 samples/sec   Loss 1.1787   LearningRate 0.000006   Epoch: 1   Global Step: 43680   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:53:20,655-Speed 140.86 samples/sec   Loss 1.1638   LearningRate 0.000006   Epoch: 1   Global Step: 43690   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:53:22,920-Speed 141.32 samples/sec   Loss 1.1620   LearningRate 0.000006   Epoch: 1   Global Step: 43700   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:53:25,190-Speed 141.04 samples/sec   Loss 1.1324   LearningRate 0.000006   Epoch: 1   Global Step: 43710   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:53:27,445-Speed 141.93 samples/sec   Loss 1.1344   LearningRate 0.000006   Epoch: 1   Global Step: 43720   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:53:29,695-Speed 142.24 samples/sec   Loss 1.1368   LearningRate 0.000006   Epoch: 1   Global Step: 43730   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:53:31,979-Speed 140.16 samples/sec   Loss 1.1621   LearningRate 0.000006   Epoch: 1   Global Step: 43740   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:53:34,255-Speed 140.61 samples/sec   Loss 1.1498   LearningRate 0.000006   Epoch: 1   Global Step: 43750   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:53:36,527-Speed 140.89 samples/sec   Loss 1.1389   LearningRate 0.000006   Epoch: 1   Global Step: 43760   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:53:38,801-Speed 140.76 samples/sec   Loss 1.1603   LearningRate 0.000006   Epoch: 1   Global Step: 43770   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:53:41,066-Speed 141.32 samples/sec   Loss 1.1713   LearningRate 0.000006   Epoch: 1   Global Step: 43780   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:53:43,334-Speed 141.15 samples/sec   Loss 1.1486   LearningRate 0.000006   Epoch: 1   Global Step: 43790   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:53:45,613-Speed 140.43 samples/sec   Loss 1.1792   LearningRate 0.000006   Epoch: 1   Global Step: 43800   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:53:47,890-Speed 140.60 samples/sec   Loss 1.1602   LearningRate 0.000006   Epoch: 1   Global Step: 43810   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:53:50,159-Speed 141.06 samples/sec   Loss 1.1351   LearningRate 0.000006   Epoch: 1   Global Step: 43820   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:53:52,420-Speed 141.60 samples/sec   Loss 1.1571   LearningRate 0.000006   Epoch: 1   Global Step: 43830   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:53:54,680-Speed 141.63 samples/sec   Loss 1.1344   LearningRate 0.000006   Epoch: 1   Global Step: 43840   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:53:56,960-Speed 140.34 samples/sec   Loss 1.1167   LearningRate 0.000006   Epoch: 1   Global Step: 43850   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:53:59,219-Speed 141.76 samples/sec   Loss 1.1518   LearningRate 0.000006   Epoch: 1   Global Step: 43860   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:54:01,486-Speed 141.17 samples/sec   Loss 1.1580   LearningRate 0.000006   Epoch: 1   Global Step: 43870   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:54:03,752-Speed 141.28 samples/sec   Loss 1.1371   LearningRate 0.000006   Epoch: 1   Global Step: 43880   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:54:06,049-Speed 139.29 samples/sec   Loss 1.1541   LearningRate 0.000005   Epoch: 1   Global Step: 43890   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:54:08,365-Speed 138.25 samples/sec   Loss 1.1496   LearningRate 0.000005   Epoch: 1   Global Step: 43900   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:54:10,693-Speed 137.47 samples/sec   Loss 1.1544   LearningRate 0.000005   Epoch: 1   Global Step: 43910   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:54:12,999-Speed 138.82 samples/sec   Loss 1.1506   LearningRate 0.000005   Epoch: 1   Global Step: 43920   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:54:15,320-Speed 137.88 samples/sec   Loss 1.1466   LearningRate 0.000005   Epoch: 1   Global Step: 43930   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:54:17,637-Speed 138.14 samples/sec   Loss 1.1267   LearningRate 0.000005   Epoch: 1   Global Step: 43940   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:54:19,962-Speed 137.73 samples/sec   Loss 1.1441   LearningRate 0.000005   Epoch: 1   Global Step: 43950   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:54:22,278-Speed 138.15 samples/sec   Loss 1.1379   LearningRate 0.000005   Epoch: 1   Global Step: 43960   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:54:24,584-Speed 138.82 samples/sec   Loss 1.1389   LearningRate 0.000005   Epoch: 1   Global Step: 43970   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:54:26,879-Speed 139.48 samples/sec   Loss 1.1357   LearningRate 0.000005   Epoch: 1   Global Step: 43980   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:54:29,164-Speed 140.13 samples/sec   Loss 1.1146   LearningRate 0.000005   Epoch: 1   Global Step: 43990   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:54:31,230-Val on RAF/AffectNet:
Training: 2023-08-17 23:54:31,345-Test: [0/48]	Time 0.115 (0.115)	Loss 0.4296 (0.4296)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-17 23:54:32,439-Test: [10/48]	Time 0.114 (0.110)	Loss 0.4703 (0.5096)	Acc@1 96.875 (93.608)	Acc@5 98.438 (99.006)	Mem 5268MB
Training: 2023-08-17 23:54:33,530-Test: [20/48]	Time 0.105 (0.110)	Loss 0.5487 (0.5211)	Acc@1 89.062 (93.229)	Acc@5 98.438 (98.512)	Mem 5268MB
Training: 2023-08-17 23:54:34,610-Test: [30/48]	Time 0.106 (0.109)	Loss 0.5365 (0.5327)	Acc@1 92.188 (92.944)	Acc@5 100.000 (98.538)	Mem 5268MB
Training: 2023-08-17 23:54:35,673-Test: [40/48]	Time 0.104 (0.108)	Loss 0.6208 (0.5445)	Acc@1 89.062 (92.454)	Acc@5 95.312 (98.247)	Mem 5268MB
Training: 2023-08-17 23:54:36,417-[43999]Expression Loss: 0.54233
Training: 2023-08-17 23:54:36,417-[43999]Expression Acc@1: 92.43807
Training: 2023-08-17 23:54:36,417-[43999]Expression Acc@1-Highest: 92.66623
Training: 2023-08-17 23:54:36,417-[43999]Expression Acc@5: 98.23990
Training: 2023-08-17 23:54:36,417-[43999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 23:54:36,417-[43999]10 Times Expression Acc@1: 92.38592
Training: 2023-08-17 23:54:36,417-[43999]10 Times Expression Acc@1-Highest: 92.38592
Training: 2023-08-17 23:54:36,649-Speed 42.75 samples/sec   Loss 1.1378   LearningRate 0.000005   Epoch: 1   Global Step: 44000   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:54:38,939-Speed 139.76 samples/sec   Loss 1.1380   LearningRate 0.000005   Epoch: 1   Global Step: 44010   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:54:41,220-Speed 140.38 samples/sec   Loss 1.1205   LearningRate 0.000005   Epoch: 1   Global Step: 44020   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:54:43,518-Speed 139.28 samples/sec   Loss 1.1309   LearningRate 0.000005   Epoch: 1   Global Step: 44030   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:54:45,800-Speed 140.22 samples/sec   Loss 1.1280   LearningRate 0.000005   Epoch: 1   Global Step: 44040   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:54:48,085-Speed 140.09 samples/sec   Loss 1.1511   LearningRate 0.000005   Epoch: 1   Global Step: 44050   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:54:50,358-Speed 140.81 samples/sec   Loss 1.1441   LearningRate 0.000005   Epoch: 1   Global Step: 44060   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:54:52,643-Speed 140.14 samples/sec   Loss 1.1383   LearningRate 0.000005   Epoch: 1   Global Step: 44070   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:54:54,927-Speed 140.12 samples/sec   Loss 1.1245   LearningRate 0.000005   Epoch: 1   Global Step: 44080   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:54:57,227-Speed 139.14 samples/sec   Loss 1.1290   LearningRate 0.000005   Epoch: 1   Global Step: 44090   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:54:59,517-Speed 139.82 samples/sec   Loss 1.1480   LearningRate 0.000005   Epoch: 1   Global Step: 44100   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:55:01,808-Speed 139.72 samples/sec   Loss 1.1513   LearningRate 0.000005   Epoch: 1   Global Step: 44110   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:55:04,086-Speed 140.52 samples/sec   Loss 1.1611   LearningRate 0.000005   Epoch: 1   Global Step: 44120   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:55:06,368-Speed 140.28 samples/sec   Loss 1.1514   LearningRate 0.000005   Epoch: 1   Global Step: 44130   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:55:08,638-Speed 140.98 samples/sec   Loss 1.1557   LearningRate 0.000005   Epoch: 1   Global Step: 44140   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:55:10,920-Speed 140.27 samples/sec   Loss 1.1347   LearningRate 0.000005   Epoch: 1   Global Step: 44150   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:55:13,203-Speed 140.20 samples/sec   Loss 1.1548   LearningRate 0.000005   Epoch: 1   Global Step: 44160   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:55:15,492-Speed 139.87 samples/sec   Loss 1.1600   LearningRate 0.000005   Epoch: 1   Global Step: 44170   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:55:17,800-Speed 138.64 samples/sec   Loss 1.1357   LearningRate 0.000005   Epoch: 1   Global Step: 44180   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:55:20,104-Speed 138.92 samples/sec   Loss 1.1757   LearningRate 0.000005   Epoch: 1   Global Step: 44190   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:55:22,427-Speed 137.80 samples/sec   Loss 1.1564   LearningRate 0.000005   Epoch: 1   Global Step: 44200   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:55:24,732-Speed 138.89 samples/sec   Loss 1.1418   LearningRate 0.000005   Epoch: 1   Global Step: 44210   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:55:27,001-Speed 141.05 samples/sec   Loss 1.1476   LearningRate 0.000005   Epoch: 1   Global Step: 44220   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:55:29,278-Speed 140.57 samples/sec   Loss 1.1567   LearningRate 0.000005   Epoch: 1   Global Step: 44230   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:55:31,560-Speed 140.29 samples/sec   Loss 1.1355   LearningRate 0.000005   Epoch: 1   Global Step: 44240   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:55:33,849-Speed 139.87 samples/sec   Loss 1.1602   LearningRate 0.000005   Epoch: 1   Global Step: 44250   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:55:36,142-Speed 139.57 samples/sec   Loss 1.1451   LearningRate 0.000005   Epoch: 1   Global Step: 44260   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:55:38,433-Speed 139.70 samples/sec   Loss 1.1216   LearningRate 0.000005   Epoch: 1   Global Step: 44270   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:55:40,724-Speed 139.71 samples/sec   Loss 1.1380   LearningRate 0.000005   Epoch: 1   Global Step: 44280   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:55:43,022-Speed 139.28 samples/sec   Loss 1.1099   LearningRate 0.000005   Epoch: 1   Global Step: 44290   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:55:45,317-Speed 139.49 samples/sec   Loss 1.1316   LearningRate 0.000005   Epoch: 1   Global Step: 44300   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:55:47,625-Speed 138.65 samples/sec   Loss 1.1299   LearningRate 0.000005   Epoch: 1   Global Step: 44310   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:55:49,915-Speed 139.79 samples/sec   Loss 1.1534   LearningRate 0.000005   Epoch: 1   Global Step: 44320   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:55:52,220-Speed 138.89 samples/sec   Loss 1.1418   LearningRate 0.000005   Epoch: 1   Global Step: 44330   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:55:54,522-Speed 139.05 samples/sec   Loss 1.1397   LearningRate 0.000005   Epoch: 1   Global Step: 44340   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:55:56,814-Speed 139.64 samples/sec   Loss 1.1505   LearningRate 0.000005   Epoch: 1   Global Step: 44350   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:55:59,101-Speed 139.96 samples/sec   Loss 1.1730   LearningRate 0.000005   Epoch: 1   Global Step: 44360   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:56:01,398-Speed 139.36 samples/sec   Loss 1.1363   LearningRate 0.000005   Epoch: 1   Global Step: 44370   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:56:03,697-Speed 139.22 samples/sec   Loss 1.1553   LearningRate 0.000005   Epoch: 1   Global Step: 44380   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:56:06,013-Speed 138.20 samples/sec   Loss 1.1438   LearningRate 0.000005   Epoch: 1   Global Step: 44390   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:56:08,328-Speed 138.26 samples/sec   Loss 1.1334   LearningRate 0.000005   Epoch: 1   Global Step: 44400   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:56:10,628-Speed 139.21 samples/sec   Loss 1.1371   LearningRate 0.000005   Epoch: 1   Global Step: 44410   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:56:12,922-Speed 139.50 samples/sec   Loss 1.1424   LearningRate 0.000005   Epoch: 1   Global Step: 44420   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:56:15,219-Speed 139.36 samples/sec   Loss 1.1458   LearningRate 0.000005   Epoch: 1   Global Step: 44430   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:56:17,505-Speed 139.99 samples/sec   Loss 1.1589   LearningRate 0.000005   Epoch: 1   Global Step: 44440   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:56:19,778-Speed 140.87 samples/sec   Loss 1.1286   LearningRate 0.000005   Epoch: 1   Global Step: 44450   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:56:22,073-Speed 139.46 samples/sec   Loss 1.1595   LearningRate 0.000005   Epoch: 1   Global Step: 44460   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:56:24,377-Speed 138.93 samples/sec   Loss 1.1484   LearningRate 0.000005   Epoch: 1   Global Step: 44470   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:56:26,671-Speed 139.54 samples/sec   Loss 1.1361   LearningRate 0.000005   Epoch: 1   Global Step: 44480   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:56:28,971-Speed 139.14 samples/sec   Loss 1.1490   LearningRate 0.000005   Epoch: 1   Global Step: 44490   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:56:31,258-Speed 140.00 samples/sec   Loss 1.1671   LearningRate 0.000005   Epoch: 1   Global Step: 44500   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:56:33,574-Speed 138.19 samples/sec   Loss 1.1352   LearningRate 0.000005   Epoch: 1   Global Step: 44510   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:56:35,886-Speed 138.47 samples/sec   Loss 1.1497   LearningRate 0.000005   Epoch: 1   Global Step: 44520   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:56:38,186-Speed 139.18 samples/sec   Loss 1.1499   LearningRate 0.000005   Epoch: 1   Global Step: 44530   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:56:40,481-Speed 139.44 samples/sec   Loss 1.1676   LearningRate 0.000005   Epoch: 1   Global Step: 44540   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:56:42,794-Speed 138.41 samples/sec   Loss 1.1380   LearningRate 0.000005   Epoch: 1   Global Step: 44550   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:56:45,093-Speed 139.20 samples/sec   Loss 1.1723   LearningRate 0.000005   Epoch: 1   Global Step: 44560   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:56:47,384-Speed 139.71 samples/sec   Loss 1.1594   LearningRate 0.000005   Epoch: 1   Global Step: 44570   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:56:49,680-Speed 139.44 samples/sec   Loss 1.1271   LearningRate 0.000005   Epoch: 1   Global Step: 44580   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:56:51,972-Speed 139.63 samples/sec   Loss 1.1503   LearningRate 0.000005   Epoch: 1   Global Step: 44590   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:56:54,273-Speed 139.13 samples/sec   Loss 1.1336   LearningRate 0.000005   Epoch: 1   Global Step: 44600   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:56:56,570-Speed 139.36 samples/sec   Loss 1.1600   LearningRate 0.000005   Epoch: 1   Global Step: 44610   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:56:58,863-Speed 139.59 samples/sec   Loss 1.1352   LearningRate 0.000005   Epoch: 1   Global Step: 44620   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:57:01,170-Speed 138.75 samples/sec   Loss 1.1390   LearningRate 0.000005   Epoch: 1   Global Step: 44630   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:57:03,469-Speed 139.20 samples/sec   Loss 1.1400   LearningRate 0.000005   Epoch: 1   Global Step: 44640   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:57:05,765-Speed 139.43 samples/sec   Loss 1.1562   LearningRate 0.000005   Epoch: 1   Global Step: 44650   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:57:08,061-Speed 139.38 samples/sec   Loss 1.1419   LearningRate 0.000005   Epoch: 1   Global Step: 44660   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:57:10,360-Speed 139.24 samples/sec   Loss 1.1395   LearningRate 0.000005   Epoch: 1   Global Step: 44670   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:57:12,653-Speed 139.60 samples/sec   Loss 1.1467   LearningRate 0.000005   Epoch: 1   Global Step: 44680   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:57:14,961-Speed 138.72 samples/sec   Loss 1.1771   LearningRate 0.000005   Epoch: 1   Global Step: 44690   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:57:17,243-Speed 140.21 samples/sec   Loss 1.1573   LearningRate 0.000005   Epoch: 1   Global Step: 44700   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:57:19,546-Speed 139.02 samples/sec   Loss 1.1529   LearningRate 0.000005   Epoch: 1   Global Step: 44710   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:57:21,846-Speed 139.16 samples/sec   Loss 1.1518   LearningRate 0.000005   Epoch: 1   Global Step: 44720   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:57:24,144-Speed 139.32 samples/sec   Loss 1.1469   LearningRate 0.000005   Epoch: 1   Global Step: 44730   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:57:26,449-Speed 138.83 samples/sec   Loss 1.1487   LearningRate 0.000005   Epoch: 1   Global Step: 44740   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:57:28,744-Speed 139.49 samples/sec   Loss 1.1526   LearningRate 0.000005   Epoch: 1   Global Step: 44750   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:57:31,060-Speed 138.21 samples/sec   Loss 1.1712   LearningRate 0.000005   Epoch: 1   Global Step: 44760   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:57:33,377-Speed 138.13 samples/sec   Loss 1.1522   LearningRate 0.000005   Epoch: 1   Global Step: 44770   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:57:35,706-Speed 137.47 samples/sec   Loss 1.1339   LearningRate 0.000005   Epoch: 1   Global Step: 44780   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:57:38,009-Speed 138.96 samples/sec   Loss 1.1322   LearningRate 0.000005   Epoch: 1   Global Step: 44790   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:57:40,316-Speed 138.73 samples/sec   Loss 1.1549   LearningRate 0.000005   Epoch: 1   Global Step: 44800   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:57:42,617-Speed 139.10 samples/sec   Loss 1.1463   LearningRate 0.000005   Epoch: 1   Global Step: 44810   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-17 23:57:44,891-Speed 140.78 samples/sec   Loss 1.1432   LearningRate 0.000005   Epoch: 1   Global Step: 44820   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:57:47,172-Speed 140.35 samples/sec   Loss 1.1614   LearningRate 0.000005   Epoch: 1   Global Step: 44830   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:57:49,476-Speed 138.93 samples/sec   Loss 1.1535   LearningRate 0.000005   Epoch: 1   Global Step: 44840   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:57:51,768-Speed 139.66 samples/sec   Loss 1.1484   LearningRate 0.000005   Epoch: 1   Global Step: 44850   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:57:54,055-Speed 139.97 samples/sec   Loss 1.1562   LearningRate 0.000005   Epoch: 1   Global Step: 44860   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:57:56,363-Speed 138.67 samples/sec   Loss 1.1561   LearningRate 0.000005   Epoch: 1   Global Step: 44870   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:57:58,645-Speed 140.24 samples/sec   Loss 1.1527   LearningRate 0.000005   Epoch: 1   Global Step: 44880   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:58:00,944-Speed 139.25 samples/sec   Loss 1.1418   LearningRate 0.000005   Epoch: 1   Global Step: 44890   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:58:03,248-Speed 138.94 samples/sec   Loss 1.1334   LearningRate 0.000005   Epoch: 1   Global Step: 44900   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:58:05,535-Speed 139.97 samples/sec   Loss 1.1407   LearningRate 0.000005   Epoch: 1   Global Step: 44910   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:58:07,810-Speed 140.66 samples/sec   Loss 1.1438   LearningRate 0.000005   Epoch: 1   Global Step: 44920   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:58:10,105-Speed 139.53 samples/sec   Loss 1.1272   LearningRate 0.000005   Epoch: 1   Global Step: 44930   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:58:12,401-Speed 139.34 samples/sec   Loss 1.1318   LearningRate 0.000005   Epoch: 1   Global Step: 44940   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:58:14,679-Speed 140.54 samples/sec   Loss 1.1303   LearningRate 0.000005   Epoch: 1   Global Step: 44950   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:58:16,974-Speed 139.47 samples/sec   Loss 1.1630   LearningRate 0.000005   Epoch: 1   Global Step: 44960   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:58:19,274-Speed 139.22 samples/sec   Loss 1.1588   LearningRate 0.000005   Epoch: 1   Global Step: 44970   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:58:21,547-Speed 140.82 samples/sec   Loss 1.1322   LearningRate 0.000005   Epoch: 1   Global Step: 44980   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:58:23,852-Speed 138.84 samples/sec   Loss 1.1400   LearningRate 0.000005   Epoch: 1   Global Step: 44990   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:58:25,910-Val on RAF/AffectNet:
Training: 2023-08-17 23:58:26,026-Test: [0/48]	Time 0.116 (0.116)	Loss 0.5029 (0.5029)	Acc@1 95.312 (95.312)	Acc@5 96.875 (96.875)	Mem 5268MB
Training: 2023-08-17 23:58:27,106-Test: [10/48]	Time 0.107 (0.109)	Loss 0.5926 (0.5567)	Acc@1 90.625 (92.188)	Acc@5 100.000 (98.438)	Mem 5268MB
Training: 2023-08-17 23:58:28,174-Test: [20/48]	Time 0.102 (0.108)	Loss 0.5785 (0.5581)	Acc@1 92.188 (92.039)	Acc@5 96.875 (98.289)	Mem 5268MB
Training: 2023-08-17 23:58:29,247-Test: [30/48]	Time 0.113 (0.108)	Loss 0.6430 (0.5551)	Acc@1 89.062 (92.238)	Acc@5 96.875 (98.337)	Mem 5268MB
Training: 2023-08-17 23:58:30,315-Test: [40/48]	Time 0.107 (0.107)	Loss 0.6111 (0.5547)	Acc@1 90.625 (92.416)	Acc@5 98.438 (98.247)	Mem 5268MB
Training: 2023-08-17 23:58:31,050-[44999]Expression Loss: 0.55426
Training: 2023-08-17 23:58:31,050-[44999]Expression Acc@1: 92.40548
Training: 2023-08-17 23:58:31,050-[44999]Expression Acc@1-Highest: 92.66623
Training: 2023-08-17 23:58:31,050-[44999]Expression Acc@5: 98.20730
Training: 2023-08-17 23:58:31,050-[44999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-17 23:58:31,050-[44999]10 Times Expression Acc@1: 92.38918
Training: 2023-08-17 23:58:31,051-[44999]10 Times Expression Acc@1-Highest: 92.38918
Training: 2023-08-17 23:58:31,284-Speed 43.06 samples/sec   Loss 1.1735   LearningRate 0.000005   Epoch: 1   Global Step: 45000   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:58:33,534-Speed 142.24 samples/sec   Loss 1.1552   LearningRate 0.000005   Epoch: 1   Global Step: 45010   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:58:35,810-Speed 140.63 samples/sec   Loss 1.1382   LearningRate 0.000005   Epoch: 1   Global Step: 45020   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:58:38,072-Speed 141.51 samples/sec   Loss 1.1380   LearningRate 0.000005   Epoch: 1   Global Step: 45030   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:58:40,322-Speed 142.31 samples/sec   Loss 1.1267   LearningRate 0.000005   Epoch: 1   Global Step: 45040   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:58:42,604-Speed 140.25 samples/sec   Loss 1.1536   LearningRate 0.000005   Epoch: 1   Global Step: 45050   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:58:44,886-Speed 140.23 samples/sec   Loss 1.1282   LearningRate 0.000005   Epoch: 1   Global Step: 45060   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:58:47,162-Speed 140.65 samples/sec   Loss 1.1512   LearningRate 0.000005   Epoch: 1   Global Step: 45070   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:58:49,447-Speed 140.11 samples/sec   Loss 1.1587   LearningRate 0.000005   Epoch: 1   Global Step: 45080   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:58:51,720-Speed 140.80 samples/sec   Loss 1.1449   LearningRate 0.000005   Epoch: 1   Global Step: 45090   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:58:54,006-Speed 140.05 samples/sec   Loss 1.1541   LearningRate 0.000005   Epoch: 1   Global Step: 45100   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:58:56,284-Speed 140.49 samples/sec   Loss 1.1510   LearningRate 0.000005   Epoch: 1   Global Step: 45110   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:58:58,538-Speed 142.00 samples/sec   Loss 1.1447   LearningRate 0.000005   Epoch: 1   Global Step: 45120   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:59:00,811-Speed 140.81 samples/sec   Loss 1.1652   LearningRate 0.000005   Epoch: 1   Global Step: 45130   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:59:03,060-Speed 142.33 samples/sec   Loss 1.1551   LearningRate 0.000005   Epoch: 1   Global Step: 45140   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:59:05,314-Speed 142.05 samples/sec   Loss 1.1374   LearningRate 0.000005   Epoch: 1   Global Step: 45150   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:59:07,569-Speed 141.93 samples/sec   Loss 1.1525   LearningRate 0.000005   Epoch: 1   Global Step: 45160   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:59:09,839-Speed 141.02 samples/sec   Loss 1.1558   LearningRate 0.000005   Epoch: 1   Global Step: 45170   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:59:12,117-Speed 140.49 samples/sec   Loss 1.1612   LearningRate 0.000005   Epoch: 1   Global Step: 45180   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:59:14,381-Speed 141.40 samples/sec   Loss 1.1520   LearningRate 0.000005   Epoch: 1   Global Step: 45190   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:59:16,658-Speed 140.59 samples/sec   Loss 1.1350   LearningRate 0.000005   Epoch: 1   Global Step: 45200   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:59:18,943-Speed 140.03 samples/sec   Loss 1.1578   LearningRate 0.000005   Epoch: 1   Global Step: 45210   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:59:21,208-Speed 141.38 samples/sec   Loss 1.1488   LearningRate 0.000005   Epoch: 1   Global Step: 45220   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:59:23,503-Speed 139.48 samples/sec   Loss 1.1266   LearningRate 0.000005   Epoch: 1   Global Step: 45230   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:59:25,777-Speed 140.75 samples/sec   Loss 1.1364   LearningRate 0.000005   Epoch: 1   Global Step: 45240   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:59:28,060-Speed 140.21 samples/sec   Loss 1.1427   LearningRate 0.000005   Epoch: 1   Global Step: 45250   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:59:30,323-Speed 141.44 samples/sec   Loss 1.1457   LearningRate 0.000005   Epoch: 1   Global Step: 45260   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:59:32,584-Speed 141.58 samples/sec   Loss 1.1227   LearningRate 0.000005   Epoch: 1   Global Step: 45270   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:59:34,844-Speed 141.64 samples/sec   Loss 1.1392   LearningRate 0.000005   Epoch: 1   Global Step: 45280   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:59:37,125-Speed 140.31 samples/sec   Loss 1.1392   LearningRate 0.000005   Epoch: 1   Global Step: 45290   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:59:39,400-Speed 140.73 samples/sec   Loss 1.1423   LearningRate 0.000005   Epoch: 1   Global Step: 45300   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:59:41,669-Speed 141.07 samples/sec   Loss 1.1428   LearningRate 0.000005   Epoch: 1   Global Step: 45310   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:59:43,946-Speed 140.54 samples/sec   Loss 1.1508   LearningRate 0.000005   Epoch: 1   Global Step: 45320   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:59:46,241-Speed 139.46 samples/sec   Loss 1.1592   LearningRate 0.000005   Epoch: 1   Global Step: 45330   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:59:48,502-Speed 141.62 samples/sec   Loss 1.1476   LearningRate 0.000005   Epoch: 1   Global Step: 45340   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:59:50,771-Speed 141.05 samples/sec   Loss 1.1479   LearningRate 0.000005   Epoch: 1   Global Step: 45350   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:59:53,052-Speed 140.32 samples/sec   Loss 1.1451   LearningRate 0.000005   Epoch: 1   Global Step: 45360   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:59:55,329-Speed 140.61 samples/sec   Loss 1.1414   LearningRate 0.000005   Epoch: 1   Global Step: 45370   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-17 23:59:57,595-Speed 141.22 samples/sec   Loss 1.1314   LearningRate 0.000005   Epoch: 1   Global Step: 45380   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-17 23:59:59,874-Speed 140.47 samples/sec   Loss 1.1276   LearningRate 0.000005   Epoch: 1   Global Step: 45390   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:00:02,151-Speed 140.58 samples/sec   Loss 1.1535   LearningRate 0.000005   Epoch: 1   Global Step: 45400   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:00:04,419-Speed 141.13 samples/sec   Loss 1.1341   LearningRate 0.000005   Epoch: 1   Global Step: 45410   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:00:06,697-Speed 140.51 samples/sec   Loss 1.1682   LearningRate 0.000005   Epoch: 1   Global Step: 45420   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:00:08,982-Speed 140.06 samples/sec   Loss 1.1264   LearningRate 0.000005   Epoch: 1   Global Step: 45430   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:00:11,250-Speed 141.19 samples/sec   Loss 1.1334   LearningRate 0.000005   Epoch: 1   Global Step: 45440   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:00:13,528-Speed 140.48 samples/sec   Loss 1.1436   LearningRate 0.000005   Epoch: 1   Global Step: 45450   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:00:15,790-Speed 141.49 samples/sec   Loss 1.1476   LearningRate 0.000005   Epoch: 1   Global Step: 45460   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:00:18,063-Speed 140.82 samples/sec   Loss 1.1782   LearningRate 0.000005   Epoch: 1   Global Step: 45470   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:00:20,332-Speed 141.08 samples/sec   Loss 1.1400   LearningRate 0.000005   Epoch: 1   Global Step: 45480   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:00:22,602-Speed 141.05 samples/sec   Loss 1.1355   LearningRate 0.000005   Epoch: 1   Global Step: 45490   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:00:24,878-Speed 140.63 samples/sec   Loss 1.1689   LearningRate 0.000005   Epoch: 1   Global Step: 45500   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:00:27,141-Speed 141.43 samples/sec   Loss 1.1244   LearningRate 0.000005   Epoch: 1   Global Step: 45510   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:00:29,407-Speed 141.26 samples/sec   Loss 1.1424   LearningRate 0.000005   Epoch: 1   Global Step: 45520   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:00:31,684-Speed 140.58 samples/sec   Loss 1.1455   LearningRate 0.000005   Epoch: 1   Global Step: 45530   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:00:33,971-Speed 139.96 samples/sec   Loss 1.1607   LearningRate 0.000005   Epoch: 1   Global Step: 45540   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:00:36,284-Speed 138.39 samples/sec   Loss 1.1435   LearningRate 0.000005   Epoch: 1   Global Step: 45550   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:00:38,576-Speed 139.68 samples/sec   Loss 1.1316   LearningRate 0.000005   Epoch: 1   Global Step: 45560   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:00:40,873-Speed 139.35 samples/sec   Loss 1.1463   LearningRate 0.000005   Epoch: 1   Global Step: 45570   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:00:43,155-Speed 140.24 samples/sec   Loss 1.1289   LearningRate 0.000005   Epoch: 1   Global Step: 45580   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:00:45,431-Speed 140.61 samples/sec   Loss 1.1713   LearningRate 0.000005   Epoch: 1   Global Step: 45590   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:00:47,721-Speed 139.78 samples/sec   Loss 1.1218   LearningRate 0.000005   Epoch: 1   Global Step: 45600   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:00:49,982-Speed 141.58 samples/sec   Loss 1.1476   LearningRate 0.000004   Epoch: 1   Global Step: 45610   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:00:52,261-Speed 140.50 samples/sec   Loss 1.1613   LearningRate 0.000004   Epoch: 1   Global Step: 45620   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:00:54,545-Speed 140.14 samples/sec   Loss 1.1505   LearningRate 0.000004   Epoch: 1   Global Step: 45630   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:00:56,818-Speed 140.77 samples/sec   Loss 1.1334   LearningRate 0.000004   Epoch: 1   Global Step: 45640   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:00:59,099-Speed 140.33 samples/sec   Loss 1.1515   LearningRate 0.000004   Epoch: 1   Global Step: 45650   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:01:01,404-Speed 138.91 samples/sec   Loss 1.1274   LearningRate 0.000004   Epoch: 1   Global Step: 45660   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:01:03,724-Speed 137.93 samples/sec   Loss 1.1473   LearningRate 0.000004   Epoch: 1   Global Step: 45670   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:01:06,051-Speed 137.53 samples/sec   Loss 1.1448   LearningRate 0.000004   Epoch: 1   Global Step: 45680   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:01:08,382-Speed 137.37 samples/sec   Loss 1.1595   LearningRate 0.000004   Epoch: 1   Global Step: 45690   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:01:10,696-Speed 138.33 samples/sec   Loss 1.1422   LearningRate 0.000004   Epoch: 1   Global Step: 45700   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:01:13,017-Speed 137.88 samples/sec   Loss 1.1190   LearningRate 0.000004   Epoch: 1   Global Step: 45710   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:01:15,326-Speed 138.67 samples/sec   Loss 1.1457   LearningRate 0.000004   Epoch: 1   Global Step: 45720   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:01:17,649-Speed 137.78 samples/sec   Loss 1.1634   LearningRate 0.000004   Epoch: 1   Global Step: 45730   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:01:19,971-Speed 137.86 samples/sec   Loss 1.1350   LearningRate 0.000004   Epoch: 1   Global Step: 45740   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:01:22,253-Speed 140.26 samples/sec   Loss 1.1231   LearningRate 0.000004   Epoch: 1   Global Step: 45750   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:01:24,522-Speed 141.07 samples/sec   Loss 1.1491   LearningRate 0.000004   Epoch: 1   Global Step: 45760   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:01:26,789-Speed 141.20 samples/sec   Loss 1.1506   LearningRate 0.000004   Epoch: 1   Global Step: 45770   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:01:29,048-Speed 141.66 samples/sec   Loss 1.1787   LearningRate 0.000004   Epoch: 1   Global Step: 45780   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:01:31,319-Speed 140.95 samples/sec   Loss 1.1314   LearningRate 0.000004   Epoch: 1   Global Step: 45790   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:01:33,583-Speed 141.39 samples/sec   Loss 1.1585   LearningRate 0.000004   Epoch: 1   Global Step: 45800   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:01:35,871-Speed 139.92 samples/sec   Loss 1.1260   LearningRate 0.000004   Epoch: 1   Global Step: 45810   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:01:38,153-Speed 140.23 samples/sec   Loss 1.1397   LearningRate 0.000004   Epoch: 1   Global Step: 45820   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:01:40,417-Speed 141.40 samples/sec   Loss 1.1149   LearningRate 0.000004   Epoch: 1   Global Step: 45830   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:01:42,686-Speed 141.10 samples/sec   Loss 1.1241   LearningRate 0.000004   Epoch: 1   Global Step: 45840   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:01:44,965-Speed 140.45 samples/sec   Loss 1.1388   LearningRate 0.000004   Epoch: 1   Global Step: 45850   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:01:47,238-Speed 140.81 samples/sec   Loss 1.1281   LearningRate 0.000004   Epoch: 1   Global Step: 45860   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:01:49,511-Speed 140.84 samples/sec   Loss 1.1619   LearningRate 0.000004   Epoch: 1   Global Step: 45870   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:01:51,773-Speed 141.47 samples/sec   Loss 1.1439   LearningRate 0.000004   Epoch: 1   Global Step: 45880   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:01:54,049-Speed 140.68 samples/sec   Loss 1.1595   LearningRate 0.000004   Epoch: 1   Global Step: 45890   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:01:56,316-Speed 141.22 samples/sec   Loss 1.1324   LearningRate 0.000004   Epoch: 1   Global Step: 45900   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:01:58,590-Speed 140.74 samples/sec   Loss 1.1392   LearningRate 0.000004   Epoch: 1   Global Step: 45910   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:02:00,860-Speed 140.99 samples/sec   Loss 1.1569   LearningRate 0.000004   Epoch: 1   Global Step: 45920   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:02:03,114-Speed 142.04 samples/sec   Loss 1.1264   LearningRate 0.000004   Epoch: 1   Global Step: 45930   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:02:05,381-Speed 141.21 samples/sec   Loss 1.1311   LearningRate 0.000004   Epoch: 1   Global Step: 45940   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:02:07,654-Speed 140.86 samples/sec   Loss 1.1506   LearningRate 0.000004   Epoch: 1   Global Step: 45950   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:02:09,918-Speed 141.35 samples/sec   Loss 1.1440   LearningRate 0.000004   Epoch: 1   Global Step: 45960   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:02:12,192-Speed 140.78 samples/sec   Loss 1.1349   LearningRate 0.000004   Epoch: 1   Global Step: 45970   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:02:14,454-Speed 141.48 samples/sec   Loss 1.1485   LearningRate 0.000004   Epoch: 1   Global Step: 45980   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:02:16,711-Speed 141.85 samples/sec   Loss 1.1434   LearningRate 0.000004   Epoch: 1   Global Step: 45990   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:02:18,744-Val on RAF/AffectNet:
Training: 2023-08-18 00:02:18,853-Test: [0/48]	Time 0.109 (0.109)	Loss 0.5387 (0.5387)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)	Mem 5268MB
Training: 2023-08-18 00:02:19,879-Test: [10/48]	Time 0.102 (0.103)	Loss 0.5020 (0.5114)	Acc@1 93.750 (93.892)	Acc@5 100.000 (99.290)	Mem 5268MB
Training: 2023-08-18 00:02:20,925-Test: [20/48]	Time 0.104 (0.104)	Loss 0.4690 (0.5325)	Acc@1 96.875 (93.378)	Acc@5 98.438 (98.661)	Mem 5268MB
Training: 2023-08-18 00:02:21,996-Test: [30/48]	Time 0.109 (0.105)	Loss 0.6070 (0.5488)	Acc@1 90.625 (92.792)	Acc@5 98.438 (98.387)	Mem 5268MB
Training: 2023-08-18 00:02:23,032-Test: [40/48]	Time 0.104 (0.105)	Loss 0.5942 (0.5543)	Acc@1 90.625 (92.607)	Acc@5 100.000 (98.438)	Mem 5268MB
Training: 2023-08-18 00:02:23,771-[45999]Expression Loss: 0.55616
Training: 2023-08-18 00:02:23,771-[45999]Expression Acc@1: 92.50326
Training: 2023-08-18 00:02:23,771-[45999]Expression Acc@1-Highest: 92.66623
Training: 2023-08-18 00:02:23,771-[45999]Expression Acc@5: 98.40287
Training: 2023-08-18 00:02:23,771-[45999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-18 00:02:23,771-[45999]10 Times Expression Acc@1: 92.41199
Training: 2023-08-18 00:02:23,771-[45999]10 Times Expression Acc@1-Highest: 92.41199
Training: 2023-08-18 00:02:23,998-Speed 43.92 samples/sec   Loss 1.1464   LearningRate 0.000004   Epoch: 1   Global Step: 46000   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:02:26,247-Speed 142.34 samples/sec   Loss 1.1161   LearningRate 0.000004   Epoch: 1   Global Step: 46010   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:02:28,510-Speed 141.43 samples/sec   Loss 1.1634   LearningRate 0.000004   Epoch: 1   Global Step: 46020   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:02:30,785-Speed 140.67 samples/sec   Loss 1.1281   LearningRate 0.000004   Epoch: 1   Global Step: 46030   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:02:33,068-Speed 140.25 samples/sec   Loss 1.1433   LearningRate 0.000004   Epoch: 1   Global Step: 46040   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:02:35,329-Speed 141.58 samples/sec   Loss 1.1253   LearningRate 0.000004   Epoch: 1   Global Step: 46050   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:02:37,605-Speed 140.62 samples/sec   Loss 1.1643   LearningRate 0.000004   Epoch: 1   Global Step: 46060   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:02:39,868-Speed 141.40 samples/sec   Loss 1.1687   LearningRate 0.000004   Epoch: 1   Global Step: 46070   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:02:42,150-Speed 140.28 samples/sec   Loss 1.1752   LearningRate 0.000004   Epoch: 1   Global Step: 46080   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:02:44,414-Speed 141.40 samples/sec   Loss 1.1530   LearningRate 0.000004   Epoch: 1   Global Step: 46090   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:02:46,689-Speed 140.69 samples/sec   Loss 1.1464   LearningRate 0.000004   Epoch: 1   Global Step: 46100   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:02:48,970-Speed 140.35 samples/sec   Loss 1.1477   LearningRate 0.000004   Epoch: 1   Global Step: 46110   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:02:51,247-Speed 140.55 samples/sec   Loss 1.1231   LearningRate 0.000004   Epoch: 1   Global Step: 46120   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:02:53,519-Speed 140.89 samples/sec   Loss 1.1533   LearningRate 0.000004   Epoch: 1   Global Step: 46130   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:02:55,788-Speed 141.11 samples/sec   Loss 1.1400   LearningRate 0.000004   Epoch: 1   Global Step: 46140   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:02:58,060-Speed 140.90 samples/sec   Loss 1.1526   LearningRate 0.000004   Epoch: 1   Global Step: 46150   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:03:00,330-Speed 140.99 samples/sec   Loss 1.1377   LearningRate 0.000004   Epoch: 1   Global Step: 46160   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:03:02,602-Speed 140.87 samples/sec   Loss 1.1500   LearningRate 0.000004   Epoch: 1   Global Step: 46170   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:03:04,884-Speed 140.27 samples/sec   Loss 1.1550   LearningRate 0.000004   Epoch: 1   Global Step: 46180   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:03:07,165-Speed 140.30 samples/sec   Loss 1.1147   LearningRate 0.000004   Epoch: 1   Global Step: 46190   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:03:09,435-Speed 141.05 samples/sec   Loss 1.1537   LearningRate 0.000004   Epoch: 1   Global Step: 46200   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:03:11,731-Speed 139.43 samples/sec   Loss 1.1423   LearningRate 0.000004   Epoch: 1   Global Step: 46210   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:03:13,993-Speed 141.46 samples/sec   Loss 1.1358   LearningRate 0.000004   Epoch: 1   Global Step: 46220   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:03:16,269-Speed 140.62 samples/sec   Loss 1.1573   LearningRate 0.000004   Epoch: 1   Global Step: 46230   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:03:18,554-Speed 140.11 samples/sec   Loss 1.1129   LearningRate 0.000004   Epoch: 1   Global Step: 46240   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:03:20,835-Speed 140.29 samples/sec   Loss 1.1362   LearningRate 0.000004   Epoch: 1   Global Step: 46250   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:03:23,076-Speed 142.84 samples/sec   Loss 1.1500   LearningRate 0.000004   Epoch: 1   Global Step: 46260   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:03:25,333-Speed 141.82 samples/sec   Loss 1.1516   LearningRate 0.000004   Epoch: 1   Global Step: 46270   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:03:27,601-Speed 141.16 samples/sec   Loss 1.1482   LearningRate 0.000004   Epoch: 1   Global Step: 46280   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:03:29,879-Speed 140.49 samples/sec   Loss 1.1435   LearningRate 0.000004   Epoch: 1   Global Step: 46290   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:03:32,133-Speed 142.02 samples/sec   Loss 1.1368   LearningRate 0.000004   Epoch: 1   Global Step: 46300   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:03:34,404-Speed 140.96 samples/sec   Loss 1.1496   LearningRate 0.000004   Epoch: 1   Global Step: 46310   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:03:36,676-Speed 140.89 samples/sec   Loss 1.1496   LearningRate 0.000004   Epoch: 1   Global Step: 46320   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:03:38,957-Speed 140.30 samples/sec   Loss 1.1603   LearningRate 0.000004   Epoch: 1   Global Step: 46330   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:03:41,255-Speed 139.30 samples/sec   Loss 1.1475   LearningRate 0.000004   Epoch: 1   Global Step: 46340   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:03:43,558-Speed 139.01 samples/sec   Loss 1.1266   LearningRate 0.000004   Epoch: 1   Global Step: 46350   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:03:45,857-Speed 139.20 samples/sec   Loss 1.1459   LearningRate 0.000004   Epoch: 1   Global Step: 46360   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:03:48,173-Speed 138.22 samples/sec   Loss 1.1353   LearningRate 0.000004   Epoch: 1   Global Step: 46370   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:03:50,466-Speed 139.60 samples/sec   Loss 1.1665   LearningRate 0.000004   Epoch: 1   Global Step: 46380   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:03:52,791-Speed 137.65 samples/sec   Loss 1.1507   LearningRate 0.000004   Epoch: 1   Global Step: 46390   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:03:55,075-Speed 140.16 samples/sec   Loss 1.1569   LearningRate 0.000004   Epoch: 1   Global Step: 46400   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:03:57,363-Speed 139.90 samples/sec   Loss 1.1492   LearningRate 0.000004   Epoch: 1   Global Step: 46410   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:03:59,657-Speed 139.53 samples/sec   Loss 1.1347   LearningRate 0.000004   Epoch: 1   Global Step: 46420   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:04:01,967-Speed 138.61 samples/sec   Loss 1.1595   LearningRate 0.000004   Epoch: 1   Global Step: 46430   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:04:04,259-Speed 139.63 samples/sec   Loss 1.1212   LearningRate 0.000004   Epoch: 1   Global Step: 46440   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:04:06,551-Speed 139.63 samples/sec   Loss 1.1581   LearningRate 0.000004   Epoch: 1   Global Step: 46450   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:04:08,837-Speed 140.02 samples/sec   Loss 1.1333   LearningRate 0.000004   Epoch: 1   Global Step: 46460   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:04:11,118-Speed 140.34 samples/sec   Loss 1.1317   LearningRate 0.000004   Epoch: 1   Global Step: 46470   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:04:13,409-Speed 139.68 samples/sec   Loss 1.1396   LearningRate 0.000004   Epoch: 1   Global Step: 46480   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:04:15,709-Speed 139.16 samples/sec   Loss 1.1542   LearningRate 0.000004   Epoch: 1   Global Step: 46490   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:04:18,013-Speed 138.96 samples/sec   Loss 1.1068   LearningRate 0.000004   Epoch: 1   Global Step: 46500   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:04:20,316-Speed 138.95 samples/sec   Loss 1.1574   LearningRate 0.000004   Epoch: 1   Global Step: 46510   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:04:22,600-Speed 140.18 samples/sec   Loss 1.1356   LearningRate 0.000004   Epoch: 1   Global Step: 46520   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:04:24,897-Speed 139.31 samples/sec   Loss 1.1289   LearningRate 0.000004   Epoch: 1   Global Step: 46530   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:04:27,187-Speed 139.81 samples/sec   Loss 1.1345   LearningRate 0.000004   Epoch: 1   Global Step: 46540   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:04:29,492-Speed 138.89 samples/sec   Loss 1.1331   LearningRate 0.000004   Epoch: 1   Global Step: 46550   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:04:31,781-Speed 139.79 samples/sec   Loss 1.1516   LearningRate 0.000004   Epoch: 1   Global Step: 46560   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:04:34,048-Speed 141.22 samples/sec   Loss 1.1219   LearningRate 0.000004   Epoch: 1   Global Step: 46570   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:04:36,341-Speed 139.57 samples/sec   Loss 1.1329   LearningRate 0.000004   Epoch: 1   Global Step: 46580   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:04:38,632-Speed 139.76 samples/sec   Loss 1.1239   LearningRate 0.000004   Epoch: 1   Global Step: 46590   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:04:40,926-Speed 139.50 samples/sec   Loss 1.1605   LearningRate 0.000004   Epoch: 1   Global Step: 46600   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:04:43,220-Speed 139.56 samples/sec   Loss 1.1422   LearningRate 0.000004   Epoch: 1   Global Step: 46610   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:04:45,516-Speed 139.37 samples/sec   Loss 1.1348   LearningRate 0.000004   Epoch: 1   Global Step: 46620   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:04:47,816-Speed 139.19 samples/sec   Loss 1.1173   LearningRate 0.000004   Epoch: 1   Global Step: 46630   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:04:50,105-Speed 139.79 samples/sec   Loss 1.1319   LearningRate 0.000004   Epoch: 1   Global Step: 46640   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:04:52,408-Speed 139.06 samples/sec   Loss 1.1457   LearningRate 0.000004   Epoch: 1   Global Step: 46650   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:04:54,695-Speed 139.94 samples/sec   Loss 1.1638   LearningRate 0.000004   Epoch: 1   Global Step: 46660   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:04:56,988-Speed 139.58 samples/sec   Loss 1.1650   LearningRate 0.000004   Epoch: 1   Global Step: 46670   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:04:59,278-Speed 139.77 samples/sec   Loss 1.1381   LearningRate 0.000004   Epoch: 1   Global Step: 46680   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:05:01,566-Speed 139.93 samples/sec   Loss 1.1212   LearningRate 0.000004   Epoch: 1   Global Step: 46690   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:05:03,854-Speed 139.86 samples/sec   Loss 1.1332   LearningRate 0.000004   Epoch: 1   Global Step: 46700   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:05:06,140-Speed 140.07 samples/sec   Loss 1.1352   LearningRate 0.000004   Epoch: 1   Global Step: 46710   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:05:08,431-Speed 139.71 samples/sec   Loss 1.1714   LearningRate 0.000004   Epoch: 1   Global Step: 46720   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:05:10,723-Speed 139.66 samples/sec   Loss 1.1625   LearningRate 0.000004   Epoch: 1   Global Step: 46730   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:05:13,010-Speed 139.93 samples/sec   Loss 1.1310   LearningRate 0.000004   Epoch: 1   Global Step: 46740   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:05:15,311-Speed 139.09 samples/sec   Loss 1.1707   LearningRate 0.000004   Epoch: 1   Global Step: 46750   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:05:17,601-Speed 139.79 samples/sec   Loss 1.1614   LearningRate 0.000004   Epoch: 1   Global Step: 46760   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:05:19,890-Speed 139.83 samples/sec   Loss 1.1560   LearningRate 0.000004   Epoch: 1   Global Step: 46770   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:05:22,201-Speed 138.52 samples/sec   Loss 1.1471   LearningRate 0.000004   Epoch: 1   Global Step: 46780   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:05:24,478-Speed 140.57 samples/sec   Loss 1.1269   LearningRate 0.000004   Epoch: 1   Global Step: 46790   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:05:26,780-Speed 139.03 samples/sec   Loss 1.1331   LearningRate 0.000004   Epoch: 1   Global Step: 46800   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:05:29,070-Speed 139.84 samples/sec   Loss 1.1657   LearningRate 0.000004   Epoch: 1   Global Step: 46810   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:05:31,383-Speed 138.34 samples/sec   Loss 1.1594   LearningRate 0.000004   Epoch: 1   Global Step: 46820   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:05:33,680-Speed 139.38 samples/sec   Loss 1.1499   LearningRate 0.000004   Epoch: 1   Global Step: 46830   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:05:35,974-Speed 139.52 samples/sec   Loss 1.1250   LearningRate 0.000004   Epoch: 1   Global Step: 46840   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:05:38,268-Speed 139.53 samples/sec   Loss 1.1335   LearningRate 0.000004   Epoch: 1   Global Step: 46850   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:05:40,572-Speed 138.93 samples/sec   Loss 1.1302   LearningRate 0.000004   Epoch: 1   Global Step: 46860   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:05:42,889-Speed 138.15 samples/sec   Loss 1.1443   LearningRate 0.000004   Epoch: 1   Global Step: 46870   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:05:45,206-Speed 138.16 samples/sec   Loss 1.1150   LearningRate 0.000004   Epoch: 1   Global Step: 46880   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:05:47,518-Speed 138.43 samples/sec   Loss 1.1606   LearningRate 0.000004   Epoch: 1   Global Step: 46890   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:05:49,817-Speed 139.23 samples/sec   Loss 1.1623   LearningRate 0.000004   Epoch: 1   Global Step: 46900   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:05:52,121-Speed 138.95 samples/sec   Loss 1.1534   LearningRate 0.000004   Epoch: 1   Global Step: 46910   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:05:54,411-Speed 139.75 samples/sec   Loss 1.1425   LearningRate 0.000004   Epoch: 1   Global Step: 46920   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:05:56,709-Speed 139.31 samples/sec   Loss 1.1307   LearningRate 0.000004   Epoch: 1   Global Step: 46930   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:05:58,997-Speed 139.90 samples/sec   Loss 1.1391   LearningRate 0.000004   Epoch: 1   Global Step: 46940   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:06:01,290-Speed 139.59 samples/sec   Loss 1.1638   LearningRate 0.000004   Epoch: 1   Global Step: 46950   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:06:03,569-Speed 140.46 samples/sec   Loss 1.1617   LearningRate 0.000004   Epoch: 1   Global Step: 46960   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:06:05,870-Speed 139.09 samples/sec   Loss 1.1469   LearningRate 0.000004   Epoch: 1   Global Step: 46970   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:06:08,153-Speed 140.22 samples/sec   Loss 1.1384   LearningRate 0.000004   Epoch: 1   Global Step: 46980   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:06:10,468-Speed 138.27 samples/sec   Loss 1.1390   LearningRate 0.000004   Epoch: 1   Global Step: 46990   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:06:12,530-Val on RAF/AffectNet:
Training: 2023-08-18 00:06:12,644-Test: [0/48]	Time 0.113 (0.113)	Loss 0.5447 (0.5447)	Acc@1 93.750 (93.750)	Acc@5 98.438 (98.438)	Mem 5268MB
Training: 2023-08-18 00:06:13,726-Test: [10/48]	Time 0.108 (0.109)	Loss 0.5749 (0.5313)	Acc@1 92.188 (93.608)	Acc@5 98.438 (98.295)	Mem 5268MB
Training: 2023-08-18 00:06:14,796-Test: [20/48]	Time 0.103 (0.108)	Loss 0.6253 (0.5483)	Acc@1 90.625 (92.411)	Acc@5 95.312 (98.363)	Mem 5268MB
Training: 2023-08-18 00:06:15,868-Test: [30/48]	Time 0.113 (0.108)	Loss 0.4862 (0.5461)	Acc@1 93.750 (92.540)	Acc@5 100.000 (98.387)	Mem 5268MB
Training: 2023-08-18 00:06:16,944-Test: [40/48]	Time 0.105 (0.108)	Loss 0.5728 (0.5551)	Acc@1 92.188 (92.416)	Acc@5 98.438 (98.399)	Mem 5268MB
Training: 2023-08-18 00:06:17,679-[46999]Expression Loss: 0.55358
Training: 2023-08-18 00:06:17,679-[46999]Expression Acc@1: 92.43807
Training: 2023-08-18 00:06:17,679-[46999]Expression Acc@1-Highest: 92.66623
Training: 2023-08-18 00:06:17,679-[46999]Expression Acc@5: 98.40287
Training: 2023-08-18 00:06:17,679-[46999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-18 00:06:17,680-[46999]10 Times Expression Acc@1: 92.41199
Training: 2023-08-18 00:06:17,680-[46999]10 Times Expression Acc@1-Highest: 92.41199
Training: 2023-08-18 00:06:17,913-Speed 42.98 samples/sec   Loss 1.1360   LearningRate 0.000004   Epoch: 1   Global Step: 47000   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:06:20,206-Speed 139.58 samples/sec   Loss 1.1414   LearningRate 0.000004   Epoch: 1   Global Step: 47010   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:06:22,490-Speed 140.18 samples/sec   Loss 1.1638   LearningRate 0.000004   Epoch: 1   Global Step: 47020   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:06:24,774-Speed 140.13 samples/sec   Loss 1.1805   LearningRate 0.000004   Epoch: 1   Global Step: 47030   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:06:27,061-Speed 139.94 samples/sec   Loss 1.1256   LearningRate 0.000004   Epoch: 1   Global Step: 47040   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:06:29,351-Speed 139.75 samples/sec   Loss 1.1232   LearningRate 0.000004   Epoch: 1   Global Step: 47050   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:06:31,641-Speed 139.83 samples/sec   Loss 1.1306   LearningRate 0.000004   Epoch: 1   Global Step: 47060   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:06:33,918-Speed 140.55 samples/sec   Loss 1.1600   LearningRate 0.000004   Epoch: 1   Global Step: 47070   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:06:36,212-Speed 139.53 samples/sec   Loss 1.1473   LearningRate 0.000004   Epoch: 1   Global Step: 47080   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:06:38,510-Speed 139.32 samples/sec   Loss 1.1482   LearningRate 0.000004   Epoch: 1   Global Step: 47090   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:06:40,807-Speed 139.33 samples/sec   Loss 1.1160   LearningRate 0.000004   Epoch: 1   Global Step: 47100   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:06:43,090-Speed 140.21 samples/sec   Loss 1.1416   LearningRate 0.000004   Epoch: 1   Global Step: 47110   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:06:45,374-Speed 140.15 samples/sec   Loss 1.1211   LearningRate 0.000004   Epoch: 1   Global Step: 47120   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:06:47,666-Speed 139.62 samples/sec   Loss 1.1376   LearningRate 0.000004   Epoch: 1   Global Step: 47130   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:06:49,967-Speed 139.09 samples/sec   Loss 1.1443   LearningRate 0.000004   Epoch: 1   Global Step: 47140   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:06:52,258-Speed 139.72 samples/sec   Loss 1.1472   LearningRate 0.000004   Epoch: 1   Global Step: 47150   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:06:54,539-Speed 140.31 samples/sec   Loss 1.1428   LearningRate 0.000004   Epoch: 1   Global Step: 47160   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:06:56,842-Speed 138.99 samples/sec   Loss 1.1321   LearningRate 0.000004   Epoch: 1   Global Step: 47170   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:06:59,129-Speed 139.99 samples/sec   Loss 1.1480   LearningRate 0.000004   Epoch: 1   Global Step: 47180   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:07:01,419-Speed 139.79 samples/sec   Loss 1.1520   LearningRate 0.000004   Epoch: 1   Global Step: 47190   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:07:03,731-Speed 138.41 samples/sec   Loss 1.1529   LearningRate 0.000004   Epoch: 1   Global Step: 47200   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:07:06,027-Speed 139.44 samples/sec   Loss 1.1239   LearningRate 0.000004   Epoch: 1   Global Step: 47210   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:07:08,325-Speed 139.29 samples/sec   Loss 1.1563   LearningRate 0.000004   Epoch: 1   Global Step: 47220   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:07:10,617-Speed 139.64 samples/sec   Loss 1.1279   LearningRate 0.000004   Epoch: 1   Global Step: 47230   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:07:12,918-Speed 139.12 samples/sec   Loss 1.1498   LearningRate 0.000004   Epoch: 1   Global Step: 47240   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:07:15,204-Speed 140.03 samples/sec   Loss 1.1403   LearningRate 0.000004   Epoch: 1   Global Step: 47250   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:07:17,500-Speed 139.42 samples/sec   Loss 1.1353   LearningRate 0.000004   Epoch: 1   Global Step: 47260   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:07:19,801-Speed 139.11 samples/sec   Loss 1.1554   LearningRate 0.000004   Epoch: 1   Global Step: 47270   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:07:22,081-Speed 140.41 samples/sec   Loss 1.1737   LearningRate 0.000004   Epoch: 1   Global Step: 47280   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:07:24,371-Speed 139.79 samples/sec   Loss 1.1395   LearningRate 0.000004   Epoch: 1   Global Step: 47290   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:07:26,670-Speed 139.23 samples/sec   Loss 1.1521   LearningRate 0.000004   Epoch: 1   Global Step: 47300   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:07:28,985-Speed 138.25 samples/sec   Loss 1.1444   LearningRate 0.000004   Epoch: 1   Global Step: 47310   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:07:31,300-Speed 138.25 samples/sec   Loss 1.1330   LearningRate 0.000004   Epoch: 1   Global Step: 47320   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:07:33,580-Speed 140.40 samples/sec   Loss 1.1510   LearningRate 0.000004   Epoch: 1   Global Step: 47330   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:07:35,881-Speed 139.13 samples/sec   Loss 1.1623   LearningRate 0.000004   Epoch: 1   Global Step: 47340   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:07:38,190-Speed 138.65 samples/sec   Loss 1.1383   LearningRate 0.000004   Epoch: 1   Global Step: 47350   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:07:40,476-Speed 140.00 samples/sec   Loss 1.1536   LearningRate 0.000004   Epoch: 1   Global Step: 47360   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:07:42,768-Speed 139.68 samples/sec   Loss 1.1465   LearningRate 0.000004   Epoch: 1   Global Step: 47370   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:07:45,064-Speed 139.42 samples/sec   Loss 1.1591   LearningRate 0.000004   Epoch: 1   Global Step: 47380   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:07:47,361-Speed 139.32 samples/sec   Loss 1.1390   LearningRate 0.000004   Epoch: 1   Global Step: 47390   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:07:49,661-Speed 139.16 samples/sec   Loss 1.1570   LearningRate 0.000004   Epoch: 1   Global Step: 47400   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:07:51,962-Speed 139.17 samples/sec   Loss 1.1476   LearningRate 0.000004   Epoch: 1   Global Step: 47410   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:07:54,266-Speed 138.91 samples/sec   Loss 1.1297   LearningRate 0.000004   Epoch: 1   Global Step: 47420   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:07:56,546-Speed 140.38 samples/sec   Loss 1.1407   LearningRate 0.000004   Epoch: 1   Global Step: 47430   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:07:58,808-Speed 141.52 samples/sec   Loss 1.1161   LearningRate 0.000004   Epoch: 1   Global Step: 47440   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:08:01,079-Speed 140.96 samples/sec   Loss 1.1224   LearningRate 0.000004   Epoch: 1   Global Step: 47450   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:08:03,385-Speed 138.77 samples/sec   Loss 1.1237   LearningRate 0.000004   Epoch: 1   Global Step: 47460   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:08:05,692-Speed 138.77 samples/sec   Loss 1.1328   LearningRate 0.000004   Epoch: 1   Global Step: 47470   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:08:07,979-Speed 139.99 samples/sec   Loss 1.1431   LearningRate 0.000004   Epoch: 1   Global Step: 47480   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:08:10,292-Speed 138.39 samples/sec   Loss 1.1497   LearningRate 0.000004   Epoch: 1   Global Step: 47490   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:08:12,600-Speed 138.69 samples/sec   Loss 1.1456   LearningRate 0.000004   Epoch: 1   Global Step: 47500   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:08:14,912-Speed 138.47 samples/sec   Loss 1.1474   LearningRate 0.000004   Epoch: 1   Global Step: 47510   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:08:17,222-Speed 138.57 samples/sec   Loss 1.1505   LearningRate 0.000003   Epoch: 1   Global Step: 47520   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:08:19,543-Speed 137.89 samples/sec   Loss 1.1077   LearningRate 0.000003   Epoch: 1   Global Step: 47530   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:08:21,855-Speed 138.43 samples/sec   Loss 1.1398   LearningRate 0.000003   Epoch: 1   Global Step: 47540   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:08:24,161-Speed 138.81 samples/sec   Loss 1.1467   LearningRate 0.000003   Epoch: 1   Global Step: 47550   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:08:26,471-Speed 138.56 samples/sec   Loss 1.1555   LearningRate 0.000003   Epoch: 1   Global Step: 47560   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:08:28,781-Speed 138.62 samples/sec   Loss 1.1527   LearningRate 0.000003   Epoch: 1   Global Step: 47570   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:08:31,072-Speed 139.72 samples/sec   Loss 1.1723   LearningRate 0.000003   Epoch: 1   Global Step: 47580   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:08:33,376-Speed 138.93 samples/sec   Loss 1.1290   LearningRate 0.000003   Epoch: 1   Global Step: 47590   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:08:35,694-Speed 138.07 samples/sec   Loss 1.1153   LearningRate 0.000003   Epoch: 1   Global Step: 47600   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:08:38,011-Speed 138.13 samples/sec   Loss 1.1313   LearningRate 0.000003   Epoch: 1   Global Step: 47610   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:08:40,325-Speed 138.30 samples/sec   Loss 1.1417   LearningRate 0.000003   Epoch: 1   Global Step: 47620   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:08:42,653-Speed 137.50 samples/sec   Loss 1.1246   LearningRate 0.000003   Epoch: 1   Global Step: 47630   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:08:44,991-Speed 136.92 samples/sec   Loss 1.1592   LearningRate 0.000003   Epoch: 1   Global Step: 47640   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:08:47,328-Speed 136.99 samples/sec   Loss 1.1609   LearningRate 0.000003   Epoch: 1   Global Step: 47650   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:08:49,648-Speed 137.97 samples/sec   Loss 1.1475   LearningRate 0.000003   Epoch: 1   Global Step: 47660   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:08:51,980-Speed 137.22 samples/sec   Loss 1.1444   LearningRate 0.000003   Epoch: 1   Global Step: 47670   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:08:54,285-Speed 138.88 samples/sec   Loss 1.1401   LearningRate 0.000003   Epoch: 1   Global Step: 47680   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:08:56,614-Speed 137.41 samples/sec   Loss 1.1447   LearningRate 0.000003   Epoch: 1   Global Step: 47690   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:08:58,942-Speed 137.51 samples/sec   Loss 1.1377   LearningRate 0.000003   Epoch: 1   Global Step: 47700   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:09:01,271-Speed 137.43 samples/sec   Loss 1.1293   LearningRate 0.000003   Epoch: 1   Global Step: 47710   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:09:03,586-Speed 138.29 samples/sec   Loss 1.1565   LearningRate 0.000003   Epoch: 1   Global Step: 47720   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:09:05,903-Speed 138.16 samples/sec   Loss 1.1304   LearningRate 0.000003   Epoch: 1   Global Step: 47730   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:09:08,227-Speed 137.72 samples/sec   Loss 1.1616   LearningRate 0.000003   Epoch: 1   Global Step: 47740   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:09:10,530-Speed 139.00 samples/sec   Loss 1.1449   LearningRate 0.000003   Epoch: 1   Global Step: 47750   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:09:12,828-Speed 139.31 samples/sec   Loss 1.1509   LearningRate 0.000003   Epoch: 1   Global Step: 47760   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:09:15,121-Speed 139.55 samples/sec   Loss 1.1229   LearningRate 0.000003   Epoch: 1   Global Step: 47770   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:09:17,422-Speed 139.13 samples/sec   Loss 1.1351   LearningRate 0.000003   Epoch: 1   Global Step: 47780   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:09:19,717-Speed 139.45 samples/sec   Loss 1.1223   LearningRate 0.000003   Epoch: 1   Global Step: 47790   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:09:21,986-Speed 141.07 samples/sec   Loss 1.1545   LearningRate 0.000003   Epoch: 1   Global Step: 47800   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:09:24,288-Speed 139.08 samples/sec   Loss 1.1303   LearningRate 0.000003   Epoch: 1   Global Step: 47810   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:09:26,589-Speed 139.08 samples/sec   Loss 1.1251   LearningRate 0.000003   Epoch: 1   Global Step: 47820   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:09:28,893-Speed 138.94 samples/sec   Loss 1.1347   LearningRate 0.000003   Epoch: 1   Global Step: 47830   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:09:31,194-Speed 139.09 samples/sec   Loss 1.1522   LearningRate 0.000003   Epoch: 1   Global Step: 47840   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:09:33,502-Speed 138.68 samples/sec   Loss 1.1316   LearningRate 0.000003   Epoch: 1   Global Step: 47850   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:09:35,810-Speed 138.69 samples/sec   Loss 1.1529   LearningRate 0.000003   Epoch: 1   Global Step: 47860   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:09:38,092-Speed 140.27 samples/sec   Loss 1.1619   LearningRate 0.000003   Epoch: 1   Global Step: 47870   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:09:40,398-Speed 138.82 samples/sec   Loss 1.1378   LearningRate 0.000003   Epoch: 1   Global Step: 47880   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:09:42,677-Speed 140.47 samples/sec   Loss 1.1397   LearningRate 0.000003   Epoch: 1   Global Step: 47890   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:09:44,992-Speed 138.27 samples/sec   Loss 1.1414   LearningRate 0.000003   Epoch: 1   Global Step: 47900   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:09:47,297-Speed 138.86 samples/sec   Loss 1.1688   LearningRate 0.000003   Epoch: 1   Global Step: 47910   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:09:49,606-Speed 138.65 samples/sec   Loss 1.1499   LearningRate 0.000003   Epoch: 1   Global Step: 47920   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:09:51,915-Speed 138.61 samples/sec   Loss 1.1623   LearningRate 0.000003   Epoch: 1   Global Step: 47930   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:09:54,216-Speed 139.11 samples/sec   Loss 1.1445   LearningRate 0.000003   Epoch: 1   Global Step: 47940   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:09:56,533-Speed 138.12 samples/sec   Loss 1.1344   LearningRate 0.000003   Epoch: 1   Global Step: 47950   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:09:58,824-Speed 139.74 samples/sec   Loss 1.1224   LearningRate 0.000003   Epoch: 1   Global Step: 47960   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:10:01,122-Speed 139.27 samples/sec   Loss 1.1438   LearningRate 0.000003   Epoch: 1   Global Step: 47970   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:10:03,409-Speed 139.96 samples/sec   Loss 1.1470   LearningRate 0.000003   Epoch: 1   Global Step: 47980   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:10:05,719-Speed 138.57 samples/sec   Loss 1.1444   LearningRate 0.000003   Epoch: 1   Global Step: 47990   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:10:07,771-Val on RAF/AffectNet:
Training: 2023-08-18 00:10:07,882-Test: [0/48]	Time 0.110 (0.110)	Loss 0.5704 (0.5704)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)	Mem 5268MB
Training: 2023-08-18 00:10:08,969-Test: [10/48]	Time 0.105 (0.109)	Loss 0.5160 (0.5343)	Acc@1 95.312 (93.466)	Acc@5 98.438 (98.864)	Mem 5268MB
Training: 2023-08-18 00:10:10,034-Test: [20/48]	Time 0.105 (0.108)	Loss 0.7070 (0.5501)	Acc@1 85.938 (92.485)	Acc@5 96.875 (98.661)	Mem 5268MB
Training: 2023-08-18 00:10:11,130-Test: [30/48]	Time 0.107 (0.108)	Loss 0.5369 (0.5510)	Acc@1 92.188 (92.440)	Acc@5 100.000 (98.589)	Mem 5268MB
Training: 2023-08-18 00:10:12,197-Test: [40/48]	Time 0.108 (0.108)	Loss 0.5373 (0.5500)	Acc@1 92.188 (92.645)	Acc@5 100.000 (98.514)	Mem 5268MB
Training: 2023-08-18 00:10:12,939-[47999]Expression Loss: 0.54878
Training: 2023-08-18 00:10:12,940-[47999]Expression Acc@1: 92.73142
Training: 2023-08-18 00:10:12,940-[47999]Expression Acc@1-Highest: 92.73142
Training: 2023-08-18 00:10:12,940-[47999]Expression Acc@5: 98.43546
Training: 2023-08-18 00:10:12,940-[47999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-18 00:10:12,940-[47999]10 Times Expression Acc@1: 92.45437
Training: 2023-08-18 00:10:12,940-[47999]10 Times Expression Acc@1-Highest: 92.45437
Training: 2023-08-18 00:10:13,539-Speed 40.93 samples/sec   Loss 1.1449   LearningRate 0.000003   Epoch: 1   Global Step: 48000   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:10:15,817-Speed 140.48 samples/sec   Loss 1.1150   LearningRate 0.000003   Epoch: 1   Global Step: 48010   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:10:18,095-Speed 140.53 samples/sec   Loss 1.1321   LearningRate 0.000003   Epoch: 1   Global Step: 48020   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:10:20,379-Speed 140.13 samples/sec   Loss 1.1274   LearningRate 0.000003   Epoch: 1   Global Step: 48030   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:10:22,658-Speed 140.48 samples/sec   Loss 1.1751   LearningRate 0.000003   Epoch: 1   Global Step: 48040   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:10:24,931-Speed 140.82 samples/sec   Loss 1.1238   LearningRate 0.000003   Epoch: 1   Global Step: 48050   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:10:27,207-Speed 140.59 samples/sec   Loss 1.1337   LearningRate 0.000003   Epoch: 1   Global Step: 48060   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:10:29,482-Speed 140.73 samples/sec   Loss 1.1595   LearningRate 0.000003   Epoch: 1   Global Step: 48070   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:10:31,756-Speed 140.75 samples/sec   Loss 1.1244   LearningRate 0.000003   Epoch: 1   Global Step: 48080   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:10:34,040-Speed 140.19 samples/sec   Loss 1.1392   LearningRate 0.000003   Epoch: 1   Global Step: 48090   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:10:36,310-Speed 140.97 samples/sec   Loss 1.1420   LearningRate 0.000003   Epoch: 1   Global Step: 48100   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:10:38,572-Speed 141.55 samples/sec   Loss 1.1621   LearningRate 0.000003   Epoch: 1   Global Step: 48110   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:10:40,859-Speed 139.94 samples/sec   Loss 1.1277   LearningRate 0.000003   Epoch: 1   Global Step: 48120   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:10:43,138-Speed 140.46 samples/sec   Loss 1.1383   LearningRate 0.000003   Epoch: 1   Global Step: 48130   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:10:45,430-Speed 139.64 samples/sec   Loss 1.1559   LearningRate 0.000003   Epoch: 1   Global Step: 48140   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:10:47,721-Speed 139.74 samples/sec   Loss 1.1486   LearningRate 0.000003   Epoch: 1   Global Step: 48150   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:10:49,999-Speed 140.49 samples/sec   Loss 1.1394   LearningRate 0.000003   Epoch: 1   Global Step: 48160   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:10:52,318-Speed 138.02 samples/sec   Loss 1.1574   LearningRate 0.000003   Epoch: 1   Global Step: 48170   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:10:54,635-Speed 138.13 samples/sec   Loss 1.1405   LearningRate 0.000003   Epoch: 1   Global Step: 48180   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:10:56,963-Speed 137.51 samples/sec   Loss 1.1155   LearningRate 0.000003   Epoch: 1   Global Step: 48190   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:10:59,258-Speed 139.46 samples/sec   Loss 1.1326   LearningRate 0.000003   Epoch: 1   Global Step: 48200   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:11:01,542-Speed 140.15 samples/sec   Loss 1.1427   LearningRate 0.000003   Epoch: 1   Global Step: 48210   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:11:03,825-Speed 140.25 samples/sec   Loss 1.1451   LearningRate 0.000003   Epoch: 1   Global Step: 48220   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:11:06,109-Speed 140.13 samples/sec   Loss 1.1430   LearningRate 0.000003   Epoch: 1   Global Step: 48230   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:11:08,395-Speed 139.99 samples/sec   Loss 1.1330   LearningRate 0.000003   Epoch: 1   Global Step: 48240   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:11:10,688-Speed 139.63 samples/sec   Loss 1.1230   LearningRate 0.000003   Epoch: 1   Global Step: 48250   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:11:12,963-Speed 140.70 samples/sec   Loss 1.1424   LearningRate 0.000003   Epoch: 1   Global Step: 48260   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:11:15,237-Speed 140.76 samples/sec   Loss 1.1194   LearningRate 0.000003   Epoch: 1   Global Step: 48270   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:11:17,521-Speed 140.14 samples/sec   Loss 1.1467   LearningRate 0.000003   Epoch: 1   Global Step: 48280   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:11:19,802-Speed 140.34 samples/sec   Loss 1.1360   LearningRate 0.000003   Epoch: 1   Global Step: 48290   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:11:22,084-Speed 140.28 samples/sec   Loss 1.1398   LearningRate 0.000003   Epoch: 1   Global Step: 48300   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:11:24,366-Speed 140.26 samples/sec   Loss 1.1427   LearningRate 0.000003   Epoch: 1   Global Step: 48310   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:11:26,646-Speed 140.37 samples/sec   Loss 1.1236   LearningRate 0.000003   Epoch: 1   Global Step: 48320   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:11:28,921-Speed 140.72 samples/sec   Loss 1.1191   LearningRate 0.000003   Epoch: 1   Global Step: 48330   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:11:31,195-Speed 140.73 samples/sec   Loss 1.1306   LearningRate 0.000003   Epoch: 1   Global Step: 48340   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:11:33,465-Speed 141.04 samples/sec   Loss 1.1387   LearningRate 0.000003   Epoch: 1   Global Step: 48350   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:11:35,736-Speed 140.91 samples/sec   Loss 1.1360   LearningRate 0.000003   Epoch: 1   Global Step: 48360   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:11:38,017-Speed 140.37 samples/sec   Loss 1.1241   LearningRate 0.000003   Epoch: 1   Global Step: 48370   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:11:40,304-Speed 139.93 samples/sec   Loss 1.1239   LearningRate 0.000003   Epoch: 1   Global Step: 48380   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:11:42,577-Speed 140.84 samples/sec   Loss 1.1433   LearningRate 0.000003   Epoch: 1   Global Step: 48390   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:11:44,842-Speed 141.32 samples/sec   Loss 1.1366   LearningRate 0.000003   Epoch: 1   Global Step: 48400   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:11:47,098-Speed 141.87 samples/sec   Loss 1.1163   LearningRate 0.000003   Epoch: 1   Global Step: 48410   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:11:49,350-Speed 142.15 samples/sec   Loss 1.1329   LearningRate 0.000003   Epoch: 1   Global Step: 48420   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:11:51,619-Speed 141.08 samples/sec   Loss 1.1527   LearningRate 0.000003   Epoch: 1   Global Step: 48430   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:11:53,878-Speed 141.69 samples/sec   Loss 1.1297   LearningRate 0.000003   Epoch: 1   Global Step: 48440   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:11:56,135-Speed 141.86 samples/sec   Loss 1.1356   LearningRate 0.000003   Epoch: 1   Global Step: 48450   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:11:58,401-Speed 141.20 samples/sec   Loss 1.1218   LearningRate 0.000003   Epoch: 1   Global Step: 48460   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:12:00,658-Speed 141.88 samples/sec   Loss 1.1558   LearningRate 0.000003   Epoch: 1   Global Step: 48470   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:12:02,914-Speed 141.86 samples/sec   Loss 1.1456   LearningRate 0.000003   Epoch: 1   Global Step: 48480   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:12:05,172-Speed 141.74 samples/sec   Loss 1.1192   LearningRate 0.000003   Epoch: 1   Global Step: 48490   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:12:07,434-Speed 141.50 samples/sec   Loss 1.1375   LearningRate 0.000003   Epoch: 1   Global Step: 48500   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:12:09,693-Speed 141.71 samples/sec   Loss 1.1568   LearningRate 0.000003   Epoch: 1   Global Step: 48510   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:12:11,953-Speed 141.65 samples/sec   Loss 1.1538   LearningRate 0.000003   Epoch: 1   Global Step: 48520   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:12:14,213-Speed 141.61 samples/sec   Loss 1.1325   LearningRate 0.000003   Epoch: 1   Global Step: 48530   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:12:16,472-Speed 141.67 samples/sec   Loss 1.1496   LearningRate 0.000003   Epoch: 1   Global Step: 48540   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:12:18,734-Speed 141.54 samples/sec   Loss 1.1260   LearningRate 0.000003   Epoch: 1   Global Step: 48550   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:12:20,993-Speed 141.66 samples/sec   Loss 1.1285   LearningRate 0.000003   Epoch: 1   Global Step: 48560   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:12:23,261-Speed 141.13 samples/sec   Loss 1.1550   LearningRate 0.000003   Epoch: 1   Global Step: 48570   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:12:25,548-Speed 140.02 samples/sec   Loss 1.1851   LearningRate 0.000003   Epoch: 1   Global Step: 48580   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:12:27,840-Speed 139.62 samples/sec   Loss 1.1196   LearningRate 0.000003   Epoch: 1   Global Step: 48590   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:12:30,116-Speed 140.61 samples/sec   Loss 1.1439   LearningRate 0.000003   Epoch: 1   Global Step: 48600   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:12:32,406-Speed 139.81 samples/sec   Loss 1.1347   LearningRate 0.000003   Epoch: 1   Global Step: 48610   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:12:34,691-Speed 140.06 samples/sec   Loss 1.1227   LearningRate 0.000003   Epoch: 1   Global Step: 48620   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:12:36,984-Speed 139.59 samples/sec   Loss 1.1210   LearningRate 0.000003   Epoch: 1   Global Step: 48630   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:12:39,273-Speed 139.83 samples/sec   Loss 1.1414   LearningRate 0.000003   Epoch: 1   Global Step: 48640   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:12:41,557-Speed 140.16 samples/sec   Loss 1.1573   LearningRate 0.000003   Epoch: 1   Global Step: 48650   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:12:43,842-Speed 140.09 samples/sec   Loss 1.1413   LearningRate 0.000003   Epoch: 1   Global Step: 48660   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:12:46,130-Speed 139.88 samples/sec   Loss 1.1485   LearningRate 0.000003   Epoch: 1   Global Step: 48670   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:12:48,426-Speed 139.43 samples/sec   Loss 1.1389   LearningRate 0.000003   Epoch: 1   Global Step: 48680   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:12:50,721-Speed 139.47 samples/sec   Loss 1.1313   LearningRate 0.000003   Epoch: 1   Global Step: 48690   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:12:52,990-Speed 141.03 samples/sec   Loss 1.1697   LearningRate 0.000003   Epoch: 1   Global Step: 48700   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:12:55,278-Speed 139.90 samples/sec   Loss 1.1434   LearningRate 0.000003   Epoch: 1   Global Step: 48710   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:12:57,568-Speed 139.79 samples/sec   Loss 1.1298   LearningRate 0.000003   Epoch: 1   Global Step: 48720   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:12:59,874-Speed 138.81 samples/sec   Loss 1.1471   LearningRate 0.000003   Epoch: 1   Global Step: 48730   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:13:02,167-Speed 139.59 samples/sec   Loss 1.1226   LearningRate 0.000003   Epoch: 1   Global Step: 48740   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:13:04,452-Speed 140.08 samples/sec   Loss 1.1858   LearningRate 0.000003   Epoch: 1   Global Step: 48750   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:13:06,734-Speed 140.24 samples/sec   Loss 1.1325   LearningRate 0.000003   Epoch: 1   Global Step: 48760   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:13:09,031-Speed 139.37 samples/sec   Loss 1.1394   LearningRate 0.000003   Epoch: 1   Global Step: 48770   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:13:11,328-Speed 139.36 samples/sec   Loss 1.1068   LearningRate 0.000003   Epoch: 1   Global Step: 48780   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:13:13,614-Speed 140.03 samples/sec   Loss 1.1433   LearningRate 0.000003   Epoch: 1   Global Step: 48790   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:13:15,905-Speed 139.67 samples/sec   Loss 1.1501   LearningRate 0.000003   Epoch: 1   Global Step: 48800   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:13:18,203-Speed 139.29 samples/sec   Loss 1.1777   LearningRate 0.000003   Epoch: 1   Global Step: 48810   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:13:20,505-Speed 139.08 samples/sec   Loss 1.1369   LearningRate 0.000003   Epoch: 1   Global Step: 48820   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:13:22,796-Speed 139.69 samples/sec   Loss 1.1387   LearningRate 0.000003   Epoch: 1   Global Step: 48830   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:13:25,091-Speed 139.45 samples/sec   Loss 1.1389   LearningRate 0.000003   Epoch: 1   Global Step: 48840   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:13:27,376-Speed 140.10 samples/sec   Loss 1.1544   LearningRate 0.000003   Epoch: 1   Global Step: 48850   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:13:29,670-Speed 139.57 samples/sec   Loss 1.1556   LearningRate 0.000003   Epoch: 1   Global Step: 48860   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:13:31,952-Speed 140.25 samples/sec   Loss 1.1337   LearningRate 0.000003   Epoch: 1   Global Step: 48870   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:13:34,243-Speed 139.71 samples/sec   Loss 1.1620   LearningRate 0.000003   Epoch: 1   Global Step: 48880   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:13:36,533-Speed 139.78 samples/sec   Loss 1.1848   LearningRate 0.000003   Epoch: 1   Global Step: 48890   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:13:38,818-Speed 140.06 samples/sec   Loss 1.1673   LearningRate 0.000003   Epoch: 1   Global Step: 48900   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:13:41,121-Speed 138.98 samples/sec   Loss 1.1496   LearningRate 0.000003   Epoch: 1   Global Step: 48910   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:13:43,421-Speed 139.17 samples/sec   Loss 1.1868   LearningRate 0.000003   Epoch: 1   Global Step: 48920   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:13:45,713-Speed 139.65 samples/sec   Loss 1.1210   LearningRate 0.000003   Epoch: 1   Global Step: 48930   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:13:47,998-Speed 140.06 samples/sec   Loss 1.1575   LearningRate 0.000003   Epoch: 1   Global Step: 48940   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:13:50,290-Speed 139.68 samples/sec   Loss 1.1359   LearningRate 0.000003   Epoch: 1   Global Step: 48950   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:13:52,564-Speed 140.73 samples/sec   Loss 1.1430   LearningRate 0.000003   Epoch: 1   Global Step: 48960   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:13:54,860-Speed 139.42 samples/sec   Loss 1.1360   LearningRate 0.000003   Epoch: 1   Global Step: 48970   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:13:57,156-Speed 139.42 samples/sec   Loss 1.1481   LearningRate 0.000003   Epoch: 1   Global Step: 48980   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:13:59,438-Speed 140.24 samples/sec   Loss 1.1419   LearningRate 0.000003   Epoch: 1   Global Step: 48990   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:14:01,513-Val on RAF/AffectNet:
Training: 2023-08-18 00:14:01,628-Test: [0/48]	Time 0.115 (0.115)	Loss 0.6290 (0.6290)	Acc@1 89.062 (89.062)	Acc@5 95.312 (95.312)	Mem 5268MB
Training: 2023-08-18 00:14:02,713-Test: [10/48]	Time 0.105 (0.109)	Loss 0.6010 (0.5715)	Acc@1 92.188 (91.477)	Acc@5 96.875 (98.295)	Mem 5268MB
Training: 2023-08-18 00:14:03,777-Test: [20/48]	Time 0.107 (0.108)	Loss 0.5398 (0.5481)	Acc@1 93.750 (92.783)	Acc@5 98.438 (98.363)	Mem 5268MB
Training: 2023-08-18 00:14:04,837-Test: [30/48]	Time 0.105 (0.107)	Loss 0.4587 (0.5547)	Acc@1 95.312 (92.540)	Acc@5 100.000 (98.438)	Mem 5268MB
Training: 2023-08-18 00:14:05,899-Test: [40/48]	Time 0.105 (0.107)	Loss 0.4276 (0.5524)	Acc@1 96.875 (92.530)	Acc@5 100.000 (98.438)	Mem 5268MB
Training: 2023-08-18 00:14:06,632-[48999]Expression Loss: 0.55132
Training: 2023-08-18 00:14:06,632-[48999]Expression Acc@1: 92.56845
Training: 2023-08-18 00:14:06,632-[48999]Expression Acc@1-Highest: 92.73142
Training: 2023-08-18 00:14:06,632-[48999]Expression Acc@5: 98.50065
Training: 2023-08-18 00:14:06,632-[48999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-18 00:14:06,632-[48999]10 Times Expression Acc@1: 92.48044
Training: 2023-08-18 00:14:06,632-[48999]10 Times Expression Acc@1-Highest: 92.48044
Training: 2023-08-18 00:14:06,864-Speed 43.10 samples/sec   Loss 1.1378   LearningRate 0.000003   Epoch: 1   Global Step: 49000   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:14:09,159-Speed 139.48 samples/sec   Loss 1.1301   LearningRate 0.000003   Epoch: 1   Global Step: 49010   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:14:11,447-Speed 139.90 samples/sec   Loss 1.1296   LearningRate 0.000003   Epoch: 1   Global Step: 49020   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:14:13,741-Speed 139.52 samples/sec   Loss 1.1430   LearningRate 0.000003   Epoch: 1   Global Step: 49030   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:14:16,012-Speed 140.97 samples/sec   Loss 1.1432   LearningRate 0.000003   Epoch: 1   Global Step: 49040   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:14:18,308-Speed 139.44 samples/sec   Loss 1.1321   LearningRate 0.000003   Epoch: 1   Global Step: 49050   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:14:20,593-Speed 140.06 samples/sec   Loss 1.1350   LearningRate 0.000003   Epoch: 1   Global Step: 49060   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:14:22,878-Speed 140.10 samples/sec   Loss 1.1692   LearningRate 0.000003   Epoch: 1   Global Step: 49070   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:14:25,169-Speed 139.68 samples/sec   Loss 1.1404   LearningRate 0.000003   Epoch: 1   Global Step: 49080   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:14:27,459-Speed 139.78 samples/sec   Loss 1.1270   LearningRate 0.000003   Epoch: 1   Global Step: 49090   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:14:29,734-Speed 140.71 samples/sec   Loss 1.1458   LearningRate 0.000003   Epoch: 1   Global Step: 49100   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:14:32,045-Speed 138.49 samples/sec   Loss 1.1420   LearningRate 0.000003   Epoch: 1   Global Step: 49110   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:14:34,335-Speed 139.82 samples/sec   Loss 1.1402   LearningRate 0.000003   Epoch: 1   Global Step: 49120   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:14:36,614-Speed 140.43 samples/sec   Loss 1.1425   LearningRate 0.000003   Epoch: 1   Global Step: 49130   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:14:38,909-Speed 139.46 samples/sec   Loss 1.1217   LearningRate 0.000003   Epoch: 1   Global Step: 49140   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:14:41,194-Speed 140.10 samples/sec   Loss 1.1320   LearningRate 0.000003   Epoch: 1   Global Step: 49150   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:14:43,483-Speed 139.82 samples/sec   Loss 1.1490   LearningRate 0.000003   Epoch: 1   Global Step: 49160   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:14:45,757-Speed 140.77 samples/sec   Loss 1.1227   LearningRate 0.000003   Epoch: 1   Global Step: 49170   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:14:48,049-Speed 139.68 samples/sec   Loss 1.1546   LearningRate 0.000003   Epoch: 1   Global Step: 49180   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:14:50,333-Speed 140.16 samples/sec   Loss 1.1280   LearningRate 0.000003   Epoch: 1   Global Step: 49190   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:14:52,607-Speed 140.73 samples/sec   Loss 1.1399   LearningRate 0.000003   Epoch: 1   Global Step: 49200   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:14:54,880-Speed 140.84 samples/sec   Loss 1.1242   LearningRate 0.000003   Epoch: 1   Global Step: 49210   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:14:57,166-Speed 139.99 samples/sec   Loss 1.1359   LearningRate 0.000003   Epoch: 1   Global Step: 49220   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:14:59,445-Speed 140.46 samples/sec   Loss 1.1156   LearningRate 0.000003   Epoch: 1   Global Step: 49230   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:15:01,733-Speed 139.94 samples/sec   Loss 1.1632   LearningRate 0.000003   Epoch: 1   Global Step: 49240   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:15:04,024-Speed 139.69 samples/sec   Loss 1.1502   LearningRate 0.000003   Epoch: 1   Global Step: 49250   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:15:06,281-Speed 141.83 samples/sec   Loss 1.1401   LearningRate 0.000003   Epoch: 1   Global Step: 49260   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:15:08,586-Speed 138.85 samples/sec   Loss 1.1173   LearningRate 0.000003   Epoch: 1   Global Step: 49270   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:15:10,861-Speed 140.74 samples/sec   Loss 1.1447   LearningRate 0.000003   Epoch: 1   Global Step: 49280   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:15:13,153-Speed 139.63 samples/sec   Loss 1.1450   LearningRate 0.000003   Epoch: 1   Global Step: 49290   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:15:15,450-Speed 139.32 samples/sec   Loss 1.1393   LearningRate 0.000003   Epoch: 1   Global Step: 49300   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:15:17,738-Speed 139.95 samples/sec   Loss 1.1425   LearningRate 0.000003   Epoch: 1   Global Step: 49310   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:15:20,030-Speed 139.61 samples/sec   Loss 1.1273   LearningRate 0.000003   Epoch: 1   Global Step: 49320   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:15:22,309-Speed 140.46 samples/sec   Loss 1.1618   LearningRate 0.000003   Epoch: 1   Global Step: 49330   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-18 00:15:24,606-Speed 139.34 samples/sec   Loss 1.0957   LearningRate 0.000003   Epoch: 1   Global Step: 49340   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-18 00:15:26,907-Speed 139.10 samples/sec   Loss 1.1449   LearningRate 0.000003   Epoch: 1   Global Step: 49350   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-18 00:15:29,198-Speed 139.74 samples/sec   Loss 1.1167   LearningRate 0.000003   Epoch: 1   Global Step: 49360   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-18 00:15:31,504-Speed 138.80 samples/sec   Loss 1.1572   LearningRate 0.000003   Epoch: 1   Global Step: 49370   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-18 00:15:33,797-Speed 139.63 samples/sec   Loss 1.1296   LearningRate 0.000003   Epoch: 1   Global Step: 49380   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-18 00:15:36,090-Speed 139.58 samples/sec   Loss 1.1328   LearningRate 0.000003   Epoch: 1   Global Step: 49390   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-18 00:15:38,369-Speed 140.44 samples/sec   Loss 1.1295   LearningRate 0.000003   Epoch: 1   Global Step: 49400   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-18 00:15:40,662-Speed 139.58 samples/sec   Loss 1.1509   LearningRate 0.000003   Epoch: 1   Global Step: 49410   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-18 00:15:42,957-Speed 139.47 samples/sec   Loss 1.1613   LearningRate 0.000003   Epoch: 1   Global Step: 49420   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-18 00:15:45,254-Speed 139.36 samples/sec   Loss 1.1470   LearningRate 0.000003   Epoch: 1   Global Step: 49430   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:15:47,566-Speed 138.50 samples/sec   Loss 1.1388   LearningRate 0.000003   Epoch: 1   Global Step: 49440   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:15:49,853-Speed 139.94 samples/sec   Loss 1.1270   LearningRate 0.000003   Epoch: 1   Global Step: 49450   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:15:52,135-Speed 140.25 samples/sec   Loss 1.1483   LearningRate 0.000003   Epoch: 1   Global Step: 49460   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:15:54,406-Speed 140.95 samples/sec   Loss 1.1314   LearningRate 0.000003   Epoch: 1   Global Step: 49470   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:15:56,658-Speed 142.12 samples/sec   Loss 1.1413   LearningRate 0.000003   Epoch: 1   Global Step: 49480   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-18 00:15:58,941-Speed 140.24 samples/sec   Loss 1.1776   LearningRate 0.000003   Epoch: 1   Global Step: 49490   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-18 00:16:01,221-Speed 140.39 samples/sec   Loss 1.1335   LearningRate 0.000003   Epoch: 1   Global Step: 49500   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-18 00:16:03,522-Speed 139.08 samples/sec   Loss 1.1279   LearningRate 0.000003   Epoch: 1   Global Step: 49510   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-18 00:16:05,824-Speed 139.07 samples/sec   Loss 1.1277   LearningRate 0.000003   Epoch: 1   Global Step: 49520   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-18 00:16:08,113-Speed 139.82 samples/sec   Loss 1.1275   LearningRate 0.000003   Epoch: 1   Global Step: 49530   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-18 00:16:10,391-Speed 140.52 samples/sec   Loss 1.1526   LearningRate 0.000003   Epoch: 1   Global Step: 49540   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-18 00:16:12,670-Speed 140.47 samples/sec   Loss 1.1241   LearningRate 0.000003   Epoch: 1   Global Step: 49550   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-18 00:16:14,962-Speed 139.63 samples/sec   Loss 1.1409   LearningRate 0.000003   Epoch: 1   Global Step: 49560   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-18 00:16:17,236-Speed 140.74 samples/sec   Loss 1.1704   LearningRate 0.000003   Epoch: 1   Global Step: 49570   Fp16 Grad Scale: 8192   Required: 1 hours
Training: 2023-08-18 00:16:19,511-Speed 140.72 samples/sec   Loss 1.1314   LearningRate 0.000003   Epoch: 1   Global Step: 49580   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:16:21,783-Speed 140.89 samples/sec   Loss 1.1260   LearningRate 0.000003   Epoch: 1   Global Step: 49590   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:16:24,050-Speed 141.20 samples/sec   Loss 1.1353   LearningRate 0.000003   Epoch: 1   Global Step: 49600   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:16:26,322-Speed 140.90 samples/sec   Loss 1.1638   LearningRate 0.000003   Epoch: 1   Global Step: 49610   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:16:28,617-Speed 139.49 samples/sec   Loss 1.1472   LearningRate 0.000003   Epoch: 1   Global Step: 49620   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:16:30,893-Speed 140.63 samples/sec   Loss 1.1480   LearningRate 0.000003   Epoch: 1   Global Step: 49630   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:16:33,171-Speed 140.48 samples/sec   Loss 1.1342   LearningRate 0.000003   Epoch: 1   Global Step: 49640   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:16:35,445-Speed 140.77 samples/sec   Loss 1.1302   LearningRate 0.000003   Epoch: 1   Global Step: 49650   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:16:37,730-Speed 140.11 samples/sec   Loss 1.1354   LearningRate 0.000003   Epoch: 1   Global Step: 49660   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:16:40,026-Speed 139.38 samples/sec   Loss 1.1643   LearningRate 0.000003   Epoch: 1   Global Step: 49670   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:16:42,307-Speed 140.31 samples/sec   Loss 1.1517   LearningRate 0.000003   Epoch: 1   Global Step: 49680   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:16:44,602-Speed 139.51 samples/sec   Loss 1.1510   LearningRate 0.000003   Epoch: 1   Global Step: 49690   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:16:46,896-Speed 139.52 samples/sec   Loss 1.1365   LearningRate 0.000003   Epoch: 1   Global Step: 49700   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:16:49,163-Speed 141.22 samples/sec   Loss 1.1163   LearningRate 0.000003   Epoch: 1   Global Step: 49710   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:16:51,454-Speed 139.71 samples/sec   Loss 1.1506   LearningRate 0.000002   Epoch: 1   Global Step: 49720   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:16:53,751-Speed 139.37 samples/sec   Loss 1.1426   LearningRate 0.000002   Epoch: 1   Global Step: 49730   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:16:56,039-Speed 139.87 samples/sec   Loss 1.1347   LearningRate 0.000002   Epoch: 1   Global Step: 49740   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:16:58,328-Speed 139.84 samples/sec   Loss 1.1365   LearningRate 0.000002   Epoch: 1   Global Step: 49750   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:17:00,617-Speed 139.90 samples/sec   Loss 1.1575   LearningRate 0.000002   Epoch: 1   Global Step: 49760   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:17:02,896-Speed 140.42 samples/sec   Loss 1.1495   LearningRate 0.000002   Epoch: 1   Global Step: 49770   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:17:05,170-Speed 140.77 samples/sec   Loss 1.1209   LearningRate 0.000002   Epoch: 1   Global Step: 49780   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:17:07,446-Speed 140.64 samples/sec   Loss 1.1337   LearningRate 0.000002   Epoch: 1   Global Step: 49790   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:17:09,718-Speed 140.89 samples/sec   Loss 1.1543   LearningRate 0.000002   Epoch: 1   Global Step: 49800   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:17:12,005-Speed 139.94 samples/sec   Loss 1.1613   LearningRate 0.000002   Epoch: 1   Global Step: 49810   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:17:14,291-Speed 140.04 samples/sec   Loss 1.1372   LearningRate 0.000002   Epoch: 1   Global Step: 49820   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:17:16,577-Speed 140.00 samples/sec   Loss 1.1564   LearningRate 0.000002   Epoch: 1   Global Step: 49830   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:17:18,862-Speed 140.09 samples/sec   Loss 1.1578   LearningRate 0.000002   Epoch: 1   Global Step: 49840   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:17:21,161-Speed 139.23 samples/sec   Loss 1.1304   LearningRate 0.000002   Epoch: 1   Global Step: 49850   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:17:23,470-Speed 138.65 samples/sec   Loss 1.1270   LearningRate 0.000002   Epoch: 1   Global Step: 49860   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:17:25,791-Speed 137.90 samples/sec   Loss 1.1637   LearningRate 0.000002   Epoch: 1   Global Step: 49870   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:17:28,126-Speed 137.11 samples/sec   Loss 1.1336   LearningRate 0.000002   Epoch: 1   Global Step: 49880   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:17:30,441-Speed 138.21 samples/sec   Loss 1.1705   LearningRate 0.000002   Epoch: 1   Global Step: 49890   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:17:32,764-Speed 137.84 samples/sec   Loss 1.1229   LearningRate 0.000002   Epoch: 1   Global Step: 49900   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:17:35,089-Speed 137.69 samples/sec   Loss 1.1491   LearningRate 0.000002   Epoch: 1   Global Step: 49910   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:17:37,381-Speed 139.62 samples/sec   Loss 1.1545   LearningRate 0.000002   Epoch: 1   Global Step: 49920   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:17:39,685-Speed 138.93 samples/sec   Loss 1.1305   LearningRate 0.000002   Epoch: 1   Global Step: 49930   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:17:41,983-Speed 139.31 samples/sec   Loss 1.1331   LearningRate 0.000002   Epoch: 1   Global Step: 49940   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:17:44,268-Speed 140.07 samples/sec   Loss 1.1852   LearningRate 0.000002   Epoch: 1   Global Step: 49950   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:17:46,569-Speed 139.11 samples/sec   Loss 1.1359   LearningRate 0.000002   Epoch: 1   Global Step: 49960   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:17:48,870-Speed 139.17 samples/sec   Loss 1.1257   LearningRate 0.000002   Epoch: 1   Global Step: 49970   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:17:51,159-Speed 139.81 samples/sec   Loss 1.1405   LearningRate 0.000002   Epoch: 1   Global Step: 49980   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:17:53,449-Speed 139.79 samples/sec   Loss 1.1475   LearningRate 0.000002   Epoch: 1   Global Step: 49990   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:17:55,518-Val on RAF/AffectNet:
Training: 2023-08-18 00:17:55,634-Test: [0/48]	Time 0.116 (0.116)	Loss 0.6479 (0.6479)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-18 00:17:56,750-Test: [10/48]	Time 0.114 (0.112)	Loss 0.4284 (0.5804)	Acc@1 96.875 (92.330)	Acc@5 100.000 (98.011)	Mem 5268MB
Training: 2023-08-18 00:17:57,842-Test: [20/48]	Time 0.107 (0.111)	Loss 0.5045 (0.5665)	Acc@1 96.875 (92.560)	Acc@5 96.875 (98.289)	Mem 5268MB
Training: 2023-08-18 00:17:58,909-Test: [30/48]	Time 0.106 (0.109)	Loss 0.4736 (0.5571)	Acc@1 95.312 (92.893)	Acc@5 100.000 (98.488)	Mem 5268MB
Training: 2023-08-18 00:17:59,982-Test: [40/48]	Time 0.108 (0.109)	Loss 0.4285 (0.5569)	Acc@1 95.312 (92.721)	Acc@5 100.000 (98.514)	Mem 5268MB
Training: 2023-08-18 00:18:00,732-[49999]Expression Loss: 0.55222
Training: 2023-08-18 00:18:00,733-[49999]Expression Acc@1: 92.86180
Training: 2023-08-18 00:18:00,733-[49999]Expression Acc@1-Highest: 92.86180
Training: 2023-08-18 00:18:00,733-[49999]Expression Acc@5: 98.56584
Training: 2023-08-18 00:18:00,733-[49999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-18 00:18:00,733-[49999]10 Times Expression Acc@1: 92.54237
Training: 2023-08-18 00:18:00,733-[49999]10 Times Expression Acc@1-Highest: 92.54237
Training: 2023-08-18 00:18:00,961-Speed 42.60 samples/sec   Loss 1.1421   LearningRate 0.000002   Epoch: 1   Global Step: 50000   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:18:03,237-Speed 140.63 samples/sec   Loss 1.1233   LearningRate 0.000002   Epoch: 1   Global Step: 50010   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:18:05,512-Speed 140.69 samples/sec   Loss 1.1417   LearningRate 0.000002   Epoch: 1   Global Step: 50020   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:18:07,786-Speed 140.79 samples/sec   Loss 1.1777   LearningRate 0.000002   Epoch: 1   Global Step: 50030   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:18:10,048-Speed 141.48 samples/sec   Loss 1.1474   LearningRate 0.000002   Epoch: 1   Global Step: 50040   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:18:12,319-Speed 140.96 samples/sec   Loss 1.1535   LearningRate 0.000002   Epoch: 1   Global Step: 50050   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:18:14,603-Speed 140.16 samples/sec   Loss 1.1542   LearningRate 0.000002   Epoch: 1   Global Step: 50060   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:18:16,895-Speed 139.63 samples/sec   Loss 1.1792   LearningRate 0.000002   Epoch: 1   Global Step: 50070   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:18:19,178-Speed 140.24 samples/sec   Loss 1.1448   LearningRate 0.000002   Epoch: 1   Global Step: 50080   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:18:21,444-Speed 141.23 samples/sec   Loss 1.1693   LearningRate 0.000002   Epoch: 1   Global Step: 50090   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:18:23,738-Speed 139.53 samples/sec   Loss 1.1271   LearningRate 0.000002   Epoch: 1   Global Step: 50100   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:18:26,025-Speed 139.95 samples/sec   Loss 1.1565   LearningRate 0.000002   Epoch: 1   Global Step: 50110   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:18:28,308-Speed 140.27 samples/sec   Loss 1.1467   LearningRate 0.000002   Epoch: 1   Global Step: 50120   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:18:30,581-Speed 140.82 samples/sec   Loss 1.1519   LearningRate 0.000002   Epoch: 1   Global Step: 50130   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:18:32,860-Speed 140.45 samples/sec   Loss 1.1410   LearningRate 0.000002   Epoch: 1   Global Step: 50140   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:18:35,145-Speed 140.08 samples/sec   Loss 1.1224   LearningRate 0.000002   Epoch: 1   Global Step: 50150   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:18:37,432-Speed 139.96 samples/sec   Loss 1.1195   LearningRate 0.000002   Epoch: 1   Global Step: 50160   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:18:39,720-Speed 139.92 samples/sec   Loss 1.1569   LearningRate 0.000002   Epoch: 1   Global Step: 50170   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:18:42,007-Speed 139.96 samples/sec   Loss 1.1213   LearningRate 0.000002   Epoch: 1   Global Step: 50180   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:18:44,290-Speed 140.20 samples/sec   Loss 1.1557   LearningRate 0.000002   Epoch: 1   Global Step: 50190   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:18:46,566-Speed 140.63 samples/sec   Loss 1.1488   LearningRate 0.000002   Epoch: 1   Global Step: 50200   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:18:48,857-Speed 139.68 samples/sec   Loss 1.1679   LearningRate 0.000002   Epoch: 1   Global Step: 50210   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:18:51,159-Speed 139.06 samples/sec   Loss 1.1376   LearningRate 0.000002   Epoch: 1   Global Step: 50220   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:18:53,449-Speed 139.76 samples/sec   Loss 1.1375   LearningRate 0.000002   Epoch: 1   Global Step: 50230   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:18:55,725-Speed 140.65 samples/sec   Loss 1.1339   LearningRate 0.000002   Epoch: 1   Global Step: 50240   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:18:58,006-Speed 140.31 samples/sec   Loss 1.1441   LearningRate 0.000002   Epoch: 1   Global Step: 50250   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:19:00,301-Speed 139.54 samples/sec   Loss 1.1838   LearningRate 0.000002   Epoch: 1   Global Step: 50260   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:19:02,585-Speed 140.15 samples/sec   Loss 1.1367   LearningRate 0.000002   Epoch: 1   Global Step: 50270   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:19:04,864-Speed 140.42 samples/sec   Loss 1.1428   LearningRate 0.000002   Epoch: 1   Global Step: 50280   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:19:07,158-Speed 139.51 samples/sec   Loss 1.1327   LearningRate 0.000002   Epoch: 1   Global Step: 50290   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:19:09,433-Speed 140.71 samples/sec   Loss 1.1567   LearningRate 0.000002   Epoch: 1   Global Step: 50300   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:19:11,729-Speed 139.45 samples/sec   Loss 1.1123   LearningRate 0.000002   Epoch: 1   Global Step: 50310   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:19:14,040-Speed 138.47 samples/sec   Loss 1.1294   LearningRate 0.000002   Epoch: 1   Global Step: 50320   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:19:16,327-Speed 139.96 samples/sec   Loss 1.1206   LearningRate 0.000002   Epoch: 1   Global Step: 50330   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:19:18,642-Speed 138.29 samples/sec   Loss 1.1425   LearningRate 0.000002   Epoch: 1   Global Step: 50340   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:19:20,944-Speed 139.05 samples/sec   Loss 1.1402   LearningRate 0.000002   Epoch: 1   Global Step: 50350   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:19:23,237-Speed 139.59 samples/sec   Loss 1.1438   LearningRate 0.000002   Epoch: 1   Global Step: 50360   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:19:25,529-Speed 139.64 samples/sec   Loss 1.1459   LearningRate 0.000002   Epoch: 1   Global Step: 50370   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:19:27,819-Speed 139.80 samples/sec   Loss 1.1450   LearningRate 0.000002   Epoch: 1   Global Step: 50380   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:19:30,113-Speed 139.54 samples/sec   Loss 1.1228   LearningRate 0.000002   Epoch: 1   Global Step: 50390   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:19:32,409-Speed 139.36 samples/sec   Loss 1.1489   LearningRate 0.000002   Epoch: 1   Global Step: 50400   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:19:34,695-Speed 140.07 samples/sec   Loss 1.1611   LearningRate 0.000002   Epoch: 1   Global Step: 50410   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:19:36,993-Speed 139.25 samples/sec   Loss 1.1523   LearningRate 0.000002   Epoch: 1   Global Step: 50420   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:19:39,286-Speed 139.63 samples/sec   Loss 1.1496   LearningRate 0.000002   Epoch: 1   Global Step: 50430   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:19:41,575-Speed 139.80 samples/sec   Loss 1.1474   LearningRate 0.000002   Epoch: 1   Global Step: 50440   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:19:43,868-Speed 139.64 samples/sec   Loss 1.1476   LearningRate 0.000002   Epoch: 1   Global Step: 50450   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:19:46,173-Speed 138.84 samples/sec   Loss 1.1278   LearningRate 0.000002   Epoch: 1   Global Step: 50460   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:19:48,455-Speed 140.28 samples/sec   Loss 1.1425   LearningRate 0.000002   Epoch: 1   Global Step: 50470   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:19:50,740-Speed 140.12 samples/sec   Loss 1.1319   LearningRate 0.000002   Epoch: 1   Global Step: 50480   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:19:53,022-Speed 140.20 samples/sec   Loss 1.1380   LearningRate 0.000002   Epoch: 1   Global Step: 50490   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:19:55,312-Speed 139.80 samples/sec   Loss 1.1349   LearningRate 0.000002   Epoch: 1   Global Step: 50500   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:19:57,593-Speed 140.32 samples/sec   Loss 1.1600   LearningRate 0.000002   Epoch: 1   Global Step: 50510   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:19:59,888-Speed 139.52 samples/sec   Loss 1.1285   LearningRate 0.000002   Epoch: 1   Global Step: 50520   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:20:02,173-Speed 140.06 samples/sec   Loss 1.1546   LearningRate 0.000002   Epoch: 1   Global Step: 50530   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:20:04,444-Speed 140.94 samples/sec   Loss 1.1714   LearningRate 0.000002   Epoch: 1   Global Step: 50540   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:20:06,727-Speed 140.17 samples/sec   Loss 1.1307   LearningRate 0.000002   Epoch: 1   Global Step: 50550   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:20:09,022-Speed 139.48 samples/sec   Loss 1.1552   LearningRate 0.000002   Epoch: 1   Global Step: 50560   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:20:11,305-Speed 140.20 samples/sec   Loss 1.1266   LearningRate 0.000002   Epoch: 1   Global Step: 50570   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:20:13,594-Speed 139.84 samples/sec   Loss 1.1462   LearningRate 0.000002   Epoch: 1   Global Step: 50580   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:20:15,883-Speed 139.88 samples/sec   Loss 1.1537   LearningRate 0.000002   Epoch: 1   Global Step: 50590   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:20:18,169-Speed 140.02 samples/sec   Loss 1.1699   LearningRate 0.000002   Epoch: 1   Global Step: 50600   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:20:20,450-Speed 140.29 samples/sec   Loss 1.1468   LearningRate 0.000002   Epoch: 1   Global Step: 50610   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:20:22,739-Speed 139.85 samples/sec   Loss 1.1427   LearningRate 0.000002   Epoch: 1   Global Step: 50620   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:20:25,035-Speed 139.42 samples/sec   Loss 1.1452   LearningRate 0.000002   Epoch: 1   Global Step: 50630   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:20:27,322-Speed 139.97 samples/sec   Loss 1.1378   LearningRate 0.000002   Epoch: 1   Global Step: 50640   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:20:29,595-Speed 140.82 samples/sec   Loss 1.1496   LearningRate 0.000002   Epoch: 1   Global Step: 50650   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:20:31,884-Speed 139.82 samples/sec   Loss 1.1183   LearningRate 0.000002   Epoch: 1   Global Step: 50660   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:20:34,171-Speed 140.00 samples/sec   Loss 1.1244   LearningRate 0.000002   Epoch: 1   Global Step: 50670   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:20:36,490-Speed 137.98 samples/sec   Loss 1.1694   LearningRate 0.000002   Epoch: 1   Global Step: 50680   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:20:38,800-Speed 138.63 samples/sec   Loss 1.1274   LearningRate 0.000002   Epoch: 1   Global Step: 50690   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:20:41,099-Speed 139.17 samples/sec   Loss 1.1427   LearningRate 0.000002   Epoch: 1   Global Step: 50700   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:20:43,401-Speed 139.07 samples/sec   Loss 1.1547   LearningRate 0.000002   Epoch: 1   Global Step: 50710   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:20:45,714-Speed 138.42 samples/sec   Loss 1.1355   LearningRate 0.000002   Epoch: 1   Global Step: 50720   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:20:48,022-Speed 138.68 samples/sec   Loss 1.1172   LearningRate 0.000002   Epoch: 1   Global Step: 50730   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:20:50,325-Speed 139.01 samples/sec   Loss 1.1369   LearningRate 0.000002   Epoch: 1   Global Step: 50740   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:20:52,637-Speed 138.43 samples/sec   Loss 1.1278   LearningRate 0.000002   Epoch: 1   Global Step: 50750   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:20:54,935-Speed 139.29 samples/sec   Loss 1.1493   LearningRate 0.000002   Epoch: 1   Global Step: 50760   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:20:57,257-Speed 137.86 samples/sec   Loss 1.1839   LearningRate 0.000002   Epoch: 1   Global Step: 50770   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:20:59,564-Speed 138.73 samples/sec   Loss 1.1563   LearningRate 0.000002   Epoch: 1   Global Step: 50780   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:21:01,907-Speed 136.59 samples/sec   Loss 1.1201   LearningRate 0.000002   Epoch: 1   Global Step: 50790   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:21:04,229-Speed 137.89 samples/sec   Loss 1.1274   LearningRate 0.000002   Epoch: 1   Global Step: 50800   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:21:06,550-Speed 137.88 samples/sec   Loss 1.1491   LearningRate 0.000002   Epoch: 1   Global Step: 50810   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:21:08,871-Speed 137.96 samples/sec   Loss 1.1661   LearningRate 0.000002   Epoch: 1   Global Step: 50820   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:21:11,188-Speed 138.15 samples/sec   Loss 1.1344   LearningRate 0.000002   Epoch: 1   Global Step: 50830   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:21:13,514-Speed 137.58 samples/sec   Loss 1.1421   LearningRate 0.000002   Epoch: 1   Global Step: 50840   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:21:15,822-Speed 138.71 samples/sec   Loss 1.1320   LearningRate 0.000002   Epoch: 1   Global Step: 50850   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:21:18,147-Speed 137.66 samples/sec   Loss 1.1347   LearningRate 0.000002   Epoch: 1   Global Step: 50860   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:21:20,448-Speed 139.11 samples/sec   Loss 1.1116   LearningRate 0.000002   Epoch: 1   Global Step: 50870   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:21:22,755-Speed 138.72 samples/sec   Loss 1.1454   LearningRate 0.000002   Epoch: 1   Global Step: 50880   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:21:25,078-Speed 137.85 samples/sec   Loss 1.1193   LearningRate 0.000002   Epoch: 1   Global Step: 50890   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:21:27,415-Speed 136.91 samples/sec   Loss 1.1665   LearningRate 0.000002   Epoch: 1   Global Step: 50900   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:21:29,724-Speed 138.63 samples/sec   Loss 1.1486   LearningRate 0.000002   Epoch: 1   Global Step: 50910   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:21:32,016-Speed 139.68 samples/sec   Loss 1.1267   LearningRate 0.000002   Epoch: 1   Global Step: 50920   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:21:34,313-Speed 139.38 samples/sec   Loss 1.1286   LearningRate 0.000002   Epoch: 1   Global Step: 50930   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:21:36,596-Speed 140.16 samples/sec   Loss 1.1470   LearningRate 0.000002   Epoch: 1   Global Step: 50940   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:21:38,899-Speed 138.98 samples/sec   Loss 1.1274   LearningRate 0.000002   Epoch: 1   Global Step: 50950   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:21:41,195-Speed 139.43 samples/sec   Loss 1.1378   LearningRate 0.000002   Epoch: 1   Global Step: 50960   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:21:43,495-Speed 139.21 samples/sec   Loss 1.1477   LearningRate 0.000002   Epoch: 1   Global Step: 50970   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:21:45,781-Speed 139.99 samples/sec   Loss 1.1526   LearningRate 0.000002   Epoch: 1   Global Step: 50980   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:21:48,074-Speed 139.68 samples/sec   Loss 1.1315   LearningRate 0.000002   Epoch: 1   Global Step: 50990   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:21:50,128-Val on RAF/AffectNet:
Training: 2023-08-18 00:21:50,243-Test: [0/48]	Time 0.114 (0.114)	Loss 0.6408 (0.6408)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)	Mem 5268MB
Training: 2023-08-18 00:21:51,315-Test: [10/48]	Time 0.114 (0.108)	Loss 0.5714 (0.5766)	Acc@1 90.625 (91.619)	Acc@5 98.438 (98.153)	Mem 5268MB
Training: 2023-08-18 00:21:52,417-Test: [20/48]	Time 0.104 (0.109)	Loss 0.5421 (0.5593)	Acc@1 92.188 (92.262)	Acc@5 98.438 (98.289)	Mem 5268MB
Training: 2023-08-18 00:21:53,480-Test: [30/48]	Time 0.105 (0.108)	Loss 0.6039 (0.5579)	Acc@1 87.500 (92.288)	Acc@5 98.438 (98.387)	Mem 5268MB
Training: 2023-08-18 00:21:54,539-Test: [40/48]	Time 0.105 (0.108)	Loss 0.4188 (0.5623)	Acc@1 95.312 (92.111)	Acc@5 100.000 (98.361)	Mem 5268MB
Training: 2023-08-18 00:21:55,296-[50999]Expression Loss: 0.55651
Training: 2023-08-18 00:21:55,296-[50999]Expression Acc@1: 92.40548
Training: 2023-08-18 00:21:55,296-[50999]Expression Acc@1-Highest: 92.86180
Training: 2023-08-18 00:21:55,296-[50999]Expression Acc@5: 98.40287
Training: 2023-08-18 00:21:55,296-[50999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-18 00:21:55,296-[50999]10 Times Expression Acc@1: 92.53585
Training: 2023-08-18 00:21:55,296-[50999]10 Times Expression Acc@1-Highest: 92.54237
Training: 2023-08-18 00:21:55,527-Speed 42.94 samples/sec   Loss 1.1325   LearningRate 0.000002   Epoch: 1   Global Step: 51000   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:21:57,790-Speed 141.46 samples/sec   Loss 1.1218   LearningRate 0.000002   Epoch: 1   Global Step: 51010   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:22:00,068-Speed 140.52 samples/sec   Loss 1.1358   LearningRate 0.000002   Epoch: 1   Global Step: 51020   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:22:02,345-Speed 140.58 samples/sec   Loss 1.1543   LearningRate 0.000002   Epoch: 1   Global Step: 51030   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:22:04,630-Speed 140.05 samples/sec   Loss 1.1341   LearningRate 0.000002   Epoch: 1   Global Step: 51040   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:22:06,909-Speed 140.46 samples/sec   Loss 1.1627   LearningRate 0.000002   Epoch: 1   Global Step: 51050   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:22:09,186-Speed 140.55 samples/sec   Loss 1.1512   LearningRate 0.000002   Epoch: 1   Global Step: 51060   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:22:11,467-Speed 140.32 samples/sec   Loss 1.1104   LearningRate 0.000002   Epoch: 1   Global Step: 51070   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:22:13,739-Speed 140.87 samples/sec   Loss 1.1345   LearningRate 0.000002   Epoch: 1   Global Step: 51080   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:22:16,026-Speed 139.96 samples/sec   Loss 1.1340   LearningRate 0.000002   Epoch: 1   Global Step: 51090   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:22:18,307-Speed 140.35 samples/sec   Loss 1.1303   LearningRate 0.000002   Epoch: 1   Global Step: 51100   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:22:20,567-Speed 141.58 samples/sec   Loss 1.1470   LearningRate 0.000002   Epoch: 1   Global Step: 51110   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:22:22,866-Speed 139.28 samples/sec   Loss 1.1509   LearningRate 0.000002   Epoch: 1   Global Step: 51120   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:22:25,133-Speed 141.17 samples/sec   Loss 1.1236   LearningRate 0.000002   Epoch: 1   Global Step: 51130   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:22:27,413-Speed 140.35 samples/sec   Loss 1.1657   LearningRate 0.000002   Epoch: 1   Global Step: 51140   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:22:29,684-Speed 140.97 samples/sec   Loss 1.1566   LearningRate 0.000002   Epoch: 1   Global Step: 51150   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:22:31,971-Speed 139.90 samples/sec   Loss 1.1413   LearningRate 0.000002   Epoch: 1   Global Step: 51160   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:22:34,248-Speed 140.60 samples/sec   Loss 1.1568   LearningRate 0.000002   Epoch: 1   Global Step: 51170   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:22:36,522-Speed 140.76 samples/sec   Loss 1.1513   LearningRate 0.000002   Epoch: 1   Global Step: 51180   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:22:38,799-Speed 140.59 samples/sec   Loss 1.1676   LearningRate 0.000002   Epoch: 1   Global Step: 51190   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:22:41,080-Speed 140.31 samples/sec   Loss 1.1528   LearningRate 0.000002   Epoch: 1   Global Step: 51200   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:22:43,353-Speed 140.85 samples/sec   Loss 1.1567   LearningRate 0.000002   Epoch: 1   Global Step: 51210   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:22:45,634-Speed 140.33 samples/sec   Loss 1.1698   LearningRate 0.000002   Epoch: 1   Global Step: 51220   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:22:47,925-Speed 139.70 samples/sec   Loss 1.1427   LearningRate 0.000002   Epoch: 1   Global Step: 51230   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:22:50,204-Speed 140.40 samples/sec   Loss 1.1151   LearningRate 0.000002   Epoch: 1   Global Step: 51240   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:22:52,489-Speed 140.13 samples/sec   Loss 1.1436   LearningRate 0.000002   Epoch: 1   Global Step: 51250   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:22:54,758-Speed 141.03 samples/sec   Loss 1.1406   LearningRate 0.000002   Epoch: 1   Global Step: 51260   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:22:57,024-Speed 141.27 samples/sec   Loss 1.1359   LearningRate 0.000002   Epoch: 1   Global Step: 51270   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:22:59,316-Speed 139.64 samples/sec   Loss 1.1394   LearningRate 0.000002   Epoch: 1   Global Step: 51280   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:23:01,595-Speed 140.47 samples/sec   Loss 1.1161   LearningRate 0.000002   Epoch: 1   Global Step: 51290   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:23:03,875-Speed 140.39 samples/sec   Loss 1.1456   LearningRate 0.000002   Epoch: 1   Global Step: 51300   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:23:06,153-Speed 140.49 samples/sec   Loss 1.1591   LearningRate 0.000002   Epoch: 1   Global Step: 51310   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:23:08,430-Speed 140.53 samples/sec   Loss 1.1294   LearningRate 0.000002   Epoch: 1   Global Step: 51320   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:23:10,699-Speed 141.09 samples/sec   Loss 1.1362   LearningRate 0.000002   Epoch: 1   Global Step: 51330   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:23:12,976-Speed 140.58 samples/sec   Loss 1.1436   LearningRate 0.000002   Epoch: 1   Global Step: 51340   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:23:15,264-Speed 139.86 samples/sec   Loss 1.1256   LearningRate 0.000002   Epoch: 1   Global Step: 51350   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:23:17,564-Speed 139.19 samples/sec   Loss 1.1468   LearningRate 0.000002   Epoch: 1   Global Step: 51360   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:23:19,876-Speed 138.43 samples/sec   Loss 1.1319   LearningRate 0.000002   Epoch: 1   Global Step: 51370   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:23:22,203-Speed 137.55 samples/sec   Loss 1.1483   LearningRate 0.000002   Epoch: 1   Global Step: 51380   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:23:24,505-Speed 139.08 samples/sec   Loss 1.1472   LearningRate 0.000002   Epoch: 1   Global Step: 51390   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:23:26,772-Speed 141.21 samples/sec   Loss 1.1614   LearningRate 0.000002   Epoch: 1   Global Step: 51400   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:23:29,059-Speed 139.97 samples/sec   Loss 1.1417   LearningRate 0.000002   Epoch: 1   Global Step: 51410   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:23:31,345-Speed 139.96 samples/sec   Loss 1.1502   LearningRate 0.000002   Epoch: 1   Global Step: 51420   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:23:33,645-Speed 139.22 samples/sec   Loss 1.1453   LearningRate 0.000002   Epoch: 1   Global Step: 51430   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:23:35,930-Speed 140.04 samples/sec   Loss 1.1343   LearningRate 0.000002   Epoch: 1   Global Step: 51440   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:23:38,216-Speed 140.05 samples/sec   Loss 1.1278   LearningRate 0.000002   Epoch: 1   Global Step: 51450   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:23:40,507-Speed 139.70 samples/sec   Loss 1.1400   LearningRate 0.000002   Epoch: 1   Global Step: 51460   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:23:42,785-Speed 140.50 samples/sec   Loss 1.1485   LearningRate 0.000002   Epoch: 1   Global Step: 51470   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:23:45,076-Speed 139.70 samples/sec   Loss 1.1322   LearningRate 0.000002   Epoch: 1   Global Step: 51480   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:23:47,352-Speed 140.70 samples/sec   Loss 1.1465   LearningRate 0.000002   Epoch: 1   Global Step: 51490   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:23:49,623-Speed 140.94 samples/sec   Loss 1.1188   LearningRate 0.000002   Epoch: 1   Global Step: 51500   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:23:51,906-Speed 140.18 samples/sec   Loss 1.1402   LearningRate 0.000002   Epoch: 1   Global Step: 51510   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:23:54,200-Speed 139.50 samples/sec   Loss 1.1549   LearningRate 0.000002   Epoch: 1   Global Step: 51520   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:23:56,479-Speed 140.49 samples/sec   Loss 1.1315   LearningRate 0.000002   Epoch: 1   Global Step: 51530   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:23:58,741-Speed 141.46 samples/sec   Loss 1.1382   LearningRate 0.000002   Epoch: 1   Global Step: 51540   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:24:01,020-Speed 140.45 samples/sec   Loss 1.1325   LearningRate 0.000002   Epoch: 1   Global Step: 51550   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:24:03,292-Speed 140.91 samples/sec   Loss 1.1604   LearningRate 0.000002   Epoch: 1   Global Step: 51560   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:24:05,582-Speed 139.77 samples/sec   Loss 1.1367   LearningRate 0.000002   Epoch: 1   Global Step: 51570   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:24:07,881-Speed 139.24 samples/sec   Loss 1.1506   LearningRate 0.000002   Epoch: 1   Global Step: 51580   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:24:10,163-Speed 140.26 samples/sec   Loss 1.1383   LearningRate 0.000002   Epoch: 1   Global Step: 51590   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:24:12,444-Speed 140.32 samples/sec   Loss 1.1490   LearningRate 0.000002   Epoch: 1   Global Step: 51600   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:24:14,726-Speed 140.28 samples/sec   Loss 1.1744   LearningRate 0.000002   Epoch: 1   Global Step: 51610   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:24:17,013-Speed 139.95 samples/sec   Loss 1.1387   LearningRate 0.000002   Epoch: 1   Global Step: 51620   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:24:19,283-Speed 141.00 samples/sec   Loss 1.1470   LearningRate 0.000002   Epoch: 1   Global Step: 51630   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:24:21,599-Speed 138.16 samples/sec   Loss 1.1297   LearningRate 0.000002   Epoch: 1   Global Step: 51640   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:24:23,929-Speed 137.39 samples/sec   Loss 1.1451   LearningRate 0.000002   Epoch: 1   Global Step: 51650   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:24:26,255-Speed 137.64 samples/sec   Loss 1.1394   LearningRate 0.000002   Epoch: 1   Global Step: 51660   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:24:28,591-Speed 137.03 samples/sec   Loss 1.1447   LearningRate 0.000002   Epoch: 1   Global Step: 51670   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:24:30,917-Speed 137.60 samples/sec   Loss 1.1267   LearningRate 0.000002   Epoch: 1   Global Step: 51680   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:24:33,246-Speed 137.41 samples/sec   Loss 1.1642   LearningRate 0.000002   Epoch: 1   Global Step: 51690   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:24:35,570-Speed 137.74 samples/sec   Loss 1.1162   LearningRate 0.000002   Epoch: 1   Global Step: 51700   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:24:37,896-Speed 137.60 samples/sec   Loss 1.1624   LearningRate 0.000002   Epoch: 1   Global Step: 51710   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:24:40,214-Speed 138.13 samples/sec   Loss 1.1583   LearningRate 0.000002   Epoch: 1   Global Step: 51720   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:24:42,538-Speed 137.68 samples/sec   Loss 1.1369   LearningRate 0.000002   Epoch: 1   Global Step: 51730   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:24:44,825-Speed 139.95 samples/sec   Loss 1.1778   LearningRate 0.000002   Epoch: 1   Global Step: 51740   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:24:47,105-Speed 140.39 samples/sec   Loss 1.1291   LearningRate 0.000002   Epoch: 1   Global Step: 51750   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:24:49,380-Speed 140.74 samples/sec   Loss 1.1392   LearningRate 0.000002   Epoch: 1   Global Step: 51760   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:24:51,651-Speed 140.94 samples/sec   Loss 1.1247   LearningRate 0.000002   Epoch: 1   Global Step: 51770   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:24:53,925-Speed 140.72 samples/sec   Loss 1.1513   LearningRate 0.000002   Epoch: 1   Global Step: 51780   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:24:56,202-Speed 140.57 samples/sec   Loss 1.1420   LearningRate 0.000002   Epoch: 1   Global Step: 51790   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:24:58,502-Speed 139.17 samples/sec   Loss 1.1309   LearningRate 0.000002   Epoch: 1   Global Step: 51800   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:25:00,809-Speed 138.78 samples/sec   Loss 1.1458   LearningRate 0.000002   Epoch: 1   Global Step: 51810   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:25:03,101-Speed 139.62 samples/sec   Loss 1.1128   LearningRate 0.000002   Epoch: 1   Global Step: 51820   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:25:05,372-Speed 141.00 samples/sec   Loss 1.1119   LearningRate 0.000002   Epoch: 1   Global Step: 51830   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:25:07,663-Speed 139.72 samples/sec   Loss 1.1142   LearningRate 0.000002   Epoch: 1   Global Step: 51840   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:25:09,952-Speed 139.79 samples/sec   Loss 1.1482   LearningRate 0.000002   Epoch: 1   Global Step: 51850   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:25:12,240-Speed 139.91 samples/sec   Loss 1.1524   LearningRate 0.000002   Epoch: 1   Global Step: 51860   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:25:14,540-Speed 139.18 samples/sec   Loss 1.1448   LearningRate 0.000002   Epoch: 1   Global Step: 51870   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:25:16,826-Speed 140.05 samples/sec   Loss 1.1348   LearningRate 0.000002   Epoch: 1   Global Step: 51880   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:25:19,113-Speed 139.93 samples/sec   Loss 1.1424   LearningRate 0.000002   Epoch: 1   Global Step: 51890   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:25:21,399-Speed 140.04 samples/sec   Loss 1.1374   LearningRate 0.000002   Epoch: 1   Global Step: 51900   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:25:23,707-Speed 138.69 samples/sec   Loss 1.1281   LearningRate 0.000002   Epoch: 1   Global Step: 51910   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:25:25,997-Speed 139.77 samples/sec   Loss 1.1516   LearningRate 0.000002   Epoch: 1   Global Step: 51920   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:25:28,297-Speed 139.17 samples/sec   Loss 1.1353   LearningRate 0.000002   Epoch: 1   Global Step: 51930   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:25:30,594-Speed 139.34 samples/sec   Loss 1.1458   LearningRate 0.000002   Epoch: 1   Global Step: 51940   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:25:32,901-Speed 138.73 samples/sec   Loss 1.1390   LearningRate 0.000002   Epoch: 1   Global Step: 51950   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:25:35,199-Speed 139.31 samples/sec   Loss 1.1211   LearningRate 0.000002   Epoch: 1   Global Step: 51960   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:25:37,507-Speed 138.68 samples/sec   Loss 1.1438   LearningRate 0.000002   Epoch: 1   Global Step: 51970   Fp16 Grad Scale: 16384   Required: 1 hours
Training: 2023-08-18 00:25:39,812-Speed 138.86 samples/sec   Loss 1.1465   LearningRate 0.000002   Epoch: 1   Global Step: 51980   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:25:42,108-Speed 139.37 samples/sec   Loss 1.1284   LearningRate 0.000002   Epoch: 1   Global Step: 51990   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:25:44,174-Val on RAF/AffectNet:
Training: 2023-08-18 00:25:44,290-Test: [0/48]	Time 0.115 (0.115)	Loss 0.5735 (0.5735)	Acc@1 90.625 (90.625)	Acc@5 98.438 (98.438)	Mem 5268MB
Training: 2023-08-18 00:25:45,358-Test: [10/48]	Time 0.108 (0.108)	Loss 0.5878 (0.5283)	Acc@1 90.625 (93.040)	Acc@5 98.438 (98.722)	Mem 5268MB
Training: 2023-08-18 00:25:46,440-Test: [20/48]	Time 0.108 (0.108)	Loss 0.5614 (0.5395)	Acc@1 90.625 (92.857)	Acc@5 100.000 (98.958)	Mem 5268MB
Training: 2023-08-18 00:25:47,529-Test: [30/48]	Time 0.108 (0.108)	Loss 0.5904 (0.5428)	Acc@1 90.625 (92.944)	Acc@5 98.438 (98.589)	Mem 5268MB
Training: 2023-08-18 00:25:48,636-Test: [40/48]	Time 0.108 (0.109)	Loss 0.4697 (0.5456)	Acc@1 95.312 (92.835)	Acc@5 100.000 (98.628)	Mem 5268MB
Training: 2023-08-18 00:25:49,423-[51999]Expression Loss: 0.55326
Training: 2023-08-18 00:25:49,423-[51999]Expression Acc@1: 92.60104
Training: 2023-08-18 00:25:49,423-[51999]Expression Acc@1-Highest: 92.86180
Training: 2023-08-18 00:25:49,423-[51999]Expression Acc@5: 98.50065
Training: 2023-08-18 00:25:49,423-[51999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-18 00:25:49,423-[51999]10 Times Expression Acc@1: 92.56193
Training: 2023-08-18 00:25:49,423-[51999]10 Times Expression Acc@1-Highest: 92.56193
Training: 2023-08-18 00:25:49,655-Speed 42.41 samples/sec   Loss 1.1431   LearningRate 0.000002   Epoch: 1   Global Step: 52000   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:25:51,950-Speed 139.45 samples/sec   Loss 1.1300   LearningRate 0.000002   Epoch: 1   Global Step: 52010   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:25:54,228-Speed 140.52 samples/sec   Loss 1.1410   LearningRate 0.000002   Epoch: 1   Global Step: 52020   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:25:56,524-Speed 139.41 samples/sec   Loss 1.1419   LearningRate 0.000002   Epoch: 1   Global Step: 52030   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:25:58,808-Speed 140.18 samples/sec   Loss 1.1551   LearningRate 0.000002   Epoch: 1   Global Step: 52040   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:26:01,113-Speed 138.87 samples/sec   Loss 1.1563   LearningRate 0.000002   Epoch: 1   Global Step: 52050   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:26:03,415-Speed 139.03 samples/sec   Loss 1.1519   LearningRate 0.000002   Epoch: 1   Global Step: 52060   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:26:05,717-Speed 139.03 samples/sec   Loss 1.1398   LearningRate 0.000002   Epoch: 1   Global Step: 52070   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:26:08,040-Speed 137.78 samples/sec   Loss 1.1290   LearningRate 0.000002   Epoch: 1   Global Step: 52080   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:26:10,352-Speed 138.47 samples/sec   Loss 1.1622   LearningRate 0.000002   Epoch: 1   Global Step: 52090   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:26:12,669-Speed 138.17 samples/sec   Loss 1.1574   LearningRate 0.000002   Epoch: 1   Global Step: 52100   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:26:14,980-Speed 138.46 samples/sec   Loss 1.1202   LearningRate 0.000002   Epoch: 1   Global Step: 52110   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:26:17,297-Speed 138.19 samples/sec   Loss 1.1332   LearningRate 0.000002   Epoch: 1   Global Step: 52120   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:26:19,592-Speed 139.44 samples/sec   Loss 1.1525   LearningRate 0.000002   Epoch: 1   Global Step: 52130   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:26:21,896-Speed 138.95 samples/sec   Loss 1.1111   LearningRate 0.000002   Epoch: 1   Global Step: 52140   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:26:24,187-Speed 139.72 samples/sec   Loss 1.1413   LearningRate 0.000002   Epoch: 1   Global Step: 52150   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:26:26,476-Speed 139.84 samples/sec   Loss 1.1357   LearningRate 0.000002   Epoch: 1   Global Step: 52160   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:26:28,757-Speed 140.30 samples/sec   Loss 1.1674   LearningRate 0.000002   Epoch: 1   Global Step: 52170   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:26:31,034-Speed 140.57 samples/sec   Loss 1.1463   LearningRate 0.000002   Epoch: 1   Global Step: 52180   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:26:33,316-Speed 140.26 samples/sec   Loss 1.1499   LearningRate 0.000002   Epoch: 1   Global Step: 52190   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:26:35,600-Speed 140.17 samples/sec   Loss 1.1308   LearningRate 0.000002   Epoch: 1   Global Step: 52200   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:26:37,895-Speed 139.46 samples/sec   Loss 1.1318   LearningRate 0.000002   Epoch: 1   Global Step: 52210   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:26:40,196-Speed 139.12 samples/sec   Loss 1.1159   LearningRate 0.000002   Epoch: 1   Global Step: 52220   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:26:42,499-Speed 138.94 samples/sec   Loss 1.1433   LearningRate 0.000002   Epoch: 1   Global Step: 52230   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:26:44,785-Speed 140.05 samples/sec   Loss 1.1452   LearningRate 0.000002   Epoch: 1   Global Step: 52240   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:26:47,094-Speed 138.63 samples/sec   Loss 1.1292   LearningRate 0.000002   Epoch: 1   Global Step: 52250   Fp16 Grad Scale: 65536   Required: 1 hours
Training: 2023-08-18 00:26:49,379-Speed 140.06 samples/sec   Loss 1.1542   LearningRate 0.000002   Epoch: 1   Global Step: 52260   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:26:51,681-Speed 139.05 samples/sec   Loss 1.1530   LearningRate 0.000002   Epoch: 1   Global Step: 52270   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:26:53,971-Speed 139.81 samples/sec   Loss 1.1428   LearningRate 0.000002   Epoch: 1   Global Step: 52280   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:26:56,262-Speed 139.72 samples/sec   Loss 1.1276   LearningRate 0.000002   Epoch: 1   Global Step: 52290   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:26:58,555-Speed 139.52 samples/sec   Loss 1.1164   LearningRate 0.000002   Epoch: 1   Global Step: 52300   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:27:00,859-Speed 138.96 samples/sec   Loss 1.1261   LearningRate 0.000002   Epoch: 1   Global Step: 52310   Fp16 Grad Scale: 32768   Required: 1 hours
Training: 2023-08-18 00:27:03,137-Speed 140.51 samples/sec   Loss 1.1520   LearningRate 0.000002   Epoch: 1   Global Step: 52320   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:27:05,421-Speed 140.13 samples/sec   Loss 1.1318   LearningRate 0.000002   Epoch: 1   Global Step: 52330   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:27:07,723-Speed 139.06 samples/sec   Loss 1.1481   LearningRate 0.000002   Epoch: 1   Global Step: 52340   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:27:10,018-Speed 139.50 samples/sec   Loss 1.1237   LearningRate 0.000002   Epoch: 1   Global Step: 52350   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:27:12,311-Speed 139.55 samples/sec   Loss 1.1458   LearningRate 0.000002   Epoch: 1   Global Step: 52360   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:27:14,595-Speed 140.14 samples/sec   Loss 1.1288   LearningRate 0.000002   Epoch: 1   Global Step: 52370   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:27:16,904-Speed 138.63 samples/sec   Loss 1.1577   LearningRate 0.000002   Epoch: 1   Global Step: 52380   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:27:19,194-Speed 139.81 samples/sec   Loss 1.1725   LearningRate 0.000002   Epoch: 1   Global Step: 52390   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:27:21,477-Speed 140.16 samples/sec   Loss 1.1278   LearningRate 0.000002   Epoch: 1   Global Step: 52400   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:27:23,767-Speed 139.78 samples/sec   Loss 1.1541   LearningRate 0.000002   Epoch: 1   Global Step: 52410   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:27:26,057-Speed 139.78 samples/sec   Loss 1.1635   LearningRate 0.000002   Epoch: 1   Global Step: 52420   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:27:28,362-Speed 138.85 samples/sec   Loss 1.1247   LearningRate 0.000002   Epoch: 1   Global Step: 52430   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:27:30,635-Speed 140.87 samples/sec   Loss 1.1405   LearningRate 0.000002   Epoch: 1   Global Step: 52440   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:27:32,928-Speed 139.58 samples/sec   Loss 1.1226   LearningRate 0.000002   Epoch: 1   Global Step: 52450   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:27:35,228-Speed 139.16 samples/sec   Loss 1.1271   LearningRate 0.000002   Epoch: 1   Global Step: 52460   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:27:37,530-Speed 139.05 samples/sec   Loss 1.1521   LearningRate 0.000001   Epoch: 1   Global Step: 52470   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:27:39,834-Speed 138.90 samples/sec   Loss 1.1421   LearningRate 0.000001   Epoch: 1   Global Step: 52480   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:27:42,132-Speed 139.32 samples/sec   Loss 1.1337   LearningRate 0.000001   Epoch: 1   Global Step: 52490   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:27:44,421-Speed 139.85 samples/sec   Loss 1.1505   LearningRate 0.000001   Epoch: 1   Global Step: 52500   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:27:46,724-Speed 138.97 samples/sec   Loss 1.1137   LearningRate 0.000001   Epoch: 1   Global Step: 52510   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:27:49,017-Speed 139.59 samples/sec   Loss 1.1719   LearningRate 0.000001   Epoch: 1   Global Step: 52520   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:27:51,313-Speed 139.42 samples/sec   Loss 1.1381   LearningRate 0.000001   Epoch: 1   Global Step: 52530   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:27:53,608-Speed 139.44 samples/sec   Loss 1.1457   LearningRate 0.000001   Epoch: 1   Global Step: 52540   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:27:55,909-Speed 139.09 samples/sec   Loss 1.1347   LearningRate 0.000001   Epoch: 1   Global Step: 52550   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:27:58,210-Speed 139.14 samples/sec   Loss 1.1403   LearningRate 0.000001   Epoch: 1   Global Step: 52560   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:28:00,516-Speed 138.78 samples/sec   Loss 1.1348   LearningRate 0.000001   Epoch: 1   Global Step: 52570   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:28:02,837-Speed 137.91 samples/sec   Loss 1.1096   LearningRate 0.000001   Epoch: 1   Global Step: 52580   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:28:05,162-Speed 137.65 samples/sec   Loss 1.1395   LearningRate 0.000001   Epoch: 1   Global Step: 52590   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:28:07,490-Speed 137.49 samples/sec   Loss 1.1643   LearningRate 0.000001   Epoch: 1   Global Step: 52600   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:28:09,830-Speed 136.81 samples/sec   Loss 1.1362   LearningRate 0.000001   Epoch: 1   Global Step: 52610   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:28:12,162-Speed 137.27 samples/sec   Loss 1.1292   LearningRate 0.000001   Epoch: 1   Global Step: 52620   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:28:14,486-Speed 137.70 samples/sec   Loss 1.1585   LearningRate 0.000001   Epoch: 1   Global Step: 52630   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:28:16,798-Speed 138.46 samples/sec   Loss 1.1237   LearningRate 0.000001   Epoch: 1   Global Step: 52640   Fp16 Grad Scale: 65536   Required: 0 hours
Training: 2023-08-18 00:28:19,061-Speed 141.43 samples/sec   Loss 1.1387   LearningRate 0.000001   Epoch: 1   Global Step: 52650   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:28:21,331-Speed 141.06 samples/sec   Loss 1.1291   LearningRate 0.000001   Epoch: 1   Global Step: 52660   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:28:23,605-Speed 140.74 samples/sec   Loss 1.1395   LearningRate 0.000001   Epoch: 1   Global Step: 52670   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:28:25,891-Speed 140.01 samples/sec   Loss 1.1689   LearningRate 0.000001   Epoch: 1   Global Step: 52680   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:28:28,191-Speed 139.18 samples/sec   Loss 1.1612   LearningRate 0.000001   Epoch: 1   Global Step: 52690   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:28:30,478-Speed 139.95 samples/sec   Loss 1.1574   LearningRate 0.000001   Epoch: 1   Global Step: 52700   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:28:32,772-Speed 139.58 samples/sec   Loss 1.1261   LearningRate 0.000001   Epoch: 1   Global Step: 52710   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:28:35,088-Speed 138.18 samples/sec   Loss 1.1660   LearningRate 0.000001   Epoch: 1   Global Step: 52720   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:28:37,387-Speed 139.20 samples/sec   Loss 1.1291   LearningRate 0.000001   Epoch: 1   Global Step: 52730   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:28:39,678-Speed 139.75 samples/sec   Loss 1.1388   LearningRate 0.000001   Epoch: 1   Global Step: 52740   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:28:41,977-Speed 139.20 samples/sec   Loss 1.1192   LearningRate 0.000001   Epoch: 1   Global Step: 52750   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:28:44,289-Speed 138.49 samples/sec   Loss 1.1377   LearningRate 0.000001   Epoch: 1   Global Step: 52760   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:28:46,589-Speed 139.12 samples/sec   Loss 1.1658   LearningRate 0.000001   Epoch: 1   Global Step: 52770   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:28:48,910-Speed 137.96 samples/sec   Loss 1.1258   LearningRate 0.000001   Epoch: 1   Global Step: 52780   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:28:51,212-Speed 139.02 samples/sec   Loss 1.1241   LearningRate 0.000001   Epoch: 1   Global Step: 52790   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:28:53,529-Speed 138.17 samples/sec   Loss 1.1529   LearningRate 0.000001   Epoch: 1   Global Step: 52800   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:28:55,842-Speed 138.32 samples/sec   Loss 1.1282   LearningRate 0.000001   Epoch: 1   Global Step: 52810   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:28:58,161-Speed 138.07 samples/sec   Loss 1.1429   LearningRate 0.000001   Epoch: 1   Global Step: 52820   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:29:00,473-Speed 138.46 samples/sec   Loss 1.1330   LearningRate 0.000001   Epoch: 1   Global Step: 52830   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:29:02,768-Speed 139.44 samples/sec   Loss 1.1537   LearningRate 0.000001   Epoch: 1   Global Step: 52840   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:29:05,069-Speed 139.09 samples/sec   Loss 1.1216   LearningRate 0.000001   Epoch: 1   Global Step: 52850   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:29:07,389-Speed 138.00 samples/sec   Loss 1.1467   LearningRate 0.000001   Epoch: 1   Global Step: 52860   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:29:09,677-Speed 139.86 samples/sec   Loss 1.1417   LearningRate 0.000001   Epoch: 1   Global Step: 52870   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:29:11,985-Speed 138.69 samples/sec   Loss 1.1424   LearningRate 0.000001   Epoch: 1   Global Step: 52880   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:29:14,276-Speed 139.76 samples/sec   Loss 1.1666   LearningRate 0.000001   Epoch: 1   Global Step: 52890   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:29:16,577-Speed 139.10 samples/sec   Loss 1.1386   LearningRate 0.000001   Epoch: 1   Global Step: 52900   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:29:18,877-Speed 139.18 samples/sec   Loss 1.1300   LearningRate 0.000001   Epoch: 1   Global Step: 52910   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:29:21,167-Speed 139.77 samples/sec   Loss 1.1242   LearningRate 0.000001   Epoch: 1   Global Step: 52920   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:29:23,453-Speed 140.00 samples/sec   Loss 1.1371   LearningRate 0.000001   Epoch: 1   Global Step: 52930   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:29:25,734-Speed 140.37 samples/sec   Loss 1.1187   LearningRate 0.000001   Epoch: 1   Global Step: 52940   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:29:28,034-Speed 139.14 samples/sec   Loss 1.1369   LearningRate 0.000001   Epoch: 1   Global Step: 52950   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:29:30,334-Speed 139.16 samples/sec   Loss 1.1489   LearningRate 0.000001   Epoch: 1   Global Step: 52960   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:29:32,630-Speed 139.42 samples/sec   Loss 1.1290   LearningRate 0.000001   Epoch: 1   Global Step: 52970   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:29:34,916-Speed 140.05 samples/sec   Loss 1.1469   LearningRate 0.000001   Epoch: 1   Global Step: 52980   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:29:37,214-Speed 139.28 samples/sec   Loss 1.1264   LearningRate 0.000001   Epoch: 1   Global Step: 52990   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:29:39,303-Val on RAF/AffectNet:
Training: 2023-08-18 00:29:39,418-Test: [0/48]	Time 0.115 (0.115)	Loss 0.5620 (0.5620)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)	Mem 5268MB
Training: 2023-08-18 00:29:40,522-Test: [10/48]	Time 0.112 (0.111)	Loss 0.4793 (0.5421)	Acc@1 96.875 (93.182)	Acc@5 98.438 (98.580)	Mem 5268MB
Training: 2023-08-18 00:29:41,577-Test: [20/48]	Time 0.104 (0.108)	Loss 0.6724 (0.5530)	Acc@1 87.500 (92.411)	Acc@5 93.750 (98.512)	Mem 5268MB
Training: 2023-08-18 00:29:42,629-Test: [30/48]	Time 0.105 (0.107)	Loss 0.5662 (0.5421)	Acc@1 93.750 (92.843)	Acc@5 96.875 (98.639)	Mem 5268MB
Training: 2023-08-18 00:29:43,688-Test: [40/48]	Time 0.106 (0.107)	Loss 0.4521 (0.5425)	Acc@1 95.312 (92.797)	Acc@5 100.000 (98.476)	Mem 5268MB
Training: 2023-08-18 00:29:44,432-[52999]Expression Loss: 0.55072
Training: 2023-08-18 00:29:44,432-[52999]Expression Acc@1: 92.47067
Training: 2023-08-18 00:29:44,432-[52999]Expression Acc@1-Highest: 92.86180
Training: 2023-08-18 00:29:44,432-[52999]Expression Acc@5: 98.46806
Training: 2023-08-18 00:29:44,432-[52999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-18 00:29:44,433-[52999]10 Times Expression Acc@1: 92.54237
Training: 2023-08-18 00:29:44,433-[52999]10 Times Expression Acc@1-Highest: 92.56193
Training: 2023-08-18 00:29:44,660-Speed 42.98 samples/sec   Loss 1.1571   LearningRate 0.000001   Epoch: 1   Global Step: 53000   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:29:46,929-Speed 141.06 samples/sec   Loss 1.1177   LearningRate 0.000001   Epoch: 1   Global Step: 53010   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:29:49,193-Speed 141.38 samples/sec   Loss 1.1519   LearningRate 0.000001   Epoch: 1   Global Step: 53020   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:29:51,465-Speed 140.91 samples/sec   Loss 1.1453   LearningRate 0.000001   Epoch: 1   Global Step: 53030   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:29:53,735-Speed 140.99 samples/sec   Loss 1.1657   LearningRate 0.000001   Epoch: 1   Global Step: 53040   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:29:55,997-Speed 141.46 samples/sec   Loss 1.1709   LearningRate 0.000001   Epoch: 1   Global Step: 53050   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:29:58,266-Speed 141.06 samples/sec   Loss 1.1423   LearningRate 0.000001   Epoch: 1   Global Step: 53060   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:30:00,546-Speed 140.38 samples/sec   Loss 1.1324   LearningRate 0.000001   Epoch: 1   Global Step: 53070   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:30:02,817-Speed 140.97 samples/sec   Loss 1.1595   LearningRate 0.000001   Epoch: 1   Global Step: 53080   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:30:05,102-Speed 140.05 samples/sec   Loss 1.1377   LearningRate 0.000001   Epoch: 1   Global Step: 53090   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:30:07,379-Speed 140.57 samples/sec   Loss 1.1352   LearningRate 0.000001   Epoch: 1   Global Step: 53100   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:30:09,659-Speed 140.42 samples/sec   Loss 1.1307   LearningRate 0.000001   Epoch: 1   Global Step: 53110   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:30:11,941-Speed 140.25 samples/sec   Loss 1.1181   LearningRate 0.000001   Epoch: 1   Global Step: 53120   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:30:14,221-Speed 140.41 samples/sec   Loss 1.1555   LearningRate 0.000001   Epoch: 1   Global Step: 53130   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:30:16,511-Speed 139.74 samples/sec   Loss 1.1412   LearningRate 0.000001   Epoch: 1   Global Step: 53140   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:30:18,847-Speed 137.06 samples/sec   Loss 1.1494   LearningRate 0.000001   Epoch: 1   Global Step: 53150   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:30:21,179-Speed 137.25 samples/sec   Loss 1.1246   LearningRate 0.000001   Epoch: 1   Global Step: 53160   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:30:23,477-Speed 139.31 samples/sec   Loss 1.1337   LearningRate 0.000001   Epoch: 1   Global Step: 53170   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:30:25,770-Speed 139.60 samples/sec   Loss 1.1504   LearningRate 0.000001   Epoch: 1   Global Step: 53180   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:30:28,070-Speed 139.12 samples/sec   Loss 1.1267   LearningRate 0.000001   Epoch: 1   Global Step: 53190   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:30:30,364-Speed 139.55 samples/sec   Loss 1.1437   LearningRate 0.000001   Epoch: 1   Global Step: 53200   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:30:32,649-Speed 140.06 samples/sec   Loss 1.1235   LearningRate 0.000001   Epoch: 1   Global Step: 53210   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:30:34,940-Speed 139.76 samples/sec   Loss 1.1438   LearningRate 0.000001   Epoch: 1   Global Step: 53220   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:30:37,240-Speed 139.13 samples/sec   Loss 1.1303   LearningRate 0.000001   Epoch: 1   Global Step: 53230   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:30:39,534-Speed 139.54 samples/sec   Loss 1.1343   LearningRate 0.000001   Epoch: 1   Global Step: 53240   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:30:41,822-Speed 139.91 samples/sec   Loss 1.1322   LearningRate 0.000001   Epoch: 1   Global Step: 53250   Fp16 Grad Scale: 65536   Required: 0 hours
Training: 2023-08-18 00:30:44,107-Speed 140.12 samples/sec   Loss 1.1244   LearningRate 0.000001   Epoch: 1   Global Step: 53260   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:30:46,397-Speed 139.73 samples/sec   Loss 1.1228   LearningRate 0.000001   Epoch: 1   Global Step: 53270   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:30:48,692-Speed 139.49 samples/sec   Loss 1.1366   LearningRate 0.000001   Epoch: 1   Global Step: 53280   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:30:50,995-Speed 139.02 samples/sec   Loss 1.1382   LearningRate 0.000001   Epoch: 1   Global Step: 53290   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:30:53,291-Speed 139.38 samples/sec   Loss 1.1331   LearningRate 0.000001   Epoch: 1   Global Step: 53300   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:30:55,604-Speed 138.42 samples/sec   Loss 1.1214   LearningRate 0.000001   Epoch: 1   Global Step: 53310   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:30:57,899-Speed 139.46 samples/sec   Loss 1.1288   LearningRate 0.000001   Epoch: 1   Global Step: 53320   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:31:00,208-Speed 138.64 samples/sec   Loss 1.1465   LearningRate 0.000001   Epoch: 1   Global Step: 53330   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:31:02,499-Speed 139.67 samples/sec   Loss 1.1508   LearningRate 0.000001   Epoch: 1   Global Step: 53340   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:31:04,796-Speed 139.37 samples/sec   Loss 1.1316   LearningRate 0.000001   Epoch: 1   Global Step: 53350   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:31:07,098-Speed 139.06 samples/sec   Loss 1.1529   LearningRate 0.000001   Epoch: 1   Global Step: 53360   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:31:09,396-Speed 139.29 samples/sec   Loss 1.1275   LearningRate 0.000001   Epoch: 1   Global Step: 53370   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:31:11,701-Speed 138.87 samples/sec   Loss 1.1377   LearningRate 0.000001   Epoch: 1   Global Step: 53380   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:31:14,008-Speed 138.76 samples/sec   Loss 1.1553   LearningRate 0.000001   Epoch: 1   Global Step: 53390   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:31:16,314-Speed 138.79 samples/sec   Loss 1.1477   LearningRate 0.000001   Epoch: 1   Global Step: 53400   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:31:18,617-Speed 138.97 samples/sec   Loss 1.1356   LearningRate 0.000001   Epoch: 1   Global Step: 53410   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:31:20,923-Speed 138.80 samples/sec   Loss 1.1509   LearningRate 0.000001   Epoch: 1   Global Step: 53420   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:31:23,220-Speed 139.37 samples/sec   Loss 1.1579   LearningRate 0.000001   Epoch: 1   Global Step: 53430   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:31:25,515-Speed 139.47 samples/sec   Loss 1.1487   LearningRate 0.000001   Epoch: 1   Global Step: 53440   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:31:27,833-Speed 138.11 samples/sec   Loss 1.1314   LearningRate 0.000001   Epoch: 1   Global Step: 53450   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:31:30,143-Speed 138.51 samples/sec   Loss 1.1213   LearningRate 0.000001   Epoch: 1   Global Step: 53460   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:31:32,433-Speed 139.81 samples/sec   Loss 1.1375   LearningRate 0.000001   Epoch: 1   Global Step: 53470   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:31:34,735-Speed 139.03 samples/sec   Loss 1.1772   LearningRate 0.000001   Epoch: 1   Global Step: 53480   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:31:37,026-Speed 139.73 samples/sec   Loss 1.1517   LearningRate 0.000001   Epoch: 1   Global Step: 53490   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:31:39,330-Speed 138.91 samples/sec   Loss 1.1326   LearningRate 0.000001   Epoch: 1   Global Step: 53500   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:31:41,637-Speed 138.74 samples/sec   Loss 1.1542   LearningRate 0.000001   Epoch: 1   Global Step: 53510   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:31:43,933-Speed 139.43 samples/sec   Loss 1.1443   LearningRate 0.000001   Epoch: 1   Global Step: 53520   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:31:46,231-Speed 139.27 samples/sec   Loss 1.1369   LearningRate 0.000001   Epoch: 1   Global Step: 53530   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:31:48,541-Speed 138.60 samples/sec   Loss 1.1321   LearningRate 0.000001   Epoch: 1   Global Step: 53540   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:31:50,830-Speed 139.80 samples/sec   Loss 1.1410   LearningRate 0.000001   Epoch: 1   Global Step: 53550   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:31:53,132-Speed 139.04 samples/sec   Loss 1.1234   LearningRate 0.000001   Epoch: 1   Global Step: 53560   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:31:55,424-Speed 139.66 samples/sec   Loss 1.1736   LearningRate 0.000001   Epoch: 1   Global Step: 53570   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:31:57,718-Speed 139.57 samples/sec   Loss 1.1211   LearningRate 0.000001   Epoch: 1   Global Step: 53580   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:32:00,004-Speed 139.98 samples/sec   Loss 1.1406   LearningRate 0.000001   Epoch: 1   Global Step: 53590   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:32:02,281-Speed 140.57 samples/sec   Loss 1.1384   LearningRate 0.000001   Epoch: 1   Global Step: 53600   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:32:04,541-Speed 141.69 samples/sec   Loss 1.1378   LearningRate 0.000001   Epoch: 1   Global Step: 53610   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:32:06,808-Speed 141.16 samples/sec   Loss 1.1285   LearningRate 0.000001   Epoch: 1   Global Step: 53620   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:32:09,089-Speed 140.34 samples/sec   Loss 1.1314   LearningRate 0.000001   Epoch: 1   Global Step: 53630   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:32:11,360-Speed 140.96 samples/sec   Loss 1.1431   LearningRate 0.000001   Epoch: 1   Global Step: 53640   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:32:13,635-Speed 140.72 samples/sec   Loss 1.1312   LearningRate 0.000001   Epoch: 1   Global Step: 53650   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:32:15,946-Speed 138.49 samples/sec   Loss 1.1127   LearningRate 0.000001   Epoch: 1   Global Step: 53660   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:32:18,249-Speed 138.95 samples/sec   Loss 1.1251   LearningRate 0.000001   Epoch: 1   Global Step: 53670   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:32:20,549-Speed 139.17 samples/sec   Loss 1.1446   LearningRate 0.000001   Epoch: 1   Global Step: 53680   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:32:22,829-Speed 140.45 samples/sec   Loss 1.1344   LearningRate 0.000001   Epoch: 1   Global Step: 53690   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:32:25,104-Speed 140.69 samples/sec   Loss 1.1321   LearningRate 0.000001   Epoch: 1   Global Step: 53700   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:32:27,381-Speed 140.58 samples/sec   Loss 1.1359   LearningRate 0.000001   Epoch: 1   Global Step: 53710   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:32:29,664-Speed 140.21 samples/sec   Loss 1.1448   LearningRate 0.000001   Epoch: 1   Global Step: 53720   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:32:31,961-Speed 139.30 samples/sec   Loss 1.1277   LearningRate 0.000001   Epoch: 1   Global Step: 53730   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:32:34,227-Speed 141.26 samples/sec   Loss 1.1400   LearningRate 0.000001   Epoch: 1   Global Step: 53740   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:32:36,508-Speed 140.36 samples/sec   Loss 1.1434   LearningRate 0.000001   Epoch: 1   Global Step: 53750   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:32:38,802-Speed 139.51 samples/sec   Loss 1.1329   LearningRate 0.000001   Epoch: 1   Global Step: 53760   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:32:41,096-Speed 139.59 samples/sec   Loss 1.1391   LearningRate 0.000001   Epoch: 1   Global Step: 53770   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:32:43,368-Speed 140.83 samples/sec   Loss 1.1245   LearningRate 0.000001   Epoch: 1   Global Step: 53780   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:32:45,652-Speed 140.15 samples/sec   Loss 1.1251   LearningRate 0.000001   Epoch: 1   Global Step: 53790   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:32:47,948-Speed 139.42 samples/sec   Loss 1.1149   LearningRate 0.000001   Epoch: 1   Global Step: 53800   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:32:50,226-Speed 140.48 samples/sec   Loss 1.1326   LearningRate 0.000001   Epoch: 1   Global Step: 53810   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:32:52,504-Speed 140.56 samples/sec   Loss 1.1383   LearningRate 0.000001   Epoch: 1   Global Step: 53820   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:32:54,780-Speed 140.62 samples/sec   Loss 1.1393   LearningRate 0.000001   Epoch: 1   Global Step: 53830   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:32:57,078-Speed 139.29 samples/sec   Loss 1.1326   LearningRate 0.000001   Epoch: 1   Global Step: 53840   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:32:59,349-Speed 140.94 samples/sec   Loss 1.1274   LearningRate 0.000001   Epoch: 1   Global Step: 53850   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:33:01,627-Speed 140.55 samples/sec   Loss 1.1252   LearningRate 0.000001   Epoch: 1   Global Step: 53860   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:33:03,911-Speed 140.16 samples/sec   Loss 1.1190   LearningRate 0.000001   Epoch: 1   Global Step: 53870   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:33:06,198-Speed 139.91 samples/sec   Loss 1.1399   LearningRate 0.000001   Epoch: 1   Global Step: 53880   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:33:08,496-Speed 139.32 samples/sec   Loss 1.1337   LearningRate 0.000001   Epoch: 1   Global Step: 53890   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:33:10,778-Speed 140.29 samples/sec   Loss 1.1561   LearningRate 0.000001   Epoch: 1   Global Step: 53900   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:33:13,070-Speed 139.59 samples/sec   Loss 1.1400   LearningRate 0.000001   Epoch: 1   Global Step: 53910   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:33:15,349-Speed 140.49 samples/sec   Loss 1.1222   LearningRate 0.000001   Epoch: 1   Global Step: 53920   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:33:17,637-Speed 139.89 samples/sec   Loss 1.1392   LearningRate 0.000001   Epoch: 1   Global Step: 53930   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:33:19,929-Speed 139.63 samples/sec   Loss 1.1343   LearningRate 0.000001   Epoch: 1   Global Step: 53940   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:33:22,208-Speed 140.51 samples/sec   Loss 1.1517   LearningRate 0.000001   Epoch: 1   Global Step: 53950   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:33:24,506-Speed 139.26 samples/sec   Loss 1.1521   LearningRate 0.000001   Epoch: 1   Global Step: 53960   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:33:26,791-Speed 140.05 samples/sec   Loss 1.1497   LearningRate 0.000001   Epoch: 1   Global Step: 53970   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:33:29,081-Speed 139.84 samples/sec   Loss 1.1423   LearningRate 0.000001   Epoch: 1   Global Step: 53980   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:33:31,370-Speed 139.79 samples/sec   Loss 1.1286   LearningRate 0.000001   Epoch: 1   Global Step: 53990   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:33:33,437-Val on RAF/AffectNet:
Training: 2023-08-18 00:33:33,548-Test: [0/48]	Time 0.110 (0.110)	Loss 0.5969 (0.5969)	Acc@1 90.625 (90.625)	Acc@5 98.438 (98.438)	Mem 5268MB
Training: 2023-08-18 00:33:34,612-Test: [10/48]	Time 0.106 (0.107)	Loss 0.5257 (0.5337)	Acc@1 93.750 (93.750)	Acc@5 98.438 (98.580)	Mem 5268MB
Training: 2023-08-18 00:33:35,657-Test: [20/48]	Time 0.103 (0.106)	Loss 0.6909 (0.5519)	Acc@1 84.375 (92.708)	Acc@5 96.875 (98.512)	Mem 5268MB
Training: 2023-08-18 00:33:36,707-Test: [30/48]	Time 0.109 (0.105)	Loss 0.5650 (0.5531)	Acc@1 92.188 (92.591)	Acc@5 96.875 (98.538)	Mem 5268MB
Training: 2023-08-18 00:33:37,748-Test: [40/48]	Time 0.103 (0.105)	Loss 0.5421 (0.5583)	Acc@1 92.188 (92.302)	Acc@5 100.000 (98.438)	Mem 5268MB
Training: 2023-08-18 00:33:38,477-[53999]Expression Loss: 0.55050
Training: 2023-08-18 00:33:38,478-[53999]Expression Acc@1: 92.53585
Training: 2023-08-18 00:33:38,478-[53999]Expression Acc@1-Highest: 92.86180
Training: 2023-08-18 00:33:38,478-[53999]Expression Acc@5: 98.50065
Training: 2023-08-18 00:33:38,478-[53999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-18 00:33:38,478-[53999]10 Times Expression Acc@1: 92.55215
Training: 2023-08-18 00:33:38,478-[53999]10 Times Expression Acc@1-Highest: 92.56193
Training: 2023-08-18 00:33:39,086-Speed 41.48 samples/sec   Loss 1.1423   LearningRate 0.000001   Epoch: 1   Global Step: 54000   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:33:41,360-Speed 140.73 samples/sec   Loss 1.1696   LearningRate 0.000001   Epoch: 1   Global Step: 54010   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:33:43,628-Speed 141.17 samples/sec   Loss 1.1321   LearningRate 0.000001   Epoch: 1   Global Step: 54020   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:33:45,897-Speed 141.06 samples/sec   Loss 1.1506   LearningRate 0.000001   Epoch: 1   Global Step: 54030   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:33:48,181-Speed 140.13 samples/sec   Loss 1.1077   LearningRate 0.000001   Epoch: 1   Global Step: 54040   Fp16 Grad Scale: 65536   Required: 0 hours
Training: 2023-08-18 00:33:50,458-Speed 140.59 samples/sec   Loss 1.1267   LearningRate 0.000001   Epoch: 1   Global Step: 54050   Fp16 Grad Scale: 65536   Required: 0 hours
Training: 2023-08-18 00:33:52,738-Speed 140.41 samples/sec   Loss 1.1541   LearningRate 0.000001   Epoch: 1   Global Step: 54060   Fp16 Grad Scale: 65536   Required: 0 hours
Training: 2023-08-18 00:33:55,026-Speed 139.90 samples/sec   Loss 1.1306   LearningRate 0.000001   Epoch: 1   Global Step: 54070   Fp16 Grad Scale: 65536   Required: 0 hours
Training: 2023-08-18 00:33:57,299-Speed 140.83 samples/sec   Loss 1.1237   LearningRate 0.000001   Epoch: 1   Global Step: 54080   Fp16 Grad Scale: 65536   Required: 0 hours
Training: 2023-08-18 00:33:59,580-Speed 140.27 samples/sec   Loss 1.1578   LearningRate 0.000001   Epoch: 1   Global Step: 54090   Fp16 Grad Scale: 65536   Required: 0 hours
Training: 2023-08-18 00:34:01,845-Speed 141.38 samples/sec   Loss 1.1425   LearningRate 0.000001   Epoch: 1   Global Step: 54100   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:34:04,132-Speed 139.94 samples/sec   Loss 1.1428   LearningRate 0.000001   Epoch: 1   Global Step: 54110   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:34:06,394-Speed 141.49 samples/sec   Loss 1.1629   LearningRate 0.000001   Epoch: 1   Global Step: 54120   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:34:08,672-Speed 140.51 samples/sec   Loss 1.1255   LearningRate 0.000001   Epoch: 1   Global Step: 54130   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:34:10,953-Speed 140.34 samples/sec   Loss 1.1416   LearningRate 0.000001   Epoch: 1   Global Step: 54140   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:34:13,236-Speed 140.20 samples/sec   Loss 1.1599   LearningRate 0.000001   Epoch: 1   Global Step: 54150   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:34:15,528-Speed 139.65 samples/sec   Loss 1.1449   LearningRate 0.000001   Epoch: 1   Global Step: 54160   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:34:17,811-Speed 140.25 samples/sec   Loss 1.1327   LearningRate 0.000001   Epoch: 1   Global Step: 54170   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:34:20,089-Speed 140.49 samples/sec   Loss 1.1271   LearningRate 0.000001   Epoch: 1   Global Step: 54180   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:34:22,363-Speed 140.80 samples/sec   Loss 1.1386   LearningRate 0.000001   Epoch: 1   Global Step: 54190   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:34:24,643-Speed 140.35 samples/sec   Loss 1.1411   LearningRate 0.000001   Epoch: 1   Global Step: 54200   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:34:26,937-Speed 139.53 samples/sec   Loss 1.1423   LearningRate 0.000001   Epoch: 1   Global Step: 54210   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:34:29,205-Speed 141.13 samples/sec   Loss 1.1070   LearningRate 0.000001   Epoch: 1   Global Step: 54220   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:34:31,484-Speed 140.48 samples/sec   Loss 1.1160   LearningRate 0.000001   Epoch: 1   Global Step: 54230   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:34:33,769-Speed 140.07 samples/sec   Loss 1.1624   LearningRate 0.000001   Epoch: 1   Global Step: 54240   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:34:36,054-Speed 140.11 samples/sec   Loss 1.1493   LearningRate 0.000001   Epoch: 1   Global Step: 54250   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:34:38,332-Speed 140.53 samples/sec   Loss 1.1306   LearningRate 0.000001   Epoch: 1   Global Step: 54260   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:34:40,612-Speed 140.37 samples/sec   Loss 1.1062   LearningRate 0.000001   Epoch: 1   Global Step: 54270   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:34:42,898-Speed 140.05 samples/sec   Loss 1.1171   LearningRate 0.000001   Epoch: 1   Global Step: 54280   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:34:45,176-Speed 140.47 samples/sec   Loss 1.1453   LearningRate 0.000001   Epoch: 1   Global Step: 54290   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:34:47,464-Speed 139.90 samples/sec   Loss 1.1422   LearningRate 0.000001   Epoch: 1   Global Step: 54300   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:34:49,749-Speed 140.09 samples/sec   Loss 1.1096   LearningRate 0.000001   Epoch: 1   Global Step: 54310   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:34:52,046-Speed 139.35 samples/sec   Loss 1.1253   LearningRate 0.000001   Epoch: 1   Global Step: 54320   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:34:54,334-Speed 139.92 samples/sec   Loss 1.1586   LearningRate 0.000001   Epoch: 1   Global Step: 54330   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:34:56,627-Speed 139.59 samples/sec   Loss 1.1348   LearningRate 0.000001   Epoch: 1   Global Step: 54340   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:34:58,910-Speed 140.22 samples/sec   Loss 1.1452   LearningRate 0.000001   Epoch: 1   Global Step: 54350   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:35:01,179-Speed 141.03 samples/sec   Loss 1.1321   LearningRate 0.000001   Epoch: 1   Global Step: 54360   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:35:03,459-Speed 140.42 samples/sec   Loss 1.1204   LearningRate 0.000001   Epoch: 1   Global Step: 54370   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:35:05,738-Speed 140.43 samples/sec   Loss 1.1315   LearningRate 0.000001   Epoch: 1   Global Step: 54380   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:35:08,027-Speed 139.85 samples/sec   Loss 1.1254   LearningRate 0.000001   Epoch: 1   Global Step: 54390   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:35:10,299-Speed 140.88 samples/sec   Loss 1.1293   LearningRate 0.000001   Epoch: 1   Global Step: 54400   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:35:12,587-Speed 139.92 samples/sec   Loss 1.1512   LearningRate 0.000001   Epoch: 1   Global Step: 54410   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:35:14,863-Speed 140.61 samples/sec   Loss 1.1451   LearningRate 0.000001   Epoch: 1   Global Step: 54420   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:35:17,137-Speed 140.75 samples/sec   Loss 1.1390   LearningRate 0.000001   Epoch: 1   Global Step: 54430   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:35:19,423-Speed 140.05 samples/sec   Loss 1.1443   LearningRate 0.000001   Epoch: 1   Global Step: 54440   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:35:21,699-Speed 140.64 samples/sec   Loss 1.1470   LearningRate 0.000001   Epoch: 1   Global Step: 54450   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:35:23,979-Speed 140.37 samples/sec   Loss 1.1245   LearningRate 0.000001   Epoch: 1   Global Step: 54460   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:35:26,265-Speed 140.06 samples/sec   Loss 1.1301   LearningRate 0.000001   Epoch: 1   Global Step: 54470   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:35:28,541-Speed 140.63 samples/sec   Loss 1.1460   LearningRate 0.000001   Epoch: 1   Global Step: 54480   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:35:30,825-Speed 140.16 samples/sec   Loss 1.1053   LearningRate 0.000001   Epoch: 1   Global Step: 54490   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:35:33,130-Speed 138.87 samples/sec   Loss 1.1427   LearningRate 0.000001   Epoch: 1   Global Step: 54500   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:35:35,426-Speed 139.38 samples/sec   Loss 1.1439   LearningRate 0.000001   Epoch: 1   Global Step: 54510   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:35:37,702-Speed 140.67 samples/sec   Loss 1.1445   LearningRate 0.000001   Epoch: 1   Global Step: 54520   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:35:40,011-Speed 138.57 samples/sec   Loss 1.1222   LearningRate 0.000001   Epoch: 1   Global Step: 54530   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:35:42,326-Speed 138.32 samples/sec   Loss 1.1372   LearningRate 0.000001   Epoch: 1   Global Step: 54540   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:35:44,640-Speed 138.32 samples/sec   Loss 1.1627   LearningRate 0.000001   Epoch: 1   Global Step: 54550   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:35:46,955-Speed 138.25 samples/sec   Loss 1.1116   LearningRate 0.000001   Epoch: 1   Global Step: 54560   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:35:49,268-Speed 138.41 samples/sec   Loss 1.1507   LearningRate 0.000001   Epoch: 1   Global Step: 54570   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:35:51,568-Speed 139.13 samples/sec   Loss 1.1536   LearningRate 0.000001   Epoch: 1   Global Step: 54580   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:35:53,856-Speed 139.91 samples/sec   Loss 1.1345   LearningRate 0.000001   Epoch: 1   Global Step: 54590   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:35:56,133-Speed 140.56 samples/sec   Loss 1.1565   LearningRate 0.000001   Epoch: 1   Global Step: 54600   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:35:58,410-Speed 140.60 samples/sec   Loss 1.1189   LearningRate 0.000001   Epoch: 1   Global Step: 54610   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:36:00,676-Speed 141.24 samples/sec   Loss 1.1622   LearningRate 0.000001   Epoch: 1   Global Step: 54620   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:36:02,960-Speed 140.18 samples/sec   Loss 1.1451   LearningRate 0.000001   Epoch: 1   Global Step: 54630   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:36:05,248-Speed 139.88 samples/sec   Loss 1.1229   LearningRate 0.000001   Epoch: 1   Global Step: 54640   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:36:07,523-Speed 140.71 samples/sec   Loss 1.1169   LearningRate 0.000001   Epoch: 1   Global Step: 54650   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:36:09,797-Speed 140.73 samples/sec   Loss 1.1257   LearningRate 0.000001   Epoch: 1   Global Step: 54660   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:36:12,057-Speed 141.69 samples/sec   Loss 1.1464   LearningRate 0.000001   Epoch: 1   Global Step: 54670   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:36:14,339-Speed 140.26 samples/sec   Loss 1.1312   LearningRate 0.000001   Epoch: 1   Global Step: 54680   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:36:16,623-Speed 140.09 samples/sec   Loss 1.1322   LearningRate 0.000001   Epoch: 1   Global Step: 54690   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:36:18,897-Speed 140.77 samples/sec   Loss 1.1184   LearningRate 0.000001   Epoch: 1   Global Step: 54700   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:36:21,171-Speed 140.77 samples/sec   Loss 1.1292   LearningRate 0.000001   Epoch: 1   Global Step: 54710   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:36:23,442-Speed 140.99 samples/sec   Loss 1.1390   LearningRate 0.000001   Epoch: 1   Global Step: 54720   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:36:25,728-Speed 139.98 samples/sec   Loss 1.1632   LearningRate 0.000001   Epoch: 1   Global Step: 54730   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:36:28,012-Speed 140.15 samples/sec   Loss 1.1465   LearningRate 0.000001   Epoch: 1   Global Step: 54740   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:36:30,297-Speed 140.12 samples/sec   Loss 1.1341   LearningRate 0.000001   Epoch: 1   Global Step: 54750   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:36:32,570-Speed 140.82 samples/sec   Loss 1.1257   LearningRate 0.000001   Epoch: 1   Global Step: 54760   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:36:34,848-Speed 140.49 samples/sec   Loss 1.1396   LearningRate 0.000001   Epoch: 1   Global Step: 54770   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:36:37,129-Speed 140.34 samples/sec   Loss 1.1254   LearningRate 0.000001   Epoch: 1   Global Step: 54780   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:36:39,399-Speed 140.98 samples/sec   Loss 1.1426   LearningRate 0.000001   Epoch: 1   Global Step: 54790   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:36:41,677-Speed 140.55 samples/sec   Loss 1.1244   LearningRate 0.000001   Epoch: 1   Global Step: 54800   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:36:43,956-Speed 140.42 samples/sec   Loss 1.1433   LearningRate 0.000001   Epoch: 1   Global Step: 54810   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:36:46,247-Speed 139.76 samples/sec   Loss 1.1257   LearningRate 0.000001   Epoch: 1   Global Step: 54820   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:36:48,519-Speed 140.89 samples/sec   Loss 1.1232   LearningRate 0.000001   Epoch: 1   Global Step: 54830   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:36:50,794-Speed 140.64 samples/sec   Loss 1.1336   LearningRate 0.000001   Epoch: 1   Global Step: 54840   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:36:53,085-Speed 139.76 samples/sec   Loss 1.1369   LearningRate 0.000001   Epoch: 1   Global Step: 54850   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:36:55,374-Speed 139.85 samples/sec   Loss 1.1438   LearningRate 0.000001   Epoch: 1   Global Step: 54860   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:36:57,672-Speed 139.26 samples/sec   Loss 1.1552   LearningRate 0.000001   Epoch: 1   Global Step: 54870   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:36:59,957-Speed 140.09 samples/sec   Loss 1.1391   LearningRate 0.000001   Epoch: 1   Global Step: 54880   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:37:02,241-Speed 140.18 samples/sec   Loss 1.1476   LearningRate 0.000001   Epoch: 1   Global Step: 54890   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:37:04,528-Speed 139.94 samples/sec   Loss 1.1318   LearningRate 0.000001   Epoch: 1   Global Step: 54900   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:37:06,812-Speed 140.17 samples/sec   Loss 1.1729   LearningRate 0.000001   Epoch: 1   Global Step: 54910   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:37:09,084-Speed 140.84 samples/sec   Loss 1.1593   LearningRate 0.000001   Epoch: 1   Global Step: 54920   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:37:11,365-Speed 140.37 samples/sec   Loss 1.1487   LearningRate 0.000001   Epoch: 1   Global Step: 54930   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:37:13,638-Speed 140.76 samples/sec   Loss 1.1174   LearningRate 0.000001   Epoch: 1   Global Step: 54940   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:37:15,910-Speed 140.96 samples/sec   Loss 1.1475   LearningRate 0.000001   Epoch: 1   Global Step: 54950   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:37:18,190-Speed 140.37 samples/sec   Loss 1.1469   LearningRate 0.000001   Epoch: 1   Global Step: 54960   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:37:20,479-Speed 139.80 samples/sec   Loss 1.1215   LearningRate 0.000001   Epoch: 1   Global Step: 54970   Fp16 Grad Scale: 65536   Required: 0 hours
Training: 2023-08-18 00:37:22,754-Speed 140.72 samples/sec   Loss 1.1295   LearningRate 0.000001   Epoch: 1   Global Step: 54980   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:37:25,041-Speed 139.94 samples/sec   Loss 1.1424   LearningRate 0.000001   Epoch: 1   Global Step: 54990   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:37:27,093-Val on RAF/AffectNet:
Training: 2023-08-18 00:37:27,203-Test: [0/48]	Time 0.110 (0.110)	Loss 0.5518 (0.5518)	Acc@1 93.750 (93.750)	Acc@5 98.438 (98.438)	Mem 5268MB
Training: 2023-08-18 00:37:28,261-Test: [10/48]	Time 0.103 (0.106)	Loss 0.5050 (0.5305)	Acc@1 92.188 (92.898)	Acc@5 98.438 (98.580)	Mem 5268MB
Training: 2023-08-18 00:37:29,311-Test: [20/48]	Time 0.105 (0.106)	Loss 0.5184 (0.5451)	Acc@1 95.312 (92.783)	Acc@5 100.000 (98.438)	Mem 5268MB
Training: 2023-08-18 00:37:30,357-Test: [30/48]	Time 0.103 (0.105)	Loss 0.5869 (0.5425)	Acc@1 95.312 (92.944)	Acc@5 96.875 (98.488)	Mem 5268MB
Training: 2023-08-18 00:37:31,403-Test: [40/48]	Time 0.104 (0.105)	Loss 0.6161 (0.5563)	Acc@1 89.062 (92.378)	Acc@5 95.312 (98.361)	Mem 5268MB
Training: 2023-08-18 00:37:32,145-[54999]Expression Loss: 0.55037
Training: 2023-08-18 00:37:32,146-[54999]Expression Acc@1: 92.56845
Training: 2023-08-18 00:37:32,146-[54999]Expression Acc@1-Highest: 92.86180
Training: 2023-08-18 00:37:32,146-[54999]Expression Acc@5: 98.46806
Training: 2023-08-18 00:37:32,146-[54999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-18 00:37:32,146-[54999]10 Times Expression Acc@1: 92.56845
Training: 2023-08-18 00:37:32,146-[54999]10 Times Expression Acc@1-Highest: 92.56845
Training: 2023-08-18 00:37:32,374-Speed 43.65 samples/sec   Loss 1.1323   LearningRate 0.000001   Epoch: 1   Global Step: 55000   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:37:34,647-Speed 140.80 samples/sec   Loss 1.1274   LearningRate 0.000001   Epoch: 1   Global Step: 55010   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:37:36,912-Speed 141.33 samples/sec   Loss 1.1262   LearningRate 0.000001   Epoch: 1   Global Step: 55020   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:37:39,168-Speed 141.89 samples/sec   Loss 1.1309   LearningRate 0.000001   Epoch: 1   Global Step: 55030   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:37:41,441-Speed 140.80 samples/sec   Loss 1.1608   LearningRate 0.000001   Epoch: 1   Global Step: 55040   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:37:43,715-Speed 140.77 samples/sec   Loss 1.1470   LearningRate 0.000001   Epoch: 1   Global Step: 55050   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:37:45,997-Speed 140.27 samples/sec   Loss 1.1311   LearningRate 0.000001   Epoch: 1   Global Step: 55060   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:37:48,246-Speed 142.34 samples/sec   Loss 1.1434   LearningRate 0.000001   Epoch: 1   Global Step: 55070   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:37:50,513-Speed 141.20 samples/sec   Loss 1.1414   LearningRate 0.000001   Epoch: 1   Global Step: 55080   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:37:52,791-Speed 140.50 samples/sec   Loss 1.1575   LearningRate 0.000001   Epoch: 1   Global Step: 55090   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:37:55,063-Speed 140.88 samples/sec   Loss 1.1485   LearningRate 0.000001   Epoch: 1   Global Step: 55100   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:37:57,345-Speed 140.28 samples/sec   Loss 1.1399   LearningRate 0.000001   Epoch: 1   Global Step: 55110   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:37:59,614-Speed 141.08 samples/sec   Loss 1.1217   LearningRate 0.000001   Epoch: 1   Global Step: 55120   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:38:01,904-Speed 139.74 samples/sec   Loss 1.1525   LearningRate 0.000001   Epoch: 1   Global Step: 55130   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:38:04,185-Speed 140.34 samples/sec   Loss 1.1424   LearningRate 0.000001   Epoch: 1   Global Step: 55140   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:38:06,471-Speed 140.00 samples/sec   Loss 1.1374   LearningRate 0.000001   Epoch: 1   Global Step: 55150   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:38:08,748-Speed 140.60 samples/sec   Loss 1.1320   LearningRate 0.000001   Epoch: 1   Global Step: 55160   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:38:11,020-Speed 140.88 samples/sec   Loss 1.1301   LearningRate 0.000001   Epoch: 1   Global Step: 55170   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:38:13,296-Speed 140.67 samples/sec   Loss 1.1269   LearningRate 0.000001   Epoch: 1   Global Step: 55180   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:38:15,608-Speed 138.43 samples/sec   Loss 1.1487   LearningRate 0.000001   Epoch: 1   Global Step: 55190   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:38:17,915-Speed 138.76 samples/sec   Loss 1.1364   LearningRate 0.000001   Epoch: 1   Global Step: 55200   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:38:20,216-Speed 139.06 samples/sec   Loss 1.1485   LearningRate 0.000001   Epoch: 1   Global Step: 55210   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:38:22,516-Speed 139.17 samples/sec   Loss 1.1200   LearningRate 0.000001   Epoch: 1   Global Step: 55220   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:38:24,809-Speed 139.58 samples/sec   Loss 1.1268   LearningRate 0.000001   Epoch: 1   Global Step: 55230   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:38:27,120-Speed 138.52 samples/sec   Loss 1.1513   LearningRate 0.000001   Epoch: 1   Global Step: 55240   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:38:29,424-Speed 138.94 samples/sec   Loss 1.1163   LearningRate 0.000001   Epoch: 1   Global Step: 55250   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:38:31,713-Speed 139.83 samples/sec   Loss 1.1421   LearningRate 0.000001   Epoch: 1   Global Step: 55260   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:38:34,018-Speed 138.86 samples/sec   Loss 1.1484   LearningRate 0.000001   Epoch: 1   Global Step: 55270   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:38:36,306-Speed 139.90 samples/sec   Loss 1.1282   LearningRate 0.000001   Epoch: 1   Global Step: 55280   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:38:38,600-Speed 139.52 samples/sec   Loss 1.1330   LearningRate 0.000001   Epoch: 1   Global Step: 55290   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:38:40,897-Speed 139.37 samples/sec   Loss 1.1378   LearningRate 0.000001   Epoch: 1   Global Step: 55300   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:38:43,199-Speed 139.05 samples/sec   Loss 1.1251   LearningRate 0.000001   Epoch: 1   Global Step: 55310   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:38:45,495-Speed 139.39 samples/sec   Loss 1.1561   LearningRate 0.000001   Epoch: 1   Global Step: 55320   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:38:47,787-Speed 139.62 samples/sec   Loss 1.1108   LearningRate 0.000001   Epoch: 1   Global Step: 55330   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:38:50,084-Speed 139.37 samples/sec   Loss 1.1631   LearningRate 0.000001   Epoch: 1   Global Step: 55340   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:38:52,372-Speed 139.92 samples/sec   Loss 1.1193   LearningRate 0.000001   Epoch: 1   Global Step: 55350   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:38:54,639-Speed 141.14 samples/sec   Loss 1.1280   LearningRate 0.000001   Epoch: 1   Global Step: 55360   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:38:56,948-Speed 138.62 samples/sec   Loss 1.1300   LearningRate 0.000001   Epoch: 1   Global Step: 55370   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:38:59,232-Speed 140.19 samples/sec   Loss 1.1618   LearningRate 0.000001   Epoch: 1   Global Step: 55380   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:39:01,505-Speed 140.80 samples/sec   Loss 1.1218   LearningRate 0.000001   Epoch: 1   Global Step: 55390   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:39:03,796-Speed 139.70 samples/sec   Loss 1.1730   LearningRate 0.000001   Epoch: 1   Global Step: 55400   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:39:06,092-Speed 139.40 samples/sec   Loss 1.1397   LearningRate 0.000001   Epoch: 1   Global Step: 55410   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:39:08,383-Speed 139.77 samples/sec   Loss 1.1185   LearningRate 0.000001   Epoch: 1   Global Step: 55420   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:39:10,669-Speed 139.98 samples/sec   Loss 1.1436   LearningRate 0.000001   Epoch: 1   Global Step: 55430   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:39:12,956-Speed 139.99 samples/sec   Loss 1.1324   LearningRate 0.000001   Epoch: 1   Global Step: 55440   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:39:15,244-Speed 139.89 samples/sec   Loss 1.1318   LearningRate 0.000001   Epoch: 1   Global Step: 55450   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:39:17,558-Speed 138.31 samples/sec   Loss 1.1361   LearningRate 0.000001   Epoch: 1   Global Step: 55460   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:39:19,850-Speed 139.67 samples/sec   Loss 1.1326   LearningRate 0.000001   Epoch: 1   Global Step: 55470   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:39:22,126-Speed 140.64 samples/sec   Loss 1.1333   LearningRate 0.000001   Epoch: 1   Global Step: 55480   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:39:24,422-Speed 139.42 samples/sec   Loss 1.1367   LearningRate 0.000001   Epoch: 1   Global Step: 55490   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:39:26,713-Speed 139.73 samples/sec   Loss 1.1520   LearningRate 0.000001   Epoch: 1   Global Step: 55500   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:39:29,007-Speed 139.52 samples/sec   Loss 1.1443   LearningRate 0.000001   Epoch: 1   Global Step: 55510   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:39:31,290-Speed 140.18 samples/sec   Loss 1.1160   LearningRate 0.000001   Epoch: 1   Global Step: 55520   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:39:33,571-Speed 140.35 samples/sec   Loss 1.1368   LearningRate 0.000001   Epoch: 1   Global Step: 55530   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:39:35,868-Speed 139.35 samples/sec   Loss 1.1293   LearningRate 0.000001   Epoch: 1   Global Step: 55540   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:39:38,151-Speed 140.20 samples/sec   Loss 1.1403   LearningRate 0.000001   Epoch: 1   Global Step: 55550   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:39:40,440-Speed 139.83 samples/sec   Loss 1.1427   LearningRate 0.000001   Epoch: 1   Global Step: 55560   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:39:42,751-Speed 138.54 samples/sec   Loss 1.1294   LearningRate 0.000001   Epoch: 1   Global Step: 55570   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:39:45,038-Speed 139.96 samples/sec   Loss 1.1379   LearningRate 0.000001   Epoch: 1   Global Step: 55580   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:39:47,336-Speed 139.25 samples/sec   Loss 1.1567   LearningRate 0.000001   Epoch: 1   Global Step: 55590   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:39:49,651-Speed 138.27 samples/sec   Loss 1.1342   LearningRate 0.000001   Epoch: 1   Global Step: 55600   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:39:51,942-Speed 139.74 samples/sec   Loss 1.1036   LearningRate 0.000001   Epoch: 1   Global Step: 55610   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:39:54,226-Speed 140.14 samples/sec   Loss 1.1558   LearningRate 0.000001   Epoch: 1   Global Step: 55620   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:39:56,523-Speed 139.36 samples/sec   Loss 1.1349   LearningRate 0.000001   Epoch: 1   Global Step: 55630   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:39:58,799-Speed 140.63 samples/sec   Loss 1.1187   LearningRate 0.000001   Epoch: 1   Global Step: 55640   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:40:01,089-Speed 139.78 samples/sec   Loss 1.1553   LearningRate 0.000001   Epoch: 1   Global Step: 55650   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:40:03,379-Speed 139.81 samples/sec   Loss 1.1535   LearningRate 0.000001   Epoch: 1   Global Step: 55660   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:40:05,678-Speed 139.17 samples/sec   Loss 1.1405   LearningRate 0.000001   Epoch: 1   Global Step: 55670   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:40:07,958-Speed 140.46 samples/sec   Loss 1.1622   LearningRate 0.000001   Epoch: 1   Global Step: 55680   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:40:10,249-Speed 139.69 samples/sec   Loss 1.1509   LearningRate 0.000001   Epoch: 1   Global Step: 55690   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:40:12,536-Speed 139.94 samples/sec   Loss 1.1235   LearningRate 0.000001   Epoch: 1   Global Step: 55700   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:40:14,828-Speed 139.69 samples/sec   Loss 1.1287   LearningRate 0.000001   Epoch: 1   Global Step: 55710   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:40:17,137-Speed 138.61 samples/sec   Loss 1.1173   LearningRate 0.000001   Epoch: 1   Global Step: 55720   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:40:19,431-Speed 139.55 samples/sec   Loss 1.1274   LearningRate 0.000001   Epoch: 1   Global Step: 55730   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:40:21,741-Speed 138.54 samples/sec   Loss 1.1250   LearningRate 0.000001   Epoch: 1   Global Step: 55740   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:40:24,063-Speed 137.86 samples/sec   Loss 1.1369   LearningRate 0.000001   Epoch: 1   Global Step: 55750   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:40:26,390-Speed 137.56 samples/sec   Loss 1.1268   LearningRate 0.000001   Epoch: 1   Global Step: 55760   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:40:28,699-Speed 138.63 samples/sec   Loss 1.1351   LearningRate 0.000001   Epoch: 1   Global Step: 55770   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:40:31,018-Speed 138.06 samples/sec   Loss 1.1262   LearningRate 0.000001   Epoch: 1   Global Step: 55780   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:40:33,328-Speed 138.51 samples/sec   Loss 1.1330   LearningRate 0.000001   Epoch: 1   Global Step: 55790   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:40:35,611-Speed 140.23 samples/sec   Loss 1.1670   LearningRate 0.000001   Epoch: 1   Global Step: 55800   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:40:37,910-Speed 139.20 samples/sec   Loss 1.1334   LearningRate 0.000001   Epoch: 1   Global Step: 55810   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:40:40,191-Speed 140.33 samples/sec   Loss 1.1727   LearningRate 0.000001   Epoch: 1   Global Step: 55820   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:40:42,484-Speed 139.62 samples/sec   Loss 1.1272   LearningRate 0.000001   Epoch: 1   Global Step: 55830   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:40:44,773-Speed 139.82 samples/sec   Loss 1.1491   LearningRate 0.000001   Epoch: 1   Global Step: 55840   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:40:47,059-Speed 140.02 samples/sec   Loss 1.1262   LearningRate 0.000001   Epoch: 1   Global Step: 55850   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:40:49,346-Speed 139.97 samples/sec   Loss 1.1556   LearningRate 0.000001   Epoch: 1   Global Step: 55860   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:40:51,636-Speed 139.82 samples/sec   Loss 1.1245   LearningRate 0.000001   Epoch: 1   Global Step: 55870   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:40:53,938-Speed 139.01 samples/sec   Loss 1.1482   LearningRate 0.000001   Epoch: 1   Global Step: 55880   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:40:56,221-Speed 140.24 samples/sec   Loss 1.1258   LearningRate 0.000001   Epoch: 1   Global Step: 55890   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:40:58,515-Speed 139.49 samples/sec   Loss 1.1321   LearningRate 0.000001   Epoch: 1   Global Step: 55900   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:41:00,807-Speed 139.67 samples/sec   Loss 1.1441   LearningRate 0.000001   Epoch: 1   Global Step: 55910   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:41:03,090-Speed 140.19 samples/sec   Loss 1.1486   LearningRate 0.000001   Epoch: 1   Global Step: 55920   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:41:05,387-Speed 139.42 samples/sec   Loss 1.1368   LearningRate 0.000001   Epoch: 1   Global Step: 55930   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:41:07,684-Speed 139.33 samples/sec   Loss 1.1194   LearningRate 0.000001   Epoch: 1   Global Step: 55940   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:41:09,966-Speed 140.26 samples/sec   Loss 1.1214   LearningRate 0.000001   Epoch: 1   Global Step: 55950   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:41:12,254-Speed 139.90 samples/sec   Loss 1.1329   LearningRate 0.000001   Epoch: 1   Global Step: 55960   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:41:14,542-Speed 139.92 samples/sec   Loss 1.1322   LearningRate 0.000001   Epoch: 1   Global Step: 55970   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:41:16,836-Speed 139.50 samples/sec   Loss 1.1360   LearningRate 0.000001   Epoch: 1   Global Step: 55980   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:41:19,117-Speed 140.35 samples/sec   Loss 1.1387   LearningRate 0.000001   Epoch: 1   Global Step: 55990   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:41:21,176-Val on RAF/AffectNet:
Training: 2023-08-18 00:41:21,289-Test: [0/48]	Time 0.113 (0.113)	Loss 0.6463 (0.6463)	Acc@1 87.500 (87.500)	Acc@5 95.312 (95.312)	Mem 5268MB
Training: 2023-08-18 00:41:22,413-Test: [10/48]	Time 0.112 (0.112)	Loss 0.4938 (0.5651)	Acc@1 95.312 (91.761)	Acc@5 100.000 (98.011)	Mem 5268MB
Training: 2023-08-18 00:41:23,509-Test: [20/48]	Time 0.105 (0.111)	Loss 0.5316 (0.5772)	Acc@1 95.312 (91.741)	Acc@5 96.875 (97.842)	Mem 5268MB
Training: 2023-08-18 00:41:24,584-Test: [30/48]	Time 0.106 (0.110)	Loss 0.5525 (0.5571)	Acc@1 93.750 (92.641)	Acc@5 98.438 (98.236)	Mem 5268MB
Training: 2023-08-18 00:41:25,651-Test: [40/48]	Time 0.107 (0.109)	Loss 0.5756 (0.5532)	Acc@1 90.625 (92.721)	Acc@5 98.438 (98.323)	Mem 5268MB
Training: 2023-08-18 00:41:26,395-[55999]Expression Loss: 0.54855
Training: 2023-08-18 00:41:26,396-[55999]Expression Acc@1: 92.69883
Training: 2023-08-18 00:41:26,396-[55999]Expression Acc@1-Highest: 92.86180
Training: 2023-08-18 00:41:26,396-[55999]Expression Acc@5: 98.46806
Training: 2023-08-18 00:41:26,396-[55999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-18 00:41:26,396-[55999]10 Times Expression Acc@1: 92.58801
Training: 2023-08-18 00:41:26,396-[55999]10 Times Expression Acc@1-Highest: 92.58801
Training: 2023-08-18 00:41:26,630-Speed 42.60 samples/sec   Loss 1.1269   LearningRate 0.000001   Epoch: 1   Global Step: 56000   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:41:28,911-Speed 140.34 samples/sec   Loss 1.1344   LearningRate 0.000001   Epoch: 1   Global Step: 56010   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:41:31,187-Speed 140.66 samples/sec   Loss 1.1383   LearningRate 0.000001   Epoch: 1   Global Step: 56020   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:41:33,462-Speed 140.70 samples/sec   Loss 1.1370   LearningRate 0.000001   Epoch: 1   Global Step: 56030   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:41:35,759-Speed 139.37 samples/sec   Loss 1.1355   LearningRate 0.000001   Epoch: 1   Global Step: 56040   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:41:38,012-Speed 142.07 samples/sec   Loss 1.1519   LearningRate 0.000001   Epoch: 1   Global Step: 56050   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:41:40,302-Speed 139.76 samples/sec   Loss 1.1093   LearningRate 0.000001   Epoch: 1   Global Step: 56060   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:41:42,585-Speed 140.21 samples/sec   Loss 1.1052   LearningRate 0.000001   Epoch: 1   Global Step: 56070   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:41:44,864-Speed 140.43 samples/sec   Loss 1.1319   LearningRate 0.000001   Epoch: 1   Global Step: 56080   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:41:47,159-Speed 139.51 samples/sec   Loss 1.1482   LearningRate 0.000001   Epoch: 1   Global Step: 56090   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:41:49,455-Speed 139.41 samples/sec   Loss 1.1403   LearningRate 0.000001   Epoch: 1   Global Step: 56100   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:41:51,746-Speed 139.72 samples/sec   Loss 1.1452   LearningRate 0.000001   Epoch: 1   Global Step: 56110   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:41:54,032-Speed 140.00 samples/sec   Loss 1.1343   LearningRate 0.000001   Epoch: 1   Global Step: 56120   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:41:56,322-Speed 139.75 samples/sec   Loss 1.1282   LearningRate 0.000001   Epoch: 1   Global Step: 56130   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:41:58,615-Speed 139.63 samples/sec   Loss 1.1364   LearningRate 0.000001   Epoch: 1   Global Step: 56140   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:42:00,914-Speed 139.25 samples/sec   Loss 1.1202   LearningRate 0.000001   Epoch: 1   Global Step: 56150   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:42:03,193-Speed 140.42 samples/sec   Loss 1.1342   LearningRate 0.000001   Epoch: 1   Global Step: 56160   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:42:05,476-Speed 140.19 samples/sec   Loss 1.1437   LearningRate 0.000001   Epoch: 1   Global Step: 56170   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:42:07,752-Speed 140.68 samples/sec   Loss 1.1579   LearningRate 0.000001   Epoch: 1   Global Step: 56180   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:42:10,032-Speed 140.36 samples/sec   Loss 1.1542   LearningRate 0.000001   Epoch: 1   Global Step: 56190   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:42:12,308-Speed 140.64 samples/sec   Loss 1.1494   LearningRate 0.000001   Epoch: 1   Global Step: 56200   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:42:14,582-Speed 140.74 samples/sec   Loss 1.1424   LearningRate 0.000001   Epoch: 1   Global Step: 56210   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:42:16,870-Speed 139.93 samples/sec   Loss 1.1367   LearningRate 0.000001   Epoch: 1   Global Step: 56220   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:42:19,147-Speed 140.58 samples/sec   Loss 1.1507   LearningRate 0.000001   Epoch: 1   Global Step: 56230   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:42:21,434-Speed 139.92 samples/sec   Loss 1.1557   LearningRate 0.000001   Epoch: 1   Global Step: 56240   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:42:23,723-Speed 139.84 samples/sec   Loss 1.1375   LearningRate 0.000001   Epoch: 1   Global Step: 56250   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:42:25,999-Speed 140.64 samples/sec   Loss 1.1421   LearningRate 0.000001   Epoch: 1   Global Step: 56260   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:42:28,259-Speed 141.68 samples/sec   Loss 1.1180   LearningRate 0.000001   Epoch: 1   Global Step: 56270   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:42:30,532-Speed 140.78 samples/sec   Loss 1.1419   LearningRate 0.000001   Epoch: 1   Global Step: 56280   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:42:32,826-Speed 139.57 samples/sec   Loss 1.1444   LearningRate 0.000001   Epoch: 1   Global Step: 56290   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:42:35,111-Speed 140.07 samples/sec   Loss 1.1461   LearningRate 0.000001   Epoch: 1   Global Step: 56300   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:42:37,399-Speed 139.89 samples/sec   Loss 1.1449   LearningRate 0.000001   Epoch: 1   Global Step: 56310   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:42:39,681-Speed 140.28 samples/sec   Loss 1.1445   LearningRate 0.000001   Epoch: 1   Global Step: 56320   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:42:41,965-Speed 140.15 samples/sec   Loss 1.1272   LearningRate 0.000001   Epoch: 1   Global Step: 56330   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:42:44,241-Speed 140.61 samples/sec   Loss 1.1654   LearningRate 0.000001   Epoch: 1   Global Step: 56340   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:42:46,533-Speed 139.65 samples/sec   Loss 1.1328   LearningRate 0.000001   Epoch: 1   Global Step: 56350   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:42:48,813-Speed 140.44 samples/sec   Loss 1.1504   LearningRate 0.000001   Epoch: 1   Global Step: 56360   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:42:51,103-Speed 139.73 samples/sec   Loss 1.1367   LearningRate 0.000001   Epoch: 1   Global Step: 56370   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:42:53,405-Speed 139.06 samples/sec   Loss 1.1307   LearningRate 0.000001   Epoch: 1   Global Step: 56380   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:42:55,692-Speed 139.95 samples/sec   Loss 1.1511   LearningRate 0.000001   Epoch: 1   Global Step: 56390   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:42:57,992-Speed 139.17 samples/sec   Loss 1.1614   LearningRate 0.000001   Epoch: 1   Global Step: 56400   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:43:00,283-Speed 139.74 samples/sec   Loss 1.1340   LearningRate 0.000001   Epoch: 1   Global Step: 56410   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:43:02,576-Speed 139.63 samples/sec   Loss 1.1326   LearningRate 0.000001   Epoch: 1   Global Step: 56420   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:43:04,882-Speed 138.82 samples/sec   Loss 1.1442   LearningRate 0.000001   Epoch: 1   Global Step: 56430   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:43:07,179-Speed 139.32 samples/sec   Loss 1.1402   LearningRate 0.000001   Epoch: 1   Global Step: 56440   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:43:09,470-Speed 139.72 samples/sec   Loss 1.1503   LearningRate 0.000001   Epoch: 1   Global Step: 56450   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:43:11,754-Speed 140.15 samples/sec   Loss 1.1681   LearningRate 0.000001   Epoch: 1   Global Step: 56460   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:43:14,049-Speed 139.46 samples/sec   Loss 1.1046   LearningRate 0.000001   Epoch: 1   Global Step: 56470   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:43:16,350-Speed 139.15 samples/sec   Loss 1.1352   LearningRate 0.000001   Epoch: 1   Global Step: 56480   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:43:18,644-Speed 139.54 samples/sec   Loss 1.1374   LearningRate 0.000001   Epoch: 1   Global Step: 56490   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:43:20,945-Speed 139.11 samples/sec   Loss 1.1387   LearningRate 0.000001   Epoch: 1   Global Step: 56500   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:43:23,237-Speed 139.60 samples/sec   Loss 1.1322   LearningRate 0.000001   Epoch: 1   Global Step: 56510   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:43:25,533-Speed 139.45 samples/sec   Loss 1.1460   LearningRate 0.000001   Epoch: 1   Global Step: 56520   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:43:27,817-Speed 140.16 samples/sec   Loss 1.1185   LearningRate 0.000001   Epoch: 1   Global Step: 56530   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:43:30,116-Speed 139.22 samples/sec   Loss 1.1514   LearningRate 0.000001   Epoch: 1   Global Step: 56540   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:43:32,385-Speed 141.07 samples/sec   Loss 1.1265   LearningRate 0.000001   Epoch: 1   Global Step: 56550   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:43:34,672-Speed 139.93 samples/sec   Loss 1.1223   LearningRate 0.000001   Epoch: 1   Global Step: 56560   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:43:36,956-Speed 140.15 samples/sec   Loss 1.1725   LearningRate 0.000001   Epoch: 1   Global Step: 56570   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:43:39,239-Speed 140.21 samples/sec   Loss 1.1414   LearningRate 0.000001   Epoch: 1   Global Step: 56580   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:43:41,536-Speed 139.35 samples/sec   Loss 1.1160   LearningRate 0.000001   Epoch: 1   Global Step: 56590   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:43:43,827-Speed 139.73 samples/sec   Loss 1.1285   LearningRate 0.000001   Epoch: 1   Global Step: 56600   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:43:46,118-Speed 139.73 samples/sec   Loss 1.1230   LearningRate 0.000001   Epoch: 1   Global Step: 56610   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:43:48,419-Speed 139.11 samples/sec   Loss 1.1452   LearningRate 0.000001   Epoch: 1   Global Step: 56620   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:43:50,717-Speed 139.31 samples/sec   Loss 1.1385   LearningRate 0.000001   Epoch: 1   Global Step: 56630   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:43:53,011-Speed 139.53 samples/sec   Loss 1.1510   LearningRate 0.000001   Epoch: 1   Global Step: 56640   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:43:55,294-Speed 140.17 samples/sec   Loss 1.1754   LearningRate 0.000001   Epoch: 1   Global Step: 56650   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:43:57,589-Speed 139.48 samples/sec   Loss 1.1297   LearningRate 0.000001   Epoch: 1   Global Step: 56660   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:43:59,872-Speed 140.24 samples/sec   Loss 1.1527   LearningRate 0.000001   Epoch: 1   Global Step: 56670   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:44:02,144-Speed 140.88 samples/sec   Loss 1.1383   LearningRate 0.000001   Epoch: 1   Global Step: 56680   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:44:04,410-Speed 141.27 samples/sec   Loss 1.1403   LearningRate 0.000001   Epoch: 1   Global Step: 56690   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:44:06,703-Speed 139.59 samples/sec   Loss 1.1371   LearningRate 0.000001   Epoch: 1   Global Step: 56700   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:44:08,990-Speed 139.95 samples/sec   Loss 1.1567   LearningRate 0.000001   Epoch: 1   Global Step: 56710   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:44:11,279-Speed 139.81 samples/sec   Loss 1.1503   LearningRate 0.000001   Epoch: 1   Global Step: 56720   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:44:13,581-Speed 139.07 samples/sec   Loss 1.1479   LearningRate 0.000001   Epoch: 1   Global Step: 56730   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:44:15,879-Speed 139.27 samples/sec   Loss 1.1070   LearningRate 0.000001   Epoch: 1   Global Step: 56740   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:44:18,173-Speed 139.56 samples/sec   Loss 1.1389   LearningRate 0.000001   Epoch: 1   Global Step: 56750   Fp16 Grad Scale: 65536   Required: 0 hours
Training: 2023-08-18 00:44:20,440-Speed 141.14 samples/sec   Loss 1.1385   LearningRate 0.000001   Epoch: 1   Global Step: 56760   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:44:22,747-Speed 138.76 samples/sec   Loss 1.1417   LearningRate 0.000001   Epoch: 1   Global Step: 56770   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:44:25,040-Speed 139.61 samples/sec   Loss 1.1056   LearningRate 0.000001   Epoch: 1   Global Step: 56780   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:44:27,308-Speed 141.10 samples/sec   Loss 1.1386   LearningRate 0.000001   Epoch: 1   Global Step: 56790   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:44:29,606-Speed 139.31 samples/sec   Loss 1.1386   LearningRate 0.000001   Epoch: 1   Global Step: 56800   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:44:31,910-Speed 138.89 samples/sec   Loss 1.1164   LearningRate 0.000001   Epoch: 1   Global Step: 56810   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:44:34,203-Speed 139.63 samples/sec   Loss 1.1398   LearningRate 0.000001   Epoch: 1   Global Step: 56820   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:44:36,505-Speed 139.02 samples/sec   Loss 1.1446   LearningRate 0.000001   Epoch: 1   Global Step: 56830   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:44:38,808-Speed 139.03 samples/sec   Loss 1.1378   LearningRate 0.000001   Epoch: 1   Global Step: 56840   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:44:41,146-Speed 136.88 samples/sec   Loss 1.1386   LearningRate 0.000001   Epoch: 1   Global Step: 56850   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:44:43,472-Speed 137.61 samples/sec   Loss 1.1301   LearningRate 0.000001   Epoch: 1   Global Step: 56860   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:44:45,804-Speed 137.28 samples/sec   Loss 1.1415   LearningRate 0.000001   Epoch: 1   Global Step: 56870   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:44:48,126-Speed 137.83 samples/sec   Loss 1.1207   LearningRate 0.000001   Epoch: 1   Global Step: 56880   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:44:50,453-Speed 137.57 samples/sec   Loss 1.1315   LearningRate 0.000001   Epoch: 1   Global Step: 56890   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:44:52,775-Speed 137.85 samples/sec   Loss 1.1370   LearningRate 0.000001   Epoch: 1   Global Step: 56900   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:44:55,084-Speed 138.63 samples/sec   Loss 1.1340   LearningRate 0.000001   Epoch: 1   Global Step: 56910   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:44:57,403-Speed 138.04 samples/sec   Loss 1.1236   LearningRate 0.000001   Epoch: 1   Global Step: 56920   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:44:59,685-Speed 140.25 samples/sec   Loss 1.1304   LearningRate 0.000001   Epoch: 1   Global Step: 56930   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:45:01,978-Speed 139.57 samples/sec   Loss 1.1467   LearningRate 0.000001   Epoch: 1   Global Step: 56940   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:45:04,273-Speed 139.53 samples/sec   Loss 1.1493   LearningRate 0.000001   Epoch: 1   Global Step: 56950   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:45:06,565-Speed 139.65 samples/sec   Loss 1.1258   LearningRate 0.000001   Epoch: 1   Global Step: 56960   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:45:08,862-Speed 139.34 samples/sec   Loss 1.1362   LearningRate 0.000001   Epoch: 1   Global Step: 56970   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:45:11,143-Speed 140.28 samples/sec   Loss 1.1501   LearningRate 0.000001   Epoch: 1   Global Step: 56980   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:45:13,437-Speed 139.56 samples/sec   Loss 1.1296   LearningRate 0.000001   Epoch: 1   Global Step: 56990   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:45:15,510-Val on RAF/AffectNet:
Training: 2023-08-18 00:45:15,625-Test: [0/48]	Time 0.114 (0.114)	Loss 0.3793 (0.3793)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-18 00:45:16,678-Test: [10/48]	Time 0.104 (0.106)	Loss 0.5513 (0.6066)	Acc@1 93.750 (90.057)	Acc@5 100.000 (98.295)	Mem 5268MB
Training: 2023-08-18 00:45:17,741-Test: [20/48]	Time 0.108 (0.106)	Loss 0.5662 (0.5725)	Acc@1 93.750 (91.667)	Acc@5 96.875 (98.289)	Mem 5268MB
Training: 2023-08-18 00:45:18,794-Test: [30/48]	Time 0.104 (0.106)	Loss 0.3947 (0.5509)	Acc@1 98.438 (92.540)	Acc@5 100.000 (98.387)	Mem 5268MB
Training: 2023-08-18 00:45:19,846-Test: [40/48]	Time 0.104 (0.106)	Loss 0.5009 (0.5519)	Acc@1 96.875 (92.645)	Acc@5 96.875 (98.247)	Mem 5268MB
Training: 2023-08-18 00:45:20,574-[56999]Expression Loss: 0.54952
Training: 2023-08-18 00:45:20,575-[56999]Expression Acc@1: 92.73142
Training: 2023-08-18 00:45:20,575-[56999]Expression Acc@1-Highest: 92.86180
Training: 2023-08-18 00:45:20,575-[56999]Expression Acc@5: 98.40287
Training: 2023-08-18 00:45:20,575-[56999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-18 00:45:20,575-[56999]10 Times Expression Acc@1: 92.61734
Training: 2023-08-18 00:45:20,575-[56999]10 Times Expression Acc@1-Highest: 92.61734
Training: 2023-08-18 00:45:20,809-Speed 43.41 samples/sec   Loss 1.1019   LearningRate 0.000001   Epoch: 1   Global Step: 57000   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:45:23,105-Speed 139.41 samples/sec   Loss 1.1543   LearningRate 0.000001   Epoch: 1   Global Step: 57010   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:45:25,396-Speed 139.70 samples/sec   Loss 1.1430   LearningRate 0.000001   Epoch: 1   Global Step: 57020   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:45:27,697-Speed 139.14 samples/sec   Loss 1.1443   LearningRate 0.000000   Epoch: 1   Global Step: 57030   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:45:29,983-Speed 140.03 samples/sec   Loss 1.1340   LearningRate 0.000000   Epoch: 1   Global Step: 57040   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:45:32,282-Speed 139.24 samples/sec   Loss 1.1272   LearningRate 0.000000   Epoch: 1   Global Step: 57050   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:45:34,589-Speed 138.72 samples/sec   Loss 1.1325   LearningRate 0.000000   Epoch: 1   Global Step: 57060   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:45:36,919-Speed 137.38 samples/sec   Loss 1.1292   LearningRate 0.000000   Epoch: 1   Global Step: 57070   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:45:39,240-Speed 137.95 samples/sec   Loss 1.1286   LearningRate 0.000000   Epoch: 1   Global Step: 57080   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:45:41,544-Speed 138.91 samples/sec   Loss 1.1428   LearningRate 0.000000   Epoch: 1   Global Step: 57090   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:45:43,845-Speed 139.13 samples/sec   Loss 1.1324   LearningRate 0.000000   Epoch: 1   Global Step: 57100   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:45:46,156-Speed 138.49 samples/sec   Loss 1.1512   LearningRate 0.000000   Epoch: 1   Global Step: 57110   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:45:48,465-Speed 138.60 samples/sec   Loss 1.1488   LearningRate 0.000000   Epoch: 1   Global Step: 57120   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:45:50,769-Speed 138.93 samples/sec   Loss 1.1210   LearningRate 0.000000   Epoch: 1   Global Step: 57130   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:45:53,073-Speed 138.98 samples/sec   Loss 1.1181   LearningRate 0.000000   Epoch: 1   Global Step: 57140   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:45:55,389-Speed 138.21 samples/sec   Loss 1.1375   LearningRate 0.000000   Epoch: 1   Global Step: 57150   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:45:57,712-Speed 137.78 samples/sec   Loss 1.1351   LearningRate 0.000000   Epoch: 1   Global Step: 57160   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:46:00,032-Speed 137.97 samples/sec   Loss 1.1557   LearningRate 0.000000   Epoch: 1   Global Step: 57170   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:46:02,341-Speed 138.63 samples/sec   Loss 1.1263   LearningRate 0.000000   Epoch: 1   Global Step: 57180   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:46:04,660-Speed 138.01 samples/sec   Loss 1.1573   LearningRate 0.000000   Epoch: 1   Global Step: 57190   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:46:06,986-Speed 137.62 samples/sec   Loss 1.1421   LearningRate 0.000000   Epoch: 1   Global Step: 57200   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:46:09,294-Speed 138.68 samples/sec   Loss 1.1199   LearningRate 0.000000   Epoch: 1   Global Step: 57210   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:46:11,590-Speed 139.42 samples/sec   Loss 1.1347   LearningRate 0.000000   Epoch: 1   Global Step: 57220   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:46:13,893-Speed 138.97 samples/sec   Loss 1.1267   LearningRate 0.000000   Epoch: 1   Global Step: 57230   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:46:16,189-Speed 139.43 samples/sec   Loss 1.1570   LearningRate 0.000000   Epoch: 1   Global Step: 57240   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:46:18,484-Speed 139.45 samples/sec   Loss 1.1557   LearningRate 0.000000   Epoch: 1   Global Step: 57250   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:46:20,785-Speed 139.11 samples/sec   Loss 1.1246   LearningRate 0.000000   Epoch: 1   Global Step: 57260   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:46:23,063-Speed 140.52 samples/sec   Loss 1.1528   LearningRate 0.000000   Epoch: 1   Global Step: 57270   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:46:25,332-Speed 141.10 samples/sec   Loss 1.1519   LearningRate 0.000000   Epoch: 1   Global Step: 57280   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:46:27,605-Speed 140.81 samples/sec   Loss 1.1502   LearningRate 0.000000   Epoch: 1   Global Step: 57290   Fp16 Grad Scale: 65536   Required: 0 hours
Training: 2023-08-18 00:46:29,881-Speed 140.62 samples/sec   Loss 1.1538   LearningRate 0.000000   Epoch: 1   Global Step: 57300   Fp16 Grad Scale: 65536   Required: 0 hours
Training: 2023-08-18 00:46:32,159-Speed 140.52 samples/sec   Loss 1.1436   LearningRate 0.000000   Epoch: 1   Global Step: 57310   Fp16 Grad Scale: 65536   Required: 0 hours
Training: 2023-08-18 00:46:34,441-Speed 140.25 samples/sec   Loss 1.1241   LearningRate 0.000000   Epoch: 1   Global Step: 57320   Fp16 Grad Scale: 65536   Required: 0 hours
Training: 2023-08-18 00:46:36,709-Speed 141.16 samples/sec   Loss 1.1402   LearningRate 0.000000   Epoch: 1   Global Step: 57330   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:46:38,959-Speed 142.27 samples/sec   Loss 1.1121   LearningRate 0.000000   Epoch: 1   Global Step: 57340   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:46:41,245-Speed 140.01 samples/sec   Loss 1.1205   LearningRate 0.000000   Epoch: 1   Global Step: 57350   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:46:43,515-Speed 141.02 samples/sec   Loss 1.1517   LearningRate 0.000000   Epoch: 1   Global Step: 57360   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:46:45,817-Speed 139.08 samples/sec   Loss 1.1348   LearningRate 0.000000   Epoch: 1   Global Step: 57370   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:46:48,094-Speed 140.53 samples/sec   Loss 1.0984   LearningRate 0.000000   Epoch: 1   Global Step: 57380   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:46:50,372-Speed 140.55 samples/sec   Loss 1.1361   LearningRate 0.000000   Epoch: 1   Global Step: 57390   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:46:52,662-Speed 139.78 samples/sec   Loss 1.1248   LearningRate 0.000000   Epoch: 1   Global Step: 57400   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:46:54,987-Speed 137.67 samples/sec   Loss 1.1497   LearningRate 0.000000   Epoch: 1   Global Step: 57410   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:46:57,314-Speed 137.53 samples/sec   Loss 1.1622   LearningRate 0.000000   Epoch: 1   Global Step: 57420   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:46:59,629-Speed 138.26 samples/sec   Loss 1.1445   LearningRate 0.000000   Epoch: 1   Global Step: 57430   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:47:01,929-Speed 139.19 samples/sec   Loss 1.1187   LearningRate 0.000000   Epoch: 1   Global Step: 57440   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:47:04,204-Speed 140.65 samples/sec   Loss 1.1631   LearningRate 0.000000   Epoch: 1   Global Step: 57450   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:47:06,489-Speed 140.10 samples/sec   Loss 1.1367   LearningRate 0.000000   Epoch: 1   Global Step: 57460   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:47:08,764-Speed 140.70 samples/sec   Loss 1.1776   LearningRate 0.000000   Epoch: 1   Global Step: 57470   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:47:11,042-Speed 140.48 samples/sec   Loss 1.1344   LearningRate 0.000000   Epoch: 1   Global Step: 57480   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:47:13,324-Speed 140.30 samples/sec   Loss 1.1436   LearningRate 0.000000   Epoch: 1   Global Step: 57490   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:47:15,603-Speed 140.43 samples/sec   Loss 1.1359   LearningRate 0.000000   Epoch: 1   Global Step: 57500   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:47:17,900-Speed 139.34 samples/sec   Loss 1.1500   LearningRate 0.000000   Epoch: 1   Global Step: 57510   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:47:20,198-Speed 139.31 samples/sec   Loss 1.1433   LearningRate 0.000000   Epoch: 1   Global Step: 57520   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:47:22,502-Speed 138.95 samples/sec   Loss 1.1515   LearningRate 0.000000   Epoch: 1   Global Step: 57530   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:47:24,805-Speed 138.97 samples/sec   Loss 1.1492   LearningRate 0.000000   Epoch: 1   Global Step: 57540   Fp16 Grad Scale: 65536   Required: 0 hours
Training: 2023-08-18 00:47:27,094-Speed 139.85 samples/sec   Loss 1.1343   LearningRate 0.000000   Epoch: 1   Global Step: 57550   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:47:29,371-Speed 140.58 samples/sec   Loss 1.1280   LearningRate 0.000000   Epoch: 1   Global Step: 57560   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:47:31,657-Speed 139.97 samples/sec   Loss 1.1315   LearningRate 0.000000   Epoch: 1   Global Step: 57570   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:47:33,954-Speed 139.37 samples/sec   Loss 1.1328   LearningRate 0.000000   Epoch: 1   Global Step: 57580   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:47:36,240-Speed 140.03 samples/sec   Loss 1.1401   LearningRate 0.000000   Epoch: 1   Global Step: 57590   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:47:38,541-Speed 139.09 samples/sec   Loss 1.1285   LearningRate 0.000000   Epoch: 1   Global Step: 57600   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:47:40,834-Speed 139.58 samples/sec   Loss 1.1436   LearningRate 0.000000   Epoch: 1   Global Step: 57610   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:47:43,141-Speed 138.73 samples/sec   Loss 1.1456   LearningRate 0.000000   Epoch: 1   Global Step: 57620   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:47:45,442-Speed 139.12 samples/sec   Loss 1.1311   LearningRate 0.000000   Epoch: 1   Global Step: 57630   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:47:47,752-Speed 138.56 samples/sec   Loss 1.1388   LearningRate 0.000000   Epoch: 1   Global Step: 57640   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:47:50,044-Speed 139.65 samples/sec   Loss 1.1366   LearningRate 0.000000   Epoch: 1   Global Step: 57650   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:47:52,353-Speed 138.62 samples/sec   Loss 1.1390   LearningRate 0.000000   Epoch: 1   Global Step: 57660   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:47:54,650-Speed 139.38 samples/sec   Loss 1.1421   LearningRate 0.000000   Epoch: 1   Global Step: 57670   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:47:56,948-Speed 139.26 samples/sec   Loss 1.1412   LearningRate 0.000000   Epoch: 1   Global Step: 57680   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:47:59,240-Speed 139.66 samples/sec   Loss 1.1389   LearningRate 0.000000   Epoch: 1   Global Step: 57690   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:48:01,537-Speed 139.36 samples/sec   Loss 1.1364   LearningRate 0.000000   Epoch: 1   Global Step: 57700   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:48:03,836-Speed 139.23 samples/sec   Loss 1.1755   LearningRate 0.000000   Epoch: 1   Global Step: 57710   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:48:06,125-Speed 139.85 samples/sec   Loss 1.1425   LearningRate 0.000000   Epoch: 1   Global Step: 57720   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:48:08,428-Speed 138.95 samples/sec   Loss 1.1471   LearningRate 0.000000   Epoch: 1   Global Step: 57730   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:48:10,727-Speed 139.28 samples/sec   Loss 1.1504   LearningRate 0.000000   Epoch: 1   Global Step: 57740   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:48:13,022-Speed 139.44 samples/sec   Loss 1.1259   LearningRate 0.000000   Epoch: 1   Global Step: 57750   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:48:15,324-Speed 139.04 samples/sec   Loss 1.1337   LearningRate 0.000000   Epoch: 1   Global Step: 57760   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:48:17,618-Speed 139.53 samples/sec   Loss 1.1445   LearningRate 0.000000   Epoch: 1   Global Step: 57770   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:48:19,916-Speed 139.33 samples/sec   Loss 1.1234   LearningRate 0.000000   Epoch: 1   Global Step: 57780   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:48:22,223-Speed 138.71 samples/sec   Loss 1.1205   LearningRate 0.000000   Epoch: 1   Global Step: 57790   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:48:24,529-Speed 138.81 samples/sec   Loss 1.1336   LearningRate 0.000000   Epoch: 1   Global Step: 57800   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:48:26,836-Speed 138.73 samples/sec   Loss 1.1272   LearningRate 0.000000   Epoch: 1   Global Step: 57810   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:48:29,113-Speed 140.58 samples/sec   Loss 1.1569   LearningRate 0.000000   Epoch: 1   Global Step: 57820   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:48:31,418-Speed 138.89 samples/sec   Loss 1.1579   LearningRate 0.000000   Epoch: 1   Global Step: 57830   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:48:33,686-Speed 141.13 samples/sec   Loss 1.1241   LearningRate 0.000000   Epoch: 1   Global Step: 57840   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:48:35,978-Speed 139.63 samples/sec   Loss 1.1405   LearningRate 0.000000   Epoch: 1   Global Step: 57850   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:48:38,261-Speed 140.25 samples/sec   Loss 1.1417   LearningRate 0.000000   Epoch: 1   Global Step: 57860   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:48:40,570-Speed 138.61 samples/sec   Loss 1.1312   LearningRate 0.000000   Epoch: 1   Global Step: 57870   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:48:42,854-Speed 140.12 samples/sec   Loss 1.1283   LearningRate 0.000000   Epoch: 1   Global Step: 57880   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:48:45,127-Speed 140.83 samples/sec   Loss 1.1112   LearningRate 0.000000   Epoch: 1   Global Step: 57890   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:48:47,405-Speed 140.53 samples/sec   Loss 1.1308   LearningRate 0.000000   Epoch: 1   Global Step: 57900   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:48:49,687-Speed 140.24 samples/sec   Loss 1.1276   LearningRate 0.000000   Epoch: 1   Global Step: 57910   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:48:51,979-Speed 139.69 samples/sec   Loss 1.1354   LearningRate 0.000000   Epoch: 1   Global Step: 57920   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:48:54,249-Speed 140.97 samples/sec   Loss 1.1332   LearningRate 0.000000   Epoch: 1   Global Step: 57930   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:48:56,522-Speed 140.83 samples/sec   Loss 1.1186   LearningRate 0.000000   Epoch: 1   Global Step: 57940   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:48:58,796-Speed 140.76 samples/sec   Loss 1.1376   LearningRate 0.000000   Epoch: 1   Global Step: 57950   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:49:01,079-Speed 140.28 samples/sec   Loss 1.1330   LearningRate 0.000000   Epoch: 1   Global Step: 57960   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:49:03,346-Speed 141.14 samples/sec   Loss 1.1176   LearningRate 0.000000   Epoch: 1   Global Step: 57970   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:49:05,630-Speed 140.17 samples/sec   Loss 1.1153   LearningRate 0.000000   Epoch: 1   Global Step: 57980   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:49:07,903-Speed 140.84 samples/sec   Loss 1.1611   LearningRate 0.000000   Epoch: 1   Global Step: 57990   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:49:09,953-Val on RAF/AffectNet:
Training: 2023-08-18 00:49:10,059-Test: [0/48]	Time 0.106 (0.106)	Loss 0.4272 (0.4272)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-18 00:49:11,114-Test: [10/48]	Time 0.113 (0.105)	Loss 0.4834 (0.5431)	Acc@1 95.312 (93.182)	Acc@5 100.000 (98.438)	Mem 5268MB
Training: 2023-08-18 00:49:12,165-Test: [20/48]	Time 0.104 (0.105)	Loss 0.5367 (0.5475)	Acc@1 92.188 (92.708)	Acc@5 98.438 (98.512)	Mem 5268MB
Training: 2023-08-18 00:49:13,220-Test: [30/48]	Time 0.108 (0.105)	Loss 0.4424 (0.5497)	Acc@1 95.312 (92.641)	Acc@5 100.000 (98.488)	Mem 5268MB
Training: 2023-08-18 00:49:14,278-Test: [40/48]	Time 0.104 (0.105)	Loss 0.6088 (0.5498)	Acc@1 90.625 (92.530)	Acc@5 96.875 (98.514)	Mem 5268MB
Training: 2023-08-18 00:49:15,023-[57999]Expression Loss: 0.54897
Training: 2023-08-18 00:49:15,024-[57999]Expression Acc@1: 92.73142
Training: 2023-08-18 00:49:15,024-[57999]Expression Acc@1-Highest: 92.86180
Training: 2023-08-18 00:49:15,024-[57999]Expression Acc@5: 98.46806
Training: 2023-08-18 00:49:15,024-[57999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-18 00:49:15,024-[57999]10 Times Expression Acc@1: 92.61734
Training: 2023-08-18 00:49:15,024-[57999]10 Times Expression Acc@1-Highest: 92.61734
Training: 2023-08-18 00:49:15,257-Speed 43.51 samples/sec   Loss 1.1253   LearningRate 0.000000   Epoch: 1   Global Step: 58000   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:49:17,574-Speed 138.16 samples/sec   Loss 1.1463   LearningRate 0.000000   Epoch: 1   Global Step: 58010   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:49:19,896-Speed 137.87 samples/sec   Loss 1.1673   LearningRate 0.000000   Epoch: 1   Global Step: 58020   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:49:22,194-Speed 139.24 samples/sec   Loss 1.1440   LearningRate 0.000000   Epoch: 1   Global Step: 58030   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:49:24,481-Speed 140.01 samples/sec   Loss 1.1347   LearningRate 0.000000   Epoch: 1   Global Step: 58040   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:49:26,767-Speed 140.01 samples/sec   Loss 1.1387   LearningRate 0.000000   Epoch: 1   Global Step: 58050   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:49:29,077-Speed 138.57 samples/sec   Loss 1.1261   LearningRate 0.000000   Epoch: 1   Global Step: 58060   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:49:31,363-Speed 140.00 samples/sec   Loss 1.1366   LearningRate 0.000000   Epoch: 1   Global Step: 58070   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:49:33,661-Speed 139.29 samples/sec   Loss 1.1400   LearningRate 0.000000   Epoch: 1   Global Step: 58080   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:49:35,959-Speed 139.33 samples/sec   Loss 1.1258   LearningRate 0.000000   Epoch: 1   Global Step: 58090   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:49:38,239-Speed 140.41 samples/sec   Loss 1.1420   LearningRate 0.000000   Epoch: 1   Global Step: 58100   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:49:40,527-Speed 139.87 samples/sec   Loss 1.1286   LearningRate 0.000000   Epoch: 1   Global Step: 58110   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:49:42,806-Speed 140.49 samples/sec   Loss 1.1604   LearningRate 0.000000   Epoch: 1   Global Step: 58120   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:49:45,080-Speed 140.76 samples/sec   Loss 1.1380   LearningRate 0.000000   Epoch: 1   Global Step: 58130   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:49:47,374-Speed 139.52 samples/sec   Loss 1.1177   LearningRate 0.000000   Epoch: 1   Global Step: 58140   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:49:49,668-Speed 139.52 samples/sec   Loss 1.1512   LearningRate 0.000000   Epoch: 1   Global Step: 58150   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:49:51,977-Speed 138.64 samples/sec   Loss 1.1267   LearningRate 0.000000   Epoch: 1   Global Step: 58160   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:49:54,269-Speed 139.69 samples/sec   Loss 1.1185   LearningRate 0.000000   Epoch: 1   Global Step: 58170   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:49:56,568-Speed 139.21 samples/sec   Loss 1.1268   LearningRate 0.000000   Epoch: 1   Global Step: 58180   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:49:58,856-Speed 139.90 samples/sec   Loss 1.1510   LearningRate 0.000000   Epoch: 1   Global Step: 58190   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:50:01,156-Speed 139.18 samples/sec   Loss 1.1193   LearningRate 0.000000   Epoch: 1   Global Step: 58200   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:50:03,458-Speed 139.06 samples/sec   Loss 1.1460   LearningRate 0.000000   Epoch: 1   Global Step: 58210   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:50:05,737-Speed 140.45 samples/sec   Loss 1.1294   LearningRate 0.000000   Epoch: 1   Global Step: 58220   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:50:08,029-Speed 139.63 samples/sec   Loss 1.1193   LearningRate 0.000000   Epoch: 1   Global Step: 58230   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:50:10,325-Speed 139.43 samples/sec   Loss 1.1491   LearningRate 0.000000   Epoch: 1   Global Step: 58240   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:50:12,616-Speed 139.72 samples/sec   Loss 1.1267   LearningRate 0.000000   Epoch: 1   Global Step: 58250   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:50:14,917-Speed 139.11 samples/sec   Loss 1.1361   LearningRate 0.000000   Epoch: 1   Global Step: 58260   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:50:17,209-Speed 139.62 samples/sec   Loss 1.1438   LearningRate 0.000000   Epoch: 1   Global Step: 58270   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:50:19,518-Speed 138.68 samples/sec   Loss 1.1221   LearningRate 0.000000   Epoch: 1   Global Step: 58280   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:50:21,804-Speed 140.01 samples/sec   Loss 1.1232   LearningRate 0.000000   Epoch: 1   Global Step: 58290   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:50:24,090-Speed 139.98 samples/sec   Loss 1.1237   LearningRate 0.000000   Epoch: 1   Global Step: 58300   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:50:26,382-Speed 139.63 samples/sec   Loss 1.1298   LearningRate 0.000000   Epoch: 1   Global Step: 58310   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:50:28,675-Speed 139.65 samples/sec   Loss 1.1250   LearningRate 0.000000   Epoch: 1   Global Step: 58320   Fp16 Grad Scale: 65536   Required: 0 hours
Training: 2023-08-18 00:50:30,946-Speed 140.91 samples/sec   Loss 1.1400   LearningRate 0.000000   Epoch: 1   Global Step: 58330   Fp16 Grad Scale: 65536   Required: 0 hours
Training: 2023-08-18 00:50:33,200-Speed 142.02 samples/sec   Loss 1.1182   LearningRate 0.000000   Epoch: 1   Global Step: 58340   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:50:35,499-Speed 139.22 samples/sec   Loss 1.1388   LearningRate 0.000000   Epoch: 1   Global Step: 58350   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:50:37,802-Speed 138.99 samples/sec   Loss 1.1274   LearningRate 0.000000   Epoch: 1   Global Step: 58360   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:50:40,112-Speed 138.57 samples/sec   Loss 1.1493   LearningRate 0.000000   Epoch: 1   Global Step: 58370   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:50:42,405-Speed 139.55 samples/sec   Loss 1.1273   LearningRate 0.000000   Epoch: 1   Global Step: 58380   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:50:44,701-Speed 139.41 samples/sec   Loss 1.1289   LearningRate 0.000000   Epoch: 1   Global Step: 58390   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:50:46,987-Speed 140.05 samples/sec   Loss 1.1407   LearningRate 0.000000   Epoch: 1   Global Step: 58400   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:50:49,265-Speed 140.48 samples/sec   Loss 1.1657   LearningRate 0.000000   Epoch: 1   Global Step: 58410   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:50:51,553-Speed 139.90 samples/sec   Loss 1.1359   LearningRate 0.000000   Epoch: 1   Global Step: 58420   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:50:53,832-Speed 140.45 samples/sec   Loss 1.1395   LearningRate 0.000000   Epoch: 1   Global Step: 58430   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:50:56,106-Speed 140.79 samples/sec   Loss 1.1538   LearningRate 0.000000   Epoch: 1   Global Step: 58440   Fp16 Grad Scale: 65536   Required: 0 hours
Training: 2023-08-18 00:50:58,368-Speed 141.48 samples/sec   Loss 1.1377   LearningRate 0.000000   Epoch: 1   Global Step: 58450   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:51:00,671-Speed 139.00 samples/sec   Loss 1.1178   LearningRate 0.000000   Epoch: 1   Global Step: 58460   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:51:02,966-Speed 139.48 samples/sec   Loss 1.1464   LearningRate 0.000000   Epoch: 1   Global Step: 58470   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:51:05,273-Speed 138.74 samples/sec   Loss 1.1503   LearningRate 0.000000   Epoch: 1   Global Step: 58480   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:51:07,559-Speed 140.00 samples/sec   Loss 1.1110   LearningRate 0.000000   Epoch: 1   Global Step: 58490   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:51:09,845-Speed 140.06 samples/sec   Loss 1.1350   LearningRate 0.000000   Epoch: 1   Global Step: 58500   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:51:12,132-Speed 139.91 samples/sec   Loss 1.1217   LearningRate 0.000000   Epoch: 1   Global Step: 58510   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:51:14,417-Speed 140.13 samples/sec   Loss 1.1275   LearningRate 0.000000   Epoch: 1   Global Step: 58520   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:51:16,692-Speed 140.65 samples/sec   Loss 1.1200   LearningRate 0.000000   Epoch: 1   Global Step: 58530   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:51:18,961-Speed 141.13 samples/sec   Loss 1.1200   LearningRate 0.000000   Epoch: 1   Global Step: 58540   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:51:21,235-Speed 140.76 samples/sec   Loss 1.1282   LearningRate 0.000000   Epoch: 1   Global Step: 58550   Fp16 Grad Scale: 65536   Required: 0 hours
Training: 2023-08-18 00:51:23,497-Speed 141.49 samples/sec   Loss 1.1622   LearningRate 0.000000   Epoch: 1   Global Step: 58560   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:51:25,771-Speed 140.77 samples/sec   Loss 1.1546   LearningRate 0.000000   Epoch: 1   Global Step: 58570   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:51:28,053-Speed 140.26 samples/sec   Loss 1.1392   LearningRate 0.000000   Epoch: 1   Global Step: 58580   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:51:30,341-Speed 139.90 samples/sec   Loss 1.1243   LearningRate 0.000000   Epoch: 1   Global Step: 58590   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:51:32,612-Speed 140.97 samples/sec   Loss 1.1440   LearningRate 0.000000   Epoch: 1   Global Step: 58600   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:51:34,887-Speed 140.64 samples/sec   Loss 1.1396   LearningRate 0.000000   Epoch: 1   Global Step: 58610   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:51:37,165-Speed 140.52 samples/sec   Loss 1.1616   LearningRate 0.000000   Epoch: 1   Global Step: 58620   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:51:39,443-Speed 140.52 samples/sec   Loss 1.1304   LearningRate 0.000000   Epoch: 1   Global Step: 58630   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:51:41,726-Speed 140.23 samples/sec   Loss 1.1301   LearningRate 0.000000   Epoch: 1   Global Step: 58640   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:51:44,009-Speed 140.18 samples/sec   Loss 1.1455   LearningRate 0.000000   Epoch: 1   Global Step: 58650   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:51:46,271-Speed 141.54 samples/sec   Loss 1.1463   LearningRate 0.000000   Epoch: 1   Global Step: 58660   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:51:48,549-Speed 140.52 samples/sec   Loss 1.1393   LearningRate 0.000000   Epoch: 1   Global Step: 58670   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:51:50,811-Speed 141.48 samples/sec   Loss 1.1287   LearningRate 0.000000   Epoch: 1   Global Step: 58680   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:51:53,086-Speed 140.72 samples/sec   Loss 1.1530   LearningRate 0.000000   Epoch: 1   Global Step: 58690   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:51:55,377-Speed 139.73 samples/sec   Loss 1.1335   LearningRate 0.000000   Epoch: 1   Global Step: 58700   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:51:57,650-Speed 140.83 samples/sec   Loss 1.1416   LearningRate 0.000000   Epoch: 1   Global Step: 58710   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:51:59,928-Speed 140.48 samples/sec   Loss 1.1410   LearningRate 0.000000   Epoch: 1   Global Step: 58720   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:52:02,204-Speed 140.68 samples/sec   Loss 1.1244   LearningRate 0.000000   Epoch: 1   Global Step: 58730   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:52:04,497-Speed 139.54 samples/sec   Loss 1.1437   LearningRate 0.000000   Epoch: 1   Global Step: 58740   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:52:06,776-Speed 140.50 samples/sec   Loss 1.1300   LearningRate 0.000000   Epoch: 1   Global Step: 58750   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:52:09,053-Speed 140.53 samples/sec   Loss 1.1245   LearningRate 0.000000   Epoch: 1   Global Step: 58760   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:52:11,324-Speed 140.93 samples/sec   Loss 1.1110   LearningRate 0.000000   Epoch: 1   Global Step: 58770   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:52:13,597-Speed 140.84 samples/sec   Loss 1.1031   LearningRate 0.000000   Epoch: 1   Global Step: 58780   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:52:15,872-Speed 140.69 samples/sec   Loss 1.1346   LearningRate 0.000000   Epoch: 1   Global Step: 58790   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:52:18,153-Speed 140.36 samples/sec   Loss 1.1198   LearningRate 0.000000   Epoch: 1   Global Step: 58800   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:52:20,445-Speed 139.62 samples/sec   Loss 1.1395   LearningRate 0.000000   Epoch: 1   Global Step: 58810   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:52:22,719-Speed 140.79 samples/sec   Loss 1.1263   LearningRate 0.000000   Epoch: 1   Global Step: 58820   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:52:25,003-Speed 140.17 samples/sec   Loss 1.1523   LearningRate 0.000000   Epoch: 1   Global Step: 58830   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:52:27,306-Speed 139.00 samples/sec   Loss 1.1404   LearningRate 0.000000   Epoch: 1   Global Step: 58840   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:52:29,581-Speed 140.66 samples/sec   Loss 1.1192   LearningRate 0.000000   Epoch: 1   Global Step: 58850   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:52:31,869-Speed 139.92 samples/sec   Loss 1.1363   LearningRate 0.000000   Epoch: 1   Global Step: 58860   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:52:34,150-Speed 140.30 samples/sec   Loss 1.1609   LearningRate 0.000000   Epoch: 1   Global Step: 58870   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:52:36,448-Speed 139.31 samples/sec   Loss 1.1609   LearningRate 0.000000   Epoch: 1   Global Step: 58880   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:52:38,726-Speed 140.50 samples/sec   Loss 1.1742   LearningRate 0.000000   Epoch: 1   Global Step: 58890   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:52:41,024-Speed 139.31 samples/sec   Loss 1.1249   LearningRate 0.000000   Epoch: 1   Global Step: 58900   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:52:43,309-Speed 140.05 samples/sec   Loss 1.1498   LearningRate 0.000000   Epoch: 1   Global Step: 58910   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:52:45,584-Speed 140.73 samples/sec   Loss 1.1421   LearningRate 0.000000   Epoch: 1   Global Step: 58920   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:52:47,886-Speed 139.03 samples/sec   Loss 1.1420   LearningRate 0.000000   Epoch: 1   Global Step: 58930   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:52:50,161-Speed 140.74 samples/sec   Loss 1.1251   LearningRate 0.000000   Epoch: 1   Global Step: 58940   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:52:52,442-Speed 140.33 samples/sec   Loss 1.1346   LearningRate 0.000000   Epoch: 1   Global Step: 58950   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:52:54,725-Speed 140.18 samples/sec   Loss 1.1359   LearningRate 0.000000   Epoch: 1   Global Step: 58960   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:52:57,021-Speed 139.38 samples/sec   Loss 1.1376   LearningRate 0.000000   Epoch: 1   Global Step: 58970   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:52:59,313-Speed 139.69 samples/sec   Loss 1.1391   LearningRate 0.000000   Epoch: 1   Global Step: 58980   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:53:01,592-Speed 140.44 samples/sec   Loss 1.1241   LearningRate 0.000000   Epoch: 1   Global Step: 58990   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:53:03,639-Val on RAF/AffectNet:
Training: 2023-08-18 00:53:03,748-Test: [0/48]	Time 0.109 (0.109)	Loss 0.5147 (0.5147)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-18 00:53:04,808-Test: [10/48]	Time 0.102 (0.106)	Loss 0.5273 (0.5402)	Acc@1 92.188 (92.472)	Acc@5 100.000 (98.580)	Mem 5268MB
Training: 2023-08-18 00:53:05,861-Test: [20/48]	Time 0.111 (0.106)	Loss 0.5193 (0.5550)	Acc@1 95.312 (92.336)	Acc@5 100.000 (98.214)	Mem 5268MB
Training: 2023-08-18 00:53:06,913-Test: [30/48]	Time 0.102 (0.106)	Loss 0.5940 (0.5503)	Acc@1 93.750 (92.792)	Acc@5 98.438 (98.337)	Mem 5268MB
Training: 2023-08-18 00:53:07,993-Test: [40/48]	Time 0.109 (0.106)	Loss 0.6153 (0.5480)	Acc@1 89.062 (92.950)	Acc@5 98.438 (98.514)	Mem 5268MB
Training: 2023-08-18 00:53:08,728-[58999]Expression Loss: 0.55217
Training: 2023-08-18 00:53:08,729-[58999]Expression Acc@1: 92.73142
Training: 2023-08-18 00:53:08,729-[58999]Expression Acc@1-Highest: 92.86180
Training: 2023-08-18 00:53:08,729-[58999]Expression Acc@5: 98.40287
Training: 2023-08-18 00:53:08,729-[58999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-18 00:53:08,729-[58999]10 Times Expression Acc@1: 92.63364
Training: 2023-08-18 00:53:08,729-[58999]10 Times Expression Acc@1-Highest: 92.63364
Training: 2023-08-18 00:53:08,958-Speed 43.45 samples/sec   Loss 1.1481   LearningRate 0.000000   Epoch: 1   Global Step: 59000   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:53:11,261-Speed 138.97 samples/sec   Loss 1.1608   LearningRate 0.000000   Epoch: 1   Global Step: 59010   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:53:13,545-Speed 140.12 samples/sec   Loss 1.1356   LearningRate 0.000000   Epoch: 1   Global Step: 59020   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:53:15,846-Speed 139.12 samples/sec   Loss 1.1482   LearningRate 0.000000   Epoch: 1   Global Step: 59030   Fp16 Grad Scale: 8192   Required: 0 hours
Training: 2023-08-18 00:53:18,143-Speed 139.34 samples/sec   Loss 1.1142   LearningRate 0.000000   Epoch: 1   Global Step: 59040   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:53:20,460-Speed 138.18 samples/sec   Loss 1.1352   LearningRate 0.000000   Epoch: 1   Global Step: 59050   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:53:22,782-Speed 137.84 samples/sec   Loss 1.1551   LearningRate 0.000000   Epoch: 1   Global Step: 59060   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:53:25,072-Speed 139.79 samples/sec   Loss 1.1484   LearningRate 0.000000   Epoch: 1   Global Step: 59070   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:53:27,385-Speed 138.38 samples/sec   Loss 1.1311   LearningRate 0.000000   Epoch: 1   Global Step: 59080   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:53:29,687-Speed 139.03 samples/sec   Loss 1.1497   LearningRate 0.000000   Epoch: 1   Global Step: 59090   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:53:31,995-Speed 138.74 samples/sec   Loss 1.1614   LearningRate 0.000000   Epoch: 1   Global Step: 59100   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:53:34,297-Speed 139.03 samples/sec   Loss 1.1545   LearningRate 0.000000   Epoch: 1   Global Step: 59110   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:53:36,608-Speed 138.52 samples/sec   Loss 1.1158   LearningRate 0.000000   Epoch: 1   Global Step: 59120   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:53:38,933-Speed 137.69 samples/sec   Loss 1.1278   LearningRate 0.000000   Epoch: 1   Global Step: 59130   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:53:41,240-Speed 138.73 samples/sec   Loss 1.1461   LearningRate 0.000000   Epoch: 1   Global Step: 59140   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:53:43,513-Speed 140.83 samples/sec   Loss 1.1484   LearningRate 0.000000   Epoch: 1   Global Step: 59150   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:53:45,817-Speed 138.89 samples/sec   Loss 1.1350   LearningRate 0.000000   Epoch: 1   Global Step: 59160   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:53:48,135-Speed 138.14 samples/sec   Loss 1.1294   LearningRate 0.000000   Epoch: 1   Global Step: 59170   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:53:50,444-Speed 138.60 samples/sec   Loss 1.1299   LearningRate 0.000000   Epoch: 1   Global Step: 59180   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:53:52,755-Speed 138.52 samples/sec   Loss 1.1477   LearningRate 0.000000   Epoch: 1   Global Step: 59190   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:53:55,068-Speed 138.38 samples/sec   Loss 1.1340   LearningRate 0.000000   Epoch: 1   Global Step: 59200   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:53:57,368-Speed 139.14 samples/sec   Loss 1.1554   LearningRate 0.000000   Epoch: 1   Global Step: 59210   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:53:59,698-Speed 137.40 samples/sec   Loss 1.1247   LearningRate 0.000000   Epoch: 1   Global Step: 59220   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:54:02,016-Speed 138.09 samples/sec   Loss 1.1525   LearningRate 0.000000   Epoch: 1   Global Step: 59230   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:54:04,325-Speed 138.59 samples/sec   Loss 1.1345   LearningRate 0.000000   Epoch: 1   Global Step: 59240   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:54:06,617-Speed 139.70 samples/sec   Loss 1.1031   LearningRate 0.000000   Epoch: 1   Global Step: 59250   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:54:08,883-Speed 141.25 samples/sec   Loss 1.1310   LearningRate 0.000000   Epoch: 1   Global Step: 59260   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:54:11,148-Speed 141.31 samples/sec   Loss 1.1426   LearningRate 0.000000   Epoch: 1   Global Step: 59270   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:54:13,421-Speed 140.85 samples/sec   Loss 1.1244   LearningRate 0.000000   Epoch: 1   Global Step: 59280   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:54:15,684-Speed 141.43 samples/sec   Loss 1.1536   LearningRate 0.000000   Epoch: 1   Global Step: 59290   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:54:17,968-Speed 140.12 samples/sec   Loss 1.1461   LearningRate 0.000000   Epoch: 1   Global Step: 59300   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:54:20,241-Speed 140.86 samples/sec   Loss 1.1304   LearningRate 0.000000   Epoch: 1   Global Step: 59310   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:54:22,520-Speed 140.45 samples/sec   Loss 1.1470   LearningRate 0.000000   Epoch: 1   Global Step: 59320   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:54:24,772-Speed 142.12 samples/sec   Loss 1.1474   LearningRate 0.000000   Epoch: 1   Global Step: 59330   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:54:27,038-Speed 141.28 samples/sec   Loss 1.1299   LearningRate 0.000000   Epoch: 1   Global Step: 59340   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:54:29,305-Speed 141.16 samples/sec   Loss 1.1035   LearningRate 0.000000   Epoch: 1   Global Step: 59350   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:54:31,595-Speed 139.80 samples/sec   Loss 1.1278   LearningRate 0.000000   Epoch: 1   Global Step: 59360   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:54:33,871-Speed 140.66 samples/sec   Loss 1.1209   LearningRate 0.000000   Epoch: 1   Global Step: 59370   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:54:36,142-Speed 140.94 samples/sec   Loss 1.1294   LearningRate 0.000000   Epoch: 1   Global Step: 59380   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:54:38,422-Speed 140.35 samples/sec   Loss 1.1314   LearningRate 0.000000   Epoch: 1   Global Step: 59390   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:54:40,699-Speed 140.62 samples/sec   Loss 1.1446   LearningRate 0.000000   Epoch: 1   Global Step: 59400   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:54:42,965-Speed 141.20 samples/sec   Loss 1.1465   LearningRate 0.000000   Epoch: 1   Global Step: 59410   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:54:45,234-Speed 141.12 samples/sec   Loss 1.1169   LearningRate 0.000000   Epoch: 1   Global Step: 59420   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:54:47,519-Speed 140.05 samples/sec   Loss 1.1553   LearningRate 0.000000   Epoch: 1   Global Step: 59430   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:54:49,787-Speed 141.15 samples/sec   Loss 1.1290   LearningRate 0.000000   Epoch: 1   Global Step: 59440   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:54:52,054-Speed 141.19 samples/sec   Loss 1.1109   LearningRate 0.000000   Epoch: 1   Global Step: 59450   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:54:54,311-Speed 141.80 samples/sec   Loss 1.1204   LearningRate 0.000000   Epoch: 1   Global Step: 59460   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:54:56,570-Speed 141.68 samples/sec   Loss 1.1210   LearningRate 0.000000   Epoch: 1   Global Step: 59470   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:54:58,847-Speed 140.63 samples/sec   Loss 1.1091   LearningRate 0.000000   Epoch: 1   Global Step: 59480   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:55:01,116-Speed 141.05 samples/sec   Loss 1.1414   LearningRate 0.000000   Epoch: 1   Global Step: 59490   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:55:03,381-Speed 141.33 samples/sec   Loss 1.1570   LearningRate 0.000000   Epoch: 1   Global Step: 59500   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:55:05,654-Speed 140.82 samples/sec   Loss 1.1377   LearningRate 0.000000   Epoch: 1   Global Step: 59510   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:55:07,934-Speed 140.38 samples/sec   Loss 1.1397   LearningRate 0.000000   Epoch: 1   Global Step: 59520   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:55:10,180-Speed 142.51 samples/sec   Loss 1.1511   LearningRate 0.000000   Epoch: 1   Global Step: 59530   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:55:12,447-Speed 141.21 samples/sec   Loss 1.1381   LearningRate 0.000000   Epoch: 1   Global Step: 59540   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:55:14,712-Speed 141.35 samples/sec   Loss 1.1535   LearningRate 0.000000   Epoch: 1   Global Step: 59550   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:55:16,970-Speed 141.74 samples/sec   Loss 1.1532   LearningRate 0.000000   Epoch: 1   Global Step: 59560   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:55:19,227-Speed 141.82 samples/sec   Loss 1.1589   LearningRate 0.000000   Epoch: 1   Global Step: 59570   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:55:21,502-Speed 140.71 samples/sec   Loss 1.1345   LearningRate 0.000000   Epoch: 1   Global Step: 59580   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:55:23,788-Speed 139.99 samples/sec   Loss 1.1271   LearningRate 0.000000   Epoch: 1   Global Step: 59590   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:55:26,079-Speed 139.72 samples/sec   Loss 1.1523   LearningRate 0.000000   Epoch: 1   Global Step: 59600   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:55:28,357-Speed 140.55 samples/sec   Loss 1.1584   LearningRate 0.000000   Epoch: 1   Global Step: 59610   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:55:30,612-Speed 141.89 samples/sec   Loss 1.1288   LearningRate 0.000000   Epoch: 1   Global Step: 59620   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:55:32,895-Speed 140.26 samples/sec   Loss 1.1116   LearningRate 0.000000   Epoch: 1   Global Step: 59630   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:55:35,159-Speed 141.34 samples/sec   Loss 1.1476   LearningRate 0.000000   Epoch: 1   Global Step: 59640   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:55:37,422-Speed 141.43 samples/sec   Loss 1.1551   LearningRate 0.000000   Epoch: 1   Global Step: 59650   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:55:39,697-Speed 140.70 samples/sec   Loss 1.1184   LearningRate 0.000000   Epoch: 1   Global Step: 59660   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:55:41,963-Speed 141.28 samples/sec   Loss 1.1315   LearningRate 0.000000   Epoch: 1   Global Step: 59670   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:55:44,234-Speed 140.92 samples/sec   Loss 1.1189   LearningRate 0.000000   Epoch: 1   Global Step: 59680   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:55:46,491-Speed 141.87 samples/sec   Loss 1.1267   LearningRate 0.000000   Epoch: 1   Global Step: 59690   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:55:48,764-Speed 140.78 samples/sec   Loss 1.1289   LearningRate 0.000000   Epoch: 1   Global Step: 59700   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:55:51,026-Speed 141.56 samples/sec   Loss 1.1307   LearningRate 0.000000   Epoch: 1   Global Step: 59710   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:55:53,296-Speed 140.99 samples/sec   Loss 1.1423   LearningRate 0.000000   Epoch: 1   Global Step: 59720   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:55:55,576-Speed 140.38 samples/sec   Loss 1.1576   LearningRate 0.000000   Epoch: 1   Global Step: 59730   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:55:57,871-Speed 139.49 samples/sec   Loss 1.1261   LearningRate 0.000000   Epoch: 1   Global Step: 59740   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:56:00,156-Speed 140.11 samples/sec   Loss 1.1339   LearningRate 0.000000   Epoch: 1   Global Step: 59750   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:56:02,423-Speed 141.15 samples/sec   Loss 1.1603   LearningRate 0.000000   Epoch: 1   Global Step: 59760   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:56:04,681-Speed 141.75 samples/sec   Loss 1.1360   LearningRate 0.000000   Epoch: 1   Global Step: 59770   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:56:06,944-Speed 141.44 samples/sec   Loss 1.1355   LearningRate 0.000000   Epoch: 1   Global Step: 59780   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:56:09,187-Speed 142.75 samples/sec   Loss 1.1491   LearningRate 0.000000   Epoch: 1   Global Step: 59790   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:56:11,449-Speed 141.52 samples/sec   Loss 1.1291   LearningRate 0.000000   Epoch: 1   Global Step: 59800   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:56:13,707-Speed 141.74 samples/sec   Loss 1.1352   LearningRate 0.000000   Epoch: 1   Global Step: 59810   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:56:15,964-Speed 141.81 samples/sec   Loss 1.1429   LearningRate 0.000000   Epoch: 1   Global Step: 59820   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:56:18,220-Speed 141.88 samples/sec   Loss 1.1554   LearningRate 0.000000   Epoch: 1   Global Step: 59830   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:56:20,477-Speed 141.86 samples/sec   Loss 1.1490   LearningRate 0.000000   Epoch: 1   Global Step: 59840   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:56:22,738-Speed 141.55 samples/sec   Loss 1.1310   LearningRate 0.000000   Epoch: 1   Global Step: 59850   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:56:24,991-Speed 142.08 samples/sec   Loss 1.1553   LearningRate 0.000000   Epoch: 1   Global Step: 59860   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:56:27,243-Speed 142.13 samples/sec   Loss 1.1475   LearningRate 0.000000   Epoch: 1   Global Step: 59870   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:56:29,498-Speed 141.96 samples/sec   Loss 1.1330   LearningRate 0.000000   Epoch: 1   Global Step: 59880   Fp16 Grad Scale: 16384   Required: 0 hours
Training: 2023-08-18 00:56:31,755-Speed 141.82 samples/sec   Loss 1.1463   LearningRate 0.000000   Epoch: 1   Global Step: 59890   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:56:34,013-Speed 141.73 samples/sec   Loss 1.1285   LearningRate 0.000000   Epoch: 1   Global Step: 59900   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:56:36,266-Speed 142.12 samples/sec   Loss 1.1244   LearningRate 0.000000   Epoch: 1   Global Step: 59910   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:56:38,526-Speed 141.61 samples/sec   Loss 1.1812   LearningRate 0.000000   Epoch: 1   Global Step: 59920   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:56:40,784-Speed 141.79 samples/sec   Loss 1.1236   LearningRate 0.000000   Epoch: 1   Global Step: 59930   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:56:43,041-Speed 141.78 samples/sec   Loss 1.1445   LearningRate 0.000000   Epoch: 1   Global Step: 59940   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:56:45,299-Speed 141.75 samples/sec   Loss 1.1489   LearningRate 0.000000   Epoch: 1   Global Step: 59950   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:56:47,551-Speed 142.13 samples/sec   Loss 1.1494   LearningRate 0.000000   Epoch: 1   Global Step: 59960   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:56:49,812-Speed 141.59 samples/sec   Loss 1.1542   LearningRate 0.000000   Epoch: 1   Global Step: 59970   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:56:52,082-Speed 141.03 samples/sec   Loss 1.1254   LearningRate 0.000000   Epoch: 1   Global Step: 59980   Fp16 Grad Scale: 32768   Required: 0 hours
Training: 2023-08-18 00:56:54,378-Speed 139.38 samples/sec   Loss 1.1101   LearningRate 0.000000   Epoch: 1   Global Step: 59990   Fp16 Grad Scale: 65536   Required: 0 hours
Training: 2023-08-18 00:56:56,433-Val on RAF/AffectNet:
Training: 2023-08-18 00:56:56,548-Test: [0/48]	Time 0.115 (0.115)	Loss 0.5580 (0.5580)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-18 00:56:57,586-Test: [10/48]	Time 0.103 (0.105)	Loss 0.4551 (0.5556)	Acc@1 96.875 (92.188)	Acc@5 98.438 (98.295)	Mem 5268MB
Training: 2023-08-18 00:56:58,633-Test: [20/48]	Time 0.103 (0.105)	Loss 0.4555 (0.5572)	Acc@1 96.875 (92.634)	Acc@5 100.000 (98.289)	Mem 5268MB
Training: 2023-08-18 00:56:59,686-Test: [30/48]	Time 0.106 (0.105)	Loss 0.5278 (0.5610)	Acc@1 92.188 (92.490)	Acc@5 98.438 (98.236)	Mem 5268MB
Training: 2023-08-18 00:57:00,740-Test: [40/48]	Time 0.105 (0.105)	Loss 0.4443 (0.5564)	Acc@1 96.875 (92.530)	Acc@5 100.000 (98.285)	Mem 5268MB
Training: 2023-08-18 00:57:01,479-[59999]Expression Loss: 0.55021
Training: 2023-08-18 00:57:01,479-[59999]Expression Acc@1: 92.69883
Training: 2023-08-18 00:57:01,479-[59999]Expression Acc@1-Highest: 92.86180
Training: 2023-08-18 00:57:01,479-[59999]Expression Acc@5: 98.43546
Training: 2023-08-18 00:57:01,479-[59999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-18 00:57:01,479-[59999]10 Times Expression Acc@1: 92.61734
Training: 2023-08-18 00:57:01,479-[59999]10 Times Expression Acc@1-Highest: 92.63364
Training: 2023-08-18 00:57:01,910-Val on RAF/AffectNet:
Training: 2023-08-18 00:57:02,022-Test: [0/48]	Time 0.112 (0.112)	Loss 0.5431 (0.5431)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)	Mem 5268MB
Training: 2023-08-18 00:57:03,083-Test: [10/48]	Time 0.104 (0.107)	Loss 0.5922 (0.5324)	Acc@1 92.188 (93.466)	Acc@5 100.000 (99.006)	Mem 5268MB
Training: 2023-08-18 00:57:04,138-Test: [20/48]	Time 0.106 (0.106)	Loss 0.6725 (0.5410)	Acc@1 89.062 (93.229)	Acc@5 95.312 (98.512)	Mem 5268MB
Training: 2023-08-18 00:57:05,210-Test: [30/48]	Time 0.105 (0.106)	Loss 0.4596 (0.5452)	Acc@1 96.875 (92.792)	Acc@5 98.438 (98.538)	Mem 5268MB
Training: 2023-08-18 00:57:06,267-Test: [40/48]	Time 0.105 (0.106)	Loss 0.4786 (0.5483)	Acc@1 95.312 (92.759)	Acc@5 100.000 (98.476)	Mem 5268MB
Training: 2023-08-18 00:57:07,034-[59999]Expression Loss: 0.55021
Training: 2023-08-18 00:57:07,034-[59999]Expression Acc@1: 92.69883
Training: 2023-08-18 00:57:07,034-[59999]Expression Acc@1-Highest: 92.86180
Training: 2023-08-18 00:57:07,034-[59999]Expression Acc@5: 98.43546
Training: 2023-08-18 00:57:07,034-[59999]Expression Acc@5-Highest: 99.44589
Training: 2023-08-18 00:57:07,034-[59999]10 Times Expression Acc@1: 92.64668
Training: 2023-08-18 00:57:07,034-[59999]10 Times Expression Acc@1-Highest: 92.64668
